{
  "experiment_info": {
    "experiment_name": "Nguyen-8",
    "dataset_name": "Nguyen-8",
    "timestamp": "2025-08-30T21:19:38.502500",
    "random_seed": 42
  },
  "model_config": {
    "input_size": 1,
    "output_size": 1,
    "num_layers": 2,
    "nonlinear_info": [
      [
        1,
        0
      ],
      [
        0,
        0
      ],
      [
        0,
        0
      ]
    ],
    "function_set": [
      "SafeIdentityFunction",
      "SafeExp",
      "SafeLog",
      "SafeSin",
      "SafePower",
      "SafeCos",
      "ExpSwitchActivation"
    ]
  },
  "training_config": {
    "num_epochs": 200,
    "batch_size": 32,
    "learning_rate": 0.01,
    "reg_strength": 0.0,
    "scheduler": "none"
  },
  "final_equation": {
    "equation_string": "Matrix([[1.0*x1**0.5]])",
    "equation_latex": "Matrix([[1.0*x1**0.5]])"
  },
  "evaluation_metrics": {
    "mse": "8.714414e-15",
    "rmse": "9.335103e-08",
    "mae": "6.529554e-08"
  },
  "data_info": {
    "train_ratio": 0.8,
    "uncertainty_value": 0.0,
    "path_to_data": "/Users/pablocornejo/Documents/Tesis/SRNetwork/data/raw/nguyen.txt"
  },
  "lbfgs_optimization": {
    "enabled": true,
    "success": true,
    "message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
    "function_evaluations": 31,
    "gradient_evaluations": 31,
    "final_loss": 1.9409187896397069e-07,
    "max_iterations": 1000,
    "tolerance": "1e-8",
    "criterion": "nrmse"
  },
  "lbfgs_topk_optimization": {
    "enabled": true,
    "num_models_optimized": 1,
    "optimization_summary": [
      {
        "rank": 1,
        "original_epoch": 196,
        "original_val_loss": 1.2183084005920212e-10,
        "optimized_val_loss": "8.714414e-15",
        "improvement_percent": "99.99284",
        "original_equation": "Matrix([[0.999985*x1**0.500013]])",
        "optimized_equation": "Matrix([[1.0*x1**0.5]])",
        "optimization_success": true,
        "function_evaluations": 31,
        "final_loss": 1.9409187896397069e-07
      }
    ],
    "best_model": {
      "original_val_loss": 1.2183084005920212e-10,
      "optimized_val_loss": "8.714414e-15",
      "improvement_percent": "99.99284",
      "equation": "Matrix([[1.0*x1**0.5]])",
      "optimization_iterations": 11
    }
  },
  "reward_tracking": {
    "reward_type": "nrmse",
    "reward_interval": 1,
    "num_measurements": 200,
    "initial_reward": 0.009999999776482582,
    "final_reward": 0.9997619986534119,
    "best_reward": 0.999774158000946,
    "worst_reward": 0.009999999776482582,
    "average_reward": 0.6268696898035705,
    "reward_history": [
      {
        "epoch": 0,
        "reward": 0.009999999776482582,
        "val_loss": 115724.91741071429,
        "train_loss": 190094.87980675974
      },
      {
        "epoch": 1,
        "reward": 0.009999999776482582,
        "val_loss": 28885.806222098214,
        "train_loss": 55882.72100477952
      },
      {
        "epoch": 2,
        "reward": 0.009999999776482582,
        "val_loss": 3921.2785121372767,
        "train_loss": 11958.02555495042
      },
      {
        "epoch": 3,
        "reward": 0.009999999776482582,
        "val_loss": 26.034452438354492,
        "train_loss": 970.9758286384435
      },
      {
        "epoch": 4,
        "reward": 0.03307662531733513,
        "val_loss": 2.0415159293583462,
        "train_loss": 16.29883383329098
      },
      {
        "epoch": 5,
        "reward": 0.04079276695847511,
        "val_loss": 1.3208990437643868,
        "train_loss": 1.3107809241001422
      },
      {
        "epoch": 6,
        "reward": 0.045122817158699036,
        "val_loss": 1.0698271649224418,
        "train_loss": 0.933213337109639
      },
      {
        "epoch": 7,
        "reward": 0.042171116918325424,
        "val_loss": 1.2324145351137434,
        "train_loss": 0.9693772976215069
      },
      {
        "epoch": 8,
        "reward": 0.04097313806414604,
        "val_loss": 1.3088025621005468,
        "train_loss": 1.0893218701418776
      },
      {
        "epoch": 9,
        "reward": 0.032624099403619766,
        "val_loss": 2.1005086728504727,
        "train_loss": 1.0028063219327192
      },
      {
        "epoch": 10,
        "reward": 0.03912126645445824,
        "val_loss": 1.4411938871656145,
        "train_loss": 1.6206240539367383
      },
      {
        "epoch": 11,
        "reward": 0.049689408391714096,
        "val_loss": 0.8738049609320504,
        "train_loss": 1.1204664500860066
      },
      {
        "epoch": 12,
        "reward": 0.03161055967211723,
        "val_loss": 2.2420575278145924,
        "train_loss": 0.973960103896948
      },
      {
        "epoch": 13,
        "reward": 0.04154713824391365,
        "val_loss": 1.2713652508599418,
        "train_loss": 1.308442546771123
      },
      {
        "epoch": 14,
        "reward": 0.04886128753423691,
        "val_loss": 0.9052508728844779,
        "train_loss": 1.1066462053702428
      },
      {
        "epoch": 15,
        "reward": 0.04787467420101166,
        "val_loss": 0.9449038505554199,
        "train_loss": 1.0566283028859358
      },
      {
        "epoch": 16,
        "reward": 0.04262436181306839,
        "val_loss": 1.2052024091993059,
        "train_loss": 0.9615791531709524
      },
      {
        "epoch": 17,
        "reward": 0.04495612904429436,
        "val_loss": 1.078151864664895,
        "train_loss": 0.9649890844638531
      },
      {
        "epoch": 18,
        "reward": 0.03911223262548447,
        "val_loss": 1.4418869274003165,
        "train_loss": 0.9317853932197278
      },
      {
        "epoch": 19,
        "reward": 0.049796778708696365,
        "val_loss": 0.8698442237717765,
        "train_loss": 1.0810981117762053
      },
      {
        "epoch": 20,
        "reward": 0.04997685179114342,
        "val_loss": 0.8632600222315107,
        "train_loss": 1.0032068124184241
      },
      {
        "epoch": 21,
        "reward": 0.0499037466943264,
        "val_loss": 0.8659242647034782,
        "train_loss": 0.970325224674665
      },
      {
        "epoch": 22,
        "reward": 0.04737178236246109,
        "val_loss": 0.9660919053213937,
        "train_loss": 1.1889586809736032
      },
      {
        "epoch": 23,
        "reward": 0.049658264964818954,
        "val_loss": 0.8749586003167289,
        "train_loss": 0.8704125107480929
      },
      {
        "epoch": 24,
        "reward": 0.03924160823225975,
        "val_loss": 1.4320091349737984,
        "train_loss": 0.9201453992953668
      },
      {
        "epoch": 25,
        "reward": 0.050104159861803055,
        "val_loss": 0.8586484278951373,
        "train_loss": 1.0399577780984914
      },
      {
        "epoch": 26,
        "reward": 0.043583944439888,
        "val_loss": 1.150407305785588,
        "train_loss": 0.9222658024384425
      },
      {
        "epoch": 27,
        "reward": 0.04779990762472153,
        "val_loss": 0.9480111173221043,
        "train_loss": 0.9889506881053631
      },
      {
        "epoch": 28,
        "reward": 0.04965924844145775,
        "val_loss": 0.8749221989086696,
        "train_loss": 0.9904954341741709
      },
      {
        "epoch": 29,
        "reward": 0.04822767898440361,
        "val_loss": 0.9304316299302238,
        "train_loss": 0.9800281662207383
      },
      {
        "epoch": 30,
        "reward": 0.047173064202070236,
        "val_loss": 0.9746552194867816,
        "train_loss": 1.0517793549941137
      },
      {
        "epoch": 31,
        "reward": 0.04124384745955467,
        "val_loss": 1.2909486378942217,
        "train_loss": 0.9753122647794393
      },
      {
        "epoch": 32,
        "reward": 0.03869336470961571,
        "val_loss": 1.4745583023343767,
        "train_loss": 1.0453065312825716
      },
      {
        "epoch": 33,
        "reward": 0.036040764302015305,
        "val_loss": 1.7089931453977312,
        "train_loss": 1.0746785608621745
      },
      {
        "epoch": 34,
        "reward": 0.04649318754673004,
        "val_loss": 1.004800762448992,
        "train_loss": 1.0233032428301299
      },
      {
        "epoch": 35,
        "reward": 0.047349389642477036,
        "val_loss": 0.9670515315873283,
        "train_loss": 0.9477664025930258
      },
      {
        "epoch": 36,
        "reward": 0.047881342470645905,
        "val_loss": 0.944627548967089,
        "train_loss": 1.0355870723724365
      },
      {
        "epoch": 37,
        "reward": 0.04406815767288208,
        "val_loss": 1.124126366206578,
        "train_loss": 0.979077833203169
      },
      {
        "epoch": 38,
        "reward": 0.04553299397230148,
        "val_loss": 1.0497369936534338,
        "train_loss": 0.9640783782188709
      },
      {
        "epoch": 39,
        "reward": 0.04069328308105469,
        "val_loss": 1.3276405760220118,
        "train_loss": 0.8961393821697968
      },
      {
        "epoch": 40,
        "reward": 0.04946969449520111,
        "val_loss": 0.8819916844367981,
        "train_loss": 1.0712352693080902
      },
      {
        "epoch": 41,
        "reward": 0.038416486233472824,
        "val_loss": 1.4967518874577113,
        "train_loss": 0.8629376223454108
      },
      {
        "epoch": 42,
        "reward": 0.037498828023672104,
        "val_loss": 1.5739038586616516,
        "train_loss": 1.0312774869111867
      },
      {
        "epoch": 43,
        "reward": 0.04455596208572388,
        "val_loss": 1.09852477482387,
        "train_loss": 1.170442236157564
      },
      {
        "epoch": 44,
        "reward": 0.05152270197868347,
        "val_loss": 0.8095945886203221,
        "train_loss": 0.9747095474830041
      },
      {
        "epoch": 45,
        "reward": 0.048224058002233505,
        "val_loss": 0.930578316961016,
        "train_loss": 0.8360434495485746
      },
      {
        "epoch": 46,
        "reward": 0.044061481952667236,
        "val_loss": 1.1244829041617257,
        "train_loss": 0.8610904056292313
      },
      {
        "epoch": 47,
        "reward": 0.05203085020184517,
        "val_loss": 0.7930078251021249,
        "train_loss": 1.0124211999086232
      },
      {
        "epoch": 48,
        "reward": 0.05062365531921387,
        "val_loss": 0.8401963540485927,
        "train_loss": 0.9153990287047166
      },
      {
        "epoch": 49,
        "reward": 0.04635298624634743,
        "val_loss": 1.0111855864524841,
        "train_loss": 0.865802180308562
      },
      {
        "epoch": 50,
        "reward": 0.03767480328679085,
        "val_loss": 1.5586649009159632,
        "train_loss": 0.850862363496652
      },
      {
        "epoch": 51,
        "reward": 0.04955627769231796,
        "val_loss": 0.8787524274417332,
        "train_loss": 1.0857553390356212
      },
      {
        "epoch": 52,
        "reward": 0.05172180011868477,
        "val_loss": 0.8030364257948739,
        "train_loss": 0.8193937792227819
      },
      {
        "epoch": 53,
        "reward": 0.0525461845099926,
        "val_loss": 0.7766845566885812,
        "train_loss": 0.8325744259815949
      },
      {
        "epoch": 54,
        "reward": 0.0521671362221241,
        "val_loss": 0.7886431557791573,
        "train_loss": 0.7848373468105609
      },
      {
        "epoch": 55,
        "reward": 0.04703960195183754,
        "val_loss": 0.9804680943489075,
        "train_loss": 0.7741623795949496
      },
      {
        "epoch": 56,
        "reward": 0.05324560031294823,
        "val_loss": 0.7552979247910636,
        "train_loss": 0.7930187972692343
      },
      {
        "epoch": 57,
        "reward": 0.0524478442966938,
        "val_loss": 0.7797618593488421,
        "train_loss": 0.7078080400824547
      },
      {
        "epoch": 58,
        "reward": 0.05537830665707588,
        "val_loss": 0.6951003585542951,
        "train_loss": 0.7317231893539429
      },
      {
        "epoch": 59,
        "reward": 0.055099017918109894,
        "val_loss": 0.7025800943374634,
        "train_loss": 0.7692262667876023
      },
      {
        "epoch": 60,
        "reward": 0.05372399091720581,
        "val_loss": 0.7411569442067828,
        "train_loss": 0.6981529129239229
      },
      {
        "epoch": 61,
        "reward": 0.056651052087545395,
        "val_loss": 0.6624297669955662,
        "train_loss": 0.6594802863322772
      },
      {
        "epoch": 62,
        "reward": 0.058164577931165695,
        "val_loss": 0.626388600894383,
        "train_loss": 0.6254684019547242
      },
      {
        "epoch": 63,
        "reward": 0.05851893499493599,
        "val_loss": 0.6183599233627319,
        "train_loss": 0.6149683101819112
      },
      {
        "epoch": 64,
        "reward": 0.06314188987016678,
        "val_loss": 0.5259245123182025,
        "train_loss": 0.5773914926327192
      },
      {
        "epoch": 65,
        "reward": 0.06652933359146118,
        "val_loss": 0.47031193120138987,
        "train_loss": 0.4754723929222411
      },
      {
        "epoch": 66,
        "reward": 0.07142927497625351,
        "val_loss": 0.4037277400493622,
        "train_loss": 0.41967156758675206
      },
      {
        "epoch": 67,
        "reward": 0.07942458242177963,
        "val_loss": 0.32093705449785503,
        "train_loss": 0.3420383930206299
      },
      {
        "epoch": 68,
        "reward": 0.09408342093229294,
        "val_loss": 0.22149365927491868,
        "train_loss": 0.2589553359609384
      },
      {
        "epoch": 69,
        "reward": 0.11213352531194687,
        "val_loss": 0.14977364242076874,
        "train_loss": 0.1829543520624821
      },
      {
        "epoch": 70,
        "reward": 0.13445766270160675,
        "val_loss": 0.09899576114756721,
        "train_loss": 0.12345057496657738
      },
      {
        "epoch": 71,
        "reward": 0.1621103286743164,
        "val_loss": 0.06382094962256295,
        "train_loss": 0.07872848298687202
      },
      {
        "epoch": 72,
        "reward": 0.19480738043785095,
        "val_loss": 0.040813127266509194,
        "train_loss": 0.04872989296340025
      },
      {
        "epoch": 73,
        "reward": 0.2321794331073761,
        "val_loss": 0.02612660958298615,
        "train_loss": 0.03128864674363285
      },
      {
        "epoch": 74,
        "reward": 0.27764853835105896,
        "val_loss": 0.01617027260363102,
        "train_loss": 0.02112643406368219
      },
      {
        "epoch": 75,
        "reward": 0.3344048261642456,
        "val_loss": 0.00946425027879221,
        "train_loss": 0.012731980711508255
      },
      {
        "epoch": 76,
        "reward": 0.40160781145095825,
        "val_loss": 0.005303695398781981,
        "train_loss": 0.0073310939702563565
      },
      {
        "epoch": 77,
        "reward": 0.47390323877334595,
        "val_loss": 0.00294417016474264,
        "train_loss": 0.0040594233970086165
      },
      {
        "epoch": 78,
        "reward": 0.5463148951530457,
        "val_loss": 0.0016475325184209006,
        "train_loss": 0.002135330520104617
      },
      {
        "epoch": 79,
        "reward": 0.6210598349571228,
        "val_loss": 0.0008893760220546808,
        "train_loss": 0.0012101536916676336
      },
      {
        "epoch": 80,
        "reward": 0.6891661882400513,
        "val_loss": 0.00048598135305967716,
        "train_loss": 0.0006866941100899846
      },
      {
        "epoch": 81,
        "reward": 0.7564379572868347,
        "val_loss": 0.0002476758568913543,
        "train_loss": 0.00035454596386094077
      },
      {
        "epoch": 82,
        "reward": 0.8115047812461853,
        "val_loss": 0.00012889312867108465,
        "train_loss": 0.0001777947011130611
      },
      {
        "epoch": 83,
        "reward": 0.8579531908035278,
        "val_loss": 6.548574050871789e-05,
        "train_loss": 9.434666417991348e-05
      },
      {
        "epoch": 84,
        "reward": 0.8945904970169067,
        "val_loss": 3.316819389250928e-05,
        "train_loss": 4.656855120489266e-05
      },
      {
        "epoch": 85,
        "reward": 0.9227213859558105,
        "val_loss": 1.675668980689287e-05,
        "train_loss": 2.490694952519754e-05
      },
      {
        "epoch": 86,
        "reward": 0.9451776742935181,
        "val_loss": 8.037098463578981e-06,
        "train_loss": 1.1428814369415144e-05
      },
      {
        "epoch": 87,
        "reward": 0.9606332778930664,
        "val_loss": 4.011928500144027e-06,
        "train_loss": 5.723031860655353e-06
      },
      {
        "epoch": 88,
        "reward": 0.9718706011772156,
        "val_loss": 2.0012981037455446e-06,
        "train_loss": 2.811449371292313e-06
      },
      {
        "epoch": 89,
        "reward": 0.979710578918457,
        "val_loss": 1.0246065634029428e-06,
        "train_loss": 1.4060872611200746e-06
      },
      {
        "epoch": 90,
        "reward": 0.9856024980545044,
        "val_loss": 5.097815046285956e-07,
        "train_loss": 7.223046366150882e-07
      },
      {
        "epoch": 91,
        "reward": 0.9898523688316345,
        "val_loss": 2.5107343252070026e-07,
        "train_loss": 3.5482785912895804e-07
      },
      {
        "epoch": 92,
        "reward": 0.9927337765693665,
        "val_loss": 1.2798884897944974e-07,
        "train_loss": 1.8765924663783224e-07
      },
      {
        "epoch": 93,
        "reward": 0.9948906898498535,
        "val_loss": 6.300653662297659e-08,
        "train_loss": 9.208013278356913e-08
      },
      {
        "epoch": 94,
        "reward": 0.9963399171829224,
        "val_loss": 3.223852169347603e-08,
        "train_loss": 4.394494532369628e-08
      },
      {
        "epoch": 95,
        "reward": 0.997248649597168,
        "val_loss": 1.8184377178645913e-08,
        "train_loss": 2.3789525255707005e-08
      },
      {
        "epoch": 96,
        "reward": 0.9978461265563965,
        "val_loss": 1.1130333480277192e-08,
        "train_loss": 1.3820193194974832e-08
      },
      {
        "epoch": 97,
        "reward": 0.9982593655586243,
        "val_loss": 7.263394457319399e-09,
        "train_loss": 8.866944119116756e-09
      },
      {
        "epoch": 98,
        "reward": 0.9985536932945251,
        "val_loss": 5.011668857690665e-09,
        "train_loss": 6.282266296918893e-09
      },
      {
        "epoch": 99,
        "reward": 0.9987844824790955,
        "val_loss": 3.5379483152654855e-09,
        "train_loss": 4.1791498893973564e-09
      },
      {
        "epoch": 100,
        "reward": 0.9989193081855774,
        "val_loss": 2.795853072866196e-09,
        "train_loss": 3.0826251038964014e-09
      },
      {
        "epoch": 101,
        "reward": 0.9990040063858032,
        "val_loss": 2.374756074325595e-09,
        "train_loss": 2.499250656856206e-09
      },
      {
        "epoch": 102,
        "reward": 0.999062180519104,
        "val_loss": 2.1050874694188745e-09,
        "train_loss": 2.1449411990149567e-09
      },
      {
        "epoch": 103,
        "reward": 0.9990983009338379,
        "val_loss": 1.9458588074172667e-09,
        "train_loss": 1.943032640766135e-09
      },
      {
        "epoch": 104,
        "reward": 0.9991273283958435,
        "val_loss": 1.8226431633802269e-09,
        "train_loss": 1.957593916028617e-09
      },
      {
        "epoch": 105,
        "reward": 0.9991676211357117,
        "val_loss": 1.65794857208214e-09,
        "train_loss": 1.6784002179534787e-09
      },
      {
        "epoch": 106,
        "reward": 0.9991772770881653,
        "val_loss": 1.6198525378184415e-09,
        "train_loss": 1.5735408745229598e-09
      },
      {
        "epoch": 107,
        "reward": 0.9991850852966309,
        "val_loss": 1.5888519389051226e-09,
        "train_loss": 1.5641388483567964e-09
      },
      {
        "epoch": 108,
        "reward": 0.9991926550865173,
        "val_loss": 1.559696847865309e-09,
        "train_loss": 1.6127815365247937e-09
      },
      {
        "epoch": 109,
        "reward": 0.9992347955703735,
        "val_loss": 1.401304405845849e-09,
        "train_loss": 1.4150749076786877e-09
      },
      {
        "epoch": 110,
        "reward": 0.9992327094078064,
        "val_loss": 1.408617619372673e-09,
        "train_loss": 1.3962618796202155e-09
      },
      {
        "epoch": 111,
        "reward": 0.9992504119873047,
        "val_loss": 1.3442403063684034e-09,
        "train_loss": 1.3335043283277606e-09
      },
      {
        "epoch": 112,
        "reward": 0.9992455840110779,
        "val_loss": 1.3618015286860035e-09,
        "train_loss": 1.2851440531416523e-09
      },
      {
        "epoch": 113,
        "reward": 0.9992551803588867,
        "val_loss": 1.3272241559749075e-09,
        "train_loss": 1.3140233260463456e-09
      },
      {
        "epoch": 114,
        "reward": 0.9992715120315552,
        "val_loss": 1.2698066883690525e-09,
        "train_loss": 1.2579808861268305e-09
      },
      {
        "epoch": 115,
        "reward": 0.9992737770080566,
        "val_loss": 1.261647516618122e-09,
        "train_loss": 1.2880099486967111e-09
      },
      {
        "epoch": 116,
        "reward": 0.9993014335632324,
        "val_loss": 1.1672060064503243e-09,
        "train_loss": 1.2041893465281488e-09
      },
      {
        "epoch": 117,
        "reward": 0.9993171691894531,
        "val_loss": 1.11535158886511e-09,
        "train_loss": 1.0790222582956177e-09
      },
      {
        "epoch": 118,
        "reward": 0.9993131756782532,
        "val_loss": 1.1286542097746884e-09,
        "train_loss": 1.0836127892424394e-09
      },
      {
        "epoch": 119,
        "reward": 0.9993193745613098,
        "val_loss": 1.108441354575567e-09,
        "train_loss": 1.0832224625825568e-09
      },
      {
        "epoch": 120,
        "reward": 0.9993224143981934,
        "val_loss": 1.0985131296667054e-09,
        "train_loss": 1.1222663909293829e-09
      },
      {
        "epoch": 121,
        "reward": 0.9993482828140259,
        "val_loss": 1.015949649804274e-09,
        "train_loss": 1.0955529816669696e-09
      },
      {
        "epoch": 122,
        "reward": 0.9993724822998047,
        "val_loss": 9.417974733416656e-10,
        "train_loss": 9.1346143683301e-10
      },
      {
        "epoch": 123,
        "reward": 0.9993586540222168,
        "val_loss": 9.836969572241117e-10,
        "train_loss": 9.225117550201936e-10
      },
      {
        "epoch": 124,
        "reward": 0.9993640184402466,
        "val_loss": 9.67597541772542e-10,
        "train_loss": 9.79217982340822e-10
      },
      {
        "epoch": 125,
        "reward": 0.9993768930435181,
        "val_loss": 9.286284281222785e-10,
        "train_loss": 9.161193321044053e-10
      },
      {
        "epoch": 126,
        "reward": 0.9993867874145508,
        "val_loss": 8.99307057394034e-10,
        "train_loss": 9.185830237482625e-10
      },
      {
        "epoch": 127,
        "reward": 0.9993979334831238,
        "val_loss": 8.66825833334417e-10,
        "train_loss": 9.106521348966313e-10
      },
      {
        "epoch": 128,
        "reward": 0.9994229674339294,
        "val_loss": 7.963690817902602e-10,
        "train_loss": 8.485610270003718e-10
      },
      {
        "epoch": 129,
        "reward": 0.9994311332702637,
        "val_loss": 7.737632994648485e-10,
        "train_loss": 7.904305671529571e-10
      },
      {
        "epoch": 130,
        "reward": 0.9994433522224426,
        "val_loss": 7.409836157355545e-10,
        "train_loss": 7.287311822355382e-10
      },
      {
        "epoch": 131,
        "reward": 0.999441921710968,
        "val_loss": 7.45022662610292e-10,
        "train_loss": 7.21761574652168e-10
      },
      {
        "epoch": 132,
        "reward": 0.9994374513626099,
        "val_loss": 7.569045786962444e-10,
        "train_loss": 7.83029207713098e-10
      },
      {
        "epoch": 133,
        "reward": 0.9994544386863708,
        "val_loss": 7.119889439926347e-10,
        "train_loss": 7.269178720497721e-10
      },
      {
        "epoch": 134,
        "reward": 0.9994611740112305,
        "val_loss": 6.944113458854214e-10,
        "train_loss": 7.316180930314267e-10
      },
      {
        "epoch": 135,
        "reward": 0.9994775056838989,
        "val_loss": 6.528321930662376e-10,
        "train_loss": 6.561821983211211e-10
      },
      {
        "epoch": 136,
        "reward": 0.9994762539863586,
        "val_loss": 6.559987156659222e-10,
        "train_loss": 6.252381070146986e-10
      },
      {
        "epoch": 137,
        "reward": 0.9994732737541199,
        "val_loss": 6.634059254321098e-10,
        "train_loss": 6.888767120840975e-10
      },
      {
        "epoch": 138,
        "reward": 0.9994814991950989,
        "val_loss": 6.429719296668119e-10,
        "train_loss": 6.276814666318951e-10
      },
      {
        "epoch": 139,
        "reward": 0.9994903802871704,
        "val_loss": 6.209224563085464e-10,
        "train_loss": 6.118394017924527e-10
      },
      {
        "epoch": 140,
        "reward": 0.999495804309845,
        "val_loss": 6.07984194735321e-10,
        "train_loss": 6.080133832306536e-10
      },
      {
        "epoch": 141,
        "reward": 0.9995036125183105,
        "val_loss": 5.891420526030597e-10,
        "train_loss": 5.771573197998182e-10
      },
      {
        "epoch": 142,
        "reward": 0.9995049834251404,
        "val_loss": 5.861461950727533e-10,
        "train_loss": 6.080724599058294e-10
      },
      {
        "epoch": 143,
        "reward": 0.9995226263999939,
        "val_loss": 5.450745291632078e-10,
        "train_loss": 5.773087147220579e-10
      },
      {
        "epoch": 144,
        "reward": 0.9995397925376892,
        "val_loss": 5.064417258575966e-10,
        "train_loss": 5.318076043639217e-10
      },
      {
        "epoch": 145,
        "reward": 0.9995419383049011,
        "val_loss": 5.016135562474489e-10,
        "train_loss": 4.774033582984808e-10
      },
      {
        "epoch": 146,
        "reward": 0.9995359778404236,
        "val_loss": 5.149627430827459e-10,
        "train_loss": 4.875629451454973e-10
      },
      {
        "epoch": 147,
        "reward": 0.9995375871658325,
        "val_loss": 5.114343670786781e-10,
        "train_loss": 4.976567704937032e-10
      },
      {
        "epoch": 148,
        "reward": 0.9995361566543579,
        "val_loss": 5.14339321133761e-10,
        "train_loss": 5.20109434153627e-10
      },
      {
        "epoch": 149,
        "reward": 0.9995537996292114,
        "val_loss": 4.76130527861583e-10,
        "train_loss": 4.709279718321332e-10
      },
      {
        "epoch": 150,
        "reward": 0.9995535016059875,
        "val_loss": 4.766294501936028e-10,
        "train_loss": 4.604750651295329e-10
      },
      {
        "epoch": 151,
        "reward": 0.9995582699775696,
        "val_loss": 4.667306660203049e-10,
        "train_loss": 4.4906238449993197e-10
      },
      {
        "epoch": 152,
        "reward": 0.9995617270469666,
        "val_loss": 4.5924855981585976e-10,
        "train_loss": 4.4915742919853913e-10
      },
      {
        "epoch": 153,
        "reward": 0.9995665550231934,
        "val_loss": 4.4916516934406e-10,
        "train_loss": 4.4327125623923647e-10
      },
      {
        "epoch": 154,
        "reward": 0.999576210975647,
        "val_loss": 4.2930578933056806e-10,
        "train_loss": 4.527777170287423e-10
      },
      {
        "epoch": 155,
        "reward": 0.9995877146720886,
        "val_loss": 4.063421067877572e-10,
        "train_loss": 4.1813309652301184e-10
      },
      {
        "epoch": 156,
        "reward": 0.9996102452278137,
        "val_loss": 3.6312110857877096e-10,
        "train_loss": 3.605970436778486e-10
      },
      {
        "epoch": 157,
        "reward": 0.9996015429496765,
        "val_loss": 3.7959697290241527e-10,
        "train_loss": 3.857197211204904e-10
      },
      {
        "epoch": 158,
        "reward": 0.9996131062507629,
        "val_loss": 3.579521916969546e-10,
        "train_loss": 3.581508828825592e-10
      },
      {
        "epoch": 159,
        "reward": 0.9996156096458435,
        "val_loss": 3.533328074567521e-10,
        "train_loss": 3.6275153927686976e-10
      },
      {
        "epoch": 160,
        "reward": 0.9996223449707031,
        "val_loss": 3.409559935972441e-10,
        "train_loss": 3.3912472829911167e-10
      },
      {
        "epoch": 161,
        "reward": 0.9996223449707031,
        "val_loss": 3.410545774367486e-10,
        "train_loss": 3.288168092508724e-10
      },
      {
        "epoch": 162,
        "reward": 0.9996232390403748,
        "val_loss": 3.3935207818406154e-10,
        "train_loss": 3.360409247874166e-10
      },
      {
        "epoch": 163,
        "reward": 0.9996253848075867,
        "val_loss": 3.355294811832213e-10,
        "train_loss": 3.269811632993908e-10
      },
      {
        "epoch": 164,
        "reward": 0.9996234774589539,
        "val_loss": 3.389352171938904e-10,
        "train_loss": 3.175333895394799e-10
      },
      {
        "epoch": 165,
        "reward": 0.9996318817138672,
        "val_loss": 3.23943173872822e-10,
        "train_loss": 3.2471997847026957e-10
      },
      {
        "epoch": 166,
        "reward": 0.9996333122253418,
        "val_loss": 3.2137024390849993e-10,
        "train_loss": 3.0651500034698603e-10
      },
      {
        "epoch": 167,
        "reward": 0.9996436238288879,
        "val_loss": 3.0369443467951184e-10,
        "train_loss": 3.0224275219344815e-10
      },
      {
        "epoch": 168,
        "reward": 0.9996436238288879,
        "val_loss": 3.035911997985506e-10,
        "train_loss": 3.0373606514537516e-10
      },
      {
        "epoch": 169,
        "reward": 0.9996504783630371,
        "val_loss": 2.9210746123529777e-10,
        "train_loss": 2.9989277941297676e-10
      },
      {
        "epoch": 170,
        "reward": 0.9996759295463562,
        "val_loss": 2.5109044010651616e-10,
        "train_loss": 2.7853188772502663e-10
      },
      {
        "epoch": 171,
        "reward": 0.9996849298477173,
        "val_loss": 2.3732943388310446e-10,
        "train_loss": 2.376446849135132e-10
      },
      {
        "epoch": 172,
        "reward": 0.9996761679649353,
        "val_loss": 2.5066676115744913e-10,
        "train_loss": 2.519457847477851e-10
      },
      {
        "epoch": 173,
        "reward": 0.9996849298477173,
        "val_loss": 2.373198681222226e-10,
        "train_loss": 2.431621784268692e-10
      },
      {
        "epoch": 174,
        "reward": 0.9996889233589172,
        "val_loss": 2.3124989819870275e-10,
        "train_loss": 2.424393848070412e-10
      },
      {
        "epoch": 175,
        "reward": 0.9996978640556335,
        "val_loss": 2.181457276722349e-10,
        "train_loss": 2.085151389159716e-10
      },
      {
        "epoch": 176,
        "reward": 0.9996834993362427,
        "val_loss": 2.3957675129463295e-10,
        "train_loss": 2.3019517542133272e-10
      },
      {
        "epoch": 177,
        "reward": 0.9996978640556335,
        "val_loss": 2.1818455772252118e-10,
        "train_loss": 2.3543851056774e-10
      },
      {
        "epoch": 178,
        "reward": 0.9997059106826782,
        "val_loss": 2.0684026317116126e-10,
        "train_loss": 1.969900791632694e-10
      },
      {
        "epoch": 179,
        "reward": 0.9996965527534485,
        "val_loss": 2.201148707747791e-10,
        "train_loss": 2.2051828792489195e-10
      },
      {
        "epoch": 180,
        "reward": 0.9997043013572693,
        "val_loss": 2.090540716727572e-10,
        "train_loss": 1.9907403610190772e-10
      },
      {
        "epoch": 181,
        "reward": 0.9997054934501648,
        "val_loss": 2.0724267341914222e-10,
        "train_loss": 2.1114871229671167e-10
      },
      {
        "epoch": 182,
        "reward": 0.9997143745422363,
        "val_loss": 1.9488781025486394e-10,
        "train_loss": 1.970089841797106e-10
      },
      {
        "epoch": 183,
        "reward": 0.9997186064720154,
        "val_loss": 1.8933443305232548e-10,
        "train_loss": 1.8278120630291858e-10
      },
      {
        "epoch": 184,
        "reward": 0.999715268611908,
        "val_loss": 1.9377616773080016e-10,
        "train_loss": 1.967451447486386e-10
      },
      {
        "epoch": 185,
        "reward": 0.9997272491455078,
        "val_loss": 1.7770626438627446e-10,
        "train_loss": 1.7451177575660964e-10
      },
      {
        "epoch": 186,
        "reward": 0.9997205138206482,
        "val_loss": 1.867532319264699e-10,
        "train_loss": 1.7421196696770352e-10
      },
      {
        "epoch": 187,
        "reward": 0.9997267127037048,
        "val_loss": 1.7847228457006688e-10,
        "train_loss": 1.862411966100033e-10
      },
      {
        "epoch": 188,
        "reward": 0.9997388124465942,
        "val_loss": 1.631257708277291e-10,
        "train_loss": 1.7523157230803221e-10
      },
      {
        "epoch": 189,
        "reward": 0.9997480511665344,
        "val_loss": 1.517379852719206e-10,
        "train_loss": 1.4696579396831735e-10
      },
      {
        "epoch": 190,
        "reward": 0.9997310638427734,
        "val_loss": 1.7293073322528178e-10,
        "train_loss": 1.6138890544483184e-10
      },
      {
        "epoch": 191,
        "reward": 0.9997450113296509,
        "val_loss": 1.5551933946993708e-10,
        "train_loss": 1.625611280202495e-10
      },
      {
        "epoch": 192,
        "reward": 0.9997562766075134,
        "val_loss": 1.4201830386298805e-10,
        "train_loss": 1.391313154429897e-10
      },
      {
        "epoch": 193,
        "reward": 0.999749481678009,
        "val_loss": 1.4995046474349953e-10,
        "train_loss": 1.4452945811303477e-10
      },
      {
        "epoch": 194,
        "reward": 0.9997459650039673,
        "val_loss": 1.5421805301039726e-10,
        "train_loss": 1.6497468989197836e-10
      },
      {
        "epoch": 195,
        "reward": 0.9997712969779968,
        "val_loss": 1.2502013610867938e-10,
        "train_loss": 1.3870735436307166e-10
      },
      {
        "epoch": 196,
        "reward": 0.999774158000946,
        "val_loss": 1.2183084005920212e-10,
        "train_loss": 1.1462786676049633e-10
      },
      {
        "epoch": 197,
        "reward": 0.9997626543045044,
        "val_loss": 1.3468878195294868e-10,
        "train_loss": 1.330881860379833e-10
      },
      {
        "epoch": 198,
        "reward": 0.9997674226760864,
        "val_loss": 1.2923097810123097e-10,
        "train_loss": 1.226682521585728e-10
      },
      {
        "epoch": 199,
        "reward": 0.9997619986534119,
        "val_loss": 1.3537390752033877e-10,
        "train_loss": 1.2860778094190797e-10
      }
    ]
  }
}