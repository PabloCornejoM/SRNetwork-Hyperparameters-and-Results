{
  "experiment_info": {
    "experiment_name": "Nguyen-9",
    "dataset_name": "Nguyen-9",
    "timestamp": "2025-08-30T22:48:02.393590",
    "random_seed": null
  },
  "model_config": {
    "input_size": 2,
    "output_size": 1,
    "num_layers": 3,
    "nonlinear_info": [
      [
        2,
        0
      ],
      [
        2,
        0
      ],
      [
        0,
        0
      ]
    ],
    "function_set": [
      "SafeIdentityFunction",
      "SafeExp",
      "SafeLog",
      "SafeSin",
      "SafePower",
      "SafeCos",
      "ExpSwitchActivation",
      "SafeElementwisePower_0",
      "SafeElementwisePower_1"
    ]
  },
  "training_config": {
    "num_epochs": 2000,
    "batch_size": 32,
    "learning_rate": 2,
    "reg_strength": 0.0,
    "scheduler": "cosine"
  },
  "final_equation": {
    "equation_string": "Matrix([[-0.594614*sin(0.0993184819817543*x1**2.03709 - 1.37686228752136*x2**1.51293) + 1.05697*sin(1.25294470787048*x1**2.03709 + 0.291320145130157*x2**1.51293)]])",
    "equation_latex": "Matrix([[-0.594614*sin(0.0993184819817543*x1**2.03709 - 1.37686228752136*x2**1.51293) + 1.05697*sin(1.25294470787048*x1**2.03709 + 0.291320145130157*x2**1.51293)]])"
  },
  "evaluation_metrics": {
    "mse": "0.007911001",
    "rmse": "0.08894381",
    "mae": "0.076023415"
  },
  "data_info": {
    "train_ratio": 0.8,
    "uncertainty_value": 0.0,
    "path_to_data": "/Users/pablocornejo/Documents/Tesis/SRNetwork/data/raw/nguyen.txt"
  },
  "lbfgs_optimization": {
    "enabled": true,
    "success": true,
    "message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
    "function_evaluations": 26,
    "gradient_evaluations": 26,
    "final_loss": 0.2409151377860973,
    "max_iterations": 1000,
    "tolerance": "1e-8",
    "criterion": "nrmse"
  },
  "lbfgs_topk_optimization": {
    "enabled": true,
    "num_models_optimized": 5,
    "optimization_summary": [
      {
        "rank": 1,
        "original_epoch": 1,
        "original_val_loss": 0.007870063385260957,
        "optimized_val_loss": "0.007911001",
        "improvement_percent": "-0.5201756",
        "original_equation": "Matrix([[-0.594614*sin(0.0993184819817543*x1**2.02455 - 1.37686228752136*x2**1.54175) + 1.05697*sin(1.30023765563965*x1**2.02455 + 0.29318630695343*x2**1.54175)]])",
        "optimized_equation": "Matrix([[-0.594614*sin(0.0993184819817543*x1**2.03709 - 1.37686228752136*x2**1.51293) + 1.05697*sin(1.25294470787048*x1**2.03709 + 0.291320145130157*x2**1.51293)]])",
        "optimization_success": true,
        "function_evaluations": 26,
        "final_loss": 0.2409151377860973
      },
      {
        "rank": 2,
        "original_epoch": 114,
        "original_val_loss": 0.01048433208572013,
        "optimized_val_loss": "0.009794263",
        "improvement_percent": "6.5819077",
        "original_equation": "Matrix([[1.77018*sin(0.540389537811279*x1**2.02455 + 0.653221845626831*x2**1.54175) - 0.0379985*sin(39.355583190918*x1**2.02455 + 2.60362768173218*x2**1.54175)]])",
        "optimized_equation": "Matrix([[1.77018*sin(0.681884050369263*x1**1.79282 + 0.553982198238373*x2**1.54228) - 0.0379985*sin(39.355583190918*x1**1.79282 + 2.60362768173218*x2**1.54228)]])",
        "optimization_success": true,
        "function_evaluations": 12,
        "final_loss": 0.2733173364594337
      },
      {
        "rank": 3,
        "original_epoch": 52,
        "original_val_loss": 0.011274617963603564,
        "optimized_val_loss": "0.010420999",
        "improvement_percent": "7.5711617",
        "original_equation": "Matrix([[1.57206*sin(0.6910080909729*x1**2.02455 + 0.806392848491669*x2**1.54175) - 0.0507688*sin(38.7705612182617*x1**2.02455 + 22.97292137146*x2**1.54175)]])",
        "optimized_equation": "Matrix([[1.57206*sin(0.678028166294098*x1**2.02909 + 0.777363777160645*x2**1.54181) - 0.0507688*sin(38.7705612182617*x1**2.02909 + 22.97292137146*x2**1.54181)]])",
        "optimization_success": true,
        "function_evaluations": 11,
        "final_loss": 0.28849694121642955
      },
      {
        "rank": 4,
        "original_epoch": 0,
        "original_val_loss": 0.011073127655046327,
        "optimized_val_loss": "0.01054759",
        "improvement_percent": "4.746057",
        "original_equation": "Matrix([[0.0115791*sin(0.322648793458939*x1**2.02455 + 0.052372895181179*x2**1.54175) + 1.3518*sin(0.809929847717285*x1**2.02455 + 0.856621265411377*x2**1.54175)]])",
        "optimized_equation": "Matrix([[0.0115791*sin(0.322648793458939*x1**1.98055 + 0.052372895181179*x2**1.54246) + 1.3518*sin(0.909448266029358*x1**1.98055 + 0.832253038883209*x2**1.54246)]])",
        "optimization_success": true,
        "function_evaluations": 11,
        "final_loss": 0.2788445433129681
      },
      {
        "rank": 5,
        "original_epoch": 204,
        "original_val_loss": 0.010610353334673814,
        "optimized_val_loss": "0.011566619",
        "improvement_percent": "-9.012576",
        "original_equation": "Matrix([[1.46442*sin(0.824510216712952*x1**2.02455 + 0.79535037279129*x2**1.54175) + 0.0630706*sin(61.8008613586426*x1**2.02455 + 62.3065567016602*x2**1.54175)]])",
        "optimized_equation": "Matrix([[1.46442*sin(0.822480082511902*x1**2.0201 + 0.769912779331207*x2**1.54169) + 0.0630706*sin(61.8008613586426*x1**2.0201 + 62.3065567016602*x2**1.54169)]])",
        "optimization_success": true,
        "function_evaluations": 18,
        "final_loss": 0.2988274566987332
      }
    ],
    "best_model": {
      "original_val_loss": 0.007870063385260957,
      "optimized_val_loss": "0.007911001",
      "improvement_percent": "-0.5201756",
      "equation": "Matrix([[-0.594614*sin(0.0993184819817543*x1**2.03709 - 1.37686228752136*x2**1.51293) + 1.05697*sin(1.25294470787048*x1**2.03709 + 0.291320145130157*x2**1.51293)]])",
      "optimization_iterations": 4
    }
  },
  "reward_tracking": {
    "reward_type": "nrmse",
    "reward_interval": 1,
    "num_measurements": 2000,
    "initial_reward": 0.2559247612953186,
    "final_reward": 0.04036540538072586,
    "best_reward": 0.289763867855072,
    "worst_reward": 0.01720474287867546,
    "average_reward": 0.047253144360147416,
    "reward_history": [
      {
        "epoch": 0,
        "reward": 0.2559247612953186,
        "val_loss": 0.011073127655046327,
        "train_loss": 0.12403385889214966
      },
      {
        "epoch": 1,
        "reward": 0.289763867855072,
        "val_loss": 0.007870063385260957,
        "train_loss": 0.018606937812784545
      },
      {
        "epoch": 2,
        "reward": 0.09108179062604904,
        "val_loss": 0.1304510555097035,
        "train_loss": 0.009395527689216228
      },
      {
        "epoch": 3,
        "reward": 0.06005847081542015,
        "val_loss": 0.32085906182016644,
        "train_loss": 0.03460690273473469
      },
      {
        "epoch": 4,
        "reward": 0.06498202681541443,
        "val_loss": 0.2712154729025705,
        "train_loss": 0.12297940601666386
      },
      {
        "epoch": 5,
        "reward": 0.1131867989897728,
        "val_loss": 0.08041441813111305,
        "train_loss": 0.14683714390803987
      },
      {
        "epoch": 6,
        "reward": 0.10879450291395187,
        "val_loss": 0.08790285140275955,
        "train_loss": 0.047049905030200116
      },
      {
        "epoch": 7,
        "reward": 0.14806462824344635,
        "val_loss": 0.04336823469826153,
        "train_loss": 0.04533164185256912
      },
      {
        "epoch": 8,
        "reward": 0.09553767740726471,
        "val_loss": 0.11740667266505105,
        "train_loss": 0.033252478756297096
      },
      {
        "epoch": 9,
        "reward": 0.09059266746044159,
        "val_loss": 0.13200546588216508,
        "train_loss": 0.06015927169042138
      },
      {
        "epoch": 10,
        "reward": 0.09554222226142883,
        "val_loss": 0.11739431640931539,
        "train_loss": 0.061628299120527044
      },
      {
        "epoch": 11,
        "reward": 0.15571783483028412,
        "val_loss": 0.03850877391440528,
        "train_loss": 0.05188975895110231
      },
      {
        "epoch": 12,
        "reward": 0.08865408599376678,
        "val_loss": 0.13842997806412832,
        "train_loss": 0.02335893394998633
      },
      {
        "epoch": 13,
        "reward": 0.10181005299091339,
        "val_loss": 0.10195679643324443,
        "train_loss": 0.06844195888306086
      },
      {
        "epoch": 14,
        "reward": 0.23599989712238312,
        "val_loss": 0.01372853945940733,
        "train_loss": 0.02546023394769201
      },
      {
        "epoch": 15,
        "reward": 0.14980672299861908,
        "val_loss": 0.04219236916729382,
        "train_loss": 0.014686642196745826
      },
      {
        "epoch": 16,
        "reward": 0.1494259536266327,
        "val_loss": 0.042445668152400425,
        "train_loss": 0.03926145818191939
      },
      {
        "epoch": 17,
        "reward": 0.2039642632007599,
        "val_loss": 0.019953457106437002,
        "train_loss": 0.026495414786040783
      },
      {
        "epoch": 18,
        "reward": 0.11700457334518433,
        "val_loss": 0.07460575391139303,
        "train_loss": 0.017675302349604093
      },
      {
        "epoch": 19,
        "reward": 0.08610151708126068,
        "val_loss": 0.1475827002099582,
        "train_loss": 0.029183203551488426
      },
      {
        "epoch": 20,
        "reward": 0.06887003034353256,
        "val_loss": 0.23945355415344238,
        "train_loss": 0.03499973160310132
      },
      {
        "epoch": 21,
        "reward": 0.04720249027013779,
        "val_loss": 0.533743577344077,
        "train_loss": 0.545225329211322
      },
      {
        "epoch": 22,
        "reward": 0.0866955891251564,
        "val_loss": 0.14537784031459264,
        "train_loss": 0.13015661556990102
      },
      {
        "epoch": 23,
        "reward": 0.05326418951153755,
        "val_loss": 0.4138549395969936,
        "train_loss": 0.09709652258942907
      },
      {
        "epoch": 24,
        "reward": 0.0788920670747757,
        "val_loss": 0.17857291443007334,
        "train_loss": 0.14958867227239983
      },
      {
        "epoch": 25,
        "reward": 0.0811711922287941,
        "val_loss": 0.16785202281815664,
        "train_loss": 0.059263243698156796
      },
      {
        "epoch": 26,
        "reward": 0.20759180188179016,
        "val_loss": 0.01908704838050263,
        "train_loss": 0.04232424003287004
      },
      {
        "epoch": 27,
        "reward": 0.18014250695705414,
        "val_loss": 0.027133474658642496,
        "train_loss": 0.05507513680137121
      },
      {
        "epoch": 28,
        "reward": 0.20421317219734192,
        "val_loss": 0.01989239760275398,
        "train_loss": 0.028129848651587963
      },
      {
        "epoch": 29,
        "reward": 0.07503240555524826,
        "val_loss": 0.1990749133484704,
        "train_loss": 0.01769452728331089
      },
      {
        "epoch": 30,
        "reward": 0.14280757308006287,
        "val_loss": 0.0471970976463386,
        "train_loss": 0.09697104277662359
      },
      {
        "epoch": 31,
        "reward": 0.09501530230045319,
        "val_loss": 0.11883834217275892,
        "train_loss": 0.063293368770526
      },
      {
        "epoch": 32,
        "reward": 0.1594257801771164,
        "val_loss": 0.03641632837908609,
        "train_loss": 0.07235771295829461
      },
      {
        "epoch": 33,
        "reward": 0.09305325895547867,
        "val_loss": 0.12444042946611132,
        "train_loss": 0.032687065621408135
      },
      {
        "epoch": 34,
        "reward": 0.20537009835243225,
        "val_loss": 0.019611760042607784,
        "train_loss": 0.03263405635236548
      },
      {
        "epoch": 35,
        "reward": 0.11608177423477173,
        "val_loss": 0.07595515570470265,
        "train_loss": 0.02512829700628152
      },
      {
        "epoch": 36,
        "reward": 0.11533874273300171,
        "val_loss": 0.07706633103745324,
        "train_loss": 0.04206042070514881
      },
      {
        "epoch": 37,
        "reward": 0.06509552150964737,
        "val_loss": 0.2702049804585321,
        "train_loss": 0.0386501091102568
      },
      {
        "epoch": 38,
        "reward": 0.046877872198820114,
        "val_loss": 0.5415300386292594,
        "train_loss": 0.2501215636013792
      },
      {
        "epoch": 39,
        "reward": 0.07011955976486206,
        "val_loss": 0.23037585190364293,
        "train_loss": 0.4776266986647478
      },
      {
        "epoch": 40,
        "reward": 0.01720474287867546,
        "val_loss": 4.274554627282279,
        "train_loss": 0.591225281644326
      },
      {
        "epoch": 41,
        "reward": 0.03012337163090706,
        "val_loss": 1.3579603603907995,
        "train_loss": 1.6169399160605211
      },
      {
        "epoch": 42,
        "reward": 0.03275846689939499,
        "val_loss": 1.1420468858310155,
        "train_loss": 1.0127147436141968
      },
      {
        "epoch": 43,
        "reward": 0.03290783241391182,
        "val_loss": 1.1313536167144775,
        "train_loss": 1.1217457766716297
      },
      {
        "epoch": 44,
        "reward": 0.04105307534337044,
        "val_loss": 0.7147578426769802,
        "train_loss": 1.031485867041808
      },
      {
        "epoch": 45,
        "reward": 0.0819837674498558,
        "val_loss": 0.16425025250230516,
        "train_loss": 0.26680081544551426
      },
      {
        "epoch": 46,
        "reward": 0.06950240582227707,
        "val_loss": 0.23479668157441275,
        "train_loss": 0.06745895908142512
      },
      {
        "epoch": 47,
        "reward": 0.08477681130170822,
        "val_loss": 0.15267260372638702,
        "train_loss": 0.10042987033151664
      },
      {
        "epoch": 48,
        "reward": 0.17396780848503113,
        "val_loss": 0.029533664296780313,
        "train_loss": 0.0899145714356564
      },
      {
        "epoch": 49,
        "reward": 0.09486519545316696,
        "val_loss": 0.11925425486905235,
        "train_loss": 0.019909587294722978
      },
      {
        "epoch": 50,
        "reward": 0.11530482769012451,
        "val_loss": 0.07711759475725037,
        "train_loss": 0.055674959189043596
      },
      {
        "epoch": 51,
        "reward": 0.21871991455554962,
        "val_loss": 0.016714678412037238,
        "train_loss": 0.03053499218255568
      },
      {
        "epoch": 52,
        "reward": 0.25421157479286194,
        "val_loss": 0.011274617963603564,
        "train_loss": 0.013861287552379928
      },
      {
        "epoch": 53,
        "reward": 0.1874420940876007,
        "val_loss": 0.024617025096501623,
        "train_loss": 0.020253719493316915
      },
      {
        "epoch": 54,
        "reward": 0.1215115338563919,
        "val_loss": 0.06846967499170985,
        "train_loss": 0.02492618625267194
      },
      {
        "epoch": 55,
        "reward": 0.16629071533679962,
        "val_loss": 0.032927168001021655,
        "train_loss": 0.030149567030513517
      },
      {
        "epoch": 56,
        "reward": 0.16287188231945038,
        "val_loss": 0.034606103120105605,
        "train_loss": 0.020594791545031164
      },
      {
        "epoch": 57,
        "reward": 0.14589114487171173,
        "val_loss": 0.04489828060780253,
        "train_loss": 0.015543849708942266
      },
      {
        "epoch": 58,
        "reward": 0.17918114364147186,
        "val_loss": 0.02748977392911911,
        "train_loss": 0.026733645023061678
      },
      {
        "epoch": 59,
        "reward": 0.21015559136867523,
        "val_loss": 0.018503860836582526,
        "train_loss": 0.01670445984032435
      },
      {
        "epoch": 60,
        "reward": 0.24268384277820587,
        "val_loss": 0.012756567714469773,
        "train_loss": 0.015275548440583337
      },
      {
        "epoch": 61,
        "reward": 0.13781744241714478,
        "val_loss": 0.05126857491476195,
        "train_loss": 0.017371872296700112
      },
      {
        "epoch": 62,
        "reward": 0.11553279310464859,
        "val_loss": 0.07677399473530906,
        "train_loss": 0.034190106035496756
      },
      {
        "epoch": 63,
        "reward": 0.10214085876941681,
        "val_loss": 0.10122283867427281,
        "train_loss": 0.03717914424263514
      },
      {
        "epoch": 64,
        "reward": 0.07071051746606827,
        "val_loss": 0.2262534030846187,
        "train_loss": 0.13962138952830663
      },
      {
        "epoch": 65,
        "reward": 0.0744534283876419,
        "val_loss": 0.20243626832962036,
        "train_loss": 0.10132820517397843
      },
      {
        "epoch": 66,
        "reward": 0.11134471744298935,
        "val_loss": 0.08344273535268647,
        "train_loss": 0.06083559985451687
      },
      {
        "epoch": 67,
        "reward": 0.13488338887691498,
        "val_loss": 0.05388817670089858,
        "train_loss": 0.0314345370637826
      },
      {
        "epoch": 68,
        "reward": 0.09815002977848053,
        "val_loss": 0.11059841087886266,
        "train_loss": 0.0439221913424822
      },
      {
        "epoch": 69,
        "reward": 0.16562417149543762,
        "val_loss": 0.033245823213032315,
        "train_loss": 0.06926295211395392
      },
      {
        "epoch": 70,
        "reward": 0.11786999553442001,
        "val_loss": 0.07337020124707903,
        "train_loss": 0.03700661243727574
      },
      {
        "epoch": 71,
        "reward": 0.07231839001178741,
        "val_loss": 0.2155567386320659,
        "train_loss": 0.028213789758200828
      },
      {
        "epoch": 72,
        "reward": 0.12719294428825378,
        "val_loss": 0.06168387085199356,
        "train_loss": 0.10028789709143054
      },
      {
        "epoch": 73,
        "reward": 0.11260538548231125,
        "val_loss": 0.08135354465671948,
        "train_loss": 0.03371731772159155
      },
      {
        "epoch": 74,
        "reward": 0.19539499282836914,
        "val_loss": 0.022212613640086993,
        "train_loss": 0.0467115927917453
      },
      {
        "epoch": 75,
        "reward": 0.17397403717041016,
        "val_loss": 0.02953109996659415,
        "train_loss": 0.02185084455861495
      },
      {
        "epoch": 76,
        "reward": 0.17785991728305817,
        "val_loss": 0.02798959772501673,
        "train_loss": 0.019500420253559872
      },
      {
        "epoch": 77,
        "reward": 0.09241195768117905,
        "val_loss": 0.12635209198508943,
        "train_loss": 0.02169532858981536
      },
      {
        "epoch": 78,
        "reward": 0.12465184926986694,
        "val_loss": 0.06459891530019897,
        "train_loss": 0.04460079903723314
      },
      {
        "epoch": 79,
        "reward": 0.11134088039398193,
        "val_loss": 0.08344923066241401,
        "train_loss": 0.02539898494545084
      },
      {
        "epoch": 80,
        "reward": 0.12541918456554413,
        "val_loss": 0.06369907249297414,
        "train_loss": 0.034889988063906245
      },
      {
        "epoch": 81,
        "reward": 0.06791581958532333,
        "val_loss": 0.24673430834497725,
        "train_loss": 0.032552154698910624
      },
      {
        "epoch": 82,
        "reward": 0.05107537657022476,
        "val_loss": 0.4521696610110147,
        "train_loss": 0.12546060871906006
      },
      {
        "epoch": 83,
        "reward": 0.08014313131570816,
        "val_loss": 0.1725714776132788,
        "train_loss": 0.36513799559235427
      },
      {
        "epoch": 84,
        "reward": 0.2076123207807541,
        "val_loss": 0.0190822800089206,
        "train_loss": 0.0943005421700386
      },
      {
        "epoch": 85,
        "reward": 0.07704765349626541,
        "val_loss": 0.18797531723976135,
        "train_loss": 0.03691260817532356
      },
      {
        "epoch": 86,
        "reward": 0.07105618715286255,
        "val_loss": 0.2238907665014267,
        "train_loss": 0.08463181103937902
      },
      {
        "epoch": 87,
        "reward": 0.07738666236400604,
        "val_loss": 0.18619513085910253,
        "train_loss": 0.06998433487919661
      },
      {
        "epoch": 88,
        "reward": 0.09055924415588379,
        "val_loss": 0.13211265632084437,
        "train_loss": 0.0641349837398873
      },
      {
        "epoch": 89,
        "reward": 0.0809486135840416,
        "val_loss": 0.16885810451848166,
        "train_loss": 0.07489378116308497
      },
      {
        "epoch": 90,
        "reward": 0.09023718535900116,
        "val_loss": 0.13315160359655107,
        "train_loss": 0.07227425929158926
      },
      {
        "epoch": 91,
        "reward": 0.07979327440261841,
        "val_loss": 0.17422055346625193,
        "train_loss": 0.08292376174806403
      },
      {
        "epoch": 92,
        "reward": 0.05026566609740257,
        "val_loss": 0.46765180570738657,
        "train_loss": 0.32635519768183047
      },
      {
        "epoch": 93,
        "reward": 0.1053677573800087,
        "val_loss": 0.09443537252289909,
        "train_loss": 0.2569849896602906
      },
      {
        "epoch": 94,
        "reward": 0.07402638345956802,
        "val_loss": 0.2049676307610103,
        "train_loss": 0.08731618928364836
      },
      {
        "epoch": 95,
        "reward": 0.06267885863780975,
        "val_loss": 0.29295157747609274,
        "train_loss": 0.17603964093499458
      },
      {
        "epoch": 96,
        "reward": 0.0692438930273056,
        "val_loss": 0.23668459483555385,
        "train_loss": 0.08988559034724648
      },
      {
        "epoch": 97,
        "reward": 0.09123263508081436,
        "val_loss": 0.12997690801109588,
        "train_loss": 0.12418933162608972
      },
      {
        "epoch": 98,
        "reward": 0.13863332569599152,
        "val_loss": 0.05057105581675257,
        "train_loss": 0.05675841165849796
      },
      {
        "epoch": 99,
        "reward": 0.20860810577869415,
        "val_loss": 0.018853063695132732,
        "train_loss": 0.020542614851505138
      },
      {
        "epoch": 100,
        "reward": 0.13560977578163147,
        "val_loss": 0.05322294309735298,
        "train_loss": 0.016749942854333382
      },
      {
        "epoch": 101,
        "reward": 0.09911663085222244,
        "val_loss": 0.108219427721841,
        "train_loss": 0.028853487246334016
      },
      {
        "epoch": 102,
        "reward": 0.12357722967863083,
        "val_loss": 0.06588878855109215,
        "train_loss": 0.051112432283564255
      },
      {
        "epoch": 103,
        "reward": 0.09993688762187958,
        "val_loss": 0.10625650095088142,
        "train_loss": 0.022278623279327385
      },
      {
        "epoch": 104,
        "reward": 0.09285087138414383,
        "val_loss": 0.12503931990691594,
        "train_loss": 0.032963375023637824
      },
      {
        "epoch": 105,
        "reward": 0.13199535012245178,
        "val_loss": 0.05664843853030886,
        "train_loss": 0.05845339331202782
      },
      {
        "epoch": 106,
        "reward": 0.08509151637554169,
        "val_loss": 0.15144117495843343,
        "train_loss": 0.0410981377443442
      },
      {
        "epoch": 107,
        "reward": 0.060166627168655396,
        "val_loss": 0.3196329431874411,
        "train_loss": 0.05985296094933382
      },
      {
        "epoch": 108,
        "reward": 0.10504259169101715,
        "val_loss": 0.09509004120315824,
        "train_loss": 0.11529946585114186
      },
      {
        "epoch": 109,
        "reward": 0.09768056124448776,
        "val_loss": 0.11178036566291537,
        "train_loss": 0.049815639710197084
      },
      {
        "epoch": 110,
        "reward": 0.05709626153111458,
        "val_loss": 0.3572568041937692,
        "train_loss": 0.6798469670690023
      },
      {
        "epoch": 111,
        "reward": 0.10858134180307388,
        "val_loss": 0.08829053757446152,
        "train_loss": 0.11983729075067319
      },
      {
        "epoch": 112,
        "reward": 0.08936487883329391,
        "val_loss": 0.13602418984685624,
        "train_loss": 0.06407026276708795
      },
      {
        "epoch": 113,
        "reward": 0.12549152970314026,
        "val_loss": 0.06361512414046697,
        "train_loss": 0.05830810570590144
      },
      {
        "epoch": 114,
        "reward": 0.26116177439689636,
        "val_loss": 0.01048433208572013,
        "train_loss": 0.023439372630001835
      },
      {
        "epoch": 115,
        "reward": 0.22389259934425354,
        "val_loss": 0.01574074729744877,
        "train_loss": 0.018123202997510537
      },
      {
        "epoch": 116,
        "reward": 0.2457139790058136,
        "val_loss": 0.012344502976962499,
        "train_loss": 0.014036253805478247
      },
      {
        "epoch": 117,
        "reward": 0.16012775897979736,
        "val_loss": 0.03603747034711497,
        "train_loss": 0.013539861977243653
      },
      {
        "epoch": 118,
        "reward": 0.14964304864406586,
        "val_loss": 0.042301002357687266,
        "train_loss": 0.021740388814718105
      },
      {
        "epoch": 119,
        "reward": 0.19654865562915802,
        "val_loss": 0.021889719047716687,
        "train_loss": 0.029537736653135374
      },
      {
        "epoch": 120,
        "reward": 0.19075995683670044,
        "val_loss": 0.023574438877403736,
        "train_loss": 0.016926054914410297
      },
      {
        "epoch": 121,
        "reward": 0.23499587178230286,
        "val_loss": 0.013882520675126995,
        "train_loss": 0.018003452255820427
      },
      {
        "epoch": 122,
        "reward": 0.09990276396274567,
        "val_loss": 0.10633714922836848,
        "train_loss": 0.014542513455335911
      },
      {
        "epoch": 123,
        "reward": 0.17929033935070038,
        "val_loss": 0.02744899597018957,
        "train_loss": 0.03166366004958176
      },
      {
        "epoch": 124,
        "reward": 0.16305844485759735,
        "val_loss": 0.03451157334659781,
        "train_loss": 0.022824354111575164
      },
      {
        "epoch": 125,
        "reward": 0.06156795844435692,
        "val_loss": 0.30433882985796246,
        "train_loss": 0.0341503036638292
      },
      {
        "epoch": 126,
        "reward": 0.06915577501058578,
        "val_loss": 0.2373330635683877,
        "train_loss": 0.16608353102436432
      },
      {
        "epoch": 127,
        "reward": 0.06567444652318954,
        "val_loss": 0.2651336427245821,
        "train_loss": 0.10338881475707659
      },
      {
        "epoch": 128,
        "reward": 0.07215888053178787,
        "val_loss": 0.21658522742135183,
        "train_loss": 0.13810017902505933
      },
      {
        "epoch": 129,
        "reward": 0.0657370314002037,
        "val_loss": 0.2645934990474156,
        "train_loss": 0.08185358148498031
      },
      {
        "epoch": 130,
        "reward": 0.19334588944911957,
        "val_loss": 0.02280162993286337,
        "train_loss": 0.08451079951751475
      },
      {
        "epoch": 131,
        "reward": 0.21411585807800293,
        "val_loss": 0.017647392515625273,
        "train_loss": 0.01870037206950096
      },
      {
        "epoch": 132,
        "reward": 0.09816425293684006,
        "val_loss": 0.11056289396115712,
        "train_loss": 0.027483200582747277
      },
      {
        "epoch": 133,
        "reward": 0.06790318340063095,
        "val_loss": 0.24683281566415513,
        "train_loss": 0.0822894201757243
      },
      {
        "epoch": 134,
        "reward": 0.0777948647737503,
        "val_loss": 0.18408330423491343,
        "train_loss": 0.17769420595588878
      },
      {
        "epoch": 135,
        "reward": 0.09221959859132767,
        "val_loss": 0.12693351613623755,
        "train_loss": 0.07825134257571055
      },
      {
        "epoch": 136,
        "reward": 0.09749048203229904,
        "val_loss": 0.11226394453219005,
        "train_loss": 0.045229282624159865
      },
      {
        "epoch": 137,
        "reward": 0.10521019995212555,
        "val_loss": 0.09475181571074895,
        "train_loss": 0.07435107546357009
      },
      {
        "epoch": 138,
        "reward": 0.1313847005367279,
        "val_loss": 0.05725672574979918,
        "train_loss": 0.029320467494052045
      },
      {
        "epoch": 139,
        "reward": 0.17282260954380035,
        "val_loss": 0.030009400099515915,
        "train_loss": 0.019111025200870175
      },
      {
        "epoch": 140,
        "reward": 0.10001271963119507,
        "val_loss": 0.10607753268310002,
        "train_loss": 0.02186717880921116
      },
      {
        "epoch": 141,
        "reward": 0.11761941015720367,
        "val_loss": 0.07372505004916872,
        "train_loss": 0.04322268215376495
      },
      {
        "epoch": 142,
        "reward": 0.1327003687620163,
        "val_loss": 0.05595710128545761,
        "train_loss": 0.03249654900999023
      },
      {
        "epoch": 143,
        "reward": 0.1363983154296875,
        "val_loss": 0.05251339716570718,
        "train_loss": 0.05707410881698776
      },
      {
        "epoch": 144,
        "reward": 0.19893324375152588,
        "val_loss": 0.021241433918476105,
        "train_loss": 0.02330914454964491
      },
      {
        "epoch": 145,
        "reward": 0.21157339215278625,
        "val_loss": 0.01819121159080948,
        "train_loss": 0.018787061497767772
      },
      {
        "epoch": 146,
        "reward": 0.18519137799739838,
        "val_loss": 0.025358928766633784,
        "train_loss": 0.015551263108276404
      },
      {
        "epoch": 147,
        "reward": 0.09078245609998703,
        "val_loss": 0.13139923768384115,
        "train_loss": 0.028176937109002702
      },
      {
        "epoch": 148,
        "reward": 0.19662243127822876,
        "val_loss": 0.021869275718927383,
        "train_loss": 0.04966404246023068
      },
      {
        "epoch": 149,
        "reward": 0.15878334641456604,
        "val_loss": 0.03676773527903216,
        "train_loss": 0.017648314233296193
      },
      {
        "epoch": 150,
        "reward": 0.07690492272377014,
        "val_loss": 0.18873209612710135,
        "train_loss": 0.03656465964964949
      },
      {
        "epoch": 151,
        "reward": 0.09128790348768234,
        "val_loss": 0.12980378312723978,
        "train_loss": 0.04870260918799501
      },
      {
        "epoch": 152,
        "reward": 0.07028040289878845,
        "val_loss": 0.22924324018614634,
        "train_loss": 0.047482732110298596
      },
      {
        "epoch": 153,
        "reward": 0.08486330509185791,
        "val_loss": 0.15233271356139863,
        "train_loss": 0.06259520162040225
      },
      {
        "epoch": 154,
        "reward": 0.07821842283010483,
        "val_loss": 0.1819277788911547,
        "train_loss": 0.04370881790796725
      },
      {
        "epoch": 155,
        "reward": 0.24464662373065948,
        "val_loss": 0.012487717771104403,
        "train_loss": 0.05230114487214731
      },
      {
        "epoch": 156,
        "reward": 0.19123171269893646,
        "val_loss": 0.02343092965228217,
        "train_loss": 0.016068294818978757
      },
      {
        "epoch": 157,
        "reward": 0.07705651968717575,
        "val_loss": 0.18792849779129028,
        "train_loss": 0.03296042605003235
      },
      {
        "epoch": 158,
        "reward": 0.18005810678005219,
        "val_loss": 0.02716451351131712,
        "train_loss": 0.06013137367195808
      },
      {
        "epoch": 159,
        "reward": 0.11683757603168488,
        "val_loss": 0.07484748320920127,
        "train_loss": 0.022361777450826664
      },
      {
        "epoch": 160,
        "reward": 0.21724338829517365,
        "val_loss": 0.017006756737828255,
        "train_loss": 0.01903810213284137
      },
      {
        "epoch": 161,
        "reward": 0.13952253758907318,
        "val_loss": 0.049825468233653476,
        "train_loss": 0.016504394078555588
      },
      {
        "epoch": 162,
        "reward": 0.13235758244991302,
        "val_loss": 0.056291772318737845,
        "train_loss": 0.021286367510373775
      },
      {
        "epoch": 163,
        "reward": 0.18813695013523102,
        "val_loss": 0.024393743968435695,
        "train_loss": 0.025430365290958434
      },
      {
        "epoch": 164,
        "reward": 0.09339363873004913,
        "val_loss": 0.12344232627323695,
        "train_loss": 0.01314913254016294
      },
      {
        "epoch": 165,
        "reward": 0.06049923971295357,
        "val_loss": 0.31590435760361807,
        "train_loss": 0.08262896347122688
      },
      {
        "epoch": 166,
        "reward": 0.04860146716237068,
        "val_loss": 0.501981088093349,
        "train_loss": 0.17322934393842632
      },
      {
        "epoch": 167,
        "reward": 0.027859488502144814,
        "val_loss": 1.5950453622000558,
        "train_loss": 0.6446529502192369
      },
      {
        "epoch": 168,
        "reward": 0.03010847233235836,
        "val_loss": 1.3593461513519287,
        "train_loss": 0.8384946501598909
      },
      {
        "epoch": 169,
        "reward": 0.03944012522697449,
        "val_loss": 0.7770223021507263,
        "train_loss": 1.3412463447222343
      },
      {
        "epoch": 170,
        "reward": 0.04424978420138359,
        "val_loss": 0.6111217609473637,
        "train_loss": 0.602913178405008
      },
      {
        "epoch": 171,
        "reward": 0.10655524581670761,
        "val_loss": 0.09209728666714259,
        "train_loss": 0.22339233619948992
      },
      {
        "epoch": 172,
        "reward": 0.15577934682369232,
        "val_loss": 0.038472761533090045,
        "train_loss": 0.04913500897013224
      },
      {
        "epoch": 173,
        "reward": 0.06270498037338257,
        "val_loss": 0.29269117968423025,
        "train_loss": 0.07001563872640523
      },
      {
        "epoch": 174,
        "reward": 0.10075441747903824,
        "val_loss": 0.10434929920094353,
        "train_loss": 0.15319685020054188
      },
      {
        "epoch": 175,
        "reward": 0.12506023049354553,
        "val_loss": 0.06411785313061305,
        "train_loss": 0.07186670811083437
      },
      {
        "epoch": 176,
        "reward": 0.14256779849529266,
        "val_loss": 0.04738248884677887,
        "train_loss": 0.10644251616814962
      },
      {
        "epoch": 177,
        "reward": 0.06399962306022644,
        "val_loss": 0.28019367371286663,
        "train_loss": 0.13318980814745793
      },
      {
        "epoch": 178,
        "reward": 0.06771647185087204,
        "val_loss": 0.24829526671341487,
        "train_loss": 0.164705914660142
      },
      {
        "epoch": 179,
        "reward": 0.09508153051137924,
        "val_loss": 0.118655442659344,
        "train_loss": 0.08733968494030145
      },
      {
        "epoch": 180,
        "reward": 0.1760789155960083,
        "val_loss": 0.028682544295276915,
        "train_loss": 0.05373068623101482
      },
      {
        "epoch": 181,
        "reward": 0.24414415657520294,
        "val_loss": 0.012555861978658609,
        "train_loss": 0.01673178838637586
      },
      {
        "epoch": 182,
        "reward": 0.20144899189472198,
        "val_loss": 0.02058431027191026,
        "train_loss": 0.014572832229672573
      },
      {
        "epoch": 183,
        "reward": 0.20759688317775726,
        "val_loss": 0.019085867596524104,
        "train_loss": 0.014629066688939929
      },
      {
        "epoch": 184,
        "reward": 0.22859492897987366,
        "val_loss": 0.014917394678507532,
        "train_loss": 0.01760853664913716
      },
      {
        "epoch": 185,
        "reward": 0.18315830826759338,
        "val_loss": 0.0260545602068305,
        "train_loss": 0.011938780868569246
      },
      {
        "epoch": 186,
        "reward": 0.0884716659784317,
        "val_loss": 0.1390570785318102,
        "train_loss": 0.016638668110737435
      },
      {
        "epoch": 187,
        "reward": 0.13792353868484497,
        "val_loss": 0.051177128085068295,
        "train_loss": 0.03488675598055124
      },
      {
        "epoch": 188,
        "reward": 0.1090550646185875,
        "val_loss": 0.08743215884481158,
        "train_loss": 0.039525453287821546
      },
      {
        "epoch": 189,
        "reward": 0.16189947724342346,
        "val_loss": 0.035104473520602496,
        "train_loss": 0.04814346220183115
      },
      {
        "epoch": 190,
        "reward": 0.07936070114374161,
        "val_loss": 0.17629058233329228,
        "train_loss": 0.023858454579917285
      },
      {
        "epoch": 191,
        "reward": 0.10128728300333023,
        "val_loss": 0.10313190519809723,
        "train_loss": 0.09064015165831034
      },
      {
        "epoch": 192,
        "reward": 0.09841389209032059,
        "val_loss": 0.10994178695338112,
        "train_loss": 0.05856912588485731
      },
      {
        "epoch": 193,
        "reward": 0.16162234544754028,
        "val_loss": 0.03524826041289738,
        "train_loss": 0.04400863319348831
      },
      {
        "epoch": 194,
        "reward": 0.14935274422168732,
        "val_loss": 0.04249460409794535,
        "train_loss": 0.03383016439441305
      },
      {
        "epoch": 195,
        "reward": 0.10861402750015259,
        "val_loss": 0.08823092122163091,
        "train_loss": 0.025488478059952076
      },
      {
        "epoch": 196,
        "reward": 0.07583549618721008,
        "val_loss": 0.19454253997121537,
        "train_loss": 0.021904917039836828
      },
      {
        "epoch": 197,
        "reward": 0.15608680248260498,
        "val_loss": 0.038293433242610524,
        "train_loss": 0.05632307397004647
      },
      {
        "epoch": 198,
        "reward": 0.05950314551591873,
        "val_loss": 0.3272622674703598,
        "train_loss": 0.02270312335055608
      },
      {
        "epoch": 199,
        "reward": 0.07357558608055115,
        "val_loss": 0.20768908091953822,
        "train_loss": 0.12379551847250415
      },
      {
        "epoch": 200,
        "reward": 0.13554120063781738,
        "val_loss": 0.05328525283506939,
        "train_loss": 0.08233026488540837
      },
      {
        "epoch": 201,
        "reward": 0.20798996090888977,
        "val_loss": 0.018994936453444616,
        "train_loss": 0.025052902432015307
      },
      {
        "epoch": 202,
        "reward": 0.17349673807621002,
        "val_loss": 0.02972812857478857,
        "train_loss": 0.015704469504551247
      },
      {
        "epoch": 203,
        "reward": 0.08549109101295471,
        "val_loss": 0.14989783402000154,
        "train_loss": 0.033237783381572135
      },
      {
        "epoch": 204,
        "reward": 0.26001062989234924,
        "val_loss": 0.010610353334673814,
        "train_loss": 0.08249636520989813
      },
      {
        "epoch": 205,
        "reward": 0.050214141607284546,
        "val_loss": 0.4686627984046936,
        "train_loss": 0.0235907702993315
      },
      {
        "epoch": 206,
        "reward": 0.029580513015389442,
        "val_loss": 1.4098366158349174,
        "train_loss": 0.18489584892701644
      },
      {
        "epoch": 207,
        "reward": 0.021702347323298454,
        "val_loss": 2.6618883269173756,
        "train_loss": 0.9431853237149951
      },
      {
        "epoch": 208,
        "reward": 0.028884727507829666,
        "val_loss": 1.480697044304439,
        "train_loss": 1.7085052928985254
      },
      {
        "epoch": 209,
        "reward": 0.033233679831027985,
        "val_loss": 1.1085297976221358,
        "train_loss": 1.000470912227264
      },
      {
        "epoch": 210,
        "reward": 0.04093913361430168,
        "val_loss": 0.7189127802848816,
        "train_loss": 0.9762551440642431
      },
      {
        "epoch": 211,
        "reward": 0.03489295393228531,
        "val_loss": 1.002159127167293,
        "train_loss": 0.8586707940468421
      },
      {
        "epoch": 212,
        "reward": 0.04130951687693596,
        "val_loss": 0.7055336790425437,
        "train_loss": 1.00321898322839
      },
      {
        "epoch": 213,
        "reward": 0.03181608021259308,
        "val_loss": 1.2130636998585291,
        "train_loss": 0.9822927667544439
      },
      {
        "epoch": 214,
        "reward": 0.03503912687301636,
        "val_loss": 0.9935141035488674,
        "train_loss": 1.0109672981959124
      },
      {
        "epoch": 215,
        "reward": 0.03808137774467468,
        "val_loss": 0.8358194828033447,
        "train_loss": 0.9821911270801837
      },
      {
        "epoch": 216,
        "reward": 0.024556627497076988,
        "val_loss": 2.066939643451146,
        "train_loss": 1.0840654012102346
      },
      {
        "epoch": 217,
        "reward": 0.03187445178627968,
        "val_loss": 1.2084788509777613,
        "train_loss": 1.2192607244046836
      },
      {
        "epoch": 218,
        "reward": 0.03306383639574051,
        "val_loss": 1.1203414372035436,
        "train_loss": 0.9481886075093195
      },
      {
        "epoch": 219,
        "reward": 0.039873283356428146,
        "val_loss": 0.7595464842660087,
        "train_loss": 0.9205136413757617
      },
      {
        "epoch": 220,
        "reward": 0.031243422999978065,
        "val_loss": 1.259427777358464,
        "train_loss": 0.7933199038872352
      },
      {
        "epoch": 221,
        "reward": 0.03262859210371971,
        "val_loss": 1.1514658417020525,
        "train_loss": 1.0420910210993428
      },
      {
        "epoch": 222,
        "reward": 0.040568847209215164,
        "val_loss": 0.7326616644859314,
        "train_loss": 0.8457770599768712
      },
      {
        "epoch": 223,
        "reward": 0.041170474141836166,
        "val_loss": 0.710513310773032,
        "train_loss": 0.9133862440402691
      },
      {
        "epoch": 224,
        "reward": 0.03834035247564316,
        "val_loss": 0.8241224714687893,
        "train_loss": 0.9317473287765796
      },
      {
        "epoch": 225,
        "reward": 0.03435668721795082,
        "val_loss": 1.0348373906952995,
        "train_loss": 0.8380967103517972
      },
      {
        "epoch": 226,
        "reward": 0.03279069438576698,
        "val_loss": 1.1397271241460527,
        "train_loss": 0.8218954036442133
      },
      {
        "epoch": 227,
        "reward": 0.028271157294511795,
        "val_loss": 1.5476195982524328,
        "train_loss": 0.8934005074776136
      },
      {
        "epoch": 228,
        "reward": 0.0416421964764595,
        "val_loss": 0.6938239591462272,
        "train_loss": 1.0631297646233668
      },
      {
        "epoch": 229,
        "reward": 0.02999422326683998,
        "val_loss": 1.3700441718101501,
        "train_loss": 0.8313057871105579
      },
      {
        "epoch": 230,
        "reward": 0.027816955000162125,
        "val_loss": 1.6000666788646154,
        "train_loss": 1.2701199238116925
      },
      {
        "epoch": 231,
        "reward": 0.037423472851514816,
        "val_loss": 0.866649695805141,
        "train_loss": 1.3322659593362074
      },
      {
        "epoch": 232,
        "reward": 0.03428223356604576,
        "val_loss": 1.0394973158836365,
        "train_loss": 0.7724805405506721
      },
      {
        "epoch": 233,
        "reward": 0.039459917694330215,
        "val_loss": 0.7762110488755363,
        "train_loss": 0.866910132078024
      },
      {
        "epoch": 234,
        "reward": 0.03139428049325943,
        "val_loss": 1.246964761189052,
        "train_loss": 0.8690729095385625
      },
      {
        "epoch": 235,
        "reward": 0.03938978165388107,
        "val_loss": 0.7790915625435966,
        "train_loss": 0.915766648375071
      },
      {
        "epoch": 236,
        "reward": 0.03980318829417229,
        "val_loss": 0.7623352493558612,
        "train_loss": 0.7413454616191582
      },
      {
        "epoch": 237,
        "reward": 0.03910958394408226,
        "val_loss": 0.7907558892454419,
        "train_loss": 0.800889824445431
      },
      {
        "epoch": 238,
        "reward": 0.031056368723511696,
        "val_loss": 1.2751371094158717,
        "train_loss": 0.8042578584013077
      },
      {
        "epoch": 239,
        "reward": 0.02773018181324005,
        "val_loss": 1.61038339138031,
        "train_loss": 0.9665717345017654
      },
      {
        "epoch": 240,
        "reward": 0.031710781157016754,
        "val_loss": 1.2213987793241228,
        "train_loss": 1.4297745136114268
      },
      {
        "epoch": 241,
        "reward": 0.04032397270202637,
        "val_loss": 0.7419657026018415,
        "train_loss": 1.060573215668018
      },
      {
        "epoch": 242,
        "reward": 0.03759802132844925,
        "val_loss": 0.8583100438117981,
        "train_loss": 0.8690162461537582
      },
      {
        "epoch": 243,
        "reward": 0.03482462838292122,
        "val_loss": 1.0062380220208849,
        "train_loss": 0.8170203062204214
      },
      {
        "epoch": 244,
        "reward": 0.03312123939394951,
        "val_loss": 1.1163285630089896,
        "train_loss": 0.8670184761285782
      },
      {
        "epoch": 245,
        "reward": 0.03875176981091499,
        "val_loss": 0.8060262288366046,
        "train_loss": 1.0529406652517186
      },
      {
        "epoch": 246,
        "reward": 0.03833624720573425,
        "val_loss": 0.824306036744799,
        "train_loss": 0.7789272808183271
      },
      {
        "epoch": 247,
        "reward": 0.040586285293102264,
        "val_loss": 0.7320055621010917,
        "train_loss": 0.839576767041133
      },
      {
        "epoch": 248,
        "reward": 0.03910220041871071,
        "val_loss": 0.7910668849945068,
        "train_loss": 0.9136786277477558
      },
      {
        "epoch": 249,
        "reward": 0.0372806116938591,
        "val_loss": 0.8735636728150504,
        "train_loss": 0.8255131657306964
      },
      {
        "epoch": 250,
        "reward": 0.03949327394366264,
        "val_loss": 0.7748465452875409,
        "train_loss": 0.8365307415907199
      },
      {
        "epoch": 251,
        "reward": 0.040312763303518295,
        "val_loss": 0.7423958012035915,
        "train_loss": 0.8963490197291741
      },
      {
        "epoch": 252,
        "reward": 0.033883098512887955,
        "val_loss": 1.065011671611241,
        "train_loss": 0.8888919995381281
      },
      {
        "epoch": 253,
        "reward": 0.0398251973092556,
        "val_loss": 0.7614580392837524,
        "train_loss": 0.8850989502209884
      },
      {
        "epoch": 254,
        "reward": 0.02323823980987072,
        "val_loss": 2.3143653699329922,
        "train_loss": 0.856590034870001
      },
      {
        "epoch": 255,
        "reward": 0.03461960330605507,
        "val_loss": 1.0186241183962141,
        "train_loss": 1.0842251456700838
      },
      {
        "epoch": 256,
        "reward": 0.03483280912041664,
        "val_loss": 1.0057485273906164,
        "train_loss": 0.878165837090749
      },
      {
        "epoch": 257,
        "reward": 0.03883465752005577,
        "val_loss": 0.8024508953094482,
        "train_loss": 0.8955201621239002
      },
      {
        "epoch": 258,
        "reward": 0.03100655972957611,
        "val_loss": 1.27936851978302,
        "train_loss": 0.8396107421184962
      },
      {
        "epoch": 259,
        "reward": 0.03752271831035614,
        "val_loss": 0.861893389906202,
        "train_loss": 0.8679788296039288
      },
      {
        "epoch": 260,
        "reward": 0.040752291679382324,
        "val_loss": 0.725802847317287,
        "train_loss": 0.793224283937329
      },
      {
        "epoch": 261,
        "reward": 0.03816799074411392,
        "val_loss": 0.8318806546075004,
        "train_loss": 0.8077376599495227
      },
      {
        "epoch": 262,
        "reward": 0.02878919057548046,
        "val_loss": 1.4908339466367448,
        "train_loss": 0.8660602800261515
      },
      {
        "epoch": 263,
        "reward": 0.03466196358203888,
        "val_loss": 1.016046668801989,
        "train_loss": 0.842693778184744
      },
      {
        "epoch": 264,
        "reward": 0.03218076750636101,
        "val_loss": 1.1848325218473161,
        "train_loss": 0.8647806551665641
      },
      {
        "epoch": 265,
        "reward": 0.02885245718061924,
        "val_loss": 1.48410964012146,
        "train_loss": 0.9125178579527599
      },
      {
        "epoch": 266,
        "reward": 0.027439771220088005,
        "val_loss": 1.6456337996891566,
        "train_loss": 1.0194701368992145
      },
      {
        "epoch": 267,
        "reward": 0.04064448922872543,
        "val_loss": 0.7298221247536796,
        "train_loss": 1.0934654625777442
      },
      {
        "epoch": 268,
        "reward": 0.0371871255338192,
        "val_loss": 0.8781318579401288,
        "train_loss": 0.7937099154178913
      },
      {
        "epoch": 269,
        "reward": 0.037601619958877563,
        "val_loss": 0.8581393105643136,
        "train_loss": 0.9164392787676591
      },
      {
        "epoch": 270,
        "reward": 0.03170154616236687,
        "val_loss": 1.2221335853849138,
        "train_loss": 0.9348379946672
      },
      {
        "epoch": 271,
        "reward": 0.03681383654475212,
        "val_loss": 0.8967253523213523,
        "train_loss": 0.9110467439660659
      },
      {
        "epoch": 272,
        "reward": 0.04035450518131256,
        "val_loss": 0.7407962594713483,
        "train_loss": 0.8501604451582983
      },
      {
        "epoch": 273,
        "reward": 0.03995504602789879,
        "val_loss": 0.7563120722770691,
        "train_loss": 0.8497230479350457
      },
      {
        "epoch": 274,
        "reward": 0.034538835287094116,
        "val_loss": 1.0235650624547685,
        "train_loss": 0.9170434727118566
      },
      {
        "epoch": 275,
        "reward": 0.03273659572005272,
        "val_loss": 1.1436251657349723,
        "train_loss": 0.878949394592872
      },
      {
        "epoch": 276,
        "reward": 0.0380929633975029,
        "val_loss": 0.8352912579263959,
        "train_loss": 0.8928625996296222
      },
      {
        "epoch": 277,
        "reward": 0.03461994603276253,
        "val_loss": 1.0186033759798323,
        "train_loss": 0.8057508293825847
      },
      {
        "epoch": 278,
        "reward": 0.035111911594867706,
        "val_loss": 0.9892502171652657,
        "train_loss": 0.9101061041538532
      },
      {
        "epoch": 279,
        "reward": 0.04055642709136009,
        "val_loss": 0.7331296035221645,
        "train_loss": 0.8845587349496782
      },
      {
        "epoch": 280,
        "reward": 0.037980515509843826,
        "val_loss": 0.8404409629958016,
        "train_loss": 0.8194564483486689
      },
      {
        "epoch": 281,
        "reward": 0.037660326808691025,
        "val_loss": 0.855361887386867,
        "train_loss": 0.8119843143683213
      },
      {
        "epoch": 282,
        "reward": 0.027375658974051476,
        "val_loss": 1.6535690171378,
        "train_loss": 0.9539024990338546
      },
      {
        "epoch": 283,
        "reward": 0.03828782960772514,
        "val_loss": 0.8264752541269574,
        "train_loss": 0.9600657087105972
      },
      {
        "epoch": 284,
        "reward": 0.03439994901418686,
        "val_loss": 1.0321435332298279,
        "train_loss": 0.7708043201383641
      },
      {
        "epoch": 285,
        "reward": 0.03220308944582939,
        "val_loss": 1.1831360374178206,
        "train_loss": 0.9038217245386198
      },
      {
        "epoch": 286,
        "reward": 0.039700087159872055,
        "val_loss": 0.7664644122123718,
        "train_loss": 0.9004261081035321
      },
      {
        "epoch": 287,
        "reward": 0.0387459360063076,
        "val_loss": 0.8062788503510612,
        "train_loss": 0.7741098541479844
      },
      {
        "epoch": 288,
        "reward": 0.03306156024336815,
        "val_loss": 1.1205006965569086,
        "train_loss": 0.8114126232954172
      },
      {
        "epoch": 289,
        "reward": 0.03821001201868057,
        "val_loss": 0.8299794026783535,
        "train_loss": 0.9117049672282659
      },
      {
        "epoch": 290,
        "reward": 0.0353529267013073,
        "val_loss": 0.9753204328673226,
        "train_loss": 0.8288673300009507
      },
      {
        "epoch": 291,
        "reward": 0.04086162894964218,
        "val_loss": 0.7217592597007751,
        "train_loss": 1.0159041766936963
      },
      {
        "epoch": 292,
        "reward": 0.03999083861708641,
        "val_loss": 0.7549027289663043,
        "train_loss": 0.8355829903426079
      },
      {
        "epoch": 293,
        "reward": 0.02984451688826084,
        "val_loss": 1.3842506408691406,
        "train_loss": 0.8129243575609647
      },
      {
        "epoch": 294,
        "reward": 0.026954451575875282,
        "val_loss": 1.7071297339030675,
        "train_loss": 1.3647636129305913
      },
      {
        "epoch": 295,
        "reward": 0.03481268510222435,
        "val_loss": 1.006953307560512,
        "train_loss": 1.0948548385730157
      },
      {
        "epoch": 296,
        "reward": 0.036583125591278076,
        "val_loss": 0.9085065381867545,
        "train_loss": 0.9147023561303146
      },
      {
        "epoch": 297,
        "reward": 0.034371268004179,
        "val_loss": 1.0339284198624747,
        "train_loss": 0.8436476622636502
      },
      {
        "epoch": 298,
        "reward": 0.035197772085666656,
        "val_loss": 0.9842545943600791,
        "train_loss": 0.8349464558638059
      },
      {
        "epoch": 299,
        "reward": 0.04085811600089073,
        "val_loss": 0.7218886698995318,
        "train_loss": 0.8660231219747891
      },
      {
        "epoch": 300,
        "reward": 0.03964753821492195,
        "val_loss": 0.7685816032545907,
        "train_loss": 0.7635362862448136
      },
      {
        "epoch": 301,
        "reward": 0.03823322430253029,
        "val_loss": 0.8289318425314767,
        "train_loss": 0.8851575003220484
      },
      {
        "epoch": 302,
        "reward": 0.03490874916315079,
        "val_loss": 1.0012196728161402,
        "train_loss": 0.8721322096311129
      },
      {
        "epoch": 303,
        "reward": 0.026062116026878357,
        "val_loss": 1.8293814999716622,
        "train_loss": 0.908371084011518
      },
      {
        "epoch": 304,
        "reward": 0.038185663521289825,
        "val_loss": 0.8310803515570504,
        "train_loss": 1.2155604866834788
      },
      {
        "epoch": 305,
        "reward": 0.03212374821305275,
        "val_loss": 1.1891822133745467,
        "train_loss": 0.9782832677547748
      },
      {
        "epoch": 306,
        "reward": 0.029395872727036476,
        "val_loss": 1.4281464559691293,
        "train_loss": 0.8136686602464089
      },
      {
        "epoch": 307,
        "reward": 0.03230161592364311,
        "val_loss": 1.1756898675646101,
        "train_loss": 0.9920834910411102
      },
      {
        "epoch": 308,
        "reward": 0.03779527172446251,
        "val_loss": 0.8490263649395534,
        "train_loss": 1.0092682815515077
      },
      {
        "epoch": 309,
        "reward": 0.03628457337617874,
        "val_loss": 0.9240911177226475,
        "train_loss": 0.9256615249010233
      },
      {
        "epoch": 310,
        "reward": 0.03667060658335686,
        "val_loss": 0.9040130632264274,
        "train_loss": 1.128662414275683
      },
      {
        "epoch": 311,
        "reward": 0.03578998148441315,
        "val_loss": 0.9507833123207092,
        "train_loss": 0.8658386801297848
      },
      {
        "epoch": 312,
        "reward": 0.03985387086868286,
        "val_loss": 0.7603171297482082,
        "train_loss": 0.9616649196698115
      },
      {
        "epoch": 313,
        "reward": 0.03125080093741417,
        "val_loss": 1.2588139261518205,
        "train_loss": 0.7939793719695165
      },
      {
        "epoch": 314,
        "reward": 0.035817701369524,
        "val_loss": 0.949257527078901,
        "train_loss": 0.8804101026975192
      },
      {
        "epoch": 315,
        "reward": 0.03924109414219856,
        "val_loss": 0.7852497185979571,
        "train_loss": 0.8860119237349584
      },
      {
        "epoch": 316,
        "reward": 0.03977956622838974,
        "val_loss": 0.7632783906800407,
        "train_loss": 0.8389463195433984
      },
      {
        "epoch": 317,
        "reward": 0.03984246775507927,
        "val_loss": 0.7607706274305072,
        "train_loss": 0.8225281674128312
      },
      {
        "epoch": 318,
        "reward": 0.033632706850767136,
        "val_loss": 1.0814885241644723,
        "train_loss": 0.9625795414814582
      },
      {
        "epoch": 319,
        "reward": 0.03329494968056679,
        "val_loss": 1.1043134587151664,
        "train_loss": 1.0763477407968962
      },
      {
        "epoch": 320,
        "reward": 0.03959332033991814,
        "val_loss": 0.7707750967570713,
        "train_loss": 0.819282907849321
      },
      {
        "epoch": 321,
        "reward": 0.030852606520056725,
        "val_loss": 1.292578969682966,
        "train_loss": 0.835291367310744
      },
      {
        "epoch": 322,
        "reward": 0.035942286252975464,
        "val_loss": 0.942444737468447,
        "train_loss": 0.9625316193470588
      },
      {
        "epoch": 323,
        "reward": 0.03980555012822151,
        "val_loss": 0.7622410314423698,
        "train_loss": 0.8332803982954758
      },
      {
        "epoch": 324,
        "reward": 0.037446584552526474,
        "val_loss": 0.865538477897644,
        "train_loss": 0.8525761629526432
      },
      {
        "epoch": 325,
        "reward": 0.03455015644431114,
        "val_loss": 1.0228702936853682,
        "train_loss": 0.948955639050557
      },
      {
        "epoch": 326,
        "reward": 0.025687161833047867,
        "val_loss": 1.8846285002572196,
        "train_loss": 0.9890642871077244
      },
      {
        "epoch": 327,
        "reward": 0.04116775840520859,
        "val_loss": 0.7106112156595502,
        "train_loss": 0.882149242151242
      },
      {
        "epoch": 328,
        "reward": 0.039166007190942764,
        "val_loss": 0.7883868387767247,
        "train_loss": 0.7705565679531831
      },
      {
        "epoch": 329,
        "reward": 0.029657354578375816,
        "val_loss": 1.402318068913051,
        "train_loss": 0.8617238494066092
      },
      {
        "epoch": 330,
        "reward": 0.04090551286935806,
        "val_loss": 0.7201455703803471,
        "train_loss": 0.9188626798299643
      },
      {
        "epoch": 331,
        "reward": 0.03785961866378784,
        "val_loss": 0.8460296562739781,
        "train_loss": 0.7658654852555349
      },
      {
        "epoch": 332,
        "reward": 0.03988147899508476,
        "val_loss": 0.7592213238988604,
        "train_loss": 0.892307853165011
      },
      {
        "epoch": 333,
        "reward": 0.04101167246699333,
        "val_loss": 0.7162636263029916,
        "train_loss": 0.8109328357072977
      },
      {
        "epoch": 334,
        "reward": 0.03693750873208046,
        "val_loss": 0.8905020526477269,
        "train_loss": 0.8710680856154516
      },
      {
        "epoch": 335,
        "reward": 0.040578074753284454,
        "val_loss": 0.7323144844600132,
        "train_loss": 0.8697413137325873
      },
      {
        "epoch": 336,
        "reward": 0.03909787908196449,
        "val_loss": 0.7912488239152091,
        "train_loss": 0.8296876274622403
      },
      {
        "epoch": 337,
        "reward": 0.037955667823553085,
        "val_loss": 0.8415851933615548,
        "train_loss": 0.8000338409955685
      },
      {
        "epoch": 338,
        "reward": 0.031573716551065445,
        "val_loss": 1.2323753578322274,
        "train_loss": 1.0261960121301503
      },
      {
        "epoch": 339,
        "reward": 0.03269655257463455,
        "val_loss": 1.1465228285108293,
        "train_loss": 0.8574667301055832
      },
      {
        "epoch": 340,
        "reward": 0.03397941216826439,
        "val_loss": 1.058771354811532,
        "train_loss": 1.0246704129072337
      },
      {
        "epoch": 341,
        "reward": 0.035209011286497116,
        "val_loss": 0.9836034178733826,
        "train_loss": 0.9108883131008881
      },
      {
        "epoch": 342,
        "reward": 0.035978879779577255,
        "val_loss": 0.9404569864273071,
        "train_loss": 1.021677124958772
      },
      {
        "epoch": 343,
        "reward": 0.0316806398332119,
        "val_loss": 1.2237999609538488,
        "train_loss": 0.9161964242274945
      },
      {
        "epoch": 344,
        "reward": 0.03463607653975487,
        "val_loss": 1.0176208530153548,
        "train_loss": 0.8883640605669755
      },
      {
        "epoch": 345,
        "reward": 0.02965918742120266,
        "val_loss": 1.402139629636492,
        "train_loss": 0.8247123956680298
      },
      {
        "epoch": 346,
        "reward": 0.04037736356258392,
        "val_loss": 0.7399224383490426,
        "train_loss": 1.054254962847783
      },
      {
        "epoch": 347,
        "reward": 0.030546078458428383,
        "val_loss": 1.3194853493145533,
        "train_loss": 0.8199509095687133
      },
      {
        "epoch": 348,
        "reward": 0.03240291774272919,
        "val_loss": 1.1681053042411804,
        "train_loss": 0.8796863315197138
      },
      {
        "epoch": 349,
        "reward": 0.040174972265958786,
        "val_loss": 0.7477116329329354,
        "train_loss": 0.8563339824859912
      },
      {
        "epoch": 350,
        "reward": 0.04059809446334839,
        "val_loss": 0.7315619162150792,
        "train_loss": 1.0365108641294332
      },
      {
        "epoch": 351,
        "reward": 0.029077595099806786,
        "val_loss": 1.4605393239430018,
        "train_loss": 0.968662847406589
      },
      {
        "epoch": 352,
        "reward": 0.035197462886571884,
        "val_loss": 0.9842724970408848,
        "train_loss": 0.9921797015346013
      },
      {
        "epoch": 353,
        "reward": 0.03779697045683861,
        "val_loss": 0.8489471248217991,
        "train_loss": 0.845207562813392
      },
      {
        "epoch": 354,
        "reward": 0.03669719025492668,
        "val_loss": 0.9026537452425275,
        "train_loss": 0.7859727857777705
      },
      {
        "epoch": 355,
        "reward": 0.034969039261341095,
        "val_loss": 0.9976455654416766,
        "train_loss": 0.80154622059602
      },
      {
        "epoch": 356,
        "reward": 0.03709550201892853,
        "val_loss": 0.8826429162706647,
        "train_loss": 0.8153704459277483
      },
      {
        "epoch": 357,
        "reward": 0.03224689140915871,
        "val_loss": 1.179816790989467,
        "train_loss": 0.8726350756791922
      },
      {
        "epoch": 358,
        "reward": 0.03919927403330803,
        "val_loss": 0.7869946190289089,
        "train_loss": 0.8508292762562633
      },
      {
        "epoch": 359,
        "reward": 0.032297905534505844,
        "val_loss": 1.1759686980928694,
        "train_loss": 0.8418393089221075
      },
      {
        "epoch": 360,
        "reward": 0.03396489843726158,
        "val_loss": 1.0597086123057775,
        "train_loss": 0.88448951443514
      },
      {
        "epoch": 361,
        "reward": 0.039644576609134674,
        "val_loss": 0.7687014085905892,
        "train_loss": 0.8142721675909482
      },
      {
        "epoch": 362,
        "reward": 0.04017535224556923,
        "val_loss": 0.7476968509810311,
        "train_loss": 0.8738922557005515
      },
      {
        "epoch": 363,
        "reward": 0.03820648416876793,
        "val_loss": 0.8301388536180768,
        "train_loss": 0.8551776357568227
      },
      {
        "epoch": 364,
        "reward": 0.03827367350459099,
        "val_loss": 0.8271110824176243,
        "train_loss": 0.9270632725495559
      },
      {
        "epoch": 365,
        "reward": 0.03656107932329178,
        "val_loss": 0.9096441779817853,
        "train_loss": 0.8430936087209445
      },
      {
        "epoch": 366,
        "reward": 0.0407346747815609,
        "val_loss": 0.7264573914664132,
        "train_loss": 0.9135423165101272
      },
      {
        "epoch": 367,
        "reward": 0.03318324312567711,
        "val_loss": 1.1120183425290244,
        "train_loss": 0.9708737112008609
      },
      {
        "epoch": 368,
        "reward": 0.03601657971739769,
        "val_loss": 0.9384159105164664,
        "train_loss": 0.941559397830413
      },
      {
        "epoch": 369,
        "reward": 0.026778846979141235,
        "val_loss": 1.7302165712629045,
        "train_loss": 0.9981629619231591
      },
      {
        "epoch": 370,
        "reward": 0.02647869661450386,
        "val_loss": 1.7707565171378,
        "train_loss": 0.8970202780686892
      },
      {
        "epoch": 371,
        "reward": 0.033824630081653595,
        "val_loss": 1.0688260282788957,
        "train_loss": 0.9962744529430683
      },
      {
        "epoch": 372,
        "reward": 0.03957526385784149,
        "val_loss": 0.7715076548712594,
        "train_loss": 0.9295110358641698
      },
      {
        "epoch": 373,
        "reward": 0.036382388323545456,
        "val_loss": 0.9189423663275582,
        "train_loss": 0.9027577890799596
      },
      {
        "epoch": 374,
        "reward": 0.03862951695919037,
        "val_loss": 0.8113424607685634,
        "train_loss": 0.8907950107867901
      },
      {
        "epoch": 375,
        "reward": 0.03972085565328598,
        "val_loss": 0.765630202633994,
        "train_loss": 0.8279559767016997
      },
      {
        "epoch": 376,
        "reward": 0.03678423911333084,
        "val_loss": 0.8982244304248265,
        "train_loss": 0.9575276443591485
      },
      {
        "epoch": 377,
        "reward": 0.03518891707062721,
        "val_loss": 0.9847680074828011,
        "train_loss": 1.026582582638814
      },
      {
        "epoch": 378,
        "reward": 0.027902066707611084,
        "val_loss": 1.5900413819721766,
        "train_loss": 0.853854949084612
      },
      {
        "epoch": 379,
        "reward": 0.03857510909438133,
        "val_loss": 0.8137247562408447,
        "train_loss": 1.094340429856227
      },
      {
        "epoch": 380,
        "reward": 0.03490143641829491,
        "val_loss": 1.001654429095132,
        "train_loss": 0.9279987651568192
      },
      {
        "epoch": 381,
        "reward": 0.03657190874218941,
        "val_loss": 0.9090851715632847,
        "train_loss": 0.837311673622865
      },
      {
        "epoch": 382,
        "reward": 0.03147342801094055,
        "val_loss": 1.2404981681278773,
        "train_loss": 0.8964692193728226
      },
      {
        "epoch": 383,
        "reward": 0.03964792937040329,
        "val_loss": 0.7685658165386745,
        "train_loss": 0.9228791434031266
      },
      {
        "epoch": 384,
        "reward": 0.04027304798364639,
        "val_loss": 0.7439223613057818,
        "train_loss": 0.867762973675361
      },
      {
        "epoch": 385,
        "reward": 0.03570513427257538,
        "val_loss": 0.955475458077022,
        "train_loss": 0.7715241496379559
      },
      {
        "epoch": 386,
        "reward": 0.038342688232660294,
        "val_loss": 0.8240179589816502,
        "train_loss": 0.8832901899631207
      },
      {
        "epoch": 387,
        "reward": 0.038116808980703354,
        "val_loss": 0.8342049632753644,
        "train_loss": 0.8841403894699537
      },
      {
        "epoch": 388,
        "reward": 0.04133802279829979,
        "val_loss": 0.7045190760067531,
        "train_loss": 0.8084088369057729
      },
      {
        "epoch": 389,
        "reward": 0.03471417725086212,
        "val_loss": 1.0128827776227678,
        "train_loss": 0.8160213438364176
      },
      {
        "epoch": 390,
        "reward": 0.03971827030181885,
        "val_loss": 0.7657338721411568,
        "train_loss": 1.0135410175873683
      },
      {
        "epoch": 391,
        "reward": 0.03785335272550583,
        "val_loss": 0.8463207738740104,
        "train_loss": 0.9968393181379025
      },
      {
        "epoch": 392,
        "reward": 0.040788739919662476,
        "val_loss": 0.7244511927877154,
        "train_loss": 0.7841395437717438
      },
      {
        "epoch": 393,
        "reward": 0.04060428589582443,
        "val_loss": 0.7313294112682343,
        "train_loss": 0.9271119099396926
      },
      {
        "epoch": 394,
        "reward": 0.041003089398145676,
        "val_loss": 0.7165762952395848,
        "train_loss": 0.846871004654811
      },
      {
        "epoch": 395,
        "reward": 0.03870311751961708,
        "val_loss": 0.8081358415739877,
        "train_loss": 0.8472910454640021
      },
      {
        "epoch": 396,
        "reward": 0.03461616858839989,
        "val_loss": 1.0188336031777518,
        "train_loss": 0.8158557979533305
      },
      {
        "epoch": 397,
        "reward": 0.028905173763632774,
        "val_loss": 1.478540531226567,
        "train_loss": 0.9084311249450996
      },
      {
        "epoch": 398,
        "reward": 0.03686441853642464,
        "val_loss": 0.8941723619188581,
        "train_loss": 0.9810743286104228
      },
      {
        "epoch": 399,
        "reward": 0.03966280445456505,
        "val_loss": 0.7679659383637565,
        "train_loss": 0.7822959245397494
      },
      {
        "epoch": 400,
        "reward": 0.03160979598760605,
        "val_loss": 1.2294720581599645,
        "train_loss": 0.7762086116350614
      },
      {
        "epoch": 401,
        "reward": 0.0363137423992157,
        "val_loss": 0.9225512402398246,
        "train_loss": 0.9087579961006458
      },
      {
        "epoch": 402,
        "reward": 0.03477240726351738,
        "val_loss": 1.0093717660222734,
        "train_loss": 0.862857019672027
      },
      {
        "epoch": 403,
        "reward": 0.04016860947012901,
        "val_loss": 0.7479584813117981,
        "train_loss": 0.7897381537790912
      },
      {
        "epoch": 404,
        "reward": 0.037179701030254364,
        "val_loss": 0.8784963147980827,
        "train_loss": 0.7764802712660569
      },
      {
        "epoch": 405,
        "reward": 0.029771283268928528,
        "val_loss": 1.3912793227604456,
        "train_loss": 0.887706492955868
      },
      {
        "epoch": 406,
        "reward": 0.03767528384923935,
        "val_loss": 0.8546561513628278,
        "train_loss": 0.8424132420466497
      },
      {
        "epoch": 407,
        "reward": 0.04015485569834709,
        "val_loss": 0.7484923260552543,
        "train_loss": 0.7760206690201392
      },
      {
        "epoch": 408,
        "reward": 0.035597484558820724,
        "val_loss": 0.9614778075899396,
        "train_loss": 0.8213095573278574
      },
      {
        "epoch": 409,
        "reward": 0.02907515875995159,
        "val_loss": 1.4607915537697929,
        "train_loss": 0.8819956576021818
      },
      {
        "epoch": 410,
        "reward": 0.0392129123210907,
        "val_loss": 0.786425062588283,
        "train_loss": 0.8802287211784949
      },
      {
        "epoch": 411,
        "reward": 0.03857606649398804,
        "val_loss": 0.8136827179363796,
        "train_loss": 0.7801129525670638
      },
      {
        "epoch": 412,
        "reward": 0.037169475108385086,
        "val_loss": 0.8789982710565839,
        "train_loss": 0.8132502322013562
      },
      {
        "epoch": 413,
        "reward": 0.031263675540685654,
        "val_loss": 1.2577443165438515,
        "train_loss": 0.8160888409385314
      },
      {
        "epoch": 414,
        "reward": 0.032855089753866196,
        "val_loss": 1.1351125495774406,
        "train_loss": 0.967566423691236
      },
      {
        "epoch": 415,
        "reward": 0.03330366313457489,
        "val_loss": 1.103715819971902,
        "train_loss": 1.1061923340536082
      },
      {
        "epoch": 416,
        "reward": 0.04069311171770096,
        "val_loss": 0.7280052815164838,
        "train_loss": 1.007055170260943
      },
      {
        "epoch": 417,
        "reward": 0.03955283388495445,
        "val_loss": 0.7724189162254333,
        "train_loss": 0.823517001592196
      },
      {
        "epoch": 418,
        "reward": 0.025777986273169518,
        "val_loss": 1.8710230078016008,
        "train_loss": 0.8138535481232864
      },
      {
        "epoch": 419,
        "reward": 0.0385960154235363,
        "val_loss": 0.8128083433423724,
        "train_loss": 0.9884480788157537
      },
      {
        "epoch": 420,
        "reward": 0.02992011420428753,
        "val_loss": 1.3770501443317957,
        "train_loss": 0.8882559661646016
      },
      {
        "epoch": 421,
        "reward": 0.04063010588288307,
        "val_loss": 0.7303607548986163,
        "train_loss": 0.852048838367829
      },
      {
        "epoch": 422,
        "reward": 0.03896971791982651,
        "val_loss": 0.7966743963105338,
        "train_loss": 0.7666572819535549
      },
      {
        "epoch": 423,
        "reward": 0.026645630598068237,
        "val_loss": 1.7480390582765852,
        "train_loss": 0.8441836604705224
      },
      {
        "epoch": 424,
        "reward": 0.03746197745203972,
        "val_loss": 0.8647997805050441,
        "train_loss": 1.2836390596169691
      },
      {
        "epoch": 425,
        "reward": 0.04001548886299133,
        "val_loss": 0.7539340002196175,
        "train_loss": 0.8516237099583333
      },
      {
        "epoch": 426,
        "reward": 0.04072674736380577,
        "val_loss": 0.7267524174281529,
        "train_loss": 0.7710026055574417
      },
      {
        "epoch": 427,
        "reward": 0.03167591616511345,
        "val_loss": 1.2241769688470023,
        "train_loss": 0.8363755161945636
      },
      {
        "epoch": 428,
        "reward": 0.026119975373148918,
        "val_loss": 1.8210699728557043,
        "train_loss": 0.9313713322377365
      },
      {
        "epoch": 429,
        "reward": 0.03580036386847496,
        "val_loss": 0.9502114057540894,
        "train_loss": 0.9979070900724485
      },
      {
        "epoch": 430,
        "reward": 0.0350797139108181,
        "val_loss": 0.9911331789834159,
        "train_loss": 0.866317677956361
      },
      {
        "epoch": 431,
        "reward": 0.03506387025117874,
        "val_loss": 0.9920615128108433,
        "train_loss": 0.9709595820078483
      },
      {
        "epoch": 432,
        "reward": 0.0398995615541935,
        "val_loss": 0.7585047653743199,
        "train_loss": 0.8415376154276041
      },
      {
        "epoch": 433,
        "reward": 0.03471789136528969,
        "val_loss": 1.0126584938594274,
        "train_loss": 0.8229079086046952
      },
      {
        "epoch": 434,
        "reward": 0.034643303602933884,
        "val_loss": 1.0171808004379272,
        "train_loss": 0.9427230941274991
      },
      {
        "epoch": 435,
        "reward": 0.038342054933309555,
        "val_loss": 0.8240464670317513,
        "train_loss": 0.8453101630394275
      },
      {
        "epoch": 436,
        "reward": 0.03956965357065201,
        "val_loss": 0.7717355489730835,
        "train_loss": 0.9444085313723638
      },
      {
        "epoch": 437,
        "reward": 0.03994358703494072,
        "val_loss": 0.7567642075674874,
        "train_loss": 0.803362117936978
      },
      {
        "epoch": 438,
        "reward": 0.03435607999563217,
        "val_loss": 1.0348754354885645,
        "train_loss": 0.8297998400834891
      },
      {
        "epoch": 439,
        "reward": 0.03430242836475372,
        "val_loss": 1.0382304702486311,
        "train_loss": 0.9378676299865429
      },
      {
        "epoch": 440,
        "reward": 0.0349026694893837,
        "val_loss": 1.0015810898372106,
        "train_loss": 0.8674971232047448
      },
      {
        "epoch": 441,
        "reward": 0.0404483936727047,
        "val_loss": 0.7372168898582458,
        "train_loss": 0.9212300055302106
      },
      {
        "epoch": 442,
        "reward": 0.03886432200670242,
        "val_loss": 0.8011767864227295,
        "train_loss": 0.8393718829521766
      },
      {
        "epoch": 443,
        "reward": 0.03181999549269676,
        "val_loss": 1.2127553990909032,
        "train_loss": 0.8167031004738349
      },
      {
        "epoch": 444,
        "reward": 0.04064536839723587,
        "val_loss": 0.7297892485346112,
        "train_loss": 0.8980510739179758
      },
      {
        "epoch": 445,
        "reward": 0.03932085260748863,
        "val_loss": 0.7819374373980931,
        "train_loss": 0.8274906759078686
      },
      {
        "epoch": 446,
        "reward": 0.03515748307108879,
        "val_loss": 0.9865939957754952,
        "train_loss": 0.8955045892642095
      },
      {
        "epoch": 447,
        "reward": 0.03894360736012459,
        "val_loss": 0.7977863209588187,
        "train_loss": 0.7656120937859109
      },
      {
        "epoch": 448,
        "reward": 0.039680227637290955,
        "val_loss": 0.767263582774571,
        "train_loss": 0.7761448722046155
      },
      {
        "epoch": 449,
        "reward": 0.0378485769033432,
        "val_loss": 0.8465426904814584,
        "train_loss": 0.8117687266606551
      },
      {
        "epoch": 450,
        "reward": 0.04176923260092735,
        "val_loss": 0.6894271714346749,
        "train_loss": 0.8436712485093337
      },
      {
        "epoch": 451,
        "reward": 0.033427558839321136,
        "val_loss": 1.095268828528268,
        "train_loss": 0.8282954950745289
      },
      {
        "epoch": 452,
        "reward": 0.036961302161216736,
        "val_loss": 0.8893118926456997,
        "train_loss": 0.8147910711212227
      },
      {
        "epoch": 453,
        "reward": 0.03836267068982124,
        "val_loss": 0.8231256348746163,
        "train_loss": 0.8901950189700494
      },
      {
        "epoch": 454,
        "reward": 0.03774687275290489,
        "val_loss": 0.8512905325208392,
        "train_loss": 0.8346040707368118
      },
      {
        "epoch": 455,
        "reward": 0.038667984306812286,
        "val_loss": 0.809664283479963,
        "train_loss": 0.8429925441741943
      },
      {
        "epoch": 456,
        "reward": 0.03543657809495926,
        "val_loss": 0.9705529042652675,
        "train_loss": 0.895694212271617
      },
      {
        "epoch": 457,
        "reward": 0.03258107230067253,
        "val_loss": 1.1549403667449951,
        "train_loss": 0.8016480356454849
      },
      {
        "epoch": 458,
        "reward": 0.03954855725169182,
        "val_loss": 0.7725929703031268,
        "train_loss": 1.0770317293130434
      },
      {
        "epoch": 459,
        "reward": 0.03557385131716728,
        "val_loss": 0.9628029635974339,
        "train_loss": 0.9098806066008714
      },
      {
        "epoch": 460,
        "reward": 0.02944045700132847,
        "val_loss": 1.4236931971141271,
        "train_loss": 0.8883560987619253
      },
      {
        "epoch": 461,
        "reward": 0.027616096660494804,
        "val_loss": 1.6240974494389124,
        "train_loss": 0.9186860850224128
      },
      {
        "epoch": 462,
        "reward": 0.027827445417642593,
        "val_loss": 1.5988258634294783,
        "train_loss": 1.1631067853707533
      },
      {
        "epoch": 463,
        "reward": 0.032895758748054504,
        "val_loss": 1.132212485585894,
        "train_loss": 1.076091156556056
      },
      {
        "epoch": 464,
        "reward": 0.03715705871582031,
        "val_loss": 0.8796084267752511,
        "train_loss": 0.8377632865538964
      },
      {
        "epoch": 465,
        "reward": 0.038843460381031036,
        "val_loss": 0.8020724398749215,
        "train_loss": 0.8841721484294305
      },
      {
        "epoch": 466,
        "reward": 0.03890478238463402,
        "val_loss": 0.7994439772197178,
        "train_loss": 0.776809968197575
      },
      {
        "epoch": 467,
        "reward": 0.03777722641825676,
        "val_loss": 0.8498695663043431,
        "train_loss": 0.8253312285971612
      },
      {
        "epoch": 468,
        "reward": 0.04062087461352348,
        "val_loss": 0.7307069982801165,
        "train_loss": 0.8190744060736436
      },
      {
        "epoch": 469,
        "reward": 0.03603256866335869,
        "val_loss": 0.9375521285193307,
        "train_loss": 0.9590088793864617
      },
      {
        "epoch": 470,
        "reward": 0.0398615300655365,
        "val_loss": 0.7600128735814776,
        "train_loss": 0.7717598269765193
      },
      {
        "epoch": 471,
        "reward": 0.03421467915177345,
        "val_loss": 1.0437522189957755,
        "train_loss": 0.8370064061421615
      },
      {
        "epoch": 472,
        "reward": 0.04050464555621147,
        "val_loss": 0.735084457056863,
        "train_loss": 0.9381342965822953
      },
      {
        "epoch": 473,
        "reward": 0.03719383105635643,
        "val_loss": 0.8778030957494464,
        "train_loss": 0.8298702881886408
      },
      {
        "epoch": 474,
        "reward": 0.033702488988637924,
        "val_loss": 1.0768593123980932,
        "train_loss": 0.8584493215267475
      },
      {
        "epoch": 475,
        "reward": 0.04112204536795616,
        "val_loss": 0.712259760924748,
        "train_loss": 0.9973345077954806
      },
      {
        "epoch": 476,
        "reward": 0.04020249471068382,
        "val_loss": 0.7466454250471932,
        "train_loss": 0.8080220733984158
      },
      {
        "epoch": 477,
        "reward": 0.03787733241915703,
        "val_loss": 0.8452073122773852,
        "train_loss": 0.7936990284002744
      },
      {
        "epoch": 478,
        "reward": 0.03882632777094841,
        "val_loss": 0.8028091021946498,
        "train_loss": 0.8467642980126234
      },
      {
        "epoch": 479,
        "reward": 0.026609351858496666,
        "val_loss": 1.752939326422555,
        "train_loss": 0.9045808292352236
      },
      {
        "epoch": 480,
        "reward": 0.029514659196138382,
        "val_loss": 1.4163273062024797,
        "train_loss": 1.0706013303536634
      },
      {
        "epoch": 481,
        "reward": 0.040325772017240524,
        "val_loss": 0.7418966804231916,
        "train_loss": 1.0587133730833347
      },
      {
        "epoch": 482,
        "reward": 0.03963126242160797,
        "val_loss": 0.7692392298153469,
        "train_loss": 0.7933791944613824
      },
      {
        "epoch": 483,
        "reward": 0.03340798243880272,
        "val_loss": 1.0965972989797592,
        "train_loss": 0.8127021012971034
      },
      {
        "epoch": 484,
        "reward": 0.038542766124010086,
        "val_loss": 0.8151459523609706,
        "train_loss": 0.9599241751890916
      },
      {
        "epoch": 485,
        "reward": 0.03933210298418999,
        "val_loss": 0.7814719506672451,
        "train_loss": 0.8401467404686488
      },
      {
        "epoch": 486,
        "reward": 0.03776168078184128,
        "val_loss": 0.8505971687180656,
        "train_loss": 0.8224208847834513
      },
      {
        "epoch": 487,
        "reward": 0.03420408070087433,
        "val_loss": 1.0444223114422388,
        "train_loss": 0.9003137304232671
      },
      {
        "epoch": 488,
        "reward": 0.03374471515417099,
        "val_loss": 1.0740718756403242,
        "train_loss": 0.9268955198618082
      },
      {
        "epoch": 489,
        "reward": 0.03983268514275551,
        "val_loss": 0.7611598457608905,
        "train_loss": 0.8346534806948441
      },
      {
        "epoch": 490,
        "reward": 0.04135708883404732,
        "val_loss": 0.7038416010992867,
        "train_loss": 1.0542183220386505
      },
      {
        "epoch": 491,
        "reward": 0.03655420243740082,
        "val_loss": 0.9099994770118168,
        "train_loss": 0.8310187504841731
      },
      {
        "epoch": 492,
        "reward": 0.03815365955233574,
        "val_loss": 0.8325306262288775,
        "train_loss": 0.8192874858012567
      },
      {
        "epoch": 493,
        "reward": 0.040855538100004196,
        "val_loss": 0.721983620098659,
        "train_loss": 0.9708633056053748
      },
      {
        "epoch": 494,
        "reward": 0.03979171812534332,
        "val_loss": 0.7627930385725838,
        "train_loss": 0.8894240718621474
      },
      {
        "epoch": 495,
        "reward": 0.033194851130247116,
        "val_loss": 1.11121381180627,
        "train_loss": 0.8648470651644927
      },
      {
        "epoch": 496,
        "reward": 0.035662610083818436,
        "val_loss": 0.9578400254249573,
        "train_loss": 0.8704008601892453
      },
      {
        "epoch": 497,
        "reward": 0.04021856561303139,
        "val_loss": 0.7460238209792546,
        "train_loss": 0.9444644496991084
      },
      {
        "epoch": 498,
        "reward": 0.04050126299262047,
        "val_loss": 0.7352124622889927,
        "train_loss": 0.9394928881755242
      },
      {
        "epoch": 499,
        "reward": 0.032604482024908066,
        "val_loss": 1.1532267587525504,
        "train_loss": 0.9394971774174616
      },
      {
        "epoch": 500,
        "reward": 0.03174158185720444,
        "val_loss": 1.2189521278653825,
        "train_loss": 0.909485285098736
      },
      {
        "epoch": 501,
        "reward": 0.03590625151991844,
        "val_loss": 0.9444078888211932,
        "train_loss": 0.9520338853964438
      },
      {
        "epoch": 502,
        "reward": 0.040918271988630295,
        "val_loss": 0.7196774567876544,
        "train_loss": 0.8729983316018031
      },
      {
        "epoch": 503,
        "reward": 0.03477617725729942,
        "val_loss": 1.0091450129236494,
        "train_loss": 0.759289260667104
      },
      {
        "epoch": 504,
        "reward": 0.04000093415379524,
        "val_loss": 0.7545057024274554,
        "train_loss": 0.9870237180819879
      },
      {
        "epoch": 505,
        "reward": 0.03749961033463478,
        "val_loss": 0.8629973445619855,
        "train_loss": 0.8038075838524562
      },
      {
        "epoch": 506,
        "reward": 0.03182632103562355,
        "val_loss": 1.212257249014718,
        "train_loss": 0.9641111470185794
      },
      {
        "epoch": 507,
        "reward": 0.03734306991100311,
        "val_loss": 0.8705310651234218,
        "train_loss": 0.8324456077355605
      },
      {
        "epoch": 508,
        "reward": 0.03663382679224014,
        "val_loss": 0.9058981878416879,
        "train_loss": 0.8240713236423639
      },
      {
        "epoch": 509,
        "reward": 0.040327463299036026,
        "val_loss": 0.7418320008686611,
        "train_loss": 0.8935630436127002
      },
      {
        "epoch": 510,
        "reward": 0.03538914769887924,
        "val_loss": 0.9732519558497837,
        "train_loss": 0.7897805382425969
      },
      {
        "epoch": 511,
        "reward": 0.02969018556177616,
        "val_loss": 1.399124026298523,
        "train_loss": 0.9404545332520053
      },
      {
        "epoch": 512,
        "reward": 0.030001694336533546,
        "val_loss": 1.3693408795765467,
        "train_loss": 1.0231414024646466
      },
      {
        "epoch": 513,
        "reward": 0.040478844195604324,
        "val_loss": 0.7360614580767495,
        "train_loss": 0.9100084087023368
      },
      {
        "epoch": 514,
        "reward": 0.02820778265595436,
        "val_loss": 1.5547842298235213,
        "train_loss": 0.8169392622434176
      },
      {
        "epoch": 515,
        "reward": 0.03961648792028427,
        "val_loss": 0.7698368685586112,
        "train_loss": 1.3492478086398199
      },
      {
        "epoch": 516,
        "reward": 0.040748756378889084,
        "val_loss": 0.7259342074394226,
        "train_loss": 0.7991816676579989
      },
      {
        "epoch": 517,
        "reward": 0.03692838177084923,
        "val_loss": 0.8909592883927482,
        "train_loss": 0.84271439909935
      },
      {
        "epoch": 518,
        "reward": 0.03233354911208153,
        "val_loss": 1.1732910445758276,
        "train_loss": 0.8725548077088136
      },
      {
        "epoch": 519,
        "reward": 0.04083621874451637,
        "val_loss": 0.7226960914475578,
        "train_loss": 0.9651439006511981
      },
      {
        "epoch": 520,
        "reward": 0.03797375410795212,
        "val_loss": 0.8407519970621381,
        "train_loss": 0.8059119221109611
      },
      {
        "epoch": 521,
        "reward": 0.028108442202210426,
        "val_loss": 1.5661135230745589,
        "train_loss": 0.9264016426526583
      },
      {
        "epoch": 522,
        "reward": 0.0359504260122776,
        "val_loss": 0.9420019813946315,
        "train_loss": 0.9870418516489176
      },
      {
        "epoch": 523,
        "reward": 0.03442804142832756,
        "val_loss": 1.0303999866758073,
        "train_loss": 0.8648968384816096
      },
      {
        "epoch": 524,
        "reward": 0.03923812881112099,
        "val_loss": 0.7853732534817287,
        "train_loss": 1.1004999165351574
      },
      {
        "epoch": 525,
        "reward": 0.038477614521980286,
        "val_loss": 0.8180195391178131,
        "train_loss": 0.8742404671815726
      },
      {
        "epoch": 526,
        "reward": 0.040420763194561005,
        "val_loss": 0.7382676601409912,
        "train_loss": 0.8719546945335773
      },
      {
        "epoch": 527,
        "reward": 0.04038647934794426,
        "val_loss": 0.73957445366042,
        "train_loss": 0.8831725579041702
      },
      {
        "epoch": 528,
        "reward": 0.039650771766901016,
        "val_loss": 0.7684512223516192,
        "train_loss": 0.8923592957166525
      },
      {
        "epoch": 529,
        "reward": 0.03843037411570549,
        "val_loss": 0.8201125008719308,
        "train_loss": 0.8657645055880914
      },
      {
        "epoch": 530,
        "reward": 0.03966382518410683,
        "val_loss": 0.7679245301655361,
        "train_loss": 0.8161482742199531
      },
      {
        "epoch": 531,
        "reward": 0.034953273832798004,
        "val_loss": 0.9985783440726144,
        "train_loss": 0.8612413796094748
      },
      {
        "epoch": 532,
        "reward": 0.034584250301122665,
        "val_loss": 1.020782619714737,
        "train_loss": 0.8459699062200693
      },
      {
        "epoch": 533,
        "reward": 0.03716808184981346,
        "val_loss": 0.879066697188786,
        "train_loss": 0.8454579109182725
      },
      {
        "epoch": 534,
        "reward": 0.03713604062795639,
        "val_loss": 0.880642967564719,
        "train_loss": 0.9637859692940345
      },
      {
        "epoch": 535,
        "reward": 0.03625550866127014,
        "val_loss": 0.9256290623119899,
        "train_loss": 0.7843022115910292
      },
      {
        "epoch": 536,
        "reward": 0.03695568069815636,
        "val_loss": 0.8895930647850037,
        "train_loss": 0.8125096101027268
      },
      {
        "epoch": 537,
        "reward": 0.038666531443595886,
        "val_loss": 0.8097274388585772,
        "train_loss": 0.871119907985513
      },
      {
        "epoch": 538,
        "reward": 0.036906614899635315,
        "val_loss": 0.8920506749834333,
        "train_loss": 0.8061628891871526
      },
      {
        "epoch": 539,
        "reward": 0.03613113984465599,
        "val_loss": 0.9322530712400164,
        "train_loss": 0.8897402584552765
      },
      {
        "epoch": 540,
        "reward": 0.030366262421011925,
        "val_loss": 1.3356536626815796,
        "train_loss": 0.9167321003400363
      },
      {
        "epoch": 541,
        "reward": 0.032477524131536484,
        "val_loss": 1.1625658443995885,
        "train_loss": 0.9425892680883408
      },
      {
        "epoch": 542,
        "reward": 0.04106386378407478,
        "val_loss": 0.7143662359033313,
        "train_loss": 0.9684160879025092
      },
      {
        "epoch": 543,
        "reward": 0.038205038756132126,
        "val_loss": 0.830204325062888,
        "train_loss": 0.864351572898718
      },
      {
        "epoch": 544,
        "reward": 0.034524012356996536,
        "val_loss": 1.0244754978588648,
        "train_loss": 1.0929121810656328
      },
      {
        "epoch": 545,
        "reward": 0.03585387021303177,
        "val_loss": 0.947272219828197,
        "train_loss": 0.8680003061890602
      },
      {
        "epoch": 546,
        "reward": 0.04133186861872673,
        "val_loss": 0.7047381145613534,
        "train_loss": 0.9460358367516444
      },
      {
        "epoch": 547,
        "reward": 0.037272945046424866,
        "val_loss": 0.8739370022501264,
        "train_loss": 0.8146904087983645
      },
      {
        "epoch": 548,
        "reward": 0.040568698197603226,
        "val_loss": 0.7326673354421344,
        "train_loss": 0.9890282429181613
      },
      {
        "epoch": 549,
        "reward": 0.038795989006757736,
        "val_loss": 0.8041160702705383,
        "train_loss": 0.7770153008974515
      },
      {
        "epoch": 550,
        "reward": 0.036115776747465134,
        "val_loss": 0.9330759218760899,
        "train_loss": 0.94326834495251
      },
      {
        "epoch": 551,
        "reward": 0.03907465934753418,
        "val_loss": 0.7922277961458478,
        "train_loss": 0.7514244272158697
      },
      {
        "epoch": 552,
        "reward": 0.03855200111865997,
        "val_loss": 0.8147396785872323,
        "train_loss": 0.8251002877950668
      },
      {
        "epoch": 553,
        "reward": 0.032777562737464905,
        "val_loss": 1.1406716193471635,
        "train_loss": 0.9316115310558906
      },
      {
        "epoch": 554,
        "reward": 0.03683076798915863,
        "val_loss": 0.895869757447924,
        "train_loss": 1.0470031178914583
      },
      {
        "epoch": 555,
        "reward": 0.040585797280073166,
        "val_loss": 0.7320240650858197,
        "train_loss": 0.9174303068564489
      },
      {
        "epoch": 556,
        "reward": 0.03454248607158661,
        "val_loss": 1.0233409234455653,
        "train_loss": 0.7596696374508051
      },
      {
        "epoch": 557,
        "reward": 0.040174201130867004,
        "val_loss": 0.7477415714945111,
        "train_loss": 0.9131074845790863
      },
      {
        "epoch": 558,
        "reward": 0.03942947834730148,
        "val_loss": 0.777459340436118,
        "train_loss": 0.8030615403101995
      },
      {
        "epoch": 559,
        "reward": 0.032377369701862335,
        "val_loss": 1.1700114182063512,
        "train_loss": 0.8008927009426631
      },
      {
        "epoch": 560,
        "reward": 0.030688345432281494,
        "val_loss": 1.3068958350590296,
        "train_loss": 0.9766592520933884
      },
      {
        "epoch": 561,
        "reward": 0.03689087554812431,
        "val_loss": 0.8928412624767849,
        "train_loss": 1.0114444356698256
      },
      {
        "epoch": 562,
        "reward": 0.03951127827167511,
        "val_loss": 0.7741115093231201,
        "train_loss": 0.7950371847702906
      },
      {
        "epoch": 563,
        "reward": 0.03571740537881851,
        "val_loss": 0.9547948496682304,
        "train_loss": 0.8653508103810824
      },
      {
        "epoch": 564,
        "reward": 0.0364944152534008,
        "val_loss": 0.9130969302994865,
        "train_loss": 0.8161162625138576
      },
      {
        "epoch": 565,
        "reward": 0.03976014629006386,
        "val_loss": 0.7640552563326699,
        "train_loss": 0.8780390689006219
      },
      {
        "epoch": 566,
        "reward": 0.037186797708272934,
        "val_loss": 0.8781479511942182,
        "train_loss": 0.8089072154118464
      },
      {
        "epoch": 567,
        "reward": 0.03894614055752754,
        "val_loss": 0.7976783514022827,
        "train_loss": 0.7997391223907471
      },
      {
        "epoch": 568,
        "reward": 0.0396190881729126,
        "val_loss": 0.7697315386363438,
        "train_loss": 0.8357561689156753
      },
      {
        "epoch": 569,
        "reward": 0.03256107121706009,
        "val_loss": 1.1564077138900757,
        "train_loss": 0.830558496599014
      },
      {
        "epoch": 570,
        "reward": 0.039670560508966446,
        "val_loss": 0.7676531161580767,
        "train_loss": 0.9467027875093313
      },
      {
        "epoch": 571,
        "reward": 0.039337512105703354,
        "val_loss": 0.7812482374055045,
        "train_loss": 0.8120655222580984
      },
      {
        "epoch": 572,
        "reward": 0.039979513734579086,
        "val_loss": 0.7553482779434749,
        "train_loss": 0.8576926909960233
      },
      {
        "epoch": 573,
        "reward": 0.03678901866078377,
        "val_loss": 0.8979820694242205,
        "train_loss": 0.9103376383964832
      },
      {
        "epoch": 574,
        "reward": 0.035138968378305435,
        "val_loss": 0.9876717754772731,
        "train_loss": 0.8224090681626246
      },
      {
        "epoch": 575,
        "reward": 0.03465705364942551,
        "val_loss": 1.0163449474743433,
        "train_loss": 0.9051395322267826
      },
      {
        "epoch": 576,
        "reward": 0.03804214671254158,
        "val_loss": 0.8376127140862601,
        "train_loss": 0.979461248104389
      },
      {
        "epoch": 577,
        "reward": 0.039753738790750504,
        "val_loss": 0.7643117393766131,
        "train_loss": 0.7571671364399103
      },
      {
        "epoch": 578,
        "reward": 0.03124973550438881,
        "val_loss": 1.2589025327137537,
        "train_loss": 0.7987383884879259
      },
      {
        "epoch": 579,
        "reward": 0.04065130278468132,
        "val_loss": 0.7295671871730259,
        "train_loss": 0.9073903629413018
      },
      {
        "epoch": 580,
        "reward": 0.03891175985336304,
        "val_loss": 0.7991457666669574,
        "train_loss": 0.8099198662317716
      },
      {
        "epoch": 581,
        "reward": 0.036242131143808365,
        "val_loss": 0.9263382383755275,
        "train_loss": 0.8404183227282304
      },
      {
        "epoch": 582,
        "reward": 0.03552108630537987,
        "val_loss": 0.9657711556979588,
        "train_loss": 0.8476292330485123
      },
      {
        "epoch": 583,
        "reward": 0.037169065326452255,
        "val_loss": 0.8790184600012643,
        "train_loss": 0.8960287903363888
      },
      {
        "epoch": 584,
        "reward": 0.03669015318155289,
        "val_loss": 0.9030132804598127,
        "train_loss": 0.8836159018369821
      },
      {
        "epoch": 585,
        "reward": 0.039572324603796005,
        "val_loss": 0.771626889705658,
        "train_loss": 0.8529224900098947
      },
      {
        "epoch": 586,
        "reward": 0.025657812133431435,
        "val_loss": 1.8890564697129386,
        "train_loss": 0.7765842148890862
      },
      {
        "epoch": 587,
        "reward": 0.03550688549876213,
        "val_loss": 0.9665721910340446,
        "train_loss": 1.0183453496832113
      },
      {
        "epoch": 588,
        "reward": 0.03962460905313492,
        "val_loss": 0.7695081915174212,
        "train_loss": 0.8169673910507789
      },
      {
        "epoch": 589,
        "reward": 0.03388325124979019,
        "val_loss": 1.0650016793182917,
        "train_loss": 0.8750694362589946
      },
      {
        "epoch": 590,
        "reward": 0.033883579075336456,
        "val_loss": 1.0649802344185966,
        "train_loss": 0.9950914233922958
      },
      {
        "epoch": 591,
        "reward": 0.03800234571099281,
        "val_loss": 0.8394375188010079,
        "train_loss": 0.8878466257682214
      },
      {
        "epoch": 592,
        "reward": 0.04087568074464798,
        "val_loss": 0.721242048910686,
        "train_loss": 1.022389088685696
      },
      {
        "epoch": 593,
        "reward": 0.0392245277762413,
        "val_loss": 0.7859404001917157,
        "train_loss": 0.8948620466085581
      },
      {
        "epoch": 594,
        "reward": 0.03742222860455513,
        "val_loss": 0.8667095175811222,
        "train_loss": 0.791594895032736
      },
      {
        "epoch": 595,
        "reward": 0.04130774363875389,
        "val_loss": 0.7055967961038861,
        "train_loss": 0.9172336161136627
      },
      {
        "epoch": 596,
        "reward": 0.03844958916306496,
        "val_loss": 0.8192604099001203,
        "train_loss": 0.8175258590624883
      },
      {
        "epoch": 597,
        "reward": 0.04046240821480751,
        "val_loss": 0.7366849098886762,
        "train_loss": 0.8077358505330406
      },
      {
        "epoch": 598,
        "reward": 0.03822736442089081,
        "val_loss": 0.8291961891310555,
        "train_loss": 0.8215551662903565
      },
      {
        "epoch": 599,
        "reward": 0.03732519969344139,
        "val_loss": 0.8713971291269574,
        "train_loss": 0.9085776049357194
      },
      {
        "epoch": 600,
        "reward": 0.0329844169318676,
        "val_loss": 1.1259275674819946,
        "train_loss": 0.829188931446809
      },
      {
        "epoch": 601,
        "reward": 0.039699725806713104,
        "val_loss": 0.7664791515895298,
        "train_loss": 0.9047353473993448
      },
      {
        "epoch": 602,
        "reward": 0.033626604825258255,
        "val_loss": 1.081895112991333,
        "train_loss": 0.8440536191830268
      },
      {
        "epoch": 603,
        "reward": 0.03877546638250351,
        "val_loss": 0.8050018463815961,
        "train_loss": 0.8929222753414741
      },
      {
        "epoch": 604,
        "reward": 0.03679187595844269,
        "val_loss": 0.8978372301374163,
        "train_loss": 0.8441319511486933
      },
      {
        "epoch": 605,
        "reward": 0.03918445110321045,
        "val_loss": 0.7876143881252834,
        "train_loss": 0.9511001052764746
      },
      {
        "epoch": 606,
        "reward": 0.03532892093062401,
        "val_loss": 0.9766949330057416,
        "train_loss": 0.7928388686134265
      },
      {
        "epoch": 607,
        "reward": 0.03954318165779114,
        "val_loss": 0.7728116427149091,
        "train_loss": 0.8692932575941086
      },
      {
        "epoch": 608,
        "reward": 0.03260171413421631,
        "val_loss": 1.1534292527607508,
        "train_loss": 0.8198274213534135
      },
      {
        "epoch": 609,
        "reward": 0.03442483767867088,
        "val_loss": 1.0305987766810827,
        "train_loss": 0.9908213890515841
      },
      {
        "epoch": 610,
        "reward": 0.04006638750433922,
        "val_loss": 0.7519400630678449,
        "train_loss": 0.9747118514317733
      },
      {
        "epoch": 611,
        "reward": 0.038884129375219345,
        "val_loss": 0.8003279992512294,
        "train_loss": 0.9258260612304394
      },
      {
        "epoch": 612,
        "reward": 0.04029465094208717,
        "val_loss": 0.743091344833374,
        "train_loss": 0.8730202706960531
      },
      {
        "epoch": 613,
        "reward": 0.03923175111413002,
        "val_loss": 0.7856391157422747,
        "train_loss": 0.8908406232412045
      },
      {
        "epoch": 614,
        "reward": 0.03615514934062958,
        "val_loss": 0.9309686592647007,
        "train_loss": 0.8396092997147486
      },
      {
        "epoch": 615,
        "reward": 0.033029116690158844,
        "val_loss": 1.1227785689490182,
        "train_loss": 0.9752638466083087
      },
      {
        "epoch": 616,
        "reward": 0.03679777309298515,
        "val_loss": 0.8975386023521423,
        "train_loss": 1.0120931680385883
      },
      {
        "epoch": 617,
        "reward": 0.03325600177049637,
        "val_loss": 1.1069909930229187,
        "train_loss": 0.9282154991076543
      },
      {
        "epoch": 618,
        "reward": 0.039823275059461594,
        "val_loss": 0.76153450352805,
        "train_loss": 0.8318770659657625
      },
      {
        "epoch": 619,
        "reward": 0.034808188676834106,
        "val_loss": 1.0072227716445923,
        "train_loss": 0.8445682227611542
      },
      {
        "epoch": 620,
        "reward": 0.04021164029836655,
        "val_loss": 0.7462916459356036,
        "train_loss": 0.874819455238489
      },
      {
        "epoch": 621,
        "reward": 0.03557664155960083,
        "val_loss": 0.9626461778368268,
        "train_loss": 0.7488906773237082
      },
      {
        "epoch": 622,
        "reward": 0.03686894103884697,
        "val_loss": 0.8939448765345982,
        "train_loss": 0.7764413798084626
      },
      {
        "epoch": 623,
        "reward": 0.03302759304642677,
        "val_loss": 1.1228854826518468,
        "train_loss": 0.82343912927004
      },
      {
        "epoch": 624,
        "reward": 0.03112349472939968,
        "val_loss": 1.269466587475368,
        "train_loss": 1.3720023677899287
      },
      {
        "epoch": 625,
        "reward": 0.040673207491636276,
        "val_loss": 0.7287481938089643,
        "train_loss": 0.9515250027179718
      },
      {
        "epoch": 626,
        "reward": 0.036823105067014694,
        "val_loss": 0.8962568129811969,
        "train_loss": 0.7792879388882563
      },
      {
        "epoch": 627,
        "reward": 0.03646666929125786,
        "val_loss": 0.9145395500319344,
        "train_loss": 0.822687069957073
      },
      {
        "epoch": 628,
        "reward": 0.036053068935871124,
        "val_loss": 0.9364464453288487,
        "train_loss": 0.9576869010925293
      },
      {
        "epoch": 629,
        "reward": 0.03569277748465538,
        "val_loss": 0.9561618566513062,
        "train_loss": 0.814476329403428
      },
      {
        "epoch": 630,
        "reward": 0.035436924546957016,
        "val_loss": 0.9705331410680499,
        "train_loss": 0.8222066066586055
      },
      {
        "epoch": 631,
        "reward": 0.04101116210222244,
        "val_loss": 0.7162822442395347,
        "train_loss": 0.8228684786993724
      },
      {
        "epoch": 632,
        "reward": 0.030457083135843277,
        "val_loss": 1.3274512205805098,
        "train_loss": 0.8376028262651883
      },
      {
        "epoch": 633,
        "reward": 0.040736179798841476,
        "val_loss": 0.7264015291418348,
        "train_loss": 0.8539856374263763
      },
      {
        "epoch": 634,
        "reward": 0.041137631982564926,
        "val_loss": 0.7116970930780683,
        "train_loss": 0.9033384391894708
      },
      {
        "epoch": 635,
        "reward": 0.04009244590997696,
        "val_loss": 0.7509221349443708,
        "train_loss": 0.8119579496291968
      },
      {
        "epoch": 636,
        "reward": 0.037259213626384735,
        "val_loss": 0.874606362410954,
        "train_loss": 0.7787432441344628
      },
      {
        "epoch": 637,
        "reward": 0.039525654166936874,
        "val_loss": 0.7735255786350795,
        "train_loss": 0.9001076313165518
      },
      {
        "epoch": 638,
        "reward": 0.03216802701354027,
        "val_loss": 1.185802161693573,
        "train_loss": 0.7999270101292775
      },
      {
        "epoch": 639,
        "reward": 0.039457328617572784,
        "val_loss": 0.7763171962329319,
        "train_loss": 0.8891996855919178
      },
      {
        "epoch": 640,
        "reward": 0.04045915976166725,
        "val_loss": 0.7368080871445792,
        "train_loss": 0.8675233905132
      },
      {
        "epoch": 641,
        "reward": 0.03315262123942375,
        "val_loss": 1.1141435929707117,
        "train_loss": 0.8251682496987857
      },
      {
        "epoch": 642,
        "reward": 0.037715502083301544,
        "val_loss": 0.8527629801205227,
        "train_loss": 0.8864028683075538
      },
      {
        "epoch": 643,
        "reward": 0.03770380839705467,
        "val_loss": 0.8533128712858472,
        "train_loss": 0.851776849765044
      },
      {
        "epoch": 644,
        "reward": 0.03388063982129097,
        "val_loss": 1.065171446119036,
        "train_loss": 0.9598094156155219
      },
      {
        "epoch": 645,
        "reward": 0.028772801160812378,
        "val_loss": 1.4925835132598877,
        "train_loss": 0.9974605118712554
      },
      {
        "epoch": 646,
        "reward": 0.03803248703479767,
        "val_loss": 0.8380550231252398,
        "train_loss": 0.9428218488509839
      },
      {
        "epoch": 647,
        "reward": 0.02794148027896881,
        "val_loss": 1.5854304007121496,
        "train_loss": 0.8361969934418224
      },
      {
        "epoch": 648,
        "reward": 0.03154364228248596,
        "val_loss": 1.2348028591700964,
        "train_loss": 0.9090163037897303
      },
      {
        "epoch": 649,
        "reward": 0.03708994761109352,
        "val_loss": 0.8829175915036883,
        "train_loss": 0.9185056652014072
      },
      {
        "epoch": 650,
        "reward": 0.03908305987715721,
        "val_loss": 0.7918733826705388,
        "train_loss": 0.8431974076307737
      },
      {
        "epoch": 651,
        "reward": 0.04072323068976402,
        "val_loss": 0.7268832325935364,
        "train_loss": 0.7839391770271155
      },
      {
        "epoch": 652,
        "reward": 0.0318719707429409,
        "val_loss": 1.2086734090532576,
        "train_loss": 0.8024271841232593
      },
      {
        "epoch": 653,
        "reward": 0.033463116735219955,
        "val_loss": 1.0928616608892168,
        "train_loss": 0.8975642759066361
      },
      {
        "epoch": 654,
        "reward": 0.03684782609343529,
        "val_loss": 0.8950087002345494,
        "train_loss": 0.9746548533439636
      },
      {
        "epoch": 655,
        "reward": 0.03630761429667473,
        "val_loss": 0.9228743655341012,
        "train_loss": 0.9561131115143116
      },
      {
        "epoch": 656,
        "reward": 0.03000178374350071,
        "val_loss": 1.3693322369030543,
        "train_loss": 0.9041699044979535
      },
      {
        "epoch": 657,
        "reward": 0.03690529242157936,
        "val_loss": 0.8921172576291221,
        "train_loss": 1.0399189885132587
      },
      {
        "epoch": 658,
        "reward": 0.03662972152233124,
        "val_loss": 0.9061088562011719,
        "train_loss": 0.8168563980322617
      },
      {
        "epoch": 659,
        "reward": 0.03353394195437431,
        "val_loss": 1.088090683732714,
        "train_loss": 0.8885638943085303
      },
      {
        "epoch": 660,
        "reward": 0.036824461072683334,
        "val_loss": 0.8961885145732335,
        "train_loss": 1.0830837281850667
      },
      {
        "epoch": 661,
        "reward": 0.04075781628489494,
        "val_loss": 0.7255977307047162,
        "train_loss": 0.8839486731001391
      },
      {
        "epoch": 662,
        "reward": 0.037977397441864014,
        "val_loss": 0.8405843462262835,
        "train_loss": 0.7604685379908636
      },
      {
        "epoch": 663,
        "reward": 0.03933308273553848,
        "val_loss": 0.7814314109938485,
        "train_loss": 0.7864352052028363
      },
      {
        "epoch": 664,
        "reward": 0.040734026581048965,
        "val_loss": 0.7264816164970398,
        "train_loss": 0.835150617819566
      },
      {
        "epoch": 665,
        "reward": 0.04040461406111717,
        "val_loss": 0.7388827971049717,
        "train_loss": 0.8833005490999383
      },
      {
        "epoch": 666,
        "reward": 0.03755602240562439,
        "val_loss": 0.8603058797972543,
        "train_loss": 0.8767117777696023
      },
      {
        "epoch": 667,
        "reward": 0.03511280193924904,
        "val_loss": 0.9891982589449201,
        "train_loss": 0.791993457537431
      },
      {
        "epoch": 668,
        "reward": 0.03864779323339462,
        "val_loss": 0.8105445333889553,
        "train_loss": 0.8243286861823156
      },
      {
        "epoch": 669,
        "reward": 0.03480256721377373,
        "val_loss": 1.0075599466051375,
        "train_loss": 0.866945342375682
      },
      {
        "epoch": 670,
        "reward": 0.035400062799453735,
        "val_loss": 0.9726297344480243,
        "train_loss": 0.9244363479889356
      },
      {
        "epoch": 671,
        "reward": 0.03722916543483734,
        "val_loss": 0.8760731645992824,
        "train_loss": 0.9012009478532351
      },
      {
        "epoch": 672,
        "reward": 0.030899984762072563,
        "val_loss": 1.2884924837521143,
        "train_loss": 0.8961418361017982
      },
      {
        "epoch": 673,
        "reward": 0.027193069458007812,
        "val_loss": 1.6764789138521468,
        "train_loss": 1.008479091983575
      },
      {
        "epoch": 674,
        "reward": 0.04082643985748291,
        "val_loss": 0.7230569805417743,
        "train_loss": 1.00038142903493
      },
      {
        "epoch": 675,
        "reward": 0.038361165672540665,
        "val_loss": 0.8231927922793797,
        "train_loss": 0.7932326610271747
      },
      {
        "epoch": 676,
        "reward": 0.03902113065123558,
        "val_loss": 0.7944913506507874,
        "train_loss": 0.8475569096895365
      },
      {
        "epoch": 677,
        "reward": 0.033405449241399765,
        "val_loss": 1.0967694776398795,
        "train_loss": 0.8122928623969738
      },
      {
        "epoch": 678,
        "reward": 0.04018121585249901,
        "val_loss": 0.7474695699555534,
        "train_loss": 0.9822264795119946
      },
      {
        "epoch": 679,
        "reward": 0.03765110298991203,
        "val_loss": 0.8557973163468497,
        "train_loss": 0.8404335402525388
      },
      {
        "epoch": 680,
        "reward": 0.04118374362587929,
        "val_loss": 0.7100359116281781,
        "train_loss": 0.8583454099985269
      },
      {
        "epoch": 681,
        "reward": 0.03351779282093048,
        "val_loss": 1.0891759395599365,
        "train_loss": 0.781785660638259
      },
      {
        "epoch": 682,
        "reward": 0.038316886872053146,
        "val_loss": 0.825172483921051,
        "train_loss": 0.8509371188970712
      },
      {
        "epoch": 683,
        "reward": 0.037611961364746094,
        "val_loss": 0.8576490793909345,
        "train_loss": 0.7678883145921506
      },
      {
        "epoch": 684,
        "reward": 0.039119429886341095,
        "val_loss": 0.7903419222150531,
        "train_loss": 0.8634870442060324
      },
      {
        "epoch": 685,
        "reward": 0.039615534245967865,
        "val_loss": 0.7698754157338824,
        "train_loss": 0.8551408052444458
      },
      {
        "epoch": 686,
        "reward": 0.03391037508845329,
        "val_loss": 1.0632388166018896,
        "train_loss": 0.7830519318007506
      },
      {
        "epoch": 687,
        "reward": 0.03367474675178528,
        "val_loss": 1.0786959528923035,
        "train_loss": 0.8882137898069161
      },
      {
        "epoch": 688,
        "reward": 0.038826700299978256,
        "val_loss": 0.8027929493359157,
        "train_loss": 0.8105342812263049
      },
      {
        "epoch": 689,
        "reward": 0.03863629326224327,
        "val_loss": 0.8110464896474566,
        "train_loss": 0.9303507644396561
      },
      {
        "epoch": 690,
        "reward": 0.029877766966819763,
        "val_loss": 1.3810769404683794,
        "train_loss": 0.9654935701535299
      },
      {
        "epoch": 691,
        "reward": 0.03978470340371132,
        "val_loss": 0.763073171888079,
        "train_loss": 0.9255476714326785
      },
      {
        "epoch": 692,
        "reward": 0.03637629374861717,
        "val_loss": 0.9192618642534528,
        "train_loss": 0.8045866477947968
      },
      {
        "epoch": 693,
        "reward": 0.038174986839294434,
        "val_loss": 0.8315637878009251,
        "train_loss": 0.8872385254273047
      },
      {
        "epoch": 694,
        "reward": 0.04146965965628624,
        "val_loss": 0.6998613008431026,
        "train_loss": 0.791085802591764
      },
      {
        "epoch": 695,
        "reward": 0.031976368278265,
        "val_loss": 1.2005354166030884,
        "train_loss": 0.8687430327901473
      },
      {
        "epoch": 696,
        "reward": 0.03799668699502945,
        "val_loss": 0.8396975483213153,
        "train_loss": 0.9436368082578366
      },
      {
        "epoch": 697,
        "reward": 0.03531695902347565,
        "val_loss": 0.9773809569222587,
        "train_loss": 0.8189634245175582
      },
      {
        "epoch": 698,
        "reward": 0.03604022413492203,
        "val_loss": 0.9371392045702253,
        "train_loss": 0.9295370555841006
      },
      {
        "epoch": 699,
        "reward": 0.03715987503528595,
        "val_loss": 0.8794699907302856,
        "train_loss": 0.8521813704417303
      },
      {
        "epoch": 700,
        "reward": 0.036569997668266296,
        "val_loss": 0.9091838257653373,
        "train_loss": 0.7563722623921981
      },
      {
        "epoch": 701,
        "reward": 0.04007810726761818,
        "val_loss": 0.7514820780072894,
        "train_loss": 0.8083720023815448
      },
      {
        "epoch": 702,
        "reward": 0.03795499727129936,
        "val_loss": 0.8416160941123962,
        "train_loss": 0.809102842440972
      },
      {
        "epoch": 703,
        "reward": 0.04074132442474365,
        "val_loss": 0.7262102791241237,
        "train_loss": 0.8564046392073998
      },
      {
        "epoch": 704,
        "reward": 0.04016343131661415,
        "val_loss": 0.7481594681739807,
        "train_loss": 0.8113380395449125
      },
      {
        "epoch": 705,
        "reward": 0.03461639583110809,
        "val_loss": 1.018819613116128,
        "train_loss": 0.8207670794083521
      },
      {
        "epoch": 706,
        "reward": 0.03325708210468292,
        "val_loss": 1.106916538306645,
        "train_loss": 0.7697749550525959
      },
      {
        "epoch": 707,
        "reward": 0.0377962701022625,
        "val_loss": 0.8489800095558167,
        "train_loss": 0.9171594243783218
      },
      {
        "epoch": 708,
        "reward": 0.04092199727892876,
        "val_loss": 0.7195409195763725,
        "train_loss": 1.0086810290813446
      },
      {
        "epoch": 709,
        "reward": 0.03972513601183891,
        "val_loss": 0.7654580984796796,
        "train_loss": 0.8250257418705866
      },
      {
        "epoch": 710,
        "reward": 0.03563455864787102,
        "val_loss": 0.9594045622008187,
        "train_loss": 0.7839902249666361
      },
      {
        "epoch": 711,
        "reward": 0.03276080638170242,
        "val_loss": 1.1418783494404383,
        "train_loss": 0.835761580329675
      },
      {
        "epoch": 712,
        "reward": 0.03250935301184654,
        "val_loss": 1.16021386214665,
        "train_loss": 0.9048356935381889
      },
      {
        "epoch": 713,
        "reward": 0.03492818400263786,
        "val_loss": 1.000065496989659,
        "train_loss": 0.8894985547432532
      },
      {
        "epoch": 714,
        "reward": 0.03662312030792236,
        "val_loss": 0.9064479896000454,
        "train_loss": 0.9670444360146155
      },
      {
        "epoch": 715,
        "reward": 0.039704058319330215,
        "val_loss": 0.7663049016680036,
        "train_loss": 0.8266662061214447
      },
      {
        "epoch": 716,
        "reward": 0.041308291256427765,
        "val_loss": 0.7055774927139282,
        "train_loss": 0.7907456755638123
      },
      {
        "epoch": 717,
        "reward": 0.04040602967143059,
        "val_loss": 0.738828820841653,
        "train_loss": 0.8233086002560762
      },
      {
        "epoch": 718,
        "reward": 0.03685063123703003,
        "val_loss": 0.8948671306882586,
        "train_loss": 0.8518519745423243
      },
      {
        "epoch": 719,
        "reward": 0.03774772211909294,
        "val_loss": 0.8512507847377232,
        "train_loss": 1.0128544156367962
      },
      {
        "epoch": 720,
        "reward": 0.03274690732359886,
        "val_loss": 1.1428805078778947,
        "train_loss": 0.7760345534636424
      },
      {
        "epoch": 721,
        "reward": 0.03574390336871147,
        "val_loss": 0.9533271704401288,
        "train_loss": 1.0459694048533072
      },
      {
        "epoch": 722,
        "reward": 0.03496360406279564,
        "val_loss": 0.9979668600218636,
        "train_loss": 0.8772591123214135
      },
      {
        "epoch": 723,
        "reward": 0.03830406069755554,
        "val_loss": 0.8257470216069903,
        "train_loss": 0.9520097913650366
      },
      {
        "epoch": 724,
        "reward": 0.03929361328482628,
        "val_loss": 0.7830664260046822,
        "train_loss": 0.7991629919180503
      },
      {
        "epoch": 725,
        "reward": 0.039419133216142654,
        "val_loss": 0.77788416828428,
        "train_loss": 0.9287453798147348
      },
      {
        "epoch": 726,
        "reward": 0.03798535838723183,
        "val_loss": 0.8402182374681745,
        "train_loss": 0.8027523240217795
      },
      {
        "epoch": 727,
        "reward": 0.030613375827670097,
        "val_loss": 1.3135083998952592,
        "train_loss": 1.0563496533208168
      },
      {
        "epoch": 728,
        "reward": 0.04035568982362747,
        "val_loss": 0.7407509769712176,
        "train_loss": 0.9278781528656299
      },
      {
        "epoch": 729,
        "reward": 0.04129016026854515,
        "val_loss": 0.7062238284519741,
        "train_loss": 0.7458364023612096
      },
      {
        "epoch": 730,
        "reward": 0.039933111518621445,
        "val_loss": 0.7571778212274823,
        "train_loss": 0.8844349636481359
      },
      {
        "epoch": 731,
        "reward": 0.03892361745238304,
        "val_loss": 0.7986390335219247,
        "train_loss": 0.7721238743800384
      },
      {
        "epoch": 732,
        "reward": 0.04066145047545433,
        "val_loss": 0.7291875566755023,
        "train_loss": 0.7794367791368411
      },
      {
        "epoch": 733,
        "reward": 0.03613484278321266,
        "val_loss": 0.9320548347064427,
        "train_loss": 0.7520592472014519
      },
      {
        "epoch": 734,
        "reward": 0.03496461734175682,
        "val_loss": 0.9979068381445748,
        "train_loss": 0.7903253871660966
      },
      {
        "epoch": 735,
        "reward": 0.03703949227929115,
        "val_loss": 0.8854174528803144,
        "train_loss": 0.9150745731133682
      },
      {
        "epoch": 736,
        "reward": 0.03800174221396446,
        "val_loss": 0.8394653626850673,
        "train_loss": 0.7505895530294555
      },
      {
        "epoch": 737,
        "reward": 0.03221959248185158,
        "val_loss": 1.1818835735321045,
        "train_loss": 0.8993485455329602
      },
      {
        "epoch": 738,
        "reward": 0.0365624763071537,
        "val_loss": 0.9095718945775714,
        "train_loss": 0.8054351173341274
      },
      {
        "epoch": 739,
        "reward": 0.037669260054826736,
        "val_loss": 0.8549400993755886,
        "train_loss": 0.7730958997092855
      },
      {
        "epoch": 740,
        "reward": 0.040914032608270645,
        "val_loss": 0.7198329440185002,
        "train_loss": 0.7359229112043977
      },
      {
        "epoch": 741,
        "reward": 0.040647681802511215,
        "val_loss": 0.7297026600156512,
        "train_loss": 0.8132586204088651
      },
      {
        "epoch": 742,
        "reward": 0.03849608451128006,
        "val_loss": 0.8172035387584141,
        "train_loss": 0.7619150005854093
      },
      {
        "epoch": 743,
        "reward": 0.04032275080680847,
        "val_loss": 0.742012619972229,
        "train_loss": 0.8197404214969048
      },
      {
        "epoch": 744,
        "reward": 0.03535541519522667,
        "val_loss": 0.9751781565802438,
        "train_loss": 0.8442686864962945
      },
      {
        "epoch": 745,
        "reward": 0.039579011499881744,
        "val_loss": 0.7713556204523359,
        "train_loss": 0.9230728080639472
      },
      {
        "epoch": 746,
        "reward": 0.03987691551446915,
        "val_loss": 0.7594023517199925,
        "train_loss": 0.8118659636149039
      },
      {
        "epoch": 747,
        "reward": 0.0351642407476902,
        "val_loss": 0.9862010734421867,
        "train_loss": 0.8464078943316753
      },
      {
        "epoch": 748,
        "reward": 0.04016078636050224,
        "val_loss": 0.7482620307377407,
        "train_loss": 0.9246055311881579
      },
      {
        "epoch": 749,
        "reward": 0.03862332925200462,
        "val_loss": 0.8116127167429242,
        "train_loss": 0.8572364247475679
      },
      {
        "epoch": 750,
        "reward": 0.03580399230122566,
        "val_loss": 0.9500116450445992,
        "train_loss": 0.7494042756465765
      },
      {
        "epoch": 751,
        "reward": 0.03851346671581268,
        "val_loss": 0.8164365547043937,
        "train_loss": 0.8736371443821833
      },
      {
        "epoch": 752,
        "reward": 0.03678834065794945,
        "val_loss": 0.8980163761547634,
        "train_loss": 0.8308909718806927
      },
      {
        "epoch": 753,
        "reward": 0.040528733283281326,
        "val_loss": 0.7341740557125637,
        "train_loss": 0.9059229172193087
      },
      {
        "epoch": 754,
        "reward": 0.03411741927266121,
        "val_loss": 1.0499231474740165,
        "train_loss": 0.7856461291129773
      },
      {
        "epoch": 755,
        "reward": 0.039824556559324265,
        "val_loss": 0.7614835756165641,
        "train_loss": 0.8730845864002521
      },
      {
        "epoch": 756,
        "reward": 0.04147276282310486,
        "val_loss": 0.6997519646372113,
        "train_loss": 0.9137592361523554
      },
      {
        "epoch": 757,
        "reward": 0.03414323180913925,
        "val_loss": 1.0482802987098694,
        "train_loss": 0.8501690488595229
      },
      {
        "epoch": 758,
        "reward": 0.041020315140485764,
        "val_loss": 0.7159489478383746,
        "train_loss": 0.8322277046166934
      },
      {
        "epoch": 759,
        "reward": 0.0374346487224102,
        "val_loss": 0.8661119256700788,
        "train_loss": 0.9956109936420734
      },
      {
        "epoch": 760,
        "reward": 0.03191761299967766,
        "val_loss": 1.205105219568525,
        "train_loss": 0.8554330055530255
      },
      {
        "epoch": 761,
        "reward": 0.0364813506603241,
        "val_loss": 0.9137755802699498,
        "train_loss": 0.8280996756198314
      },
      {
        "epoch": 762,
        "reward": 0.04079950600862503,
        "val_loss": 0.7240528379167829,
        "train_loss": 0.8537049270593203
      },
      {
        "epoch": 763,
        "reward": 0.03419703617691994,
        "val_loss": 1.0448676007134574,
        "train_loss": 0.8144491945321743
      },
      {
        "epoch": 764,
        "reward": 0.03521598502993584,
        "val_loss": 0.9831996389797756,
        "train_loss": 0.9295705740268414
      },
      {
        "epoch": 765,
        "reward": 0.03419741988182068,
        "val_loss": 1.0448432905333382,
        "train_loss": 0.998700425028801
      },
      {
        "epoch": 766,
        "reward": 0.035797420889139175,
        "val_loss": 0.9503733260290963,
        "train_loss": 0.9403702559379431
      },
      {
        "epoch": 767,
        "reward": 0.0318242572247982,
        "val_loss": 1.2124198419707162,
        "train_loss": 0.8343233844408622
      },
      {
        "epoch": 768,
        "reward": 0.03405126556754112,
        "val_loss": 1.0541507686887468,
        "train_loss": 1.0404826861161451
      },
      {
        "epoch": 769,
        "reward": 0.03128494322299957,
        "val_loss": 1.2559794442994254,
        "train_loss": 0.799046746813334
      },
      {
        "epoch": 770,
        "reward": 0.03993970900774002,
        "val_loss": 0.7569171871457782,
        "train_loss": 0.8802644770879012
      },
      {
        "epoch": 771,
        "reward": 0.0404571071267128,
        "val_loss": 0.7368858797209603,
        "train_loss": 0.8040058177251083
      },
      {
        "epoch": 772,
        "reward": 0.039118941873311996,
        "val_loss": 0.7903624602726528,
        "train_loss": 0.9536324074635139
      },
      {
        "epoch": 773,
        "reward": 0.037494804710149765,
        "val_loss": 0.8632273077964783,
        "train_loss": 0.8127398725885612
      },
      {
        "epoch": 774,
        "reward": 0.0371282659471035,
        "val_loss": 0.8810259699821472,
        "train_loss": 0.9781196386768267
      },
      {
        "epoch": 775,
        "reward": 0.03738662227988243,
        "val_loss": 0.8684254629271371,
        "train_loss": 0.7792807221412659
      },
      {
        "epoch": 776,
        "reward": 0.039955023676157,
        "val_loss": 0.7563129918915885,
        "train_loss": 0.8352402265255268
      },
      {
        "epoch": 777,
        "reward": 0.04104242101311684,
        "val_loss": 0.7151449152401516,
        "train_loss": 0.7548283029061097
      },
      {
        "epoch": 778,
        "reward": 0.03878210857510567,
        "val_loss": 0.804714926651546,
        "train_loss": 0.8527540874022704
      },
      {
        "epoch": 779,
        "reward": 0.035618655383586884,
        "val_loss": 0.9602931993348258,
        "train_loss": 1.0350658847735479
      },
      {
        "epoch": 780,
        "reward": 0.034718107432127,
        "val_loss": 1.0126455085618156,
        "train_loss": 0.815961438875932
      },
      {
        "epoch": 781,
        "reward": 0.038361553102731705,
        "val_loss": 0.8231755835669381,
        "train_loss": 0.8800599941840539
      },
      {
        "epoch": 782,
        "reward": 0.03974414989352226,
        "val_loss": 0.7646957465580532,
        "train_loss": 0.8302626357628748
      },
      {
        "epoch": 783,
        "reward": 0.04039723426103592,
        "val_loss": 0.7391641821180072,
        "train_loss": 0.7912923911443124
      },
      {
        "epoch": 784,
        "reward": 0.040308285504579544,
        "val_loss": 0.7425676839692252,
        "train_loss": 0.8550298236883603
      },
      {
        "epoch": 785,
        "reward": 0.02936786785721779,
        "val_loss": 1.43095406464168,
        "train_loss": 0.9376220932373633
      },
      {
        "epoch": 786,
        "reward": 0.04033183678984642,
        "val_loss": 0.7416642223085675,
        "train_loss": 0.9982096976958789
      },
      {
        "epoch": 787,
        "reward": 0.03302625194191933,
        "val_loss": 1.122980066708156,
        "train_loss": 0.9947196589066432
      },
      {
        "epoch": 788,
        "reward": 0.03821045532822609,
        "val_loss": 0.8299593073981149,
        "train_loss": 0.9535795358511118
      },
      {
        "epoch": 789,
        "reward": 0.04124319553375244,
        "val_loss": 0.7079025677272252,
        "train_loss": 0.856337118607301
      },
      {
        "epoch": 790,
        "reward": 0.03669492527842522,
        "val_loss": 0.902769420828138,
        "train_loss": 0.7632454221065228
      },
      {
        "epoch": 791,
        "reward": 0.039451323449611664,
        "val_loss": 0.776563252721514,
        "train_loss": 0.8966287855918591
      },
      {
        "epoch": 792,
        "reward": 0.038723841309547424,
        "val_loss": 0.8072362116404942,
        "train_loss": 0.740949967358924
      },
      {
        "epoch": 793,
        "reward": 0.040779661387205124,
        "val_loss": 0.7247875588280814,
        "train_loss": 0.7891113597613114
      },
      {
        "epoch": 794,
        "reward": 0.03684384375810623,
        "val_loss": 0.8952095849173409,
        "train_loss": 0.7716640738340524
      },
      {
        "epoch": 795,
        "reward": 0.04003347083926201,
        "val_loss": 0.7532286643981934,
        "train_loss": 0.7654335831220334
      },
      {
        "epoch": 796,
        "reward": 0.037770118564367294,
        "val_loss": 0.850202168737139,
        "train_loss": 0.8773945271968842
      },
      {
        "epoch": 797,
        "reward": 0.04033910483121872,
        "val_loss": 0.7413858430726188,
        "train_loss": 0.7315973676741123
      },
      {
        "epoch": 798,
        "reward": 0.0386430025100708,
        "val_loss": 0.8107534902436393,
        "train_loss": 0.8395148997123425
      },
      {
        "epoch": 799,
        "reward": 0.04079405963420868,
        "val_loss": 0.724254310131073,
        "train_loss": 0.7720781041380878
      },
      {
        "epoch": 800,
        "reward": 0.03718581795692444,
        "val_loss": 0.8781959584781102,
        "train_loss": 0.7979928094607133
      },
      {
        "epoch": 801,
        "reward": 0.03834884986281395,
        "val_loss": 0.8237426451274327,
        "train_loss": 0.7883011010976938
      },
      {
        "epoch": 802,
        "reward": 0.037211839109659195,
        "val_loss": 0.8769208788871765,
        "train_loss": 0.9002848336329827
      },
      {
        "epoch": 803,
        "reward": 0.03186873719096184,
        "val_loss": 1.2089265244347709,
        "train_loss": 0.9234040058576144
      },
      {
        "epoch": 804,
        "reward": 0.03809181973338127,
        "val_loss": 0.8353433694158282,
        "train_loss": 0.8047877343801352
      },
      {
        "epoch": 805,
        "reward": 0.03125723823904991,
        "val_loss": 1.2582793746675764,
        "train_loss": 0.7492078072749652
      },
      {
        "epoch": 806,
        "reward": 0.031379468739032745,
        "val_loss": 1.2481806789125716,
        "train_loss": 1.0275882482528687
      },
      {
        "epoch": 807,
        "reward": 0.03894902393221855,
        "val_loss": 0.7975555913788932,
        "train_loss": 0.9940886884354628
      },
      {
        "epoch": 808,
        "reward": 0.032086774706840515,
        "val_loss": 1.1920153839247567,
        "train_loss": 0.8162469634642968
      },
      {
        "epoch": 809,
        "reward": 0.03694063052535057,
        "val_loss": 0.8903457948139736,
        "train_loss": 0.9345422845620376
      },
      {
        "epoch": 810,
        "reward": 0.04028187692165375,
        "val_loss": 0.743582546710968,
        "train_loss": 0.8622042661691711
      },
      {
        "epoch": 811,
        "reward": 0.03621182590723038,
        "val_loss": 0.9279478447777885,
        "train_loss": 0.9250829128118662
      },
      {
        "epoch": 812,
        "reward": 0.03397069126367569,
        "val_loss": 1.059334201472146,
        "train_loss": 0.7704401933229886
      },
      {
        "epoch": 813,
        "reward": 0.04063991829752922,
        "val_loss": 0.7299932071140834,
        "train_loss": 0.8492168240123786
      },
      {
        "epoch": 814,
        "reward": 0.036063335835933685,
        "val_loss": 0.9358935015542167,
        "train_loss": 0.7728392733977392
      },
      {
        "epoch": 815,
        "reward": 0.040399834513664246,
        "val_loss": 0.7390649914741516,
        "train_loss": 0.8612198722190582
      },
      {
        "epoch": 816,
        "reward": 0.04097680374979973,
        "val_loss": 0.717535308429173,
        "train_loss": 0.772151309137161
      },
      {
        "epoch": 817,
        "reward": 0.03780553489923477,
        "val_loss": 0.8485474501337323,
        "train_loss": 0.8612986069459182
      },
      {
        "epoch": 818,
        "reward": 0.03986330330371857,
        "val_loss": 0.7599425656454903,
        "train_loss": 0.8877160640863272
      },
      {
        "epoch": 819,
        "reward": 0.037080880254507065,
        "val_loss": 0.8833661590303693,
        "train_loss": 0.7917471470741125
      },
      {
        "epoch": 820,
        "reward": 0.039995331317186356,
        "val_loss": 0.7547258734703064,
        "train_loss": 0.8066542217364678
      },
      {
        "epoch": 821,
        "reward": 0.03252245485782623,
        "val_loss": 1.1592478496687753,
        "train_loss": 0.8876752222959812
      },
      {
        "epoch": 822,
        "reward": 0.03594672679901123,
        "val_loss": 0.9422031044960022,
        "train_loss": 1.1823234649804921
      },
      {
        "epoch": 823,
        "reward": 0.03850225359201431,
        "val_loss": 0.8169311838490623,
        "train_loss": 0.814298139168666
      },
      {
        "epoch": 824,
        "reward": 0.041299592703580856,
        "val_loss": 0.705887462411608,
        "train_loss": 0.7921675738806908
      },
      {
        "epoch": 825,
        "reward": 0.03974210470914841,
        "val_loss": 0.7647777540343148,
        "train_loss": 0.7505597976537851
      },
      {
        "epoch": 826,
        "reward": 0.040364887565374374,
        "val_loss": 0.7403992669922965,
        "train_loss": 0.7597260509769862
      },
      {
        "epoch": 827,
        "reward": 0.03800959885120392,
        "val_loss": 0.8391045672552926,
        "train_loss": 0.8415615123051864
      },
      {
        "epoch": 828,
        "reward": 0.03781751170754433,
        "val_loss": 0.8479888779776437,
        "train_loss": 0.8735408462010897
      },
      {
        "epoch": 829,
        "reward": 0.04045114666223526,
        "val_loss": 0.7371124710355487,
        "train_loss": 0.7797396733210638
      },
      {
        "epoch": 830,
        "reward": 0.03853197023272514,
        "val_loss": 0.8156210737568992,
        "train_loss": 0.8352328815784019
      },
      {
        "epoch": 831,
        "reward": 0.03286729380488396,
        "val_loss": 1.1342411467007227,
        "train_loss": 0.8392229492847736
      },
      {
        "epoch": 832,
        "reward": 0.038630686700344086,
        "val_loss": 0.8112913114683968,
        "train_loss": 0.9133645112697895
      },
      {
        "epoch": 833,
        "reward": 0.03493092581629753,
        "val_loss": 0.9999028018542698,
        "train_loss": 0.8480784847186162
      },
      {
        "epoch": 834,
        "reward": 0.038204919546842575,
        "val_loss": 0.8302094680922372,
        "train_loss": 0.9782838815679917
      },
      {
        "epoch": 835,
        "reward": 0.04100475460290909,
        "val_loss": 0.716515736920493,
        "train_loss": 0.7862022885909448
      },
      {
        "epoch": 836,
        "reward": 0.040426772087812424,
        "val_loss": 0.7380390592983791,
        "train_loss": 0.7849292388329139
      },
      {
        "epoch": 837,
        "reward": 0.03995557501912117,
        "val_loss": 0.7562914064952305,
        "train_loss": 0.8109126056616123
      },
      {
        "epoch": 838,
        "reward": 0.04048909246921539,
        "val_loss": 0.7356731465884617,
        "train_loss": 0.7956750140740321
      },
      {
        "epoch": 839,
        "reward": 0.03910547122359276,
        "val_loss": 0.7909291727202279,
        "train_loss": 0.780997675198775
      },
      {
        "epoch": 840,
        "reward": 0.03460162878036499,
        "val_loss": 1.0197204606873649,
        "train_loss": 0.8736620247364044
      },
      {
        "epoch": 841,
        "reward": 0.03647046536207199,
        "val_loss": 0.914341926574707,
        "train_loss": 0.9375979880300852
      },
      {
        "epoch": 842,
        "reward": 0.033651698380708694,
        "val_loss": 1.0802259615489416,
        "train_loss": 0.7637488807623203
      },
      {
        "epoch": 843,
        "reward": 0.03673553839325905,
        "val_loss": 0.9006983382361275,
        "train_loss": 0.8641489257033055
      },
      {
        "epoch": 844,
        "reward": 0.03801574185490608,
        "val_loss": 0.8388226883752006,
        "train_loss": 0.8304747709861169
      },
      {
        "epoch": 845,
        "reward": 0.03768385574221611,
        "val_loss": 0.8542520914758954,
        "train_loss": 0.8001114898003064
      },
      {
        "epoch": 846,
        "reward": 0.038929589092731476,
        "val_loss": 0.7983843684196472,
        "train_loss": 0.8041248550781837
      },
      {
        "epoch": 847,
        "reward": 0.035380396991968155,
        "val_loss": 0.9737509574208941,
        "train_loss": 0.7940761779363339
      },
      {
        "epoch": 848,
        "reward": 0.0388917475938797,
        "val_loss": 0.8000015871865409,
        "train_loss": 0.890156221217834
      },
      {
        "epoch": 849,
        "reward": 0.038656994700431824,
        "val_loss": 0.81014313016619,
        "train_loss": 0.8382783898940454
      },
      {
        "epoch": 850,
        "reward": 0.03955244645476341,
        "val_loss": 0.7724348732403347,
        "train_loss": 0.8109023413405969
      },
      {
        "epoch": 851,
        "reward": 0.03892470523715019,
        "val_loss": 0.7985928228923252,
        "train_loss": 0.8602600418604337
      },
      {
        "epoch": 852,
        "reward": 0.03608895093202591,
        "val_loss": 0.9345156039510455,
        "train_loss": 0.8494066366782556
      },
      {
        "epoch": 853,
        "reward": 0.03876153752207756,
        "val_loss": 0.8056037851742336,
        "train_loss": 0.8361480213128604
      },
      {
        "epoch": 854,
        "reward": 0.04086429625749588,
        "val_loss": 0.7216610908508301,
        "train_loss": 1.0432948515965388
      },
      {
        "epoch": 855,
        "reward": 0.033143043518066406,
        "val_loss": 1.1148099132946558,
        "train_loss": 0.8455710714826217
      },
      {
        "epoch": 856,
        "reward": 0.03650622442364693,
        "val_loss": 0.9124839987073626,
        "train_loss": 0.9097734471926322
      },
      {
        "epoch": 857,
        "reward": 0.03930997475981712,
        "val_loss": 0.7823881506919861,
        "train_loss": 0.9359270517642682
      },
      {
        "epoch": 858,
        "reward": 0.036444928497076035,
        "val_loss": 0.915672412940434,
        "train_loss": 0.7886888224344987
      },
      {
        "epoch": 859,
        "reward": 0.03600050136446953,
        "val_loss": 0.9392856700079781,
        "train_loss": 0.8247494731958096
      },
      {
        "epoch": 860,
        "reward": 0.03774624317884445,
        "val_loss": 0.8513201645442418,
        "train_loss": 0.7811046615242958
      },
      {
        "epoch": 861,
        "reward": 0.03459851071238518,
        "val_loss": 1.0199110167367118,
        "train_loss": 0.7636904934277902
      },
      {
        "epoch": 862,
        "reward": 0.03964090719819069,
        "val_loss": 0.7688494494983128,
        "train_loss": 0.8465034686602079
      },
      {
        "epoch": 863,
        "reward": 0.0332583524286747,
        "val_loss": 1.1068292771066939,
        "train_loss": 0.8369782097064532
      },
      {
        "epoch": 864,
        "reward": 0.04072284325957298,
        "val_loss": 0.7268974099840436,
        "train_loss": 0.8456538480061752
      },
      {
        "epoch": 865,
        "reward": 0.03992626443505287,
        "val_loss": 0.7574483581951686,
        "train_loss": 0.764341815159871
      },
      {
        "epoch": 866,
        "reward": 0.04149206727743149,
        "val_loss": 0.6990729740687779,
        "train_loss": 0.7635267331049993
      },
      {
        "epoch": 867,
        "reward": 0.030007898807525635,
        "val_loss": 1.36875695841653,
        "train_loss": 0.8228053244260641
      },
      {
        "epoch": 868,
        "reward": 0.039567507803440094,
        "val_loss": 0.7718226313591003,
        "train_loss": 0.9581229117913888
      },
      {
        "epoch": 869,
        "reward": 0.03966391086578369,
        "val_loss": 0.7679210390363421,
        "train_loss": 0.8023223601854764
      },
      {
        "epoch": 870,
        "reward": 0.0400310754776001,
        "val_loss": 0.7533225331987653,
        "train_loss": 0.8504951768196546
      },
      {
        "epoch": 871,
        "reward": 0.040311310440301895,
        "val_loss": 0.7424514804567609,
        "train_loss": 0.8363150816697341
      },
      {
        "epoch": 872,
        "reward": 0.03702901303768158,
        "val_loss": 0.8859380483627319,
        "train_loss": 0.750119657950843
      },
      {
        "epoch": 873,
        "reward": 0.03840411826968193,
        "val_loss": 0.8212792532784599,
        "train_loss": 0.9103516694516517
      },
      {
        "epoch": 874,
        "reward": 0.034445133060216904,
        "val_loss": 1.0293413741247994,
        "train_loss": 0.8243058226429499
      },
      {
        "epoch": 875,
        "reward": 0.033350780606269836,
        "val_loss": 1.1004920090947832,
        "train_loss": 0.7799683243725807
      },
      {
        "epoch": 876,
        "reward": 0.035363733768463135,
        "val_loss": 0.974702605179378,
        "train_loss": 0.8502342976056613
      },
      {
        "epoch": 877,
        "reward": 0.04058268293738365,
        "val_loss": 0.7321412478174482,
        "train_loss": 0.8556289489452655
      },
      {
        "epoch": 878,
        "reward": 0.04095522686839104,
        "val_loss": 0.7183237757001605,
        "train_loss": 0.7941705515751472
      },
      {
        "epoch": 879,
        "reward": 0.04164620861411095,
        "val_loss": 0.6936845864568438,
        "train_loss": 0.8112150476529048
      },
      {
        "epoch": 880,
        "reward": 0.03869868814945221,
        "val_loss": 0.8083282113075256,
        "train_loss": 0.7528401166200638
      },
      {
        "epoch": 881,
        "reward": 0.039544299244880676,
        "val_loss": 0.7727662154606411,
        "train_loss": 0.9046311550415479
      },
      {
        "epoch": 882,
        "reward": 0.03761403635144234,
        "val_loss": 0.8575507232121059,
        "train_loss": 0.8418171146454719
      },
      {
        "epoch": 883,
        "reward": 0.03640086576342583,
        "val_loss": 0.9179743102618626,
        "train_loss": 0.7513728411151812
      },
      {
        "epoch": 884,
        "reward": 0.039853163063526154,
        "val_loss": 0.7603455441338676,
        "train_loss": 0.907699316740036
      },
      {
        "epoch": 885,
        "reward": 0.0391673780977726,
        "val_loss": 0.7883293117795672,
        "train_loss": 0.8239380029531626
      },
      {
        "epoch": 886,
        "reward": 0.04043639451265335,
        "val_loss": 0.7376730867794582,
        "train_loss": 0.7996921355907733
      },
      {
        "epoch": 887,
        "reward": 0.039169665426015854,
        "val_loss": 0.7882335271154132,
        "train_loss": 0.9454762224967663
      },
      {
        "epoch": 888,
        "reward": 0.03642650321125984,
        "val_loss": 0.9166340359619686,
        "train_loss": 0.9066437459908999
      },
      {
        "epoch": 889,
        "reward": 0.038110848516225815,
        "val_loss": 0.8344761558941433,
        "train_loss": 0.8593352826742026
      },
      {
        "epoch": 890,
        "reward": 0.0376591794192791,
        "val_loss": 0.8554158210754395,
        "train_loss": 0.8757736786053731
      },
      {
        "epoch": 891,
        "reward": 0.04066848382353783,
        "val_loss": 0.7289245894977024,
        "train_loss": 0.816981152846263
      },
      {
        "epoch": 892,
        "reward": 0.03654557093977928,
        "val_loss": 0.9104457753045219,
        "train_loss": 0.8035124597641138
      },
      {
        "epoch": 893,
        "reward": 0.04060214385390282,
        "val_loss": 0.7314096987247467,
        "train_loss": 0.8190657404752878
      },
      {
        "epoch": 894,
        "reward": 0.041090767830610275,
        "val_loss": 0.7133911848068237,
        "train_loss": 0.9022216888574454
      },
      {
        "epoch": 895,
        "reward": 0.03840544447302818,
        "val_loss": 0.8212200403213501,
        "train_loss": 0.7995856473079095
      },
      {
        "epoch": 896,
        "reward": 0.040774453431367874,
        "val_loss": 0.7249806608472552,
        "train_loss": 0.8430633842945099
      },
      {
        "epoch": 897,
        "reward": 0.04105452448129654,
        "val_loss": 0.7147053480148315,
        "train_loss": 0.8015606598212168
      },
      {
        "epoch": 898,
        "reward": 0.0365256667137146,
        "val_loss": 0.9114758372306824,
        "train_loss": 0.7841485750216705
      },
      {
        "epoch": 899,
        "reward": 0.03940766304731369,
        "val_loss": 0.778355598449707,
        "train_loss": 0.7848252287277808
      },
      {
        "epoch": 900,
        "reward": 0.04037830978631973,
        "val_loss": 0.7398865308080401,
        "train_loss": 0.8488298975504361
      },
      {
        "epoch": 901,
        "reward": 0.039118289947509766,
        "val_loss": 0.790389861379351,
        "train_loss": 0.8231814053769295
      },
      {
        "epoch": 902,
        "reward": 0.040326543152332306,
        "val_loss": 0.7418672527585711,
        "train_loss": 0.8786132243963388
      },
      {
        "epoch": 903,
        "reward": 0.03920156881213188,
        "val_loss": 0.7868986810956683,
        "train_loss": 0.7439389274670527
      },
      {
        "epoch": 904,
        "reward": 0.03665308281779289,
        "val_loss": 0.9049103345189776,
        "train_loss": 0.7733730673789978
      },
      {
        "epoch": 905,
        "reward": 0.0337357372045517,
        "val_loss": 1.074663622038705,
        "train_loss": 0.9126310039025086
      },
      {
        "epoch": 906,
        "reward": 0.041423484683036804,
        "val_loss": 0.7014899935041156,
        "train_loss": 0.8564262653772647
      },
      {
        "epoch": 907,
        "reward": 0.03762258216738701,
        "val_loss": 0.8571460332189288,
        "train_loss": 0.8811415617282574
      },
      {
        "epoch": 908,
        "reward": 0.03788747638463974,
        "val_loss": 0.8447371806417193,
        "train_loss": 0.7890677624023877
      },
      {
        "epoch": 909,
        "reward": 0.04098840430378914,
        "val_loss": 0.7171119025775364,
        "train_loss": 0.818719180730673
      },
      {
        "epoch": 910,
        "reward": 0.04073144868016243,
        "val_loss": 0.7265774437359401,
        "train_loss": 0.761475913799726
      },
      {
        "epoch": 911,
        "reward": 0.040307216346263885,
        "val_loss": 0.7426087558269501,
        "train_loss": 0.7994109254616958
      },
      {
        "epoch": 912,
        "reward": 0.03994748368859291,
        "val_loss": 0.7566103935241699,
        "train_loss": 0.9312786918420058
      },
      {
        "epoch": 913,
        "reward": 0.03845852240920067,
        "val_loss": 0.8188644817897252,
        "train_loss": 0.8008728485841018
      },
      {
        "epoch": 914,
        "reward": 0.035806458443403244,
        "val_loss": 0.9498758571488517,
        "train_loss": 0.8093584936398727
      },
      {
        "epoch": 915,
        "reward": 0.035715922713279724,
        "val_loss": 0.9548769678388324,
        "train_loss": 0.9769537999079778
      },
      {
        "epoch": 916,
        "reward": 0.03819757327437401,
        "val_loss": 0.8305416873523167,
        "train_loss": 0.7774184824934659
      },
      {
        "epoch": 917,
        "reward": 0.03986549749970436,
        "val_loss": 0.7598553895950317,
        "train_loss": 0.8252813586821923
      },
      {
        "epoch": 918,
        "reward": 0.03953327238559723,
        "val_loss": 0.7732149021966117,
        "train_loss": 0.7974520119336935
      },
      {
        "epoch": 919,
        "reward": 0.03541765734553337,
        "val_loss": 0.9716283806732723,
        "train_loss": 0.8450653896881983
      },
      {
        "epoch": 920,
        "reward": 0.037533391267061234,
        "val_loss": 0.8613842300006321,
        "train_loss": 0.8237475557969167
      },
      {
        "epoch": 921,
        "reward": 0.03813336417078972,
        "val_loss": 0.8334523269108364,
        "train_loss": 0.8063142207952646
      },
      {
        "epoch": 922,
        "reward": 0.03498499467968941,
        "val_loss": 0.9967028456074851,
        "train_loss": 0.9281114855637917
      },
      {
        "epoch": 923,
        "reward": 0.03531251847743988,
        "val_loss": 0.9776358689580645,
        "train_loss": 0.8882215305661353
      },
      {
        "epoch": 924,
        "reward": 0.039433643221855164,
        "val_loss": 0.7772881473813739,
        "train_loss": 0.8622919298135318
      },
      {
        "epoch": 925,
        "reward": 0.0350683219730854,
        "val_loss": 0.9918006403105599,
        "train_loss": 0.8289558772857373
      },
      {
        "epoch": 926,
        "reward": 0.03268946707248688,
        "val_loss": 1.1470369611467635,
        "train_loss": 0.9814097881317139
      },
      {
        "epoch": 927,
        "reward": 0.036098625510931015,
        "val_loss": 0.9339960558073861,
        "train_loss": 0.9270905004097865
      },
      {
        "epoch": 928,
        "reward": 0.03783384710550308,
        "val_loss": 0.8472280161721366,
        "train_loss": 0.8297399843398195
      },
      {
        "epoch": 929,
        "reward": 0.03450211137533188,
        "val_loss": 1.0258230992725916,
        "train_loss": 0.7553987546035876
      },
      {
        "epoch": 930,
        "reward": 0.03390425816178322,
        "val_loss": 1.0636360560144698,
        "train_loss": 0.8980681724273242
      },
      {
        "epoch": 931,
        "reward": 0.03267389163374901,
        "val_loss": 1.1481675931385584,
        "train_loss": 0.9430371429771185
      },
      {
        "epoch": 932,
        "reward": 0.03859464079141617,
        "val_loss": 0.8128685440335955,
        "train_loss": 0.8449640457446759
      },
      {
        "epoch": 933,
        "reward": 0.04029109701514244,
        "val_loss": 0.7432279246194022,
        "train_loss": 0.7417386781710845
      },
      {
        "epoch": 934,
        "reward": 0.035846367478370667,
        "val_loss": 0.9476834791047233,
        "train_loss": 0.8157502917143015
      },
      {
        "epoch": 935,
        "reward": 0.04065456613898277,
        "val_loss": 0.7294450998306274,
        "train_loss": 0.8548096899802868
      },
      {
        "epoch": 936,
        "reward": 0.037756022065877914,
        "val_loss": 0.8508621113640922,
        "train_loss": 0.8397792531893804
      },
      {
        "epoch": 937,
        "reward": 0.03447192534804344,
        "val_loss": 1.0276849355016435,
        "train_loss": 0.8239997556576362
      },
      {
        "epoch": 938,
        "reward": 0.040915440768003464,
        "val_loss": 0.7197812838213784,
        "train_loss": 0.768256685432369
      },
      {
        "epoch": 939,
        "reward": 0.03738623484969139,
        "val_loss": 0.8684441702706474,
        "train_loss": 0.7448931814959416
      },
      {
        "epoch": 940,
        "reward": 0.040019869804382324,
        "val_loss": 0.7537621217114585,
        "train_loss": 0.7971275838521811
      },
      {
        "epoch": 941,
        "reward": 0.040396548807621,
        "val_loss": 0.7391903230122158,
        "train_loss": 0.8137065298282183
      },
      {
        "epoch": 942,
        "reward": 0.040608204901218414,
        "val_loss": 0.7311822261129107,
        "train_loss": 0.810636641887518
      },
      {
        "epoch": 943,
        "reward": 0.039997365325689316,
        "val_loss": 0.7546459947313581,
        "train_loss": 0.8167773393484262
      },
      {
        "epoch": 944,
        "reward": 0.04052725061774254,
        "val_loss": 0.7342300202165332,
        "train_loss": 0.8194164817149823
      },
      {
        "epoch": 945,
        "reward": 0.0407705120742321,
        "val_loss": 0.7251267688614982,
        "train_loss": 0.8153026218597705
      },
      {
        "epoch": 946,
        "reward": 0.036890823394060135,
        "val_loss": 0.8928438935961042,
        "train_loss": 0.8060791996809152
      },
      {
        "epoch": 947,
        "reward": 0.03751615062355995,
        "val_loss": 0.862207123211452,
        "train_loss": 0.8455169590619894
      },
      {
        "epoch": 948,
        "reward": 0.03628857806324959,
        "val_loss": 0.9238794786589486,
        "train_loss": 0.7609499658529575
      },
      {
        "epoch": 949,
        "reward": 0.03876734897494316,
        "val_loss": 0.8053525771413531,
        "train_loss": 0.8670192727675805
      },
      {
        "epoch": 950,
        "reward": 0.03227801248431206,
        "val_loss": 1.177466869354248,
        "train_loss": 0.8375728670149468
      },
      {
        "epoch": 951,
        "reward": 0.03642837703227997,
        "val_loss": 0.9165360416684832,
        "train_loss": 0.818083602648515
      },
      {
        "epoch": 952,
        "reward": 0.04099569842219353,
        "val_loss": 0.7168459466525486,
        "train_loss": 0.8446916387631342
      },
      {
        "epoch": 953,
        "reward": 0.038213100284338,
        "val_loss": 0.8298400810786656,
        "train_loss": 0.8739067316055298
      },
      {
        "epoch": 954,
        "reward": 0.03946184739470482,
        "val_loss": 0.7761321152959552,
        "train_loss": 0.7937751698952454
      },
      {
        "epoch": 955,
        "reward": 0.03400510177016258,
        "val_loss": 1.0571161678859167,
        "train_loss": 0.8113285245803686
      },
      {
        "epoch": 956,
        "reward": 0.04051295295357704,
        "val_loss": 0.734770383153643,
        "train_loss": 1.041644492974648
      },
      {
        "epoch": 957,
        "reward": 0.037639960646629333,
        "val_loss": 0.8563237615994045,
        "train_loss": 0.8293497422844387
      },
      {
        "epoch": 958,
        "reward": 0.03875308856368065,
        "val_loss": 0.8059692127364022,
        "train_loss": 0.8271693014181577
      },
      {
        "epoch": 959,
        "reward": 0.03626841679215431,
        "val_loss": 0.9249456950596401,
        "train_loss": 0.7810896910153903
      },
      {
        "epoch": 960,
        "reward": 0.038192372769117355,
        "val_loss": 0.8307768872806004,
        "train_loss": 1.0330356646042604
      },
      {
        "epoch": 961,
        "reward": 0.04133237153291702,
        "val_loss": 0.7047201182161059,
        "train_loss": 0.844391779257701
      },
      {
        "epoch": 962,
        "reward": 0.03471522778272629,
        "val_loss": 1.0128195456096105,
        "train_loss": 0.7861829537611741
      },
      {
        "epoch": 963,
        "reward": 0.03656815364956856,
        "val_loss": 0.909278929233551,
        "train_loss": 0.9063078259619383
      },
      {
        "epoch": 964,
        "reward": 0.03967670351266861,
        "val_loss": 0.7674055610384259,
        "train_loss": 0.8576592482053317
      },
      {
        "epoch": 965,
        "reward": 0.035816844552755356,
        "val_loss": 0.9493046743529183,
        "train_loss": 0.8680159862224872
      },
      {
        "epoch": 966,
        "reward": 0.040229786187410355,
        "val_loss": 0.7455904143197196,
        "train_loss": 0.8116002610096564
      },
      {
        "epoch": 967,
        "reward": 0.04127439856529236,
        "val_loss": 0.7067865559032985,
        "train_loss": 0.8082197145200692
      },
      {
        "epoch": 968,
        "reward": 0.03621990606188774,
        "val_loss": 0.9275183592523847,
        "train_loss": 0.8092334958223196
      },
      {
        "epoch": 969,
        "reward": 0.03972448781132698,
        "val_loss": 0.7654842904635838,
        "train_loss": 0.9277752316915072
      },
      {
        "epoch": 970,
        "reward": 0.03572695702314377,
        "val_loss": 0.954265466758183,
        "train_loss": 0.7454006992853605
      },
      {
        "epoch": 971,
        "reward": 0.038098182529211044,
        "val_loss": 0.8350532991545541,
        "train_loss": 0.8423371888124026
      },
      {
        "epoch": 972,
        "reward": 0.03815959766507149,
        "val_loss": 0.8322611834321704,
        "train_loss": 0.7797721303426303
      },
      {
        "epoch": 973,
        "reward": 0.0391940139234066,
        "val_loss": 0.7872144324438912,
        "train_loss": 0.8157868637488439
      },
      {
        "epoch": 974,
        "reward": 0.037659283727407455,
        "val_loss": 0.8554107461656842,
        "train_loss": 0.7653260546234938
      },
      {
        "epoch": 975,
        "reward": 0.035496365278959274,
        "val_loss": 0.967166372707912,
        "train_loss": 0.8712966419183291
      },
      {
        "epoch": 976,
        "reward": 0.036712896078825,
        "val_loss": 0.9018521734646389,
        "train_loss": 0.8135214648567713
      },
      {
        "epoch": 977,
        "reward": 0.03783933445811272,
        "val_loss": 0.846972644329071,
        "train_loss": 0.8338009944328895
      },
      {
        "epoch": 978,
        "reward": 0.03979041799902916,
        "val_loss": 0.7628449712480817,
        "train_loss": 0.7546406181959006
      },
      {
        "epoch": 979,
        "reward": 0.03947388380765915,
        "val_loss": 0.7756393296377999,
        "train_loss": 0.8180477687945733
      },
      {
        "epoch": 980,
        "reward": 0.0379098616540432,
        "val_loss": 0.8437004855700901,
        "train_loss": 0.8441606771487457
      },
      {
        "epoch": 981,
        "reward": 0.03534495830535889,
        "val_loss": 0.9757762721606663,
        "train_loss": 0.7957491702758349
      },
      {
        "epoch": 982,
        "reward": 0.03995326906442642,
        "val_loss": 0.7563822610037667,
        "train_loss": 0.8668876382020804
      },
      {
        "epoch": 983,
        "reward": 0.03536228835582733,
        "val_loss": 0.9747851065226963,
        "train_loss": 0.7652324627672967
      },
      {
        "epoch": 984,
        "reward": 0.04009762778878212,
        "val_loss": 0.7507200155939374,
        "train_loss": 0.8520940060798938
      },
      {
        "epoch": 985,
        "reward": 0.03885846957564354,
        "val_loss": 0.8014281562396458,
        "train_loss": 0.7688416861570798
      },
      {
        "epoch": 986,
        "reward": 0.034780751913785934,
        "val_loss": 1.0088698863983154,
        "train_loss": 0.8185664908244059
      },
      {
        "epoch": 987,
        "reward": 0.03934857249259949,
        "val_loss": 0.7807912230491638,
        "train_loss": 0.7742403055912851
      },
      {
        "epoch": 988,
        "reward": 0.035788342356681824,
        "val_loss": 0.9508734856333051,
        "train_loss": 0.7424316131151639
      },
      {
        "epoch": 989,
        "reward": 0.038156088441610336,
        "val_loss": 0.8324205279350281,
        "train_loss": 0.8545892330316397
      },
      {
        "epoch": 990,
        "reward": 0.03644813224673271,
        "val_loss": 0.9155051793370929,
        "train_loss": 0.7915672602561804
      },
      {
        "epoch": 991,
        "reward": 0.03877672180533409,
        "val_loss": 0.8049476104123252,
        "train_loss": 0.7929462549778131
      },
      {
        "epoch": 992,
        "reward": 0.03995386138558388,
        "val_loss": 0.7563588534082685,
        "train_loss": 0.8471343035881336
      },
      {
        "epoch": 993,
        "reward": 0.04059083014726639,
        "val_loss": 0.731834909745625,
        "train_loss": 0.7932629241393163
      },
      {
        "epoch": 994,
        "reward": 0.03800453990697861,
        "val_loss": 0.8393368210111346,
        "train_loss": 0.8502853375214797
      },
      {
        "epoch": 995,
        "reward": 0.04094232618808746,
        "val_loss": 0.7187957763671875,
        "train_loss": 0.7962426004501489
      },
      {
        "epoch": 996,
        "reward": 0.03739437833428383,
        "val_loss": 0.8680512223924909,
        "train_loss": 0.8238331262881939
      },
      {
        "epoch": 997,
        "reward": 0.040252890437841415,
        "val_loss": 0.744698737348829,
        "train_loss": 0.7704323667746323
      },
      {
        "epoch": 998,
        "reward": 0.038356829434633255,
        "val_loss": 0.8233863541058132,
        "train_loss": 0.7958984200197917
      },
      {
        "epoch": 999,
        "reward": 0.03970151022076607,
        "val_loss": 0.7664072939327785,
        "train_loss": 0.8560352119115683
      },
      {
        "epoch": 1000,
        "reward": 0.040559038519859314,
        "val_loss": 0.733031017439706,
        "train_loss": 0.9158511184729062
      },
      {
        "epoch": 1001,
        "reward": 0.03976729139685631,
        "val_loss": 0.7637692264148167,
        "train_loss": 0.738710996050101
      },
      {
        "epoch": 1002,
        "reward": 0.039868004620075226,
        "val_loss": 0.7597560371671405,
        "train_loss": 0.889397009060933
      },
      {
        "epoch": 1003,
        "reward": 0.03945080563426018,
        "val_loss": 0.7765842420714242,
        "train_loss": 0.7735521380717938
      },
      {
        "epoch": 1004,
        "reward": 0.04144538938999176,
        "val_loss": 0.7007166487830025,
        "train_loss": 0.7843113472828498
      },
      {
        "epoch": 1005,
        "reward": 0.040714677423238754,
        "val_loss": 0.7272016406059265,
        "train_loss": 0.7666348539865934
      },
      {
        "epoch": 1006,
        "reward": 0.03964182734489441,
        "val_loss": 0.7688122051102775,
        "train_loss": 0.7721139341592789
      },
      {
        "epoch": 1007,
        "reward": 0.02997630275785923,
        "val_loss": 1.3717336228915624,
        "train_loss": 0.8228888397033398
      },
      {
        "epoch": 1008,
        "reward": 0.037694986909627914,
        "val_loss": 0.8537280644689288,
        "train_loss": 1.0749932412917798
      },
      {
        "epoch": 1009,
        "reward": 0.041090186685323715,
        "val_loss": 0.7134121145520892,
        "train_loss": 0.8615875307183999
      },
      {
        "epoch": 1010,
        "reward": 0.040256474167108536,
        "val_loss": 0.7445605993270874,
        "train_loss": 0.7626438095019414
      },
      {
        "epoch": 1011,
        "reward": 0.03905175253748894,
        "val_loss": 0.7931953157697406,
        "train_loss": 0.7928436902853159
      },
      {
        "epoch": 1012,
        "reward": 0.04069267213344574,
        "val_loss": 0.728021672793797,
        "train_loss": 0.7675977578529944
      },
      {
        "epoch": 1013,
        "reward": 0.03965338319540024,
        "val_loss": 0.7683458200522831,
        "train_loss": 0.7956636576698377
      },
      {
        "epoch": 1014,
        "reward": 0.03684490546584129,
        "val_loss": 0.8951559747968402,
        "train_loss": 0.8063870715693786
      },
      {
        "epoch": 1015,
        "reward": 0.038959801197052,
        "val_loss": 0.7970962566988808,
        "train_loss": 0.810899460544953
      },
      {
        "epoch": 1016,
        "reward": 0.03652368485927582,
        "val_loss": 0.9115784849439349,
        "train_loss": 0.7988635853219491
      },
      {
        "epoch": 1017,
        "reward": 0.039688896387815475,
        "val_loss": 0.7669145720345634,
        "train_loss": 0.8183512664758242
      },
      {
        "epoch": 1018,
        "reward": 0.040367480367422104,
        "val_loss": 0.7403002636773246,
        "train_loss": 0.8140213489532471
      },
      {
        "epoch": 1019,
        "reward": 0.03637987747788429,
        "val_loss": 0.919073862688882,
        "train_loss": 0.7833207341340872
      },
      {
        "epoch": 1020,
        "reward": 0.036199238151311874,
        "val_loss": 0.9286175540515355,
        "train_loss": 1.0138400953549604
      },
      {
        "epoch": 1021,
        "reward": 0.03397445008158684,
        "val_loss": 1.0590915083885193,
        "train_loss": 0.7854170122971902
      },
      {
        "epoch": 1022,
        "reward": 0.03984229639172554,
        "val_loss": 0.7607774479048592,
        "train_loss": 0.8580705947600878
      },
      {
        "epoch": 1023,
        "reward": 0.03807268664240837,
        "val_loss": 0.8362161857741219,
        "train_loss": 0.7751229840975541
      },
      {
        "epoch": 1024,
        "reward": 0.038219153881073,
        "val_loss": 0.8295667426926749,
        "train_loss": 0.7769993473767289
      },
      {
        "epoch": 1025,
        "reward": 0.03834310546517372,
        "val_loss": 0.8239993282726833,
        "train_loss": 0.8057672862823193
      },
      {
        "epoch": 1026,
        "reward": 0.03735551983118057,
        "val_loss": 0.8699284195899963,
        "train_loss": 0.9329705822926301
      },
      {
        "epoch": 1027,
        "reward": 0.04014812037348747,
        "val_loss": 0.7487539947032928,
        "train_loss": 0.8321810227174026
      },
      {
        "epoch": 1028,
        "reward": 0.036417633295059204,
        "val_loss": 0.9170973641531808,
        "train_loss": 0.8420493992475363
      },
      {
        "epoch": 1029,
        "reward": 0.03687555715441704,
        "val_loss": 0.8936116014208112,
        "train_loss": 0.9721580973038306
      },
      {
        "epoch": 1030,
        "reward": 0.038572072982788086,
        "val_loss": 0.8138580875737327,
        "train_loss": 0.7589117666849723
      },
      {
        "epoch": 1031,
        "reward": 0.038317929953336716,
        "val_loss": 0.8251259241785321,
        "train_loss": 0.8551044945533459
      },
      {
        "epoch": 1032,
        "reward": 0.03966768831014633,
        "val_loss": 0.7677689279828753,
        "train_loss": 0.8797156031315143
      },
      {
        "epoch": 1033,
        "reward": 0.04119396209716797,
        "val_loss": 0.7096686448369708,
        "train_loss": 0.7928835359903482
      },
      {
        "epoch": 1034,
        "reward": 0.038597237318754196,
        "val_loss": 0.8127547587667193,
        "train_loss": 0.7962497679086832
      },
      {
        "epoch": 1035,
        "reward": 0.03939234837889671,
        "val_loss": 0.7789857387542725,
        "train_loss": 0.8536148277612833
      },
      {
        "epoch": 1036,
        "reward": 0.037982963025569916,
        "val_loss": 0.8403282761573792,
        "train_loss": 0.8261664473953155
      },
      {
        "epoch": 1037,
        "reward": 0.03919908031821251,
        "val_loss": 0.7870027933801923,
        "train_loss": 0.7570998920844152
      },
      {
        "epoch": 1038,
        "reward": 0.038782354444265366,
        "val_loss": 0.8047042999948774,
        "train_loss": 0.787480904505803
      },
      {
        "epoch": 1039,
        "reward": 0.03802147135138512,
        "val_loss": 0.8385600277355739,
        "train_loss": 0.7507772864057467
      },
      {
        "epoch": 1040,
        "reward": 0.03978442773222923,
        "val_loss": 0.7630843094417027,
        "train_loss": 0.8254754474529853
      },
      {
        "epoch": 1041,
        "reward": 0.03649383783340454,
        "val_loss": 0.9131267411368233,
        "train_loss": 0.8219836537654583
      },
      {
        "epoch": 1042,
        "reward": 0.03962389752268791,
        "val_loss": 0.7695370316505432,
        "train_loss": 0.8751149269250723
      },
      {
        "epoch": 1043,
        "reward": 0.038125112652778625,
        "val_loss": 0.833827291216169,
        "train_loss": 0.7976240309385153
      },
      {
        "epoch": 1044,
        "reward": 0.03720162436366081,
        "val_loss": 0.877420995916639,
        "train_loss": 0.866718455002858
      },
      {
        "epoch": 1045,
        "reward": 0.039200518280267715,
        "val_loss": 0.7869427459580558,
        "train_loss": 0.8296839321175447
      },
      {
        "epoch": 1046,
        "reward": 0.03912489488720894,
        "val_loss": 0.7901121292795453,
        "train_loss": 0.8968118612582867
      },
      {
        "epoch": 1047,
        "reward": 0.03894747048616409,
        "val_loss": 0.7976216844149998,
        "train_loss": 0.760321672146137
      },
      {
        "epoch": 1048,
        "reward": 0.03884787857532501,
        "val_loss": 0.8018827097756522,
        "train_loss": 0.7609495331461613
      },
      {
        "epoch": 1049,
        "reward": 0.035952936857938766,
        "val_loss": 0.9418654697281974,
        "train_loss": 0.8311702746611375
      },
      {
        "epoch": 1050,
        "reward": 0.03978528082370758,
        "val_loss": 0.7630500538008553,
        "train_loss": 0.8767697753814551
      },
      {
        "epoch": 1051,
        "reward": 0.03915881738066673,
        "val_loss": 0.7886880551065717,
        "train_loss": 0.8611777539436634
      },
      {
        "epoch": 1052,
        "reward": 0.040473125874996185,
        "val_loss": 0.7362781933375767,
        "train_loss": 0.8030105382204056
      },
      {
        "epoch": 1053,
        "reward": 0.038751572370529175,
        "val_loss": 0.8060346586363656,
        "train_loss": 0.7773482593206259
      },
      {
        "epoch": 1054,
        "reward": 0.03803621605038643,
        "val_loss": 0.8378842941352299,
        "train_loss": 0.7816274681916604
      },
      {
        "epoch": 1055,
        "reward": 0.040492333471775055,
        "val_loss": 0.7355504972594125,
        "train_loss": 0.8167825730947348
      },
      {
        "epoch": 1056,
        "reward": 0.0329897478222847,
        "val_loss": 1.1255514110837663,
        "train_loss": 0.8018456055567815
      },
      {
        "epoch": 1057,
        "reward": 0.03645245358347893,
        "val_loss": 0.9152800355638776,
        "train_loss": 0.9546159574618707
      },
      {
        "epoch": 1058,
        "reward": 0.03999992460012436,
        "val_loss": 0.754545407635825,
        "train_loss": 0.8110714262494674
      },
      {
        "epoch": 1059,
        "reward": 0.04099355265498161,
        "val_loss": 0.7169240627970014,
        "train_loss": 0.7829756597773387
      },
      {
        "epoch": 1060,
        "reward": 0.03619217500090599,
        "val_loss": 0.9289937104497638,
        "train_loss": 0.7930585415317462
      },
      {
        "epoch": 1061,
        "reward": 0.03951723501086235,
        "val_loss": 0.7738685522760663,
        "train_loss": 0.8167802714384519
      },
      {
        "epoch": 1062,
        "reward": 0.03835217282176018,
        "val_loss": 0.8235942806516375,
        "train_loss": 0.932870287161607
      },
      {
        "epoch": 1063,
        "reward": 0.040181275457143784,
        "val_loss": 0.7474673986434937,
        "train_loss": 0.7862976147578313
      },
      {
        "epoch": 1064,
        "reward": 0.03858944773674011,
        "val_loss": 0.8130959911005837,
        "train_loss": 0.7935396994535739
      },
      {
        "epoch": 1065,
        "reward": 0.04047171398997307,
        "val_loss": 0.736331752368382,
        "train_loss": 0.7937870919704437
      },
      {
        "epoch": 1066,
        "reward": 0.036439936608076096,
        "val_loss": 0.9159326212746757,
        "train_loss": 0.8536148300537696
      },
      {
        "epoch": 1067,
        "reward": 0.03757292777299881,
        "val_loss": 0.8595018301691327,
        "train_loss": 0.9322644815995142
      },
      {
        "epoch": 1068,
        "reward": 0.04116463288664818,
        "val_loss": 0.7107237747737339,
        "train_loss": 0.916060631091778
      },
      {
        "epoch": 1069,
        "reward": 0.035895079374313354,
        "val_loss": 0.9450176869119916,
        "train_loss": 0.816143048210786
      },
      {
        "epoch": 1070,
        "reward": 0.041119031608104706,
        "val_loss": 0.7123686671257019,
        "train_loss": 0.851629984493439
      },
      {
        "epoch": 1071,
        "reward": 0.040380191057920456,
        "val_loss": 0.7398145369121006,
        "train_loss": 0.8123818177443284
      },
      {
        "epoch": 1072,
        "reward": 0.03483891114592552,
        "val_loss": 1.0053830742835999,
        "train_loss": 0.7576951315769782
      },
      {
        "epoch": 1073,
        "reward": 0.04038231819868088,
        "val_loss": 0.7397334405354091,
        "train_loss": 0.8857314059367547
      },
      {
        "epoch": 1074,
        "reward": 0.041148167103528976,
        "val_loss": 0.7113170410905566,
        "train_loss": 0.7670699081276185
      },
      {
        "epoch": 1075,
        "reward": 0.040605854243040085,
        "val_loss": 0.7312704835619245,
        "train_loss": 0.7332968935370445
      },
      {
        "epoch": 1076,
        "reward": 0.04081060364842415,
        "val_loss": 0.7236423151833671,
        "train_loss": 0.7940979714577014
      },
      {
        "epoch": 1077,
        "reward": 0.038972046226263046,
        "val_loss": 0.7965752737862724,
        "train_loss": 0.8026275823895748
      },
      {
        "epoch": 1078,
        "reward": 0.039227232336997986,
        "val_loss": 0.7858274536473411,
        "train_loss": 0.9559441781961001
      },
      {
        "epoch": 1079,
        "reward": 0.037459760904312134,
        "val_loss": 0.8649060726165771,
        "train_loss": 0.7857535607539691
      },
      {
        "epoch": 1080,
        "reward": 0.0385298989713192,
        "val_loss": 0.8157124774796622,
        "train_loss": 0.8236881196498871
      },
      {
        "epoch": 1081,
        "reward": 0.04093887656927109,
        "val_loss": 0.7189223681177411,
        "train_loss": 0.7308011880287757
      },
      {
        "epoch": 1082,
        "reward": 0.03810093551874161,
        "val_loss": 0.8349277717726571,
        "train_loss": 0.7405070289969444
      },
      {
        "epoch": 1083,
        "reward": 0.03813568875193596,
        "val_loss": 0.83334652866636,
        "train_loss": 0.7840858197842653
      },
      {
        "epoch": 1084,
        "reward": 0.035347651690244675,
        "val_loss": 0.9756221430642265,
        "train_loss": 0.8388437170248765
      },
      {
        "epoch": 1085,
        "reward": 0.039133064448833466,
        "val_loss": 0.7897688576153347,
        "train_loss": 0.8010506741702557
      },
      {
        "epoch": 1086,
        "reward": 0.04021751508116722,
        "val_loss": 0.7460646373885018,
        "train_loss": 0.8530809374955984
      },
      {
        "epoch": 1087,
        "reward": 0.041087400168180466,
        "val_loss": 0.713513161454882,
        "train_loss": 0.7766543546548257
      },
      {
        "epoch": 1088,
        "reward": 0.04027773067355156,
        "val_loss": 0.7437420317104885,
        "train_loss": 0.7718411569411938
      },
      {
        "epoch": 1089,
        "reward": 0.03735606372356415,
        "val_loss": 0.869901989187513,
        "train_loss": 0.786195942415641
      },
      {
        "epoch": 1090,
        "reward": 0.037451621145009995,
        "val_loss": 0.8652967129434858,
        "train_loss": 0.8238190779319177
      },
      {
        "epoch": 1091,
        "reward": 0.03691425547003746,
        "val_loss": 0.8916674937520709,
        "train_loss": 0.813441100028845
      },
      {
        "epoch": 1092,
        "reward": 0.03876187652349472,
        "val_loss": 0.8055891139166695,
        "train_loss": 0.804268129169941
      },
      {
        "epoch": 1093,
        "reward": 0.040721531957387924,
        "val_loss": 0.7269463283675057,
        "train_loss": 0.8509223392376533
      },
      {
        "epoch": 1094,
        "reward": 0.0401504747569561,
        "val_loss": 0.7486626761300224,
        "train_loss": 0.8311780966245211
      },
      {
        "epoch": 1095,
        "reward": 0.03776341304183006,
        "val_loss": 0.8505158339227948,
        "train_loss": 0.7839287702853863
      },
      {
        "epoch": 1096,
        "reward": 0.03738957270979881,
        "val_loss": 0.8682831525802612,
        "train_loss": 0.8109786510467529
      },
      {
        "epoch": 1097,
        "reward": 0.03985368832945824,
        "val_loss": 0.760324341910226,
        "train_loss": 0.830753679602192
      },
      {
        "epoch": 1098,
        "reward": 0.038593802601099014,
        "val_loss": 0.8129052604947772,
        "train_loss": 0.750431858576261
      },
      {
        "epoch": 1099,
        "reward": 0.03541068732738495,
        "val_loss": 0.9720248069081988,
        "train_loss": 0.8440332275170547
      },
      {
        "epoch": 1100,
        "reward": 0.04090656712651253,
        "val_loss": 0.7201069891452789,
        "train_loss": 0.7921744653811822
      },
      {
        "epoch": 1101,
        "reward": 0.03570783510804176,
        "val_loss": 0.9553256886346,
        "train_loss": 0.758091525389598
      },
      {
        "epoch": 1102,
        "reward": 0.041757579892873764,
        "val_loss": 0.6898287790162223,
        "train_loss": 0.9034952085751754
      },
      {
        "epoch": 1103,
        "reward": 0.0384962372481823,
        "val_loss": 0.8171967438289097,
        "train_loss": 0.821015172279798
      },
      {
        "epoch": 1104,
        "reward": 0.0350368432700634,
        "val_loss": 0.9936484609331403,
        "train_loss": 0.77234768982117
      },
      {
        "epoch": 1105,
        "reward": 0.04076028987765312,
        "val_loss": 0.7255059991564069,
        "train_loss": 0.8875901699066162
      },
      {
        "epoch": 1106,
        "reward": 0.04025312140583992,
        "val_loss": 0.7446900180407933,
        "train_loss": 0.8017648848203512
      },
      {
        "epoch": 1107,
        "reward": 0.04034096375107765,
        "val_loss": 0.7413146410669599,
        "train_loss": 0.8655018210411072
      },
      {
        "epoch": 1108,
        "reward": 0.037388306111097336,
        "val_loss": 0.8683440940720695,
        "train_loss": 0.9778161438611838
      },
      {
        "epoch": 1109,
        "reward": 0.037905897945165634,
        "val_loss": 0.8438838805471148,
        "train_loss": 0.7907691712562854
      },
      {
        "epoch": 1110,
        "reward": 0.040302786976099014,
        "val_loss": 0.7427787780761719,
        "train_loss": 0.8070302445154923
      },
      {
        "epoch": 1111,
        "reward": 0.03909320756793022,
        "val_loss": 0.7914458002362933,
        "train_loss": 0.7889302556331341
      },
      {
        "epoch": 1112,
        "reward": 0.0400005504488945,
        "val_loss": 0.7545209016118731,
        "train_loss": 0.8149221241474152
      },
      {
        "epoch": 1113,
        "reward": 0.04073290154337883,
        "val_loss": 0.7265234759875706,
        "train_loss": 0.7435040898047961
      },
      {
        "epoch": 1114,
        "reward": 0.04064911976456642,
        "val_loss": 0.7296487774167743,
        "train_loss": 0.7633763528787173
      },
      {
        "epoch": 1115,
        "reward": 0.04114928096532822,
        "val_loss": 0.7112769186496735,
        "train_loss": 0.8742492359418136
      },
      {
        "epoch": 1116,
        "reward": 0.04102631285786629,
        "val_loss": 0.715730607509613,
        "train_loss": 0.7800563275814056
      },
      {
        "epoch": 1117,
        "reward": 0.03909391537308693,
        "val_loss": 0.7914159297943115,
        "train_loss": 0.7922263563333007
      },
      {
        "epoch": 1118,
        "reward": 0.03995519503951073,
        "val_loss": 0.7563062139919826,
        "train_loss": 0.7912678328844217
      },
      {
        "epoch": 1119,
        "reward": 0.04006919264793396,
        "val_loss": 0.7518303138869149,
        "train_loss": 0.7864343111331646
      },
      {
        "epoch": 1120,
        "reward": 0.03692154213786125,
        "val_loss": 0.8913017426218305,
        "train_loss": 0.7823487864090846
      },
      {
        "epoch": 1121,
        "reward": 0.041807983070611954,
        "val_loss": 0.6880941263266972,
        "train_loss": 0.7780507963437301
      },
      {
        "epoch": 1122,
        "reward": 0.03911726549267769,
        "val_loss": 0.790432904447828,
        "train_loss": 0.7829043564315026
      },
      {
        "epoch": 1123,
        "reward": 0.041153207421302795,
        "val_loss": 0.7111352511814663,
        "train_loss": 0.7821615200776321
      },
      {
        "epoch": 1124,
        "reward": 0.039822857826948166,
        "val_loss": 0.7615512268883842,
        "train_loss": 0.840757817029953
      },
      {
        "epoch": 1125,
        "reward": 0.03909749910235405,
        "val_loss": 0.7912649171692985,
        "train_loss": 0.804490878031804
      },
      {
        "epoch": 1126,
        "reward": 0.03652995452284813,
        "val_loss": 0.911253809928894,
        "train_loss": 0.7397706451324316
      },
      {
        "epoch": 1127,
        "reward": 0.041599806398153305,
        "val_loss": 0.6953001235212598,
        "train_loss": 0.8956331083407769
      },
      {
        "epoch": 1128,
        "reward": 0.03882254660129547,
        "val_loss": 0.8029717632702419,
        "train_loss": 0.8275908598533044
      },
      {
        "epoch": 1129,
        "reward": 0.03747374564409256,
        "val_loss": 0.8642356225422451,
        "train_loss": 0.7560580842770063
      },
      {
        "epoch": 1130,
        "reward": 0.04134363308548927,
        "val_loss": 0.7043196984699794,
        "train_loss": 0.7986479092102784
      },
      {
        "epoch": 1131,
        "reward": 0.039505865424871445,
        "val_loss": 0.7743325063160488,
        "train_loss": 0.781607169801226
      },
      {
        "epoch": 1132,
        "reward": 0.03103259764611721,
        "val_loss": 1.2771537389074052,
        "train_loss": 0.7303364988989555
      },
      {
        "epoch": 1133,
        "reward": 0.03410125896334648,
        "val_loss": 1.0509536692074366,
        "train_loss": 0.9080295241796054
      },
      {
        "epoch": 1134,
        "reward": 0.04025237262248993,
        "val_loss": 0.7447188241141183,
        "train_loss": 0.8961457701829764
      },
      {
        "epoch": 1135,
        "reward": 0.04027801379561424,
        "val_loss": 0.7437312688146319,
        "train_loss": 0.7519354591002831
      },
      {
        "epoch": 1136,
        "reward": 0.03955515846610069,
        "val_loss": 0.7723244684083121,
        "train_loss": 0.7713761558899512
      },
      {
        "epoch": 1137,
        "reward": 0.0389154888689518,
        "val_loss": 0.7989862476076398,
        "train_loss": 0.7899812450632453
      },
      {
        "epoch": 1138,
        "reward": 0.039362456649541855,
        "val_loss": 0.7802180477551052,
        "train_loss": 0.769575508741232
      },
      {
        "epoch": 1139,
        "reward": 0.03946978971362114,
        "val_loss": 0.7758069975035531,
        "train_loss": 0.7824899095755357
      },
      {
        "epoch": 1140,
        "reward": 0.03820131719112396,
        "val_loss": 0.8303722739219666,
        "train_loss": 0.8033271156824552
      },
      {
        "epoch": 1141,
        "reward": 0.04017842188477516,
        "val_loss": 0.7475778801100594,
        "train_loss": 0.8447101505903097
      },
      {
        "epoch": 1142,
        "reward": 0.03759808465838432,
        "val_loss": 0.8583069443702698,
        "train_loss": 0.7357245430063742
      },
      {
        "epoch": 1143,
        "reward": 0.03861577808856964,
        "val_loss": 0.8119430797440665,
        "train_loss": 0.8239561938322507
      },
      {
        "epoch": 1144,
        "reward": 0.03387698903679848,
        "val_loss": 1.0654093282563346,
        "train_loss": 0.8242651281448511
      },
      {
        "epoch": 1145,
        "reward": 0.034955572336912155,
        "val_loss": 0.9984425221170697,
        "train_loss": 0.9456470528474221
      },
      {
        "epoch": 1146,
        "reward": 0.03889283537864685,
        "val_loss": 0.7999550444739205,
        "train_loss": 0.8516293534865746
      },
      {
        "epoch": 1147,
        "reward": 0.04112092778086662,
        "val_loss": 0.7122999940599714,
        "train_loss": 0.8174398908248315
      },
      {
        "epoch": 1148,
        "reward": 0.04126448556780815,
        "val_loss": 0.7071407181876046,
        "train_loss": 0.7879508917148297
      },
      {
        "epoch": 1149,
        "reward": 0.03848283737897873,
        "val_loss": 0.8177887116159711,
        "train_loss": 0.7750626994440188
      },
      {
        "epoch": 1150,
        "reward": 0.03829328715801239,
        "val_loss": 0.8262304152761187,
        "train_loss": 0.7483433129695746
      },
      {
        "epoch": 1151,
        "reward": 0.04047250375151634,
        "val_loss": 0.7363018478666034,
        "train_loss": 0.8429607634360974
      },
      {
        "epoch": 1152,
        "reward": 0.04010148346424103,
        "val_loss": 0.7505695905004229,
        "train_loss": 0.7904451489448547
      },
      {
        "epoch": 1153,
        "reward": 0.040672872215509415,
        "val_loss": 0.7287607448441642,
        "train_loss": 0.8148531455260056
      },
      {
        "epoch": 1154,
        "reward": 0.041027043014764786,
        "val_loss": 0.7157041600772313,
        "train_loss": 0.7890314839493769
      },
      {
        "epoch": 1155,
        "reward": 0.03965719789266586,
        "val_loss": 0.7681919421468463,
        "train_loss": 0.7677719902533752
      },
      {
        "epoch": 1156,
        "reward": 0.040409158915281296,
        "val_loss": 0.7387096541268485,
        "train_loss": 0.7702222581093128
      },
      {
        "epoch": 1157,
        "reward": 0.04069199040532112,
        "val_loss": 0.7280470473425729,
        "train_loss": 0.755202496281037
      },
      {
        "epoch": 1158,
        "reward": 0.03872666880488396,
        "val_loss": 0.8071136730057853,
        "train_loss": 0.8200884048755352
      },
      {
        "epoch": 1159,
        "reward": 0.04061529040336609,
        "val_loss": 0.7309162446430751,
        "train_loss": 0.8042803911062387
      },
      {
        "epoch": 1160,
        "reward": 0.039182618260383606,
        "val_loss": 0.7876910993031093,
        "train_loss": 0.7453481735518346
      },
      {
        "epoch": 1161,
        "reward": 0.03775428608059883,
        "val_loss": 0.8509433780397687,
        "train_loss": 0.771361211171517
      },
      {
        "epoch": 1162,
        "reward": 0.04022083058953285,
        "val_loss": 0.7459363852228437,
        "train_loss": 0.8649651339420905
      },
      {
        "epoch": 1163,
        "reward": 0.03947703167796135,
        "val_loss": 0.7755107368741717,
        "train_loss": 0.768677816941188
      },
      {
        "epoch": 1164,
        "reward": 0.04071732982993126,
        "val_loss": 0.7271027650151934,
        "train_loss": 0.810914560006215
      },
      {
        "epoch": 1165,
        "reward": 0.038752879947423935,
        "val_loss": 0.8059781960078648,
        "train_loss": 0.7583742863856829
      },
      {
        "epoch": 1166,
        "reward": 0.040785472840070724,
        "val_loss": 0.7245722157614571,
        "train_loss": 0.7990763256183038
      },
      {
        "epoch": 1167,
        "reward": 0.0405413955450058,
        "val_loss": 0.7336961967604501,
        "train_loss": 0.759696717445667
      },
      {
        "epoch": 1168,
        "reward": 0.0401814803481102,
        "val_loss": 0.7474593775612968,
        "train_loss": 0.7722826256201818
      },
      {
        "epoch": 1169,
        "reward": 0.04011024162173271,
        "val_loss": 0.7502281836100987,
        "train_loss": 0.7682053320682966
      },
      {
        "epoch": 1170,
        "reward": 0.038771096616983414,
        "val_loss": 0.8051906142915998,
        "train_loss": 0.7872080115171579
      },
      {
        "epoch": 1171,
        "reward": 0.04029722511768341,
        "val_loss": 0.7429925458771842,
        "train_loss": 0.7737468675925181
      },
      {
        "epoch": 1172,
        "reward": 0.03807181492447853,
        "val_loss": 0.8362561294010707,
        "train_loss": 0.7704526595771313
      },
      {
        "epoch": 1173,
        "reward": 0.040821176022291183,
        "val_loss": 0.7232513768332345,
        "train_loss": 0.8412104936746451
      },
      {
        "epoch": 1174,
        "reward": 0.041375741362571716,
        "val_loss": 0.7031799214226859,
        "train_loss": 0.8676267151649182
      },
      {
        "epoch": 1175,
        "reward": 0.0398561991751194,
        "val_loss": 0.7602246829441616,
        "train_loss": 0.7601129745061581
      },
      {
        "epoch": 1176,
        "reward": 0.038595203310251236,
        "val_loss": 0.8128437570163182,
        "train_loss": 0.85877525806427
      },
      {
        "epoch": 1177,
        "reward": 0.03704719617962837,
        "val_loss": 0.885035114628928,
        "train_loss": 0.8957419555920821
      },
      {
        "epoch": 1178,
        "reward": 0.0408155731856823,
        "val_loss": 0.7234586562429156,
        "train_loss": 0.8227134748147085
      },
      {
        "epoch": 1179,
        "reward": 0.04091968759894371,
        "val_loss": 0.7196253708430699,
        "train_loss": 0.7851905318406912
      },
      {
        "epoch": 1180,
        "reward": 0.04099084436893463,
        "val_loss": 0.7170229171003614,
        "train_loss": 0.8169448971748352
      },
      {
        "epoch": 1181,
        "reward": 0.03244830295443535,
        "val_loss": 1.1647308724267142,
        "train_loss": 0.7465463870993028
      },
      {
        "epoch": 1182,
        "reward": 0.036700289696455,
        "val_loss": 0.9024956396647862,
        "train_loss": 0.8451702795349635
      },
      {
        "epoch": 1183,
        "reward": 0.03563545644283295,
        "val_loss": 0.959354179246085,
        "train_loss": 0.8388175388368276
      },
      {
        "epoch": 1184,
        "reward": 0.04006141424179077,
        "val_loss": 0.7521344934191022,
        "train_loss": 0.8554256953872167
      },
      {
        "epoch": 1185,
        "reward": 0.03990338370203972,
        "val_loss": 0.7583533866064889,
        "train_loss": 0.7588038439504229
      },
      {
        "epoch": 1186,
        "reward": 0.037598513066768646,
        "val_loss": 0.8582868150302342,
        "train_loss": 0.7694725812627718
      },
      {
        "epoch": 1187,
        "reward": 0.041212521493434906,
        "val_loss": 0.7090022138186863,
        "train_loss": 0.824769519842588
      },
      {
        "epoch": 1188,
        "reward": 0.04159284010529518,
        "val_loss": 0.6955433104719434,
        "train_loss": 0.7450103151540344
      },
      {
        "epoch": 1189,
        "reward": 0.03843731805682182,
        "val_loss": 0.8198045066424778,
        "train_loss": 0.8495999964383932
      },
      {
        "epoch": 1190,
        "reward": 0.03712202236056328,
        "val_loss": 0.8813338705471584,
        "train_loss": 0.870768775160496
      },
      {
        "epoch": 1191,
        "reward": 0.03544406220316887,
        "val_loss": 0.9701279742377145,
        "train_loss": 0.8720424519135401
      },
      {
        "epoch": 1192,
        "reward": 0.0382331907749176,
        "val_loss": 0.8289335199764797,
        "train_loss": 0.8745015469881204
      },
      {
        "epoch": 1193,
        "reward": 0.040082380175590515,
        "val_loss": 0.7513151126248496,
        "train_loss": 0.7691576652801954
      },
      {
        "epoch": 1194,
        "reward": 0.03951273858547211,
        "val_loss": 0.774051947253091,
        "train_loss": 0.7475143559277058
      },
      {
        "epoch": 1195,
        "reward": 0.038202300667762756,
        "val_loss": 0.8303279110363552,
        "train_loss": 0.8101613727899698
      },
      {
        "epoch": 1196,
        "reward": 0.035848263651132584,
        "val_loss": 0.9475797499929156,
        "train_loss": 0.8011142468559018
      },
      {
        "epoch": 1197,
        "reward": 0.0410572849214077,
        "val_loss": 0.7146051185471671,
        "train_loss": 0.8330386040302423
      },
      {
        "epoch": 1198,
        "reward": 0.04044325277209282,
        "val_loss": 0.7374120780399868,
        "train_loss": 0.7864085160768949
      },
      {
        "epoch": 1199,
        "reward": 0.03994454815983772,
        "val_loss": 0.7567262734685626,
        "train_loss": 0.7641357492942077
      },
      {
        "epoch": 1200,
        "reward": 0.03763071075081825,
        "val_loss": 0.8567612767219543,
        "train_loss": 0.7970285140551053
      },
      {
        "epoch": 1201,
        "reward": 0.04105142503976822,
        "val_loss": 0.7148178475243705,
        "train_loss": 0.7959133994120818
      },
      {
        "epoch": 1202,
        "reward": 0.038732051849365234,
        "val_loss": 0.8068802101271493,
        "train_loss": 0.8179116890980647
      },
      {
        "epoch": 1203,
        "reward": 0.04084338620305061,
        "val_loss": 0.72243161712374,
        "train_loss": 0.8329710708214686
      },
      {
        "epoch": 1204,
        "reward": 0.040160637348890305,
        "val_loss": 0.7482679401125226,
        "train_loss": 0.7472893355331437
      },
      {
        "epoch": 1205,
        "reward": 0.04025524482131004,
        "val_loss": 0.7446079083851406,
        "train_loss": 0.7801481668765728
      },
      {
        "epoch": 1206,
        "reward": 0.03907952085137367,
        "val_loss": 0.7920227817126683,
        "train_loss": 0.760928492133434
      },
      {
        "epoch": 1207,
        "reward": 0.04169164225459099,
        "val_loss": 0.6921078051839556,
        "train_loss": 0.7357429953721853
      },
      {
        "epoch": 1208,
        "reward": 0.038751550018787384,
        "val_loss": 0.8060358507292611,
        "train_loss": 0.7656965232812442
      },
      {
        "epoch": 1209,
        "reward": 0.038495007902383804,
        "val_loss": 0.8172509797981807,
        "train_loss": 0.8940294820528764
      },
      {
        "epoch": 1210,
        "reward": 0.03617274388670921,
        "val_loss": 0.9300294007573809,
        "train_loss": 0.9665071084522284
      },
      {
        "epoch": 1211,
        "reward": 0.03976641595363617,
        "val_loss": 0.7638041887964521,
        "train_loss": 0.7886722798530872
      },
      {
        "epoch": 1212,
        "reward": 0.03351294621825218,
        "val_loss": 1.0895020876611983,
        "train_loss": 0.7731309017309775
      },
      {
        "epoch": 1213,
        "reward": 0.04154474660754204,
        "val_loss": 0.6972244211605617,
        "train_loss": 0.7824981774275119
      },
      {
        "epoch": 1214,
        "reward": 0.03832395002245903,
        "val_loss": 0.8248562642506191,
        "train_loss": 0.8009745650566541
      },
      {
        "epoch": 1215,
        "reward": 0.037824489176273346,
        "val_loss": 0.847663938999176,
        "train_loss": 0.7804435663498365
      },
      {
        "epoch": 1216,
        "reward": 0.034497860819101334,
        "val_loss": 1.026084908417293,
        "train_loss": 0.7665136502339289
      },
      {
        "epoch": 1217,
        "reward": 0.041022446006536484,
        "val_loss": 0.7158713340759277,
        "train_loss": 0.8223677383592496
      },
      {
        "epoch": 1218,
        "reward": 0.035211171954870224,
        "val_loss": 0.9834781544549125,
        "train_loss": 0.8212308883666992
      },
      {
        "epoch": 1219,
        "reward": 0.04164876788854599,
        "val_loss": 0.6935956392969403,
        "train_loss": 0.7840448732559497
      },
      {
        "epoch": 1220,
        "reward": 0.03757164999842644,
        "val_loss": 0.8595627120562962,
        "train_loss": 0.7511093427355473
      },
      {
        "epoch": 1221,
        "reward": 0.040864091366529465,
        "val_loss": 0.7216686350958688,
        "train_loss": 0.8121103736070486
      },
      {
        "epoch": 1222,
        "reward": 0.0395071879029274,
        "val_loss": 0.774278495992933,
        "train_loss": 0.7439790196143664
      },
      {
        "epoch": 1223,
        "reward": 0.04000132158398628,
        "val_loss": 0.7544905287878854,
        "train_loss": 0.7442534076623045
      },
      {
        "epoch": 1224,
        "reward": 0.036642905324697495,
        "val_loss": 0.9054320710045951,
        "train_loss": 0.7573498774033326
      },
      {
        "epoch": 1225,
        "reward": 0.03299308195710182,
        "val_loss": 1.1253162111554826,
        "train_loss": 0.8810876584970034
      },
      {
        "epoch": 1226,
        "reward": 0.040126051753759384,
        "val_loss": 0.7496122888156346,
        "train_loss": 0.8615472408441397
      },
      {
        "epoch": 1227,
        "reward": 0.03896322473883629,
        "val_loss": 0.7969505616596767,
        "train_loss": 0.7890086552271476
      },
      {
        "epoch": 1228,
        "reward": 0.03741229698061943,
        "val_loss": 0.867187670298985,
        "train_loss": 0.8771519913123205
      },
      {
        "epoch": 1229,
        "reward": 0.03835934028029442,
        "val_loss": 0.8232743740081787,
        "train_loss": 0.7611118302895472
      },
      {
        "epoch": 1230,
        "reward": 0.04128393158316612,
        "val_loss": 0.70644611120224,
        "train_loss": 0.7744097927441964
      },
      {
        "epoch": 1231,
        "reward": 0.04092549905180931,
        "val_loss": 0.719412339585168,
        "train_loss": 0.765764234157709
      },
      {
        "epoch": 1232,
        "reward": 0.0388462133705616,
        "val_loss": 0.8019541842596871,
        "train_loss": 0.7571183314117101
      },
      {
        "epoch": 1233,
        "reward": 0.03711860254406929,
        "val_loss": 0.8815025516918727,
        "train_loss": 0.8021225516612713
      },
      {
        "epoch": 1234,
        "reward": 0.04018974304199219,
        "val_loss": 0.7471391814095634,
        "train_loss": 0.7749346242501185
      },
      {
        "epoch": 1235,
        "reward": 0.04061631113290787,
        "val_loss": 0.7308780636106219,
        "train_loss": 0.7958457584564502
      },
      {
        "epoch": 1236,
        "reward": 0.03998471796512604,
        "val_loss": 0.7551433742046356,
        "train_loss": 0.7836637302086904
      },
      {
        "epoch": 1237,
        "reward": 0.04071846976876259,
        "val_loss": 0.7270603946277073,
        "train_loss": 0.8170594573020935
      },
      {
        "epoch": 1238,
        "reward": 0.03932113200426102,
        "val_loss": 0.7819260018212455,
        "train_loss": 0.7771159937748542
      },
      {
        "epoch": 1239,
        "reward": 0.03903196007013321,
        "val_loss": 0.79403270142419,
        "train_loss": 0.7752676603312676
      },
      {
        "epoch": 1240,
        "reward": 0.03625566512346268,
        "val_loss": 0.9256208368710109,
        "train_loss": 0.8257580101490021
      },
      {
        "epoch": 1241,
        "reward": 0.04013020917773247,
        "val_loss": 0.7494506239891052,
        "train_loss": 0.7969590666202399
      },
      {
        "epoch": 1242,
        "reward": 0.0400453619658947,
        "val_loss": 0.7527629477637154,
        "train_loss": 0.7786105917050288
      },
      {
        "epoch": 1243,
        "reward": 0.0385720394551754,
        "val_loss": 0.8138595989772252,
        "train_loss": 0.7414030237839773
      },
      {
        "epoch": 1244,
        "reward": 0.04086580500006676,
        "val_loss": 0.7216054030827114,
        "train_loss": 0.7593793559532899
      },
      {
        "epoch": 1245,
        "reward": 0.03871859237551689,
        "val_loss": 0.807463960988181,
        "train_loss": 0.76138652746494
      },
      {
        "epoch": 1246,
        "reward": 0.03690018877387047,
        "val_loss": 0.892373263835907,
        "train_loss": 0.7861173290472764
      },
      {
        "epoch": 1247,
        "reward": 0.03884635865688324,
        "val_loss": 0.8019479513168335,
        "train_loss": 0.8099076100266897
      },
      {
        "epoch": 1248,
        "reward": 0.038108523935079575,
        "val_loss": 0.8345822010721479,
        "train_loss": 0.8562878943406619
      },
      {
        "epoch": 1249,
        "reward": 0.03376896306872368,
        "val_loss": 1.072476097515651,
        "train_loss": 0.8159831051643078
      },
      {
        "epoch": 1250,
        "reward": 0.04062692075967789,
        "val_loss": 0.7304801600319999,
        "train_loss": 0.8301155622690343
      },
      {
        "epoch": 1251,
        "reward": 0.04120512306690216,
        "val_loss": 0.7092676843915667,
        "train_loss": 0.7729201534619698
      },
      {
        "epoch": 1252,
        "reward": 0.038288213312625885,
        "val_loss": 0.826458181653704,
        "train_loss": 0.7382073195364612
      },
      {
        "epoch": 1253,
        "reward": 0.04152557998895645,
        "val_loss": 0.6978962080819267,
        "train_loss": 0.8017822160170629
      },
      {
        "epoch": 1254,
        "reward": 0.03940268233418465,
        "val_loss": 0.7785604085241046,
        "train_loss": 0.8644685676464667
      },
      {
        "epoch": 1255,
        "reward": 0.04095442220568657,
        "val_loss": 0.7183533310890198,
        "train_loss": 0.8125488505913661
      },
      {
        "epoch": 1256,
        "reward": 0.04126438498497009,
        "val_loss": 0.7071444136755807,
        "train_loss": 0.7518428518221929
      },
      {
        "epoch": 1257,
        "reward": 0.036390915513038635,
        "val_loss": 0.9184955443654742,
        "train_loss": 0.7984232871005168
      },
      {
        "epoch": 1258,
        "reward": 0.0417095422744751,
        "val_loss": 0.6914879679679871,
        "train_loss": 0.7780215258781726
      },
      {
        "epoch": 1259,
        "reward": 0.03927409276366234,
        "val_loss": 0.783876895904541,
        "train_loss": 0.7521896488391436
      },
      {
        "epoch": 1260,
        "reward": 0.040110841393470764,
        "val_loss": 0.7502048781939915,
        "train_loss": 0.7659565886625876
      },
      {
        "epoch": 1261,
        "reward": 0.03854016587138176,
        "val_loss": 0.8152602059500558,
        "train_loss": 0.7903271775979263
      },
      {
        "epoch": 1262,
        "reward": 0.0397365540266037,
        "val_loss": 0.7650003433227539,
        "train_loss": 0.8248977500658768
      },
      {
        "epoch": 1263,
        "reward": 0.04102743789553642,
        "val_loss": 0.7156897016933986,
        "train_loss": 0.8588196841570047
      },
      {
        "epoch": 1264,
        "reward": 0.04014336317777634,
        "val_loss": 0.7489391224724906,
        "train_loss": 0.7420449027648339
      },
      {
        "epoch": 1265,
        "reward": 0.04000761732459068,
        "val_loss": 0.7542431439672198,
        "train_loss": 0.7478575884149625
      },
      {
        "epoch": 1266,
        "reward": 0.04120562598109245,
        "val_loss": 0.7092496114117759,
        "train_loss": 0.8240724779092349
      },
      {
        "epoch": 1267,
        "reward": 0.03838503733277321,
        "val_loss": 0.8221284917422703,
        "train_loss": 0.8139827641157004
      },
      {
        "epoch": 1268,
        "reward": 0.037792500108480453,
        "val_loss": 0.849155843257904,
        "train_loss": 0.7848951231974822
      },
      {
        "epoch": 1269,
        "reward": 0.04135270044207573,
        "val_loss": 0.7039976503167834,
        "train_loss": 0.7505028141805759
      },
      {
        "epoch": 1270,
        "reward": 0.04010770842432976,
        "val_loss": 0.7503268463271004,
        "train_loss": 0.7451409701831065
      },
      {
        "epoch": 1271,
        "reward": 0.04057017341256142,
        "val_loss": 0.7326117668833051,
        "train_loss": 0.7606628628877493
      },
      {
        "epoch": 1272,
        "reward": 0.03785594925284386,
        "val_loss": 0.8462002532822746,
        "train_loss": 0.8116503449586722
      },
      {
        "epoch": 1273,
        "reward": 0.04044065997004509,
        "val_loss": 0.7375108514513288,
        "train_loss": 0.7561086530868824
      },
      {
        "epoch": 1274,
        "reward": 0.040925249457359314,
        "val_loss": 0.7194215144429889,
        "train_loss": 0.7625570801588205
      },
      {
        "epoch": 1275,
        "reward": 0.03854875639081001,
        "val_loss": 0.8148825083460126,
        "train_loss": 0.8156169194441575
      },
      {
        "epoch": 1276,
        "reward": 0.04029377922415733,
        "val_loss": 0.7431249277932304,
        "train_loss": 0.7550446471342673
      },
      {
        "epoch": 1277,
        "reward": 0.04044445604085922,
        "val_loss": 0.7373666337558201,
        "train_loss": 0.8823329439530005
      },
      {
        "epoch": 1278,
        "reward": 0.03951902315020561,
        "val_loss": 0.7737957579748971,
        "train_loss": 0.8244952674095447
      },
      {
        "epoch": 1279,
        "reward": 0.04109729826450348,
        "val_loss": 0.7131547416959491,
        "train_loss": 0.7969078077719762
      },
      {
        "epoch": 1280,
        "reward": 0.040927425026893616,
        "val_loss": 0.7193416782787868,
        "train_loss": 0.7907153047048129
      },
      {
        "epoch": 1281,
        "reward": 0.04008958488702774,
        "val_loss": 0.7510338212762561,
        "train_loss": 0.8827377259731293
      },
      {
        "epoch": 1282,
        "reward": 0.040580231696367264,
        "val_loss": 0.7322333369936261,
        "train_loss": 0.823237021238758
      },
      {
        "epoch": 1283,
        "reward": 0.04036543518304825,
        "val_loss": 0.7403782946722848,
        "train_loss": 0.7271618562249037
      },
      {
        "epoch": 1284,
        "reward": 0.038945574313402176,
        "val_loss": 0.7977024061339242,
        "train_loss": 0.7520314214321283
      },
      {
        "epoch": 1285,
        "reward": 0.04010568559169769,
        "val_loss": 0.7504056096076965,
        "train_loss": 0.7873092752236587
      },
      {
        "epoch": 1286,
        "reward": 0.037394825369119644,
        "val_loss": 0.8680297391755241,
        "train_loss": 0.776844828747786
      },
      {
        "epoch": 1287,
        "reward": 0.03929353877902031,
        "val_loss": 0.7830695339611599,
        "train_loss": 0.76384565864618
      },
      {
        "epoch": 1288,
        "reward": 0.04090219736099243,
        "val_loss": 0.7202672277178083,
        "train_loss": 0.786751002073288
      },
      {
        "epoch": 1289,
        "reward": 0.038938891142606735,
        "val_loss": 0.7979874866349357,
        "train_loss": 0.7634690999984741
      },
      {
        "epoch": 1290,
        "reward": 0.037772417068481445,
        "val_loss": 0.8500945312636239,
        "train_loss": 0.869756471652251
      },
      {
        "epoch": 1291,
        "reward": 0.038953423500061035,
        "val_loss": 0.7973680070468357,
        "train_loss": 0.8602490906531994
      },
      {
        "epoch": 1292,
        "reward": 0.03912092000246048,
        "val_loss": 0.7902792096138,
        "train_loss": 0.8733547306977786
      },
      {
        "epoch": 1293,
        "reward": 0.040380075573921204,
        "val_loss": 0.7398189221109662,
        "train_loss": 0.8382882154904879
      },
      {
        "epoch": 1294,
        "reward": 0.03974885866045952,
        "val_loss": 0.7645071915217808,
        "train_loss": 0.7790171779119052
      },
      {
        "epoch": 1295,
        "reward": 0.03922173008322716,
        "val_loss": 0.7860570890562875,
        "train_loss": 0.7768623840350372
      },
      {
        "epoch": 1296,
        "reward": 0.04021008685231209,
        "val_loss": 0.7463517785072327,
        "train_loss": 0.8589649412494439
      },
      {
        "epoch": 1297,
        "reward": 0.03978101164102554,
        "val_loss": 0.763220659324101,
        "train_loss": 0.7577133213098233
      },
      {
        "epoch": 1298,
        "reward": 0.03887467831373215,
        "val_loss": 0.8007328680583409,
        "train_loss": 0.8455951695258801
      },
      {
        "epoch": 1299,
        "reward": 0.04014347121119499,
        "val_loss": 0.7489348820277623,
        "train_loss": 0.8059754646741427
      },
      {
        "epoch": 1300,
        "reward": 0.03819615766406059,
        "val_loss": 0.8306054898670742,
        "train_loss": 0.7501864788623956
      },
      {
        "epoch": 1301,
        "reward": 0.039530277252197266,
        "val_loss": 0.7733370576586042,
        "train_loss": 0.8290448395105509
      },
      {
        "epoch": 1302,
        "reward": 0.04102369770407677,
        "val_loss": 0.7158257450376239,
        "train_loss": 0.8035632475064352
      },
      {
        "epoch": 1303,
        "reward": 0.03688288480043411,
        "val_loss": 0.8932431425367083,
        "train_loss": 0.7749105284993465
      },
      {
        "epoch": 1304,
        "reward": 0.040810827165842056,
        "val_loss": 0.7236339620181492,
        "train_loss": 0.7726754781145316
      },
      {
        "epoch": 1305,
        "reward": 0.040735818445682526,
        "val_loss": 0.7264149870191302,
        "train_loss": 0.7343756396036881
      },
      {
        "epoch": 1306,
        "reward": 0.038207631558179855,
        "val_loss": 0.8300870316369193,
        "train_loss": 0.7679746781404202
      },
      {
        "epoch": 1307,
        "reward": 0.0404743067920208,
        "val_loss": 0.7362336601529803,
        "train_loss": 0.8073747410224035
      },
      {
        "epoch": 1308,
        "reward": 0.04111577197909355,
        "val_loss": 0.7124865821429661,
        "train_loss": 0.7425786657975271
      },
      {
        "epoch": 1309,
        "reward": 0.039917394518852234,
        "val_loss": 0.7577988079616002,
        "train_loss": 0.7661987153383402
      },
      {
        "epoch": 1310,
        "reward": 0.039588239043951035,
        "val_loss": 0.7709811500140599,
        "train_loss": 0.7326387937825459
      },
      {
        "epoch": 1311,
        "reward": 0.0404680036008358,
        "val_loss": 0.736472623688834,
        "train_loss": 0.7427971408917353
      },
      {
        "epoch": 1312,
        "reward": 0.04003860428929329,
        "val_loss": 0.7530274220875331,
        "train_loss": 0.8289895989000797
      },
      {
        "epoch": 1313,
        "reward": 0.04052344337105751,
        "val_loss": 0.734373927116394,
        "train_loss": 0.7704287561086508
      },
      {
        "epoch": 1314,
        "reward": 0.04079257324337959,
        "val_loss": 0.724309367792947,
        "train_loss": 0.7667352603032038
      },
      {
        "epoch": 1315,
        "reward": 0.03985541686415672,
        "val_loss": 0.7602558902331761,
        "train_loss": 0.8096760488473452
      },
      {
        "epoch": 1316,
        "reward": 0.04024600610136986,
        "val_loss": 0.7449642079217094,
        "train_loss": 0.7708936820809658
      },
      {
        "epoch": 1317,
        "reward": 0.040552470833063126,
        "val_loss": 0.7332785725593567,
        "train_loss": 0.7677460679641137
      },
      {
        "epoch": 1318,
        "reward": 0.03793635964393616,
        "val_loss": 0.842475814478738,
        "train_loss": 0.744252666939876
      },
      {
        "epoch": 1319,
        "reward": 0.039850521832704544,
        "val_loss": 0.7604502354349408,
        "train_loss": 0.8255689121209658
      },
      {
        "epoch": 1320,
        "reward": 0.037214577198028564,
        "val_loss": 0.8767868110111782,
        "train_loss": 0.7443557267005627
      },
      {
        "epoch": 1321,
        "reward": 0.03882019221782684,
        "val_loss": 0.8030730485916138,
        "train_loss": 0.7771680194597977
      },
      {
        "epoch": 1322,
        "reward": 0.03777706250548363,
        "val_loss": 0.8498773915427071,
        "train_loss": 0.7593877948820591
      },
      {
        "epoch": 1323,
        "reward": 0.041563164442777634,
        "val_loss": 0.6965799757412502,
        "train_loss": 0.768152835778892
      },
      {
        "epoch": 1324,
        "reward": 0.038108404725790024,
        "val_loss": 0.8345874803406852,
        "train_loss": 0.7532677730688682
      },
      {
        "epoch": 1325,
        "reward": 0.0410301610827446,
        "val_loss": 0.7155905621392387,
        "train_loss": 0.8251387843718896
      },
      {
        "epoch": 1326,
        "reward": 0.039799656718969345,
        "val_loss": 0.7624762398856026,
        "train_loss": 0.7819766700267792
      },
      {
        "epoch": 1327,
        "reward": 0.038389068096876144,
        "val_loss": 0.8219490647315979,
        "train_loss": 0.7922079723614913
      },
      {
        "epoch": 1328,
        "reward": 0.04063458368182182,
        "val_loss": 0.730193018913269,
        "train_loss": 0.8316095677705911
      },
      {
        "epoch": 1329,
        "reward": 0.039318591356277466,
        "val_loss": 0.7820311869893756,
        "train_loss": 0.77448092515652
      },
      {
        "epoch": 1330,
        "reward": 0.040835775434970856,
        "val_loss": 0.7227124784673963,
        "train_loss": 0.7813549099060205
      },
      {
        "epoch": 1331,
        "reward": 0.03885890915989876,
        "val_loss": 0.8014090742383685,
        "train_loss": 0.7820803156265845
      },
      {
        "epoch": 1332,
        "reward": 0.03954976424574852,
        "val_loss": 0.7725438475608826,
        "train_loss": 0.7351246990550023
      },
      {
        "epoch": 1333,
        "reward": 0.03963075205683708,
        "val_loss": 0.7692598445074899,
        "train_loss": 0.7755518968288715
      },
      {
        "epoch": 1334,
        "reward": 0.03756048157811165,
        "val_loss": 0.8600937809262957,
        "train_loss": 0.7939499158125657
      },
      {
        "epoch": 1335,
        "reward": 0.04104382544755936,
        "val_loss": 0.7150938979216984,
        "train_loss": 0.8361042692111089
      },
      {
        "epoch": 1336,
        "reward": 0.03890301659703255,
        "val_loss": 0.7995195814541408,
        "train_loss": 0.8411840203289802
      },
      {
        "epoch": 1337,
        "reward": 0.04003908857703209,
        "val_loss": 0.7530086721692767,
        "train_loss": 0.7403035307876192
      },
      {
        "epoch": 1338,
        "reward": 0.038352783769369125,
        "val_loss": 0.8235670157841274,
        "train_loss": 0.8207542919195615
      },
      {
        "epoch": 1339,
        "reward": 0.037466369569301605,
        "val_loss": 0.8645892143249512,
        "train_loss": 0.7779241869082818
      },
      {
        "epoch": 1340,
        "reward": 0.03968515992164612,
        "val_loss": 0.7670649800981794,
        "train_loss": 0.8062752691599039
      },
      {
        "epoch": 1341,
        "reward": 0.03915157541632652,
        "val_loss": 0.7889918770108905,
        "train_loss": 0.769652877907412
      },
      {
        "epoch": 1342,
        "reward": 0.0392073430120945,
        "val_loss": 0.7866575207029071,
        "train_loss": 0.7916343120428232
      },
      {
        "epoch": 1343,
        "reward": 0.0407145731151104,
        "val_loss": 0.7272054127284459,
        "train_loss": 0.8238687308935019
      },
      {
        "epoch": 1344,
        "reward": 0.037296097725629807,
        "val_loss": 0.8728101083210537,
        "train_loss": 0.8117732726610624
      },
      {
        "epoch": 1345,
        "reward": 0.040618106722831726,
        "val_loss": 0.7308105826377869,
        "train_loss": 0.8306004244547623
      },
      {
        "epoch": 1346,
        "reward": 0.041238054633140564,
        "val_loss": 0.7080866183553424,
        "train_loss": 0.8614588334010198
      },
      {
        "epoch": 1347,
        "reward": 0.03787655755877495,
        "val_loss": 0.8452434710093907,
        "train_loss": 0.7802371359788455
      },
      {
        "epoch": 1348,
        "reward": 0.04045672342181206,
        "val_loss": 0.7369005935532706,
        "train_loss": 0.8040674644020888
      },
      {
        "epoch": 1349,
        "reward": 0.03965548425912857,
        "val_loss": 0.7682610069002423,
        "train_loss": 0.7377881210010785
      },
      {
        "epoch": 1350,
        "reward": 0.04085804149508476,
        "val_loss": 0.7218915053776332,
        "train_loss": 0.7957461843123803
      },
      {
        "epoch": 1351,
        "reward": 0.04062514007091522,
        "val_loss": 0.7305469172341483,
        "train_loss": 0.7406961215803256
      },
      {
        "epoch": 1352,
        "reward": 0.04035606607794762,
        "val_loss": 0.7407364589827401,
        "train_loss": 0.765043162382566
      },
      {
        "epoch": 1353,
        "reward": 0.04088282585144043,
        "val_loss": 0.7209791966847011,
        "train_loss": 0.8530593308118674
      },
      {
        "epoch": 1354,
        "reward": 0.04114473983645439,
        "val_loss": 0.7114406994410923,
        "train_loss": 0.7447996758497678
      },
      {
        "epoch": 1355,
        "reward": 0.04020770639181137,
        "val_loss": 0.7464438336236137,
        "train_loss": 0.7732751323626592
      },
      {
        "epoch": 1356,
        "reward": 0.03918281942605972,
        "val_loss": 0.78768276316779,
        "train_loss": 0.7936690564338977
      },
      {
        "epoch": 1357,
        "reward": 0.04063400626182556,
        "val_loss": 0.7302146639142718,
        "train_loss": 0.7602961327020938
      },
      {
        "epoch": 1358,
        "reward": 0.03786752372980118,
        "val_loss": 0.845662670476096,
        "train_loss": 0.8056441430862133
      },
      {
        "epoch": 1359,
        "reward": 0.037212010473012924,
        "val_loss": 0.8769123894827706,
        "train_loss": 0.807358987056292
      },
      {
        "epoch": 1360,
        "reward": 0.0397455058991909,
        "val_loss": 0.764641387122018,
        "train_loss": 0.7887933105230331
      },
      {
        "epoch": 1361,
        "reward": 0.040020864456892014,
        "val_loss": 0.7537232637405396,
        "train_loss": 0.7923235228428473
      },
      {
        "epoch": 1362,
        "reward": 0.04080202057957649,
        "val_loss": 0.7239597610064915,
        "train_loss": 0.7586457240753449
      },
      {
        "epoch": 1363,
        "reward": 0.039883460849523544,
        "val_loss": 0.7591426117079598,
        "train_loss": 0.7407516507575145
      },
      {
        "epoch": 1364,
        "reward": 0.04078447446227074,
        "val_loss": 0.7246091365814209,
        "train_loss": 0.7695929614397196
      },
      {
        "epoch": 1365,
        "reward": 0.04115403816103935,
        "val_loss": 0.7111052615301949,
        "train_loss": 0.7293986287010756
      },
      {
        "epoch": 1366,
        "reward": 0.04067523404955864,
        "val_loss": 0.7286725044250488,
        "train_loss": 0.7577719321617713
      },
      {
        "epoch": 1367,
        "reward": 0.0408787839114666,
        "val_loss": 0.7211276633398873,
        "train_loss": 0.7835302398755
      },
      {
        "epoch": 1368,
        "reward": 0.040680527687072754,
        "val_loss": 0.7284747191837856,
        "train_loss": 0.8185118092940404
      },
      {
        "epoch": 1369,
        "reward": 0.041040822863578796,
        "val_loss": 0.7152029957090106,
        "train_loss": 0.7934488975084745
      },
      {
        "epoch": 1370,
        "reward": 0.04098940268158913,
        "val_loss": 0.717075492654528,
        "train_loss": 0.7343028262257576
      },
      {
        "epoch": 1371,
        "reward": 0.03887820243835449,
        "val_loss": 0.8005818128585815,
        "train_loss": 0.8138824242811936
      },
      {
        "epoch": 1372,
        "reward": 0.04010250046849251,
        "val_loss": 0.7505298938070025,
        "train_loss": 0.7638012251028647
      },
      {
        "epoch": 1373,
        "reward": 0.04032233729958534,
        "val_loss": 0.7420284748077393,
        "train_loss": 0.7888126499377764
      },
      {
        "epoch": 1374,
        "reward": 0.04092298075556755,
        "val_loss": 0.719504748071943,
        "train_loss": 0.7627767416147085
      },
      {
        "epoch": 1375,
        "reward": 0.03917867690324783,
        "val_loss": 0.7878561445644924,
        "train_loss": 0.7553418313081448
      },
      {
        "epoch": 1376,
        "reward": 0.03979405388236046,
        "val_loss": 0.7626997573035104,
        "train_loss": 0.7823718155805881
      },
      {
        "epoch": 1377,
        "reward": 0.03924749791622162,
        "val_loss": 0.7849830644471305,
        "train_loss": 0.7483540704617133
      },
      {
        "epoch": 1378,
        "reward": 0.03963860496878624,
        "val_loss": 0.7689424327441624,
        "train_loss": 0.7986768795487408
      },
      {
        "epoch": 1379,
        "reward": 0.04083395004272461,
        "val_loss": 0.7227798317159925,
        "train_loss": 0.7949833526061132
      },
      {
        "epoch": 1380,
        "reward": 0.04011766240000725,
        "val_loss": 0.7499390244483948,
        "train_loss": 0.7448080067451184
      },
      {
        "epoch": 1381,
        "reward": 0.04053373262286186,
        "val_loss": 0.7339853729520526,
        "train_loss": 0.8357816155140216
      },
      {
        "epoch": 1382,
        "reward": 0.037534505128860474,
        "val_loss": 0.8613312414714268,
        "train_loss": 0.8159302679392008
      },
      {
        "epoch": 1383,
        "reward": 0.04053454101085663,
        "val_loss": 0.733954838344029,
        "train_loss": 0.8272426311786358
      },
      {
        "epoch": 1384,
        "reward": 0.04086654633283615,
        "val_loss": 0.721578129700252,
        "train_loss": 0.7221875180705235
      },
      {
        "epoch": 1385,
        "reward": 0.03967282176017761,
        "val_loss": 0.7675619465964181,
        "train_loss": 0.7466672949779493
      },
      {
        "epoch": 1386,
        "reward": 0.039334822446107864,
        "val_loss": 0.7813595192773002,
        "train_loss": 0.7319926135241985
      },
      {
        "epoch": 1387,
        "reward": 0.03916047140955925,
        "val_loss": 0.788618837084089,
        "train_loss": 0.8096319918449109
      },
      {
        "epoch": 1388,
        "reward": 0.040145810693502426,
        "val_loss": 0.748843959399632,
        "train_loss": 0.8535897158659421
      },
      {
        "epoch": 1389,
        "reward": 0.03983840346336365,
        "val_loss": 0.7609321985925946,
        "train_loss": 0.7801293610380247
      },
      {
        "epoch": 1390,
        "reward": 0.039836570620536804,
        "val_loss": 0.7610051717076983,
        "train_loss": 0.7669742657588079
      },
      {
        "epoch": 1391,
        "reward": 0.04080016538500786,
        "val_loss": 0.7240281530788967,
        "train_loss": 0.7849859847472265
      },
      {
        "epoch": 1392,
        "reward": 0.040221765637397766,
        "val_loss": 0.7459001541137695,
        "train_loss": 0.7854141180331891
      },
      {
        "epoch": 1393,
        "reward": 0.03928392007946968,
        "val_loss": 0.7834688084466117,
        "train_loss": 0.7954342136016259
      },
      {
        "epoch": 1394,
        "reward": 0.04077113792300224,
        "val_loss": 0.7251033186912537,
        "train_loss": 0.7607722213635078
      },
      {
        "epoch": 1395,
        "reward": 0.03940562158823013,
        "val_loss": 0.7784395473343986,
        "train_loss": 0.7845835227232713
      },
      {
        "epoch": 1396,
        "reward": 0.04128425940871239,
        "val_loss": 0.7064344882965088,
        "train_loss": 0.7638004915072367
      },
      {
        "epoch": 1397,
        "reward": 0.0412849560379982,
        "val_loss": 0.7064096885068076,
        "train_loss": 0.7472406258949866
      },
      {
        "epoch": 1398,
        "reward": 0.0407666377723217,
        "val_loss": 0.7252703649657113,
        "train_loss": 0.8004291332685031
      },
      {
        "epoch": 1399,
        "reward": 0.0409204475581646,
        "val_loss": 0.7195977228028434,
        "train_loss": 0.8312044487549708
      },
      {
        "epoch": 1400,
        "reward": 0.0393965020775795,
        "val_loss": 0.7788147074835641,
        "train_loss": 0.7342182713059279
      },
      {
        "epoch": 1401,
        "reward": 0.03942128270864487,
        "val_loss": 0.7777958767754691,
        "train_loss": 0.7566805659578397
      },
      {
        "epoch": 1402,
        "reward": 0.03982030972838402,
        "val_loss": 0.7616526825087411,
        "train_loss": 0.7608641110933744
      },
      {
        "epoch": 1403,
        "reward": 0.04132895544171333,
        "val_loss": 0.7048417202063969,
        "train_loss": 0.7722175591267072
      },
      {
        "epoch": 1404,
        "reward": 0.04062167927622795,
        "val_loss": 0.7306766339710781,
        "train_loss": 0.8059826997610239
      },
      {
        "epoch": 1405,
        "reward": 0.038381606340408325,
        "val_loss": 0.8222813180514744,
        "train_loss": 0.7486606469521155
      },
      {
        "epoch": 1406,
        "reward": 0.04060661420226097,
        "val_loss": 0.7312420521463666,
        "train_loss": 0.7326480390933844
      },
      {
        "epoch": 1407,
        "reward": 0.040456950664520264,
        "val_loss": 0.7368919593947274,
        "train_loss": 0.7332737177046231
      },
      {
        "epoch": 1408,
        "reward": 0.0407056100666523,
        "val_loss": 0.7275393775531224,
        "train_loss": 0.7837226024040809
      },
      {
        "epoch": 1409,
        "reward": 0.03983050584793091,
        "val_loss": 0.7612466216087341,
        "train_loss": 0.7643650059516613
      },
      {
        "epoch": 1410,
        "reward": 0.0392659455537796,
        "val_loss": 0.7842154162270683,
        "train_loss": 0.8787440829552137
      },
      {
        "epoch": 1411,
        "reward": 0.04093824326992035,
        "val_loss": 0.7189454095704215,
        "train_loss": 0.8247587130619929
      },
      {
        "epoch": 1412,
        "reward": 0.03980245813727379,
        "val_loss": 0.7623645322663444,
        "train_loss": 0.8038553824791541
      },
      {
        "epoch": 1413,
        "reward": 0.03916112706065178,
        "val_loss": 0.7885912614209312,
        "train_loss": 0.7637231533343976
      },
      {
        "epoch": 1414,
        "reward": 0.03982030972838402,
        "val_loss": 0.7616528357778277,
        "train_loss": 0.7239798817497033
      },
      {
        "epoch": 1415,
        "reward": 0.041381847113370895,
        "val_loss": 0.7029634203229632,
        "train_loss": 0.7605738559594521
      },
      {
        "epoch": 1416,
        "reward": 0.0347558967769146,
        "val_loss": 1.0103652392114912,
        "train_loss": 0.9823651130382831
      },
      {
        "epoch": 1417,
        "reward": 0.040368348360061646,
        "val_loss": 0.7402669276509967,
        "train_loss": 0.8206800680894119
      },
      {
        "epoch": 1418,
        "reward": 0.0407806858420372,
        "val_loss": 0.7247495821544102,
        "train_loss": 0.7792320389014024
      },
      {
        "epoch": 1419,
        "reward": 0.037451375275850296,
        "val_loss": 0.8653085572378976,
        "train_loss": 0.7643364094770871
      },
      {
        "epoch": 1420,
        "reward": 0.03878142312169075,
        "val_loss": 0.8047444905553546,
        "train_loss": 0.7838834168819281
      },
      {
        "epoch": 1421,
        "reward": 0.040655963122844696,
        "val_loss": 0.7293927499226162,
        "train_loss": 0.8583426750623263
      },
      {
        "epoch": 1422,
        "reward": 0.03968435898423195,
        "val_loss": 0.7670974050249372,
        "train_loss": 0.8085141136096075
      },
      {
        "epoch": 1423,
        "reward": 0.041959431022405624,
        "val_loss": 0.6829200003828321,
        "train_loss": 0.7679791358801035
      },
      {
        "epoch": 1424,
        "reward": 0.037071216851472855,
        "val_loss": 0.8838444948196411,
        "train_loss": 0.7781625481752249
      },
      {
        "epoch": 1425,
        "reward": 0.04127094894647598,
        "val_loss": 0.7069099290030343,
        "train_loss": 0.8390379020800958
      },
      {
        "epoch": 1426,
        "reward": 0.040252089500427246,
        "val_loss": 0.7447296891893659,
        "train_loss": 0.7646760986401484
      },
      {
        "epoch": 1427,
        "reward": 0.04024782404303551,
        "val_loss": 0.744894198008946,
        "train_loss": 0.8077827050135686
      },
      {
        "epoch": 1428,
        "reward": 0.03886018693447113,
        "val_loss": 0.8013542975698199,
        "train_loss": 0.7800549933543572
      },
      {
        "epoch": 1429,
        "reward": 0.04004276543855667,
        "val_loss": 0.75286465883255,
        "train_loss": 0.7410999462008476
      },
      {
        "epoch": 1430,
        "reward": 0.04024703428149223,
        "val_loss": 0.7449246219226292,
        "train_loss": 0.7756595336473905
      },
      {
        "epoch": 1431,
        "reward": 0.03838402405381203,
        "val_loss": 0.822173706122807,
        "train_loss": 0.7436583838783778
      },
      {
        "epoch": 1432,
        "reward": 0.040545504540205,
        "val_loss": 0.7335411054747445,
        "train_loss": 0.7526328586615049
      },
      {
        "epoch": 1433,
        "reward": 0.04018709063529968,
        "val_loss": 0.7472419568470546,
        "train_loss": 0.7402560292528226
      },
      {
        "epoch": 1434,
        "reward": 0.04145378991961479,
        "val_loss": 0.7004204051835197,
        "train_loss": 0.7621946128515097
      },
      {
        "epoch": 1435,
        "reward": 0.04053645581007004,
        "val_loss": 0.7338827337537494,
        "train_loss": 0.7415696780842084
      },
      {
        "epoch": 1436,
        "reward": 0.03987739235162735,
        "val_loss": 0.7593835166522435,
        "train_loss": 0.7275145735878211
      },
      {
        "epoch": 1437,
        "reward": 0.03972970321774483,
        "val_loss": 0.7652750355856759,
        "train_loss": 0.7500322988400092
      },
      {
        "epoch": 1438,
        "reward": 0.04134097322821617,
        "val_loss": 0.7044142654963902,
        "train_loss": 0.7625231032188122
      },
      {
        "epoch": 1439,
        "reward": 0.03798593953251839,
        "val_loss": 0.8401915345873151,
        "train_loss": 0.7504652807345757
      },
      {
        "epoch": 1440,
        "reward": 0.04110120236873627,
        "val_loss": 0.7130133850233895,
        "train_loss": 0.7599856337675681
      },
      {
        "epoch": 1441,
        "reward": 0.0410771444439888,
        "val_loss": 0.7138847964150565,
        "train_loss": 0.7350428562897903
      },
      {
        "epoch": 1442,
        "reward": 0.04145907238125801,
        "val_loss": 0.7002341491835458,
        "train_loss": 0.7957004446249741
      },
      {
        "epoch": 1443,
        "reward": 0.04222029820084572,
        "val_loss": 0.674139678478241,
        "train_loss": 0.7328385025835954
      },
      {
        "epoch": 1444,
        "reward": 0.03925180062651634,
        "val_loss": 0.7848040035792759,
        "train_loss": 0.7407392383768008
      },
      {
        "epoch": 1445,
        "reward": 0.041166070848703384,
        "val_loss": 0.7106717654636928,
        "train_loss": 0.7406511994508597
      },
      {
        "epoch": 1446,
        "reward": 0.040740709751844406,
        "val_loss": 0.7262330906731742,
        "train_loss": 0.7400409831450536
      },
      {
        "epoch": 1447,
        "reward": 0.037774890661239624,
        "val_loss": 0.8499789408275059,
        "train_loss": 0.7856682888590373
      },
      {
        "epoch": 1448,
        "reward": 0.04088209196925163,
        "val_loss": 0.7210062486784798,
        "train_loss": 0.7533553153849565
      },
      {
        "epoch": 1449,
        "reward": 0.04114218428730965,
        "val_loss": 0.7115329078265599,
        "train_loss": 0.734042403789667
      },
      {
        "epoch": 1450,
        "reward": 0.038510002195835114,
        "val_loss": 0.8165893639836993,
        "train_loss": 0.7662023672690759
      },
      {
        "epoch": 1451,
        "reward": 0.04173671826720238,
        "val_loss": 0.6905487179756165,
        "train_loss": 0.8043237787026626
      },
      {
        "epoch": 1452,
        "reward": 0.040356434881687164,
        "val_loss": 0.7407224178314209,
        "train_loss": 0.7843894087351285
      },
      {
        "epoch": 1453,
        "reward": 0.04067586362361908,
        "val_loss": 0.7286488924707685,
        "train_loss": 0.7401960252855833
      },
      {
        "epoch": 1454,
        "reward": 0.04071441665291786,
        "val_loss": 0.7272111432892936,
        "train_loss": 0.7907241869431275
      },
      {
        "epoch": 1455,
        "reward": 0.040184393525123596,
        "val_loss": 0.7473464608192444,
        "train_loss": 0.7539880831654255
      },
      {
        "epoch": 1456,
        "reward": 0.040567100048065186,
        "val_loss": 0.7327273743493217,
        "train_loss": 0.7439352589157912
      },
      {
        "epoch": 1457,
        "reward": 0.04094374179840088,
        "val_loss": 0.7187440097332001,
        "train_loss": 0.7826331074421222
      },
      {
        "epoch": 1458,
        "reward": 0.040600381791591644,
        "val_loss": 0.7314759620598384,
        "train_loss": 0.7483064142557291
      },
      {
        "epoch": 1459,
        "reward": 0.03959011659026146,
        "val_loss": 0.770904962505613,
        "train_loss": 0.8738273771909567
      },
      {
        "epoch": 1460,
        "reward": 0.04059981927275658,
        "val_loss": 0.7314970408167157,
        "train_loss": 0.8487047667686756
      },
      {
        "epoch": 1461,
        "reward": 0.040595363825559616,
        "val_loss": 0.7316644617489406,
        "train_loss": 0.7362019929748315
      },
      {
        "epoch": 1462,
        "reward": 0.04113418236374855,
        "val_loss": 0.7118215305464608,
        "train_loss": 0.7985870838165283
      },
      {
        "epoch": 1463,
        "reward": 0.03972240909934044,
        "val_loss": 0.7655678050858634,
        "train_loss": 0.7327751620457723
      },
      {
        "epoch": 1464,
        "reward": 0.04052033647894859,
        "val_loss": 0.734491378068924,
        "train_loss": 0.7378464834048197
      },
      {
        "epoch": 1465,
        "reward": 0.04061643034219742,
        "val_loss": 0.730873567717416,
        "train_loss": 0.7891437869805557
      },
      {
        "epoch": 1466,
        "reward": 0.04021623358130455,
        "val_loss": 0.7461138963699341,
        "train_loss": 0.756601652273765
      },
      {
        "epoch": 1467,
        "reward": 0.04015995189547539,
        "val_loss": 0.748294540813991,
        "train_loss": 0.7962075815751002
      },
      {
        "epoch": 1468,
        "reward": 0.04032320901751518,
        "val_loss": 0.7419949769973755,
        "train_loss": 0.800408450456766
      },
      {
        "epoch": 1469,
        "reward": 0.038110654801130295,
        "val_loss": 0.8344851561955043,
        "train_loss": 0.7700941654352041
      },
      {
        "epoch": 1470,
        "reward": 0.03871612623333931,
        "val_loss": 0.8075710833072662,
        "train_loss": 0.7446574786534677
      },
      {
        "epoch": 1471,
        "reward": 0.0406736396253109,
        "val_loss": 0.7287320494651794,
        "train_loss": 0.7412253022193909
      },
      {
        "epoch": 1472,
        "reward": 0.04143231734633446,
        "val_loss": 0.7011780185358865,
        "train_loss": 0.7269022969099191
      },
      {
        "epoch": 1473,
        "reward": 0.03619014471769333,
        "val_loss": 0.9291017736707415,
        "train_loss": 0.7580047112244827
      },
      {
        "epoch": 1474,
        "reward": 0.040712159126996994,
        "val_loss": 0.7272953050477164,
        "train_loss": 0.7538912148358157
      },
      {
        "epoch": 1475,
        "reward": 0.041085030883550644,
        "val_loss": 0.7135986430304391,
        "train_loss": 0.732612669467926
      },
      {
        "epoch": 1476,
        "reward": 0.04102440923452377,
        "val_loss": 0.715799799987248,
        "train_loss": 0.8128203405783727
      },
      {
        "epoch": 1477,
        "reward": 0.040728501975536346,
        "val_loss": 0.7266870481627328,
        "train_loss": 0.8248571902513504
      },
      {
        "epoch": 1478,
        "reward": 0.04033871367573738,
        "val_loss": 0.7414008208683559,
        "train_loss": 0.8122549790602464
      },
      {
        "epoch": 1479,
        "reward": 0.0411226712167263,
        "val_loss": 0.7122371792793274,
        "train_loss": 0.7386253338593703
      },
      {
        "epoch": 1480,
        "reward": 0.04108428582549095,
        "val_loss": 0.7136259206703731,
        "train_loss": 0.7422570053201455
      },
      {
        "epoch": 1481,
        "reward": 0.04134944826364517,
        "val_loss": 0.7041129853044238,
        "train_loss": 0.8161882918614608
      },
      {
        "epoch": 1482,
        "reward": 0.041104674339294434,
        "val_loss": 0.7128877810069493,
        "train_loss": 0.7957089451643137
      },
      {
        "epoch": 1483,
        "reward": 0.039687152951955795,
        "val_loss": 0.766984931060246,
        "train_loss": 0.7779779502978692
      },
      {
        "epoch": 1484,
        "reward": 0.036357637494802475,
        "val_loss": 0.9202412366867065,
        "train_loss": 0.8494905691880447
      },
      {
        "epoch": 1485,
        "reward": 0.04128892347216606,
        "val_loss": 0.70626814024789,
        "train_loss": 0.7925885755282182
      },
      {
        "epoch": 1486,
        "reward": 0.04046587273478508,
        "val_loss": 0.7365533028330121,
        "train_loss": 0.7574532009088076
      },
      {
        "epoch": 1487,
        "reward": 0.040647249668836594,
        "val_loss": 0.729718702180045,
        "train_loss": 0.7404488726304128
      },
      {
        "epoch": 1488,
        "reward": 0.04059768095612526,
        "val_loss": 0.7315773623330253,
        "train_loss": 0.7764330162451818
      },
      {
        "epoch": 1489,
        "reward": 0.041037604212760925,
        "val_loss": 0.7153200166566032,
        "train_loss": 0.7665039644791529
      },
      {
        "epoch": 1490,
        "reward": 0.03957831487059593,
        "val_loss": 0.7713837964194161,
        "train_loss": 0.7810563422166384
      },
      {
        "epoch": 1491,
        "reward": 0.04044157266616821,
        "val_loss": 0.737476110458374,
        "train_loss": 0.7706653063113873
      },
      {
        "epoch": 1492,
        "reward": 0.041120871901512146,
        "val_loss": 0.7123020589351654,
        "train_loss": 0.7643474844785837
      },
      {
        "epoch": 1493,
        "reward": 0.040899522602558136,
        "val_loss": 0.7203654987471444,
        "train_loss": 0.7621707228513864
      },
      {
        "epoch": 1494,
        "reward": 0.03987627848982811,
        "val_loss": 0.759427377155849,
        "train_loss": 0.7728168872686533
      },
      {
        "epoch": 1495,
        "reward": 0.04111412540078163,
        "val_loss": 0.7125459909439087,
        "train_loss": 0.7749520654861743
      },
      {
        "epoch": 1496,
        "reward": 0.039674241095781326,
        "val_loss": 0.7675047261374337,
        "train_loss": 0.7647110407169049
      },
      {
        "epoch": 1497,
        "reward": 0.04033684358000755,
        "val_loss": 0.7414725508008685,
        "train_loss": 0.7470036905545455
      },
      {
        "epoch": 1498,
        "reward": 0.03923014923930168,
        "val_loss": 0.7857059580939156,
        "train_loss": 0.747083285680184
      },
      {
        "epoch": 1499,
        "reward": 0.04027978330850601,
        "val_loss": 0.7436630811010089,
        "train_loss": 0.7681885292896857
      },
      {
        "epoch": 1500,
        "reward": 0.04127761721611023,
        "val_loss": 0.7066717360700879,
        "train_loss": 0.8092546577637012
      },
      {
        "epoch": 1501,
        "reward": 0.04019065573811531,
        "val_loss": 0.747103865657534,
        "train_loss": 0.7480201331468729
      },
      {
        "epoch": 1502,
        "reward": 0.03755543753504753,
        "val_loss": 0.8603336215019226,
        "train_loss": 0.7671080552614652
      },
      {
        "epoch": 1503,
        "reward": 0.0410001315176487,
        "val_loss": 0.7166841370718819,
        "train_loss": 0.7361626584942524
      },
      {
        "epoch": 1504,
        "reward": 0.03502805531024933,
        "val_loss": 0.9941649607249669,
        "train_loss": 0.7546945389073628
      },
      {
        "epoch": 1505,
        "reward": 0.038436781615018845,
        "val_loss": 0.8198279823575702,
        "train_loss": 0.7978604963192573
      },
      {
        "epoch": 1506,
        "reward": 0.0398864783346653,
        "val_loss": 0.7590230447905404,
        "train_loss": 0.7698561824285067
      },
      {
        "epoch": 1507,
        "reward": 0.04130057990550995,
        "val_loss": 0.7058522871562413,
        "train_loss": 0.7531209060778985
      },
      {
        "epoch": 1508,
        "reward": 0.040873464196920395,
        "val_loss": 0.7213235199451447,
        "train_loss": 0.7642681506963876
      },
      {
        "epoch": 1509,
        "reward": 0.03800557926297188,
        "val_loss": 0.8392891372953143,
        "train_loss": 0.7554720804954951
      },
      {
        "epoch": 1510,
        "reward": 0.040892887860536575,
        "val_loss": 0.7206094009535653,
        "train_loss": 0.7416626931383059
      },
      {
        "epoch": 1511,
        "reward": 0.03984590992331505,
        "val_loss": 0.7606337240764073,
        "train_loss": 0.7747107354494241
      },
      {
        "epoch": 1512,
        "reward": 0.037863098084926605,
        "val_loss": 0.8458679062979562,
        "train_loss": 0.7510774055352578
      },
      {
        "epoch": 1513,
        "reward": 0.04083111137151718,
        "val_loss": 0.7228845953941345,
        "train_loss": 0.7509661746712831
      },
      {
        "epoch": 1514,
        "reward": 0.03931514546275139,
        "val_loss": 0.7821739486285618,
        "train_loss": 0.7601586465652173
      },
      {
        "epoch": 1515,
        "reward": 0.04076605290174484,
        "val_loss": 0.7252921121461051,
        "train_loss": 0.7555751865013287
      },
      {
        "epoch": 1516,
        "reward": 0.04084652289748192,
        "val_loss": 0.7223160309450967,
        "train_loss": 0.7714548729933225
      },
      {
        "epoch": 1517,
        "reward": 0.0410170704126358,
        "val_loss": 0.7160669820649284,
        "train_loss": 0.7589077789049882
      },
      {
        "epoch": 1518,
        "reward": 0.041246578097343445,
        "val_loss": 0.7077814510890416,
        "train_loss": 0.8397607757495
      },
      {
        "epoch": 1519,
        "reward": 0.03869754821062088,
        "val_loss": 0.8083777938570295,
        "train_loss": 0.7498236504884866
      },
      {
        "epoch": 1520,
        "reward": 0.04107608646154404,
        "val_loss": 0.7139230115073067,
        "train_loss": 0.7740536400905023
      },
      {
        "epoch": 1521,
        "reward": 0.041185490787029266,
        "val_loss": 0.7099730372428894,
        "train_loss": 0.7173180942638562
      },
      {
        "epoch": 1522,
        "reward": 0.04060768708586693,
        "val_loss": 0.7312016401972089,
        "train_loss": 0.766183655995589
      },
      {
        "epoch": 1523,
        "reward": 0.04080947861075401,
        "val_loss": 0.7236839532852173,
        "train_loss": 0.830526936512727
      },
      {
        "epoch": 1524,
        "reward": 0.04125494137406349,
        "val_loss": 0.7074821506227765,
        "train_loss": 0.7374376803636551
      },
      {
        "epoch": 1525,
        "reward": 0.04161286726593971,
        "val_loss": 0.694844833442143,
        "train_loss": 0.7929762968650231
      },
      {
        "epoch": 1526,
        "reward": 0.04094287008047104,
        "val_loss": 0.7187760514872414,
        "train_loss": 0.7256815046645128
      },
      {
        "epoch": 1527,
        "reward": 0.03931867703795433,
        "val_loss": 0.78202771289008,
        "train_loss": 0.7494395398176633
      },
      {
        "epoch": 1528,
        "reward": 0.04080292955040932,
        "val_loss": 0.7239260758672442,
        "train_loss": 0.7937765969679906
      },
      {
        "epoch": 1529,
        "reward": 0.04064129665493965,
        "val_loss": 0.7299416746412005,
        "train_loss": 0.7688717406529647
      },
      {
        "epoch": 1530,
        "reward": 0.04067404195666313,
        "val_loss": 0.7287168885980334,
        "train_loss": 0.7963077746904813
      },
      {
        "epoch": 1531,
        "reward": 0.04066414758563042,
        "val_loss": 0.7290868333407811,
        "train_loss": 0.7541927729661648
      },
      {
        "epoch": 1532,
        "reward": 0.039885811507701874,
        "val_loss": 0.759049619947161,
        "train_loss": 0.7414768785238266
      },
      {
        "epoch": 1533,
        "reward": 0.04058980941772461,
        "val_loss": 0.7318731801850455,
        "train_loss": 0.7588110589064084
      },
      {
        "epoch": 1534,
        "reward": 0.0408884733915329,
        "val_loss": 0.7207715426172528,
        "train_loss": 0.755278094456746
      },
      {
        "epoch": 1535,
        "reward": 0.040899332612752914,
        "val_loss": 0.7203726129872459,
        "train_loss": 0.7265086569465123
      },
      {
        "epoch": 1536,
        "reward": 0.04018118232488632,
        "val_loss": 0.7474709578922817,
        "train_loss": 0.7507800196225827
      },
      {
        "epoch": 1537,
        "reward": 0.04088839516043663,
        "val_loss": 0.7207744547298977,
        "train_loss": 0.7799603663958036
      },
      {
        "epoch": 1538,
        "reward": 0.03924357891082764,
        "val_loss": 0.7851460916655404,
        "train_loss": 0.7242563367606356
      },
      {
        "epoch": 1539,
        "reward": 0.040856871753931046,
        "val_loss": 0.721934471811567,
        "train_loss": 0.7685464803989117
      },
      {
        "epoch": 1540,
        "reward": 0.040935687720775604,
        "val_loss": 0.7190390825271606,
        "train_loss": 0.7853876214761001
      },
      {
        "epoch": 1541,
        "reward": 0.04117245972156525,
        "val_loss": 0.7104417681694031,
        "train_loss": 0.766797281228579
      },
      {
        "epoch": 1542,
        "reward": 0.04043220728635788,
        "val_loss": 0.7378321715763637,
        "train_loss": 0.7280083702017481
      },
      {
        "epoch": 1543,
        "reward": 0.04050670191645622,
        "val_loss": 0.7350068262645176,
        "train_loss": 0.7224995562663445
      },
      {
        "epoch": 1544,
        "reward": 0.04073899984359741,
        "val_loss": 0.7262966632843018,
        "train_loss": 0.7347216637303623
      },
      {
        "epoch": 1545,
        "reward": 0.040951307862997055,
        "val_loss": 0.718467082296099,
        "train_loss": 0.7528268649027898
      },
      {
        "epoch": 1546,
        "reward": 0.038489360362291336,
        "val_loss": 0.8175003528594971,
        "train_loss": 0.792641479235429
      },
      {
        "epoch": 1547,
        "reward": 0.04098232835531235,
        "val_loss": 0.7173335637365069,
        "train_loss": 0.7831627061733832
      },
      {
        "epoch": 1548,
        "reward": 0.04089626669883728,
        "val_loss": 0.7204850741795131,
        "train_loss": 0.7363078187291439
      },
      {
        "epoch": 1549,
        "reward": 0.0407872200012207,
        "val_loss": 0.7245074510574341,
        "train_loss": 0.746141601067323
      },
      {
        "epoch": 1550,
        "reward": 0.03867470473051071,
        "val_loss": 0.8093715139797756,
        "train_loss": 0.7651204604368943
      },
      {
        "epoch": 1551,
        "reward": 0.03885902836918831,
        "val_loss": 0.801403990813664,
        "train_loss": 0.7551653545636398
      },
      {
        "epoch": 1552,
        "reward": 0.04119928181171417,
        "val_loss": 0.709477424621582,
        "train_loss": 0.7405713911060817
      },
      {
        "epoch": 1553,
        "reward": 0.04067055508494377,
        "val_loss": 0.7288473503930228,
        "train_loss": 0.7514985776864566
      },
      {
        "epoch": 1554,
        "reward": 0.039603278040885925,
        "val_loss": 0.770371539252145,
        "train_loss": 0.7437953542058284
      },
      {
        "epoch": 1555,
        "reward": 0.04005652293562889,
        "val_loss": 0.752325986112867,
        "train_loss": 0.8059083979863387
      },
      {
        "epoch": 1556,
        "reward": 0.04112192988395691,
        "val_loss": 0.712263992854527,
        "train_loss": 0.7592448964715004
      },
      {
        "epoch": 1557,
        "reward": 0.041161563247442245,
        "val_loss": 0.7108341796057565,
        "train_loss": 0.7607208765470065
      },
      {
        "epoch": 1558,
        "reward": 0.040946248918771744,
        "val_loss": 0.7186523335320609,
        "train_loss": 0.7409222481342462
      },
      {
        "epoch": 1559,
        "reward": 0.04021817073225975,
        "val_loss": 0.7460392968995231,
        "train_loss": 0.7504085806699899
      },
      {
        "epoch": 1560,
        "reward": 0.04106822609901428,
        "val_loss": 0.7142081345830645,
        "train_loss": 0.7628813065015353
      },
      {
        "epoch": 1561,
        "reward": 0.04117785394191742,
        "val_loss": 0.7102477763380323,
        "train_loss": 0.7409309469736539
      },
      {
        "epoch": 1562,
        "reward": 0.041042525321245193,
        "val_loss": 0.7151411431176322,
        "train_loss": 0.7519161036381354
      },
      {
        "epoch": 1563,
        "reward": 0.04109781235456467,
        "val_loss": 0.7131360258374896,
        "train_loss": 0.7811838846940261
      },
      {
        "epoch": 1564,
        "reward": 0.040658172219991684,
        "val_loss": 0.7293100953102112,
        "train_loss": 0.7525229305028915
      },
      {
        "epoch": 1565,
        "reward": 0.04116739332675934,
        "val_loss": 0.7106242563043322,
        "train_loss": 0.737806043945826
      },
      {
        "epoch": 1566,
        "reward": 0.041370004415512085,
        "val_loss": 0.7033832924706596,
        "train_loss": 0.7414202575500195
      },
      {
        "epoch": 1567,
        "reward": 0.04088011011481285,
        "val_loss": 0.7210790685244969,
        "train_loss": 0.8021060549295865
      },
      {
        "epoch": 1568,
        "reward": 0.0396139919757843,
        "val_loss": 0.7699377366474697,
        "train_loss": 0.7304138105649215
      },
      {
        "epoch": 1569,
        "reward": 0.041030462831258774,
        "val_loss": 0.7155796885490417,
        "train_loss": 0.7471564320417551
      },
      {
        "epoch": 1570,
        "reward": 0.04007231816649437,
        "val_loss": 0.7517080817903791,
        "train_loss": 0.7505155767385776
      },
      {
        "epoch": 1571,
        "reward": 0.03955329582095146,
        "val_loss": 0.7724002003669739,
        "train_loss": 0.7458242132113531
      },
      {
        "epoch": 1572,
        "reward": 0.040993258357048035,
        "val_loss": 0.7169347107410431,
        "train_loss": 0.7891547840375167
      },
      {
        "epoch": 1573,
        "reward": 0.04085926339030266,
        "val_loss": 0.7218464059489114,
        "train_loss": 0.7803846735220689
      },
      {
        "epoch": 1574,
        "reward": 0.03991721197962761,
        "val_loss": 0.7578062329973493,
        "train_loss": 0.7641979455947876
      },
      {
        "epoch": 1575,
        "reward": 0.04062456637620926,
        "val_loss": 0.730568357876369,
        "train_loss": 0.7485018616112379
      },
      {
        "epoch": 1576,
        "reward": 0.039653412997722626,
        "val_loss": 0.7683446322168622,
        "train_loss": 0.7170156615857894
      },
      {
        "epoch": 1577,
        "reward": 0.040464214980602264,
        "val_loss": 0.736616211278098,
        "train_loss": 0.7425617415171403
      },
      {
        "epoch": 1578,
        "reward": 0.04016481712460518,
        "val_loss": 0.7481057729039874,
        "train_loss": 0.7765472921041342
      },
      {
        "epoch": 1579,
        "reward": 0.04098864644765854,
        "val_loss": 0.7171030555452619,
        "train_loss": 0.7351969474783311
      },
      {
        "epoch": 1580,
        "reward": 0.04064241051673889,
        "val_loss": 0.7298999088151115,
        "train_loss": 0.7702298347766583
      },
      {
        "epoch": 1581,
        "reward": 0.04088028892874718,
        "val_loss": 0.7210725120135716,
        "train_loss": 0.7218915797734203
      },
      {
        "epoch": 1582,
        "reward": 0.040843069553375244,
        "val_loss": 0.722443333693913,
        "train_loss": 0.7406470268391646
      },
      {
        "epoch": 1583,
        "reward": 0.04101329669356346,
        "val_loss": 0.7162043878010341,
        "train_loss": 0.7316705636107005
      },
      {
        "epoch": 1584,
        "reward": 0.04009551927447319,
        "val_loss": 0.7508021337645394,
        "train_loss": 0.8059359571108451
      },
      {
        "epoch": 1585,
        "reward": 0.040285177528858185,
        "val_loss": 0.7434557335717338,
        "train_loss": 0.7370920846095452
      },
      {
        "epoch": 1586,
        "reward": 0.04115503281354904,
        "val_loss": 0.7110695242881775,
        "train_loss": 0.7806663329784687
      },
      {
        "epoch": 1587,
        "reward": 0.04118354246020317,
        "val_loss": 0.7100431323051453,
        "train_loss": 0.7349426047160075
      },
      {
        "epoch": 1588,
        "reward": 0.0404842309653759,
        "val_loss": 0.7358572312763759,
        "train_loss": 0.7489303281674018
      },
      {
        "epoch": 1589,
        "reward": 0.040966104716062546,
        "val_loss": 0.7179259998457772,
        "train_loss": 0.7426576878015811
      },
      {
        "epoch": 1590,
        "reward": 0.04093090817332268,
        "val_loss": 0.719214311667851,
        "train_loss": 0.7697213269197024
      },
      {
        "epoch": 1591,
        "reward": 0.038614027202129364,
        "val_loss": 0.8120198760713849,
        "train_loss": 0.7476407954326043
      },
      {
        "epoch": 1592,
        "reward": 0.039693158119916916,
        "val_loss": 0.7667431490761893,
        "train_loss": 0.7504267858771178
      },
      {
        "epoch": 1593,
        "reward": 0.0397331677377224,
        "val_loss": 0.7651359183447701,
        "train_loss": 0.7974892648366781
      },
      {
        "epoch": 1594,
        "reward": 0.04098309203982353,
        "val_loss": 0.717305736882346,
        "train_loss": 0.7788467705249786
      },
      {
        "epoch": 1595,
        "reward": 0.040272943675518036,
        "val_loss": 0.7439262696674892,
        "train_loss": 0.7854381478749789
      },
      {
        "epoch": 1596,
        "reward": 0.040414806455373764,
        "val_loss": 0.7384945324489048,
        "train_loss": 0.8329635010315821
      },
      {
        "epoch": 1597,
        "reward": 0.04116428270936012,
        "val_loss": 0.7107362491743905,
        "train_loss": 0.74550749705388
      },
      {
        "epoch": 1598,
        "reward": 0.04098961129784584,
        "val_loss": 0.7170678717749459,
        "train_loss": 0.8392321513249323
      },
      {
        "epoch": 1599,
        "reward": 0.040416356176137924,
        "val_loss": 0.738435617515019,
        "train_loss": 0.8143564210488246
      },
      {
        "epoch": 1600,
        "reward": 0.03997155278921127,
        "val_loss": 0.755661530154092,
        "train_loss": 0.7427166459652094
      },
      {
        "epoch": 1601,
        "reward": 0.04074876010417938,
        "val_loss": 0.725933986050742,
        "train_loss": 0.7446580781386449
      },
      {
        "epoch": 1602,
        "reward": 0.04070133715867996,
        "val_loss": 0.7276985560144696,
        "train_loss": 0.7710051651184375
      },
      {
        "epoch": 1603,
        "reward": 0.04130468890070915,
        "val_loss": 0.7057057704244342,
        "train_loss": 0.8335703771847945
      },
      {
        "epoch": 1604,
        "reward": 0.04163598641753197,
        "val_loss": 0.6940400685582843,
        "train_loss": 0.7341963591483923
      },
      {
        "epoch": 1605,
        "reward": 0.040793467313051224,
        "val_loss": 0.724276065826416,
        "train_loss": 0.7684001670433924
      },
      {
        "epoch": 1606,
        "reward": 0.04160016402602196,
        "val_loss": 0.6952876959528241,
        "train_loss": 0.8004295711333935
      },
      {
        "epoch": 1607,
        "reward": 0.040848854929208755,
        "val_loss": 0.722230042730059,
        "train_loss": 0.7321841705303925
      },
      {
        "epoch": 1608,
        "reward": 0.0408824197947979,
        "val_loss": 0.7209940552711487,
        "train_loss": 0.768626467539714
      },
      {
        "epoch": 1609,
        "reward": 0.04098442196846008,
        "val_loss": 0.7172571250370571,
        "train_loss": 0.7438129782676697
      },
      {
        "epoch": 1610,
        "reward": 0.04074491932988167,
        "val_loss": 0.7260766838278089,
        "train_loss": 0.7369512078853754
      },
      {
        "epoch": 1611,
        "reward": 0.04105690121650696,
        "val_loss": 0.7146189766270774,
        "train_loss": 0.7309619618149904
      },
      {
        "epoch": 1612,
        "reward": 0.039249908179044724,
        "val_loss": 0.7848828094346183,
        "train_loss": 0.7486190658349258
      },
      {
        "epoch": 1613,
        "reward": 0.039652638137340546,
        "val_loss": 0.7683759459427425,
        "train_loss": 0.7458103812084749
      },
      {
        "epoch": 1614,
        "reward": 0.04129601642489433,
        "val_loss": 0.7060149993215289,
        "train_loss": 0.7571228433113831
      },
      {
        "epoch": 1615,
        "reward": 0.041749268770217896,
        "val_loss": 0.6901153751782009,
        "train_loss": 0.7795005853359516
      },
      {
        "epoch": 1616,
        "reward": 0.04157210513949394,
        "val_loss": 0.6962674515587943,
        "train_loss": 0.7962962182668539
      },
      {
        "epoch": 1617,
        "reward": 0.03989609703421593,
        "val_loss": 0.7586419412067958,
        "train_loss": 0.7460292050471673
      },
      {
        "epoch": 1618,
        "reward": 0.04095622897148132,
        "val_loss": 0.7182872550828117,
        "train_loss": 0.7337299272991143
      },
      {
        "epoch": 1619,
        "reward": 0.04112212359905243,
        "val_loss": 0.712256942476545,
        "train_loss": 0.7369382404364072
      },
      {
        "epoch": 1620,
        "reward": 0.04140549525618553,
        "val_loss": 0.702125975063869,
        "train_loss": 0.7382403279726322
      },
      {
        "epoch": 1621,
        "reward": 0.04099404811859131,
        "val_loss": 0.7169058322906494,
        "train_loss": 0.7204867028273069
      },
      {
        "epoch": 1622,
        "reward": 0.04084078222513199,
        "val_loss": 0.7225277509008136,
        "train_loss": 0.7917714073107793
      },
      {
        "epoch": 1623,
        "reward": 0.04085562005639076,
        "val_loss": 0.7219807165009635,
        "train_loss": 0.7484889259705176
      },
      {
        "epoch": 1624,
        "reward": 0.04054029658436775,
        "val_loss": 0.7337377071380615,
        "train_loss": 0.7621681266106092
      },
      {
        "epoch": 1625,
        "reward": 0.041110046207904816,
        "val_loss": 0.7126936401639666,
        "train_loss": 0.7583329471258017
      },
      {
        "epoch": 1626,
        "reward": 0.04084119573235512,
        "val_loss": 0.7225125517163958,
        "train_loss": 0.805893776508478
      },
      {
        "epoch": 1627,
        "reward": 0.04053563252091408,
        "val_loss": 0.7339136600494385,
        "train_loss": 0.7514365200813
      },
      {
        "epoch": 1628,
        "reward": 0.039553336799144745,
        "val_loss": 0.772398693220956,
        "train_loss": 0.7398297010132899
      },
      {
        "epoch": 1629,
        "reward": 0.03944927081465721,
        "val_loss": 0.7766473123005458,
        "train_loss": 0.7870208483475906
      },
      {
        "epoch": 1630,
        "reward": 0.04093774035573006,
        "val_loss": 0.7189637252262661,
        "train_loss": 0.773826016829564
      },
      {
        "epoch": 1631,
        "reward": 0.04056469351053238,
        "val_loss": 0.732818067073822,
        "train_loss": 0.7546712635801389
      },
      {
        "epoch": 1632,
        "reward": 0.04084480553865433,
        "val_loss": 0.7223793012755257,
        "train_loss": 0.772929141154656
      },
      {
        "epoch": 1633,
        "reward": 0.04098627343773842,
        "val_loss": 0.7171894907951355,
        "train_loss": 0.7603412201771369
      },
      {
        "epoch": 1634,
        "reward": 0.04095153138041496,
        "val_loss": 0.7184590782438006,
        "train_loss": 0.7429592047746365
      },
      {
        "epoch": 1635,
        "reward": 0.04036688432097435,
        "val_loss": 0.7403228197778974,
        "train_loss": 0.7513231451694782
      },
      {
        "epoch": 1636,
        "reward": 0.04091368988156319,
        "val_loss": 0.7198454311915806,
        "train_loss": 0.7482171792250413
      },
      {
        "epoch": 1637,
        "reward": 0.04065338894724846,
        "val_loss": 0.7294890454837254,
        "train_loss": 0.7158853016220607
      },
      {
        "epoch": 1638,
        "reward": 0.0405021607875824,
        "val_loss": 0.7351786494255066,
        "train_loss": 0.7437067031860352
      },
      {
        "epoch": 1639,
        "reward": 0.04042576625943184,
        "val_loss": 0.7380773510251727,
        "train_loss": 0.7538256370104276
      },
      {
        "epoch": 1640,
        "reward": 0.04020363837480545,
        "val_loss": 0.7466011728559222,
        "train_loss": 0.7317244129685255
      },
      {
        "epoch": 1641,
        "reward": 0.04082925245165825,
        "val_loss": 0.7229530130113874,
        "train_loss": 0.7562818916944357
      },
      {
        "epoch": 1642,
        "reward": 0.0407649390399456,
        "val_loss": 0.7253333926200867,
        "train_loss": 0.7430535875833951
      },
      {
        "epoch": 1643,
        "reward": 0.04080769792199135,
        "val_loss": 0.7237496972084045,
        "train_loss": 0.7834721207618713
      },
      {
        "epoch": 1644,
        "reward": 0.04092751815915108,
        "val_loss": 0.719338310616357,
        "train_loss": 0.7553330957889557
      },
      {
        "epoch": 1645,
        "reward": 0.04096829518675804,
        "val_loss": 0.7178460529872349,
        "train_loss": 0.7661587985662314
      },
      {
        "epoch": 1646,
        "reward": 0.040542956441640854,
        "val_loss": 0.7336373584611076,
        "train_loss": 0.751537113235547
      },
      {
        "epoch": 1647,
        "reward": 0.040230464190244675,
        "val_loss": 0.745564341545105,
        "train_loss": 0.7437105729029729
      },
      {
        "epoch": 1648,
        "reward": 0.04086398705840111,
        "val_loss": 0.7216723901884896,
        "train_loss": 0.7615391451578873
      },
      {
        "epoch": 1649,
        "reward": 0.040592193603515625,
        "val_loss": 0.7317835518292019,
        "train_loss": 0.7487588020471426
      },
      {
        "epoch": 1650,
        "reward": 0.04134916886687279,
        "val_loss": 0.7041230073996952,
        "train_loss": 0.7361618395035083
      },
      {
        "epoch": 1651,
        "reward": 0.03884440287947655,
        "val_loss": 0.8020319938659668,
        "train_loss": 0.7586979682628925
      },
      {
        "epoch": 1652,
        "reward": 0.04021169990301132,
        "val_loss": 0.7462895129408155,
        "train_loss": 0.7716110486250657
      },
      {
        "epoch": 1653,
        "reward": 0.04080161079764366,
        "val_loss": 0.7239746834550586,
        "train_loss": 0.7255010954462565
      },
      {
        "epoch": 1654,
        "reward": 0.04097466170787811,
        "val_loss": 0.7176134841782706,
        "train_loss": 0.7179788560248338
      },
      {
        "epoch": 1655,
        "reward": 0.04063425585627556,
        "val_loss": 0.7302052804401943,
        "train_loss": 0.7812692981499892
      },
      {
        "epoch": 1656,
        "reward": 0.0408492349088192,
        "val_loss": 0.7222158142498561,
        "train_loss": 0.7212448830787952
      },
      {
        "epoch": 1657,
        "reward": 0.04088371619582176,
        "val_loss": 0.7209465333393642,
        "train_loss": 0.7466080268988242
      },
      {
        "epoch": 1658,
        "reward": 0.04026619717478752,
        "val_loss": 0.7441860820565905,
        "train_loss": 0.722906782076909
      },
      {
        "epoch": 1659,
        "reward": 0.040697429329156876,
        "val_loss": 0.7278441531317574,
        "train_loss": 0.7453628193873626
      },
      {
        "epoch": 1660,
        "reward": 0.041304267942905426,
        "val_loss": 0.7057208333696637,
        "train_loss": 0.7628197383422118
      },
      {
        "epoch": 1661,
        "reward": 0.041012171655893326,
        "val_loss": 0.7162453830242157,
        "train_loss": 0.7225431198827349
      },
      {
        "epoch": 1662,
        "reward": 0.040902163833379745,
        "val_loss": 0.7202685347625187,
        "train_loss": 0.7999341121086707
      },
      {
        "epoch": 1663,
        "reward": 0.04133902117609978,
        "val_loss": 0.704483585698264,
        "train_loss": 0.8242202492860647
      },
      {
        "epoch": 1664,
        "reward": 0.040522027760744095,
        "val_loss": 0.7344273839678083,
        "train_loss": 0.804778630916889
      },
      {
        "epoch": 1665,
        "reward": 0.03976186364889145,
        "val_loss": 0.7639863405908857,
        "train_loss": 0.7291460083081172
      },
      {
        "epoch": 1666,
        "reward": 0.04118989408016205,
        "val_loss": 0.709814761366163,
        "train_loss": 0.7671741178402534
      },
      {
        "epoch": 1667,
        "reward": 0.04076344147324562,
        "val_loss": 0.7253889271191188,
        "train_loss": 0.765395347888653
      },
      {
        "epoch": 1668,
        "reward": 0.04111376404762268,
        "val_loss": 0.7125591124807086,
        "train_loss": 0.7785036197075477
      },
      {
        "epoch": 1669,
        "reward": 0.04012865945696831,
        "val_loss": 0.7495108246803284,
        "train_loss": 0.7330107322105994
      },
      {
        "epoch": 1670,
        "reward": 0.04036691412329674,
        "val_loss": 0.7403216872896466,
        "train_loss": 0.7244191510746112
      },
      {
        "epoch": 1671,
        "reward": 0.04169522970914841,
        "val_loss": 0.6919835167271751,
        "train_loss": 0.7415597163713895
      },
      {
        "epoch": 1672,
        "reward": 0.039761196821928024,
        "val_loss": 0.7640130306993212,
        "train_loss": 0.7538510859012604
      },
      {
        "epoch": 1673,
        "reward": 0.04044942930340767,
        "val_loss": 0.737177597624915,
        "train_loss": 0.7604888448348412
      },
      {
        "epoch": 1674,
        "reward": 0.041338514536619186,
        "val_loss": 0.7045016884803772,
        "train_loss": 0.7288475976540492
      },
      {
        "epoch": 1675,
        "reward": 0.04082142934203148,
        "val_loss": 0.7232420699937003,
        "train_loss": 0.7769455795104687
      },
      {
        "epoch": 1676,
        "reward": 0.04098537191748619,
        "val_loss": 0.7172225287982396,
        "train_loss": 0.7178201259901891
      },
      {
        "epoch": 1677,
        "reward": 0.0396566316485405,
        "val_loss": 0.7682148133005414,
        "train_loss": 0.7224929561981788
      },
      {
        "epoch": 1678,
        "reward": 0.0403556190431118,
        "val_loss": 0.7407538379941668,
        "train_loss": 0.757340146945073
      },
      {
        "epoch": 1679,
        "reward": 0.039843685925006866,
        "val_loss": 0.760722279548645,
        "train_loss": 0.8232159935511075
      },
      {
        "epoch": 1680,
        "reward": 0.040613215416669846,
        "val_loss": 0.7309942926679339,
        "train_loss": 0.7701890537372003
      },
      {
        "epoch": 1681,
        "reward": 0.0410354919731617,
        "val_loss": 0.7153967363493783,
        "train_loss": 0.7741064841930683
      },
      {
        "epoch": 1682,
        "reward": 0.03959967941045761,
        "val_loss": 0.7705174429076058,
        "train_loss": 0.7473404109477997
      },
      {
        "epoch": 1683,
        "reward": 0.04057453200221062,
        "val_loss": 0.7324476071766445,
        "train_loss": 0.8075918005062983
      },
      {
        "epoch": 1684,
        "reward": 0.04091842100024223,
        "val_loss": 0.719672007220132,
        "train_loss": 0.7419270030581034
      },
      {
        "epoch": 1685,
        "reward": 0.04080034792423248,
        "val_loss": 0.724021417754037,
        "train_loss": 0.7271540829768548
      },
      {
        "epoch": 1686,
        "reward": 0.0414087139070034,
        "val_loss": 0.70201233455113,
        "train_loss": 0.7741425725129935
      },
      {
        "epoch": 1687,
        "reward": 0.040353648364543915,
        "val_loss": 0.7408291271754673,
        "train_loss": 0.7283667323107903
      },
      {
        "epoch": 1688,
        "reward": 0.040699850767850876,
        "val_loss": 0.7277540053640094,
        "train_loss": 0.74180301794639
      },
      {
        "epoch": 1689,
        "reward": 0.041007380932569504,
        "val_loss": 0.7164199352264404,
        "train_loss": 0.7579138668683859
      },
      {
        "epoch": 1690,
        "reward": 0.041154976934194565,
        "val_loss": 0.7110715253012521,
        "train_loss": 0.7206890130272279
      },
      {
        "epoch": 1691,
        "reward": 0.0408424437046051,
        "val_loss": 0.7224664347512382,
        "train_loss": 0.7615798390828646
      },
      {
        "epoch": 1692,
        "reward": 0.04089748486876488,
        "val_loss": 0.7204404686178479,
        "train_loss": 0.7460112984363849
      },
      {
        "epoch": 1693,
        "reward": 0.03963043913245201,
        "val_loss": 0.7692723870277405,
        "train_loss": 0.738155892262092
      },
      {
        "epoch": 1694,
        "reward": 0.041007403284311295,
        "val_loss": 0.7164191263062614,
        "train_loss": 0.744335610132951
      },
      {
        "epoch": 1695,
        "reward": 0.04043252393603325,
        "val_loss": 0.7378202165876117,
        "train_loss": 0.7825958820489737
      },
      {
        "epoch": 1696,
        "reward": 0.038746174424886703,
        "val_loss": 0.8062685259750911,
        "train_loss": 0.7542846775971926
      },
      {
        "epoch": 1697,
        "reward": 0.040972672402858734,
        "val_loss": 0.7176860570907593,
        "train_loss": 0.7617724274213498
      },
      {
        "epoch": 1698,
        "reward": 0.040111642330884933,
        "val_loss": 0.7501737645694188,
        "train_loss": 0.72770267782303
      },
      {
        "epoch": 1699,
        "reward": 0.040142737329006195,
        "val_loss": 0.7489634241376605,
        "train_loss": 0.7483183879118699
      },
      {
        "epoch": 1700,
        "reward": 0.039809588342905045,
        "val_loss": 0.7620799200875419,
        "train_loss": 0.7453732352990371
      },
      {
        "epoch": 1701,
        "reward": 0.04038120061159134,
        "val_loss": 0.7397759301321847,
        "train_loss": 0.7567176589599023
      },
      {
        "epoch": 1702,
        "reward": 0.04081891104578972,
        "val_loss": 0.723335291658129,
        "train_loss": 0.7793951080395625
      },
      {
        "epoch": 1703,
        "reward": 0.03995237499475479,
        "val_loss": 0.7564175214086261,
        "train_loss": 0.7851044191763952
      },
      {
        "epoch": 1704,
        "reward": 0.04071114584803581,
        "val_loss": 0.7273330858775547,
        "train_loss": 0.7656996571100675
      },
      {
        "epoch": 1705,
        "reward": 0.040514539927244186,
        "val_loss": 0.7347104464258466,
        "train_loss": 0.7358523011207581
      },
      {
        "epoch": 1706,
        "reward": 0.040854331105947495,
        "val_loss": 0.7220280085291181,
        "train_loss": 0.7256114528729365
      },
      {
        "epoch": 1707,
        "reward": 0.04104602336883545,
        "val_loss": 0.7150138446262905,
        "train_loss": 0.7264662820559281
      },
      {
        "epoch": 1708,
        "reward": 0.041084084659814835,
        "val_loss": 0.7136331030300685,
        "train_loss": 0.737930586704841
      },
      {
        "epoch": 1709,
        "reward": 0.04070553928613663,
        "val_loss": 0.7275419064930507,
        "train_loss": 0.7414981149710141
      },
      {
        "epoch": 1710,
        "reward": 0.041031613945961,
        "val_loss": 0.7155377013342721,
        "train_loss": 0.7825506581709936
      },
      {
        "epoch": 1711,
        "reward": 0.0408146046102047,
        "val_loss": 0.7234941465514046,
        "train_loss": 0.8072590369444627
      },
      {
        "epoch": 1712,
        "reward": 0.040552619844675064,
        "val_loss": 0.7332729612077985,
        "train_loss": 0.7488968429657129
      },
      {
        "epoch": 1713,
        "reward": 0.04090220853686333,
        "val_loss": 0.7202669169221606,
        "train_loss": 0.7525237615291889
      },
      {
        "epoch": 1714,
        "reward": 0.04098552092909813,
        "val_loss": 0.7172170494283948,
        "train_loss": 0.7406477595751102
      },
      {
        "epoch": 1715,
        "reward": 0.040490344166755676,
        "val_loss": 0.7356258205005101,
        "train_loss": 0.7325047518198307
      },
      {
        "epoch": 1716,
        "reward": 0.04045797139406204,
        "val_loss": 0.7368532972676414,
        "train_loss": 0.7297545359111749
      },
      {
        "epoch": 1717,
        "reward": 0.04073235020041466,
        "val_loss": 0.726543835231236,
        "train_loss": 0.7357938851301487
      },
      {
        "epoch": 1718,
        "reward": 0.040858056396245956,
        "val_loss": 0.7218908752713885,
        "train_loss": 0.733901063983257
      },
      {
        "epoch": 1719,
        "reward": 0.04112888500094414,
        "val_loss": 0.7120127337319511,
        "train_loss": 0.7457402073420011
      },
      {
        "epoch": 1720,
        "reward": 0.03971244767308235,
        "val_loss": 0.7659676585878644,
        "train_loss": 0.7499420562615762
      },
      {
        "epoch": 1721,
        "reward": 0.041143953800201416,
        "val_loss": 0.7114689350128174,
        "train_loss": 0.7402728417745004
      },
      {
        "epoch": 1722,
        "reward": 0.041168756783008575,
        "val_loss": 0.7105752144541059,
        "train_loss": 0.7319763933236783
      },
      {
        "epoch": 1723,
        "reward": 0.040926747024059296,
        "val_loss": 0.7193665845053536,
        "train_loss": 0.730781288101123
      },
      {
        "epoch": 1724,
        "reward": 0.04041796550154686,
        "val_loss": 0.7383741736412048,
        "train_loss": 0.7276159267012889
      },
      {
        "epoch": 1725,
        "reward": 0.04115249589085579,
        "val_loss": 0.7111610429627555,
        "train_loss": 0.7979563142244632
      },
      {
        "epoch": 1726,
        "reward": 0.04121681675314903,
        "val_loss": 0.7088479484830584,
        "train_loss": 0.7506459802389145
      },
      {
        "epoch": 1727,
        "reward": 0.040732551366090775,
        "val_loss": 0.7265364442552839,
        "train_loss": 0.7211237830611376
      },
      {
        "epoch": 1728,
        "reward": 0.04102234169840813,
        "val_loss": 0.7158752126353127,
        "train_loss": 0.774226773243684
      },
      {
        "epoch": 1729,
        "reward": 0.04098508507013321,
        "val_loss": 0.7172330490180424,
        "train_loss": 0.7654308883043436
      },
      {
        "epoch": 1730,
        "reward": 0.04103169962763786,
        "val_loss": 0.715534542288099,
        "train_loss": 0.7220069571183279
      },
      {
        "epoch": 1731,
        "reward": 0.04104040190577507,
        "val_loss": 0.7152183055877686,
        "train_loss": 0.7852978431261503
      },
      {
        "epoch": 1732,
        "reward": 0.04023037478327751,
        "val_loss": 0.7455675857407706,
        "train_loss": 0.7634196120959061
      },
      {
        "epoch": 1733,
        "reward": 0.04087429866194725,
        "val_loss": 0.7212927000863212,
        "train_loss": 0.7828943477227137
      },
      {
        "epoch": 1734,
        "reward": 0.04090551286935806,
        "val_loss": 0.7201456129550934,
        "train_loss": 0.7425722984167246
      },
      {
        "epoch": 1735,
        "reward": 0.04092347249388695,
        "val_loss": 0.7194866282599313,
        "train_loss": 0.7772171772443331
      },
      {
        "epoch": 1736,
        "reward": 0.04103982821106911,
        "val_loss": 0.715239235333034,
        "train_loss": 0.7161126153973433
      },
      {
        "epoch": 1737,
        "reward": 0.04095287248492241,
        "val_loss": 0.7184098703520638,
        "train_loss": 0.7752535480719346
      },
      {
        "epoch": 1738,
        "reward": 0.04078728333115578,
        "val_loss": 0.7245052116257804,
        "train_loss": 0.739679006429819
      },
      {
        "epoch": 1739,
        "reward": 0.04088251665234566,
        "val_loss": 0.7209906237465995,
        "train_loss": 0.7489490027611072
      },
      {
        "epoch": 1740,
        "reward": 0.041017819195985794,
        "val_loss": 0.7160398023469108,
        "train_loss": 0.7307902941336999
      },
      {
        "epoch": 1741,
        "reward": 0.041032690554857254,
        "val_loss": 0.7154987709862846,
        "train_loss": 0.7417018459393427
      },
      {
        "epoch": 1742,
        "reward": 0.040953490883111954,
        "val_loss": 0.7183873738561358,
        "train_loss": 0.7289649993181229
      },
      {
        "epoch": 1743,
        "reward": 0.04059438034892082,
        "val_loss": 0.7317014421735492,
        "train_loss": 0.7398440562761747
      },
      {
        "epoch": 1744,
        "reward": 0.04100150614976883,
        "val_loss": 0.7166340010506767,
        "train_loss": 0.7600357784674718
      },
      {
        "epoch": 1745,
        "reward": 0.04080123081803322,
        "val_loss": 0.723988971539906,
        "train_loss": 0.7373926777106065
      },
      {
        "epoch": 1746,
        "reward": 0.040701933205127716,
        "val_loss": 0.7276762638773236,
        "train_loss": 0.7541550237398881
      },
      {
        "epoch": 1747,
        "reward": 0.04043840616941452,
        "val_loss": 0.7375966310501099,
        "train_loss": 0.7454305589199066
      },
      {
        "epoch": 1748,
        "reward": 0.04092244431376457,
        "val_loss": 0.7195243750299726,
        "train_loss": 0.7584275374045739
      },
      {
        "epoch": 1749,
        "reward": 0.04106311500072479,
        "val_loss": 0.7143933943339756,
        "train_loss": 0.7633415025014144
      },
      {
        "epoch": 1750,
        "reward": 0.0411786288022995,
        "val_loss": 0.7102197791848864,
        "train_loss": 0.8007966532157018
      },
      {
        "epoch": 1751,
        "reward": 0.04090969264507294,
        "val_loss": 0.7199920330728803,
        "train_loss": 0.7462982191489294
      },
      {
        "epoch": 1752,
        "reward": 0.04099729284644127,
        "val_loss": 0.7167876958847046,
        "train_loss": 0.7378081106222593
      },
      {
        "epoch": 1753,
        "reward": 0.04104795679450035,
        "val_loss": 0.7149437708514077,
        "train_loss": 0.7954105276327866
      },
      {
        "epoch": 1754,
        "reward": 0.041086532175540924,
        "val_loss": 0.713544487953186,
        "train_loss": 0.7475120012576764
      },
      {
        "epoch": 1755,
        "reward": 0.040873829275369644,
        "val_loss": 0.7213101216724941,
        "train_loss": 0.7804383841844705
      },
      {
        "epoch": 1756,
        "reward": 0.041087038815021515,
        "val_loss": 0.7135260573455265,
        "train_loss": 0.7149841321202425
      },
      {
        "epoch": 1757,
        "reward": 0.04097668454051018,
        "val_loss": 0.7175396765981402,
        "train_loss": 0.7200007195082995
      },
      {
        "epoch": 1758,
        "reward": 0.041009481996297836,
        "val_loss": 0.7163432325635638,
        "train_loss": 0.777173672731106
      },
      {
        "epoch": 1759,
        "reward": 0.04105312004685402,
        "val_loss": 0.7147562290940966,
        "train_loss": 0.7522866061100593
      },
      {
        "epoch": 1760,
        "reward": 0.040709804743528366,
        "val_loss": 0.7273832091263362,
        "train_loss": 0.7173080186431224
      },
      {
        "epoch": 1761,
        "reward": 0.04104679450392723,
        "val_loss": 0.7149859751973834,
        "train_loss": 0.7248598640927901
      },
      {
        "epoch": 1762,
        "reward": 0.04096819460391998,
        "val_loss": 0.7178496633257184,
        "train_loss": 0.7204447841415038
      },
      {
        "epoch": 1763,
        "reward": 0.0410071462392807,
        "val_loss": 0.7164283863135746,
        "train_loss": 0.7483589901373937
      },
      {
        "epoch": 1764,
        "reward": 0.041066527366638184,
        "val_loss": 0.714269586971828,
        "train_loss": 0.7432994406956893
      },
      {
        "epoch": 1765,
        "reward": 0.04075707867741585,
        "val_loss": 0.7256251871585846,
        "train_loss": 0.7228921182143565
      },
      {
        "epoch": 1766,
        "reward": 0.0406038872897625,
        "val_loss": 0.7313442996570042,
        "train_loss": 0.7499530154925126
      },
      {
        "epoch": 1767,
        "reward": 0.04088905453681946,
        "val_loss": 0.720750059400286,
        "train_loss": 0.7715259813345395
      },
      {
        "epoch": 1768,
        "reward": 0.040957823395729065,
        "val_loss": 0.7182288340159825,
        "train_loss": 0.7237863827210206
      },
      {
        "epoch": 1769,
        "reward": 0.040824007242918015,
        "val_loss": 0.7231469069208417,
        "train_loss": 0.717981896434839
      },
      {
        "epoch": 1770,
        "reward": 0.04098273068666458,
        "val_loss": 0.7173189265387399,
        "train_loss": 0.7655115402661837
      },
      {
        "epoch": 1771,
        "reward": 0.04080915451049805,
        "val_loss": 0.7236957890646798,
        "train_loss": 0.7416411088063166
      },
      {
        "epoch": 1772,
        "reward": 0.0408872589468956,
        "val_loss": 0.7208161354064941,
        "train_loss": 0.7200684048808538
      },
      {
        "epoch": 1773,
        "reward": 0.04088834673166275,
        "val_loss": 0.7207762173243931,
        "train_loss": 0.7146149704662653
      },
      {
        "epoch": 1774,
        "reward": 0.041014011949300766,
        "val_loss": 0.716178412948336,
        "train_loss": 0.7498115943028376
      },
      {
        "epoch": 1775,
        "reward": 0.04072955250740051,
        "val_loss": 0.726647960288184,
        "train_loss": 0.7358045772864268
      },
      {
        "epoch": 1776,
        "reward": 0.04100034013390541,
        "val_loss": 0.7166764480727059,
        "train_loss": 0.7208542941281428
      },
      {
        "epoch": 1777,
        "reward": 0.041020315140485764,
        "val_loss": 0.7159490798200879,
        "train_loss": 0.7195059293164656
      },
      {
        "epoch": 1778,
        "reward": 0.040899623185396194,
        "val_loss": 0.7203618798937116,
        "train_loss": 0.7248663913745147
      },
      {
        "epoch": 1779,
        "reward": 0.04088084027171135,
        "val_loss": 0.7210520761353629,
        "train_loss": 0.743086808002912
      },
      {
        "epoch": 1780,
        "reward": 0.040704432874917984,
        "val_loss": 0.7275831401348114,
        "train_loss": 0.7559154904805697
      },
      {
        "epoch": 1781,
        "reward": 0.040793273597955704,
        "val_loss": 0.7242834142276219,
        "train_loss": 0.7737326140587146
      },
      {
        "epoch": 1782,
        "reward": 0.04093196988105774,
        "val_loss": 0.7191751769610814,
        "train_loss": 0.7254531566913311
      },
      {
        "epoch": 1783,
        "reward": 0.04095260798931122,
        "val_loss": 0.7184195816516876,
        "train_loss": 0.7491132892095126
      },
      {
        "epoch": 1784,
        "reward": 0.04091375693678856,
        "val_loss": 0.719843042748315,
        "train_loss": 0.7261534103980432
      },
      {
        "epoch": 1785,
        "reward": 0.040982894599437714,
        "val_loss": 0.7173129107270922,
        "train_loss": 0.7330232858657837
      },
      {
        "epoch": 1786,
        "reward": 0.040999457240104675,
        "val_loss": 0.7167086430958339,
        "train_loss": 0.7161493714039142
      },
      {
        "epoch": 1787,
        "reward": 0.04086759313941002,
        "val_loss": 0.7215396208422524,
        "train_loss": 0.7704309316781851
      },
      {
        "epoch": 1788,
        "reward": 0.04075542464852333,
        "val_loss": 0.7256865842001778,
        "train_loss": 0.7239792255254892
      },
      {
        "epoch": 1789,
        "reward": 0.040872957557439804,
        "val_loss": 0.7213420740195683,
        "train_loss": 0.7166367605901681
      },
      {
        "epoch": 1790,
        "reward": 0.040901683270931244,
        "val_loss": 0.7202860457556588,
        "train_loss": 0.7368249228367438
      },
      {
        "epoch": 1791,
        "reward": 0.040923185646533966,
        "val_loss": 0.719497161252158,
        "train_loss": 0.7590333521366119
      },
      {
        "epoch": 1792,
        "reward": 0.04097727686166763,
        "val_loss": 0.7175179421901703,
        "train_loss": 0.7218242677358481
      },
      {
        "epoch": 1793,
        "reward": 0.0404372401535511,
        "val_loss": 0.737640951360975,
        "train_loss": 0.7946377557057601
      },
      {
        "epoch": 1794,
        "reward": 0.04095717892050743,
        "val_loss": 0.7182525907244001,
        "train_loss": 0.7482040249384366
      },
      {
        "epoch": 1795,
        "reward": 0.04093996435403824,
        "val_loss": 0.718882543700082,
        "train_loss": 0.7206924431599103
      },
      {
        "epoch": 1796,
        "reward": 0.04093528538942337,
        "val_loss": 0.7190538815089634,
        "train_loss": 0.7342278475944812
      },
      {
        "epoch": 1797,
        "reward": 0.04081064090132713,
        "val_loss": 0.7236407995223999,
        "train_loss": 0.7337758793280675
      },
      {
        "epoch": 1798,
        "reward": 0.04073803871870041,
        "val_loss": 0.7263325112206596,
        "train_loss": 0.7360941996941199
      },
      {
        "epoch": 1799,
        "reward": 0.040785472840070724,
        "val_loss": 0.7245722838810512,
        "train_loss": 0.7273517698049545
      },
      {
        "epoch": 1800,
        "reward": 0.04087406396865845,
        "val_loss": 0.7213013853345599,
        "train_loss": 0.762277949314851
      },
      {
        "epoch": 1801,
        "reward": 0.04097370058298111,
        "val_loss": 0.7176485742841449,
        "train_loss": 0.7841281386522146
      },
      {
        "epoch": 1802,
        "reward": 0.040506795048713684,
        "val_loss": 0.7350031733512878,
        "train_loss": 0.759851696399542
      },
      {
        "epoch": 1803,
        "reward": 0.041025761514902115,
        "val_loss": 0.7157505580357143,
        "train_loss": 0.7203134057613519
      },
      {
        "epoch": 1804,
        "reward": 0.040855731815099716,
        "val_loss": 0.7219765995229993,
        "train_loss": 0.7339509519246908
      },
      {
        "epoch": 1805,
        "reward": 0.04099680483341217,
        "val_loss": 0.716805466583797,
        "train_loss": 0.7435333350530038
      },
      {
        "epoch": 1806,
        "reward": 0.04047253355383873,
        "val_loss": 0.7363008260726929,
        "train_loss": 0.762083881176435
      },
      {
        "epoch": 1807,
        "reward": 0.04103470221161842,
        "val_loss": 0.7154254913330078,
        "train_loss": 0.7977314087060782
      },
      {
        "epoch": 1808,
        "reward": 0.040671251714229584,
        "val_loss": 0.7288213457380023,
        "train_loss": 0.7174509336742071
      },
      {
        "epoch": 1809,
        "reward": 0.04064050316810608,
        "val_loss": 0.7299712215151105,
        "train_loss": 0.7710651411459997
      },
      {
        "epoch": 1810,
        "reward": 0.04059630632400513,
        "val_loss": 0.7316289671829769,
        "train_loss": 0.7309548568267089
      },
      {
        "epoch": 1811,
        "reward": 0.0408443957567215,
        "val_loss": 0.7223944664001465,
        "train_loss": 0.7167464408736962
      },
      {
        "epoch": 1812,
        "reward": 0.04079194366931915,
        "val_loss": 0.724332583802087,
        "train_loss": 0.7157622839395816
      },
      {
        "epoch": 1813,
        "reward": 0.04084555059671402,
        "val_loss": 0.7223517979894366,
        "train_loss": 0.7228562671404618
      },
      {
        "epoch": 1814,
        "reward": 0.04043160006403923,
        "val_loss": 0.7378554940223694,
        "train_loss": 0.7107909361903484
      },
      {
        "epoch": 1815,
        "reward": 0.04085308313369751,
        "val_loss": 0.7220741638115474,
        "train_loss": 0.7449468465951773
      },
      {
        "epoch": 1816,
        "reward": 0.040552686899900436,
        "val_loss": 0.7332704152379718,
        "train_loss": 0.7433207974984095
      },
      {
        "epoch": 1817,
        "reward": 0.040475621819496155,
        "val_loss": 0.7361836348261152,
        "train_loss": 0.7141408627996078
      },
      {
        "epoch": 1818,
        "reward": 0.04064171016216278,
        "val_loss": 0.729926164661135,
        "train_loss": 0.7149324652094108
      },
      {
        "epoch": 1819,
        "reward": 0.04074905440211296,
        "val_loss": 0.7259229293891362,
        "train_loss": 0.7166509674145625
      },
      {
        "epoch": 1820,
        "reward": 0.04057661443948746,
        "val_loss": 0.7323692909308842,
        "train_loss": 0.7140283481432841
      },
      {
        "epoch": 1821,
        "reward": 0.040892936289310455,
        "val_loss": 0.7206075957843235,
        "train_loss": 0.7507015650088971
      },
      {
        "epoch": 1822,
        "reward": 0.04081430658698082,
        "val_loss": 0.7235053522246224,
        "train_loss": 0.7595851650604835
      },
      {
        "epoch": 1823,
        "reward": 0.04015485569834709,
        "val_loss": 0.7484925431864602,
        "train_loss": 0.7138596912129567
      },
      {
        "epoch": 1824,
        "reward": 0.04065016284584999,
        "val_loss": 0.7296096980571747,
        "train_loss": 0.7139194977398102
      },
      {
        "epoch": 1825,
        "reward": 0.04050077497959137,
        "val_loss": 0.7352309099265507,
        "train_loss": 0.7221438116752185
      },
      {
        "epoch": 1826,
        "reward": 0.04055950790643692,
        "val_loss": 0.7330134127821241,
        "train_loss": 0.7387326566072611
      },
      {
        "epoch": 1827,
        "reward": 0.040515437722206116,
        "val_loss": 0.7346764462334769,
        "train_loss": 0.7438170634783231
      },
      {
        "epoch": 1828,
        "reward": 0.04042033478617668,
        "val_loss": 0.7382840045860836,
        "train_loss": 0.7482109321997716
      },
      {
        "epoch": 1829,
        "reward": 0.040696073323488235,
        "val_loss": 0.727894834109715,
        "train_loss": 0.7220083990922341
      },
      {
        "epoch": 1830,
        "reward": 0.0403880849480629,
        "val_loss": 0.7395132098879132,
        "train_loss": 0.7816207741315548
      },
      {
        "epoch": 1831,
        "reward": 0.040154531598091125,
        "val_loss": 0.7485049622399467,
        "train_loss": 0.7114812107040331
      },
      {
        "epoch": 1832,
        "reward": 0.040760088711977005,
        "val_loss": 0.725513471024377,
        "train_loss": 0.7420148987036485
      },
      {
        "epoch": 1833,
        "reward": 0.04076963663101196,
        "val_loss": 0.7251592108181545,
        "train_loss": 0.736624878186446
      },
      {
        "epoch": 1834,
        "reward": 0.04050607979297638,
        "val_loss": 0.7350302849497113,
        "train_loss": 0.7203773787388434
      },
      {
        "epoch": 1835,
        "reward": 0.040684301406145096,
        "val_loss": 0.7283339543001992,
        "train_loss": 0.7578384715777177
      },
      {
        "epoch": 1836,
        "reward": 0.040504228323698044,
        "val_loss": 0.7351002437727792,
        "train_loss": 0.74285410459225
      },
      {
        "epoch": 1837,
        "reward": 0.04066964238882065,
        "val_loss": 0.7288814187049866,
        "train_loss": 0.7169417263223574
      },
      {
        "epoch": 1838,
        "reward": 0.04069487005472183,
        "val_loss": 0.7279398100716727,
        "train_loss": 0.729696301313547
      },
      {
        "epoch": 1839,
        "reward": 0.040229301899671555,
        "val_loss": 0.7456088576998029,
        "train_loss": 0.7585305479856638
      },
      {
        "epoch": 1840,
        "reward": 0.04044713079929352,
        "val_loss": 0.7372648928846631,
        "train_loss": 0.715846443692079
      },
      {
        "epoch": 1841,
        "reward": 0.0406474731862545,
        "val_loss": 0.7297104171344212,
        "train_loss": 0.7620115646949182
      },
      {
        "epoch": 1842,
        "reward": 0.040514566004276276,
        "val_loss": 0.7347093224525452,
        "train_loss": 0.7800509585784032
      },
      {
        "epoch": 1843,
        "reward": 0.04053488373756409,
        "val_loss": 0.7339419637407575,
        "train_loss": 0.7935064056744943
      },
      {
        "epoch": 1844,
        "reward": 0.04040137678384781,
        "val_loss": 0.7390062553542001,
        "train_loss": 0.7606965968242059
      },
      {
        "epoch": 1845,
        "reward": 0.040467847138643265,
        "val_loss": 0.7364784819739205,
        "train_loss": 0.717574445100931
      },
      {
        "epoch": 1846,
        "reward": 0.04037628695368767,
        "val_loss": 0.7399636421884809,
        "train_loss": 0.7436644503703485
      },
      {
        "epoch": 1847,
        "reward": 0.040367353707551956,
        "val_loss": 0.740304959671838,
        "train_loss": 0.7929714345015012
      },
      {
        "epoch": 1848,
        "reward": 0.04063340276479721,
        "val_loss": 0.7302373477390834,
        "train_loss": 0.7225867888102164
      },
      {
        "epoch": 1849,
        "reward": 0.04047001898288727,
        "val_loss": 0.7363961040973663,
        "train_loss": 0.718903084213917
      },
      {
        "epoch": 1850,
        "reward": 0.04034360125660896,
        "val_loss": 0.7412136920860836,
        "train_loss": 0.7360513462470128
      },
      {
        "epoch": 1851,
        "reward": 0.04028774052858353,
        "val_loss": 0.7433571219444275,
        "train_loss": 0.7109163572581915
      },
      {
        "epoch": 1852,
        "reward": 0.040598947554826736,
        "val_loss": 0.7315298318862915,
        "train_loss": 0.7530879882665781
      },
      {
        "epoch": 1853,
        "reward": 0.040314022451639175,
        "val_loss": 0.7423472830227443,
        "train_loss": 0.7664091839240148
      },
      {
        "epoch": 1854,
        "reward": 0.04055590555071831,
        "val_loss": 0.7331491410732269,
        "train_loss": 0.7418182767354525
      },
      {
        "epoch": 1855,
        "reward": 0.040337275713682175,
        "val_loss": 0.7414558018956866,
        "train_loss": 0.7251225320192484
      },
      {
        "epoch": 1856,
        "reward": 0.04035195708274841,
        "val_loss": 0.7408937130655561,
        "train_loss": 0.7538701754349929
      },
      {
        "epoch": 1857,
        "reward": 0.04072710871696472,
        "val_loss": 0.7267388318266187,
        "train_loss": 0.7150615276052401
      },
      {
        "epoch": 1858,
        "reward": 0.04018935188651085,
        "val_loss": 0.7471543891089303,
        "train_loss": 0.7090074495197489
      },
      {
        "epoch": 1859,
        "reward": 0.04030154272913933,
        "val_loss": 0.742826555456434,
        "train_loss": 0.7643355406247653
      },
      {
        "epoch": 1860,
        "reward": 0.040710728615522385,
        "val_loss": 0.7273485362529755,
        "train_loss": 0.7904932200908661
      },
      {
        "epoch": 1861,
        "reward": 0.040480565279722214,
        "val_loss": 0.7359961271286011,
        "train_loss": 0.7142021330789878
      },
      {
        "epoch": 1862,
        "reward": 0.040422722697257996,
        "val_loss": 0.7381930777004787,
        "train_loss": 0.7153193354606628
      },
      {
        "epoch": 1863,
        "reward": 0.040236376225948334,
        "val_loss": 0.7453360259532928,
        "train_loss": 0.7400032648673425
      },
      {
        "epoch": 1864,
        "reward": 0.040538426488637924,
        "val_loss": 0.7338082279477801,
        "train_loss": 0.7199585907734357
      },
      {
        "epoch": 1865,
        "reward": 0.04043910279870033,
        "val_loss": 0.7375700303486415,
        "train_loss": 0.752700347166795
      },
      {
        "epoch": 1866,
        "reward": 0.04062264785170555,
        "val_loss": 0.73064039008958,
        "train_loss": 0.7116685738930335
      },
      {
        "epoch": 1867,
        "reward": 0.0400647334754467,
        "val_loss": 0.7520047298499516,
        "train_loss": 0.7353466772116147
      },
      {
        "epoch": 1868,
        "reward": 0.04023539647459984,
        "val_loss": 0.745373798268182,
        "train_loss": 0.771323011471675
      },
      {
        "epoch": 1869,
        "reward": 0.040346935391426086,
        "val_loss": 0.7410859635898045,
        "train_loss": 0.7125728485675958
      },
      {
        "epoch": 1870,
        "reward": 0.04044388607144356,
        "val_loss": 0.7373882148947034,
        "train_loss": 0.7118467330359496
      },
      {
        "epoch": 1871,
        "reward": 0.0404665432870388,
        "val_loss": 0.7365278601646423,
        "train_loss": 0.7314330110183129
      },
      {
        "epoch": 1872,
        "reward": 0.040342122316360474,
        "val_loss": 0.7412701674870082,
        "train_loss": 0.7138163739672074
      },
      {
        "epoch": 1873,
        "reward": 0.04020443186163902,
        "val_loss": 0.7465705445834568,
        "train_loss": 0.7235662375505154
      },
      {
        "epoch": 1874,
        "reward": 0.04055668041110039,
        "val_loss": 0.7331200327192035,
        "train_loss": 0.7124207994112601
      },
      {
        "epoch": 1875,
        "reward": 0.0404994823038578,
        "val_loss": 0.7352798751422337,
        "train_loss": 0.7121512832549902
      },
      {
        "epoch": 1876,
        "reward": 0.040471505373716354,
        "val_loss": 0.7363398160253253,
        "train_loss": 0.8013577575866992
      },
      {
        "epoch": 1877,
        "reward": 0.04044005647301674,
        "val_loss": 0.7375336630003793,
        "train_loss": 0.7294143575888413
      },
      {
        "epoch": 1878,
        "reward": 0.040404222905635834,
        "val_loss": 0.7388977152960641,
        "train_loss": 0.7279440852311941
      },
      {
        "epoch": 1879,
        "reward": 0.04032519459724426,
        "val_loss": 0.741919036422457,
        "train_loss": 0.7450983088750106
      },
      {
        "epoch": 1880,
        "reward": 0.04029995575547218,
        "val_loss": 0.7428876417023795,
        "train_loss": 0.7585794971539424
      },
      {
        "epoch": 1881,
        "reward": 0.040523890405893326,
        "val_loss": 0.7343570334570748,
        "train_loss": 0.7199021405898608
      },
      {
        "epoch": 1882,
        "reward": 0.04056529700756073,
        "val_loss": 0.7327952768121447,
        "train_loss": 0.7312506781174586
      },
      {
        "epoch": 1883,
        "reward": 0.04007129743695259,
        "val_loss": 0.7517479530402592,
        "train_loss": 0.7550022189433758
      },
      {
        "epoch": 1884,
        "reward": 0.040270544588565826,
        "val_loss": 0.7440186398369926,
        "train_loss": 0.7285497601215656
      },
      {
        "epoch": 1885,
        "reward": 0.0402233861386776,
        "val_loss": 0.7458375181470599,
        "train_loss": 0.7672599714535934
      },
      {
        "epoch": 1886,
        "reward": 0.04060819000005722,
        "val_loss": 0.7311828051294599,
        "train_loss": 0.7220563441514969
      },
      {
        "epoch": 1887,
        "reward": 0.04038558900356293,
        "val_loss": 0.7396083857331958,
        "train_loss": 0.7707912898980654
      },
      {
        "epoch": 1888,
        "reward": 0.04039077088236809,
        "val_loss": 0.7394106388092041,
        "train_loss": 0.7556027953441327
      },
      {
        "epoch": 1889,
        "reward": 0.0404808484017849,
        "val_loss": 0.7359856537410191,
        "train_loss": 0.7765697172054877
      },
      {
        "epoch": 1890,
        "reward": 0.040240321308374405,
        "val_loss": 0.7451837744031634,
        "train_loss": 0.7630561315096341
      },
      {
        "epoch": 1891,
        "reward": 0.04035092890262604,
        "val_loss": 0.7409330947058541,
        "train_loss": 0.7172192060030423
      },
      {
        "epoch": 1892,
        "reward": 0.04028894007205963,
        "val_loss": 0.7433108176503863,
        "train_loss": 0.7546682197314042
      },
      {
        "epoch": 1893,
        "reward": 0.04010898619890213,
        "val_loss": 0.7502771190234593,
        "train_loss": 0.7415926364751962
      },
      {
        "epoch": 1894,
        "reward": 0.04030301794409752,
        "val_loss": 0.7427699140139988,
        "train_loss": 0.7783804742189554
      },
      {
        "epoch": 1895,
        "reward": 0.04041779413819313,
        "val_loss": 0.7383807471820286,
        "train_loss": 0.7375221710938674
      },
      {
        "epoch": 1896,
        "reward": 0.04023938253521919,
        "val_loss": 0.7452198565006256,
        "train_loss": 0.7324652901062598
      },
      {
        "epoch": 1897,
        "reward": 0.040216390043497086,
        "val_loss": 0.7461079912526267,
        "train_loss": 0.7776037041957562
      },
      {
        "epoch": 1898,
        "reward": 0.04041735455393791,
        "val_loss": 0.7383974066802433,
        "train_loss": 0.7077865848461022
      },
      {
        "epoch": 1899,
        "reward": 0.0405043326318264,
        "val_loss": 0.7350962885788509,
        "train_loss": 0.7247126721418821
      },
      {
        "epoch": 1900,
        "reward": 0.040551211684942245,
        "val_loss": 0.7333260817187173,
        "train_loss": 0.7630717421953495
      },
      {
        "epoch": 1901,
        "reward": 0.040301185101270676,
        "val_loss": 0.7428403922489711,
        "train_loss": 0.7312920254010421
      },
      {
        "epoch": 1902,
        "reward": 0.040281765162944794,
        "val_loss": 0.7435868382453918,
        "train_loss": 0.7205181305225079
      },
      {
        "epoch": 1903,
        "reward": 0.04019997641444206,
        "val_loss": 0.7467430106231144,
        "train_loss": 0.7079875347598528
      },
      {
        "epoch": 1904,
        "reward": 0.04019036889076233,
        "val_loss": 0.7471148669719696,
        "train_loss": 0.7446262951080616
      },
      {
        "epoch": 1905,
        "reward": 0.04019296169281006,
        "val_loss": 0.7470145140375409,
        "train_loss": 0.7282808514741751
      },
      {
        "epoch": 1906,
        "reward": 0.04019724205136299,
        "val_loss": 0.7468486768858773,
        "train_loss": 0.7142784108336155
      },
      {
        "epoch": 1907,
        "reward": 0.0405132882297039,
        "val_loss": 0.7347577554838998,
        "train_loss": 0.7840451437693375
      },
      {
        "epoch": 1908,
        "reward": 0.040216851979494095,
        "val_loss": 0.7460900843143463,
        "train_loss": 0.760884105012967
      },
      {
        "epoch": 1909,
        "reward": 0.040529217571020126,
        "val_loss": 0.7341559188706535,
        "train_loss": 0.7328373514688932
      },
      {
        "epoch": 1910,
        "reward": 0.040368810296058655,
        "val_loss": 0.7402493400233132,
        "train_loss": 0.7252957545793973
      },
      {
        "epoch": 1911,
        "reward": 0.04043222963809967,
        "val_loss": 0.7378313754286084,
        "train_loss": 0.7074098658676331
      },
      {
        "epoch": 1912,
        "reward": 0.04056619107723236,
        "val_loss": 0.7327617151396615,
        "train_loss": 0.7373384764561286
      },
      {
        "epoch": 1913,
        "reward": 0.04055740684270859,
        "val_loss": 0.7330926997320992,
        "train_loss": 0.7765249564097478
      },
      {
        "epoch": 1914,
        "reward": 0.040586747229099274,
        "val_loss": 0.7319883108139038,
        "train_loss": 0.7107111235650686
      },
      {
        "epoch": 1915,
        "reward": 0.04057122394442558,
        "val_loss": 0.7325721297945295,
        "train_loss": 0.7647241010115697
      },
      {
        "epoch": 1916,
        "reward": 0.04044903442263603,
        "val_loss": 0.7371927499771118,
        "train_loss": 0.7858633055136754
      },
      {
        "epoch": 1917,
        "reward": 0.040636416524648666,
        "val_loss": 0.7301243330751147,
        "train_loss": 0.7115674193661946
      },
      {
        "epoch": 1918,
        "reward": 0.04036039859056473,
        "val_loss": 0.7405710475785392,
        "train_loss": 0.716192914889409
      },
      {
        "epoch": 1919,
        "reward": 0.04016276076436043,
        "val_loss": 0.7481854472841535,
        "train_loss": 0.7309995270692385
      },
      {
        "epoch": 1920,
        "reward": 0.04047774896025658,
        "val_loss": 0.7361030110291072,
        "train_loss": 0.7463329365620246
      },
      {
        "epoch": 1921,
        "reward": 0.040494851768016815,
        "val_loss": 0.735455082995551,
        "train_loss": 0.7171412511513784
      },
      {
        "epoch": 1922,
        "reward": 0.040221672505140305,
        "val_loss": 0.7459037899971008,
        "train_loss": 0.7237143711401866
      },
      {
        "epoch": 1923,
        "reward": 0.040459197014570236,
        "val_loss": 0.7368065416812897,
        "train_loss": 0.711372437958534
      },
      {
        "epoch": 1924,
        "reward": 0.04030770808458328,
        "val_loss": 0.7425897462027413,
        "train_loss": 0.714086797948067
      },
      {
        "epoch": 1925,
        "reward": 0.04034397378563881,
        "val_loss": 0.7411993741989136,
        "train_loss": 0.7278765462912046
      },
      {
        "epoch": 1926,
        "reward": 0.040197502821683884,
        "val_loss": 0.7468386122158596,
        "train_loss": 0.7314201295375824
      },
      {
        "epoch": 1927,
        "reward": 0.04018242657184601,
        "val_loss": 0.7474226355552673,
        "train_loss": 0.7710664662031027
      },
      {
        "epoch": 1928,
        "reward": 0.040203846991062164,
        "val_loss": 0.7465930325644357,
        "train_loss": 0.7242529896589426
      },
      {
        "epoch": 1929,
        "reward": 0.0402575246989727,
        "val_loss": 0.7445201277732849,
        "train_loss": 0.7406821319690118
      },
      {
        "epoch": 1930,
        "reward": 0.04035426303744316,
        "val_loss": 0.740805617400578,
        "train_loss": 0.768492593215062
      },
      {
        "epoch": 1931,
        "reward": 0.04019041359424591,
        "val_loss": 0.7471132065568652,
        "train_loss": 0.790179037130796
      },
      {
        "epoch": 1932,
        "reward": 0.04026542976498604,
        "val_loss": 0.7442157098225185,
        "train_loss": 0.7587203864867871
      },
      {
        "epoch": 1933,
        "reward": 0.04045340418815613,
        "val_loss": 0.7370265764849526,
        "train_loss": 0.7412849848087018
      },
      {
        "epoch": 1934,
        "reward": 0.04042060673236847,
        "val_loss": 0.7382735865456718,
        "train_loss": 0.7542637357344995
      },
      {
        "epoch": 1935,
        "reward": 0.040285345166921616,
        "val_loss": 0.7434490663664681,
        "train_loss": 0.7211159249910941
      },
      {
        "epoch": 1936,
        "reward": 0.040239833295345306,
        "val_loss": 0.7452024902616229,
        "train_loss": 0.7452186277279487
      },
      {
        "epoch": 1937,
        "reward": 0.04028589278459549,
        "val_loss": 0.7434280514717102,
        "train_loss": 0.7760260449006007
      },
      {
        "epoch": 1938,
        "reward": 0.04026155173778534,
        "val_loss": 0.7443649300507137,
        "train_loss": 0.7215292201592372
      },
      {
        "epoch": 1939,
        "reward": 0.040364012122154236,
        "val_loss": 0.740432756287711,
        "train_loss": 0.7090240748455892
      },
      {
        "epoch": 1940,
        "reward": 0.040414005517959595,
        "val_loss": 0.7385250926017761,
        "train_loss": 0.7550872770639566
      },
      {
        "epoch": 1941,
        "reward": 0.04047840088605881,
        "val_loss": 0.7360783304486956,
        "train_loss": 0.7250447342028985
      },
      {
        "epoch": 1942,
        "reward": 0.04038802534341812,
        "val_loss": 0.7395154110022953,
        "train_loss": 0.7150142983748362
      },
      {
        "epoch": 1943,
        "reward": 0.04034625366330147,
        "val_loss": 0.7411120023046222,
        "train_loss": 0.7156635075807571
      },
      {
        "epoch": 1944,
        "reward": 0.04029037803411484,
        "val_loss": 0.7432555896895272,
        "train_loss": 0.7170183257414744
      },
      {
        "epoch": 1945,
        "reward": 0.04025343433022499,
        "val_loss": 0.7446778331484113,
        "train_loss": 0.7518114172495328
      },
      {
        "epoch": 1946,
        "reward": 0.040284253656864166,
        "val_loss": 0.7434913047722408,
        "train_loss": 0.7155678604657834
      },
      {
        "epoch": 1947,
        "reward": 0.04034455120563507,
        "val_loss": 0.7411772779056004,
        "train_loss": 0.7161087038425299
      },
      {
        "epoch": 1948,
        "reward": 0.04026805981993675,
        "val_loss": 0.7441141435078212,
        "train_loss": 0.7233328899511924
      },
      {
        "epoch": 1949,
        "reward": 0.04025138542056084,
        "val_loss": 0.744756919997079,
        "train_loss": 0.722147694000831
      },
      {
        "epoch": 1950,
        "reward": 0.04028984531760216,
        "val_loss": 0.7432759702205658,
        "train_loss": 0.7063544405122789
      },
      {
        "epoch": 1951,
        "reward": 0.040329709649086,
        "val_loss": 0.7417458551270621,
        "train_loss": 0.7992930091344393
      },
      {
        "epoch": 1952,
        "reward": 0.04032276198267937,
        "val_loss": 0.7420120877879006,
        "train_loss": 0.7997012665638557
      },
      {
        "epoch": 1953,
        "reward": 0.04031258821487427,
        "val_loss": 0.7424025109836033,
        "train_loss": 0.7187732114241674
      },
      {
        "epoch": 1954,
        "reward": 0.04045238345861435,
        "val_loss": 0.7370654046535492,
        "train_loss": 0.715577592070286
      },
      {
        "epoch": 1955,
        "reward": 0.040483228862285614,
        "val_loss": 0.7358953527041844,
        "train_loss": 0.7090276998396103
      },
      {
        "epoch": 1956,
        "reward": 0.040444839745759964,
        "val_loss": 0.7373520646776471,
        "train_loss": 0.7098429326254588
      },
      {
        "epoch": 1957,
        "reward": 0.040479015558958054,
        "val_loss": 0.7360550335475377,
        "train_loss": 0.7708172568908105
      },
      {
        "epoch": 1958,
        "reward": 0.04041927680373192,
        "val_loss": 0.7383242121764592,
        "train_loss": 0.7276458946558145
      },
      {
        "epoch": 1959,
        "reward": 0.04044334217905998,
        "val_loss": 0.7374088593891689,
        "train_loss": 0.7620496268455799
      },
      {
        "epoch": 1960,
        "reward": 0.040466465055942535,
        "val_loss": 0.7365309979234423,
        "train_loss": 0.772926940367772
      },
      {
        "epoch": 1961,
        "reward": 0.04043448716402054,
        "val_loss": 0.7377455489976066,
        "train_loss": 0.7124492589097756
      },
      {
        "epoch": 1962,
        "reward": 0.04043595492839813,
        "val_loss": 0.7376896483557565,
        "train_loss": 0.7231868436703315
      },
      {
        "epoch": 1963,
        "reward": 0.040460582822561264,
        "val_loss": 0.7367541534560067,
        "train_loss": 0.7467745817624606
      },
      {
        "epoch": 1964,
        "reward": 0.04041574150323868,
        "val_loss": 0.7384587611470904,
        "train_loss": 0.7591702869305244
      },
      {
        "epoch": 1965,
        "reward": 0.04045813903212547,
        "val_loss": 0.7368467918464116,
        "train_loss": 0.7675649638359363
      },
      {
        "epoch": 1966,
        "reward": 0.04045191407203674,
        "val_loss": 0.7370832306998116,
        "train_loss": 0.7343571713337531
      },
      {
        "epoch": 1967,
        "reward": 0.04040716215968132,
        "val_loss": 0.7387857522283282,
        "train_loss": 0.7243086924919715
      },
      {
        "epoch": 1968,
        "reward": 0.04041832312941551,
        "val_loss": 0.7383605326925006,
        "train_loss": 0.776869365802178
      },
      {
        "epoch": 1969,
        "reward": 0.040378641337156296,
        "val_loss": 0.7398738179888044,
        "train_loss": 0.7476018025324895
      },
      {
        "epoch": 1970,
        "reward": 0.040400780737400055,
        "val_loss": 0.7390288880893162,
        "train_loss": 0.709452933130356
      },
      {
        "epoch": 1971,
        "reward": 0.0403967909514904,
        "val_loss": 0.7391810161726815,
        "train_loss": 0.723489679969274
      },
      {
        "epoch": 1972,
        "reward": 0.04038984701037407,
        "val_loss": 0.7394458396094186,
        "train_loss": 0.7155283173689475
      },
      {
        "epoch": 1973,
        "reward": 0.04036373645067215,
        "val_loss": 0.740443195615496,
        "train_loss": 0.7085642361870179
      },
      {
        "epoch": 1974,
        "reward": 0.040338560938835144,
        "val_loss": 0.7414066238062722,
        "train_loss": 0.7498769049461071
      },
      {
        "epoch": 1975,
        "reward": 0.040338147431612015,
        "val_loss": 0.7414224658693586,
        "train_loss": 0.7451594792879545
      },
      {
        "epoch": 1976,
        "reward": 0.04034795984625816,
        "val_loss": 0.7410468288830349,
        "train_loss": 0.70580437935244
      },
      {
        "epoch": 1977,
        "reward": 0.04034539312124252,
        "val_loss": 0.7411450786249978,
        "train_loss": 0.7374527270977314
      },
      {
        "epoch": 1978,
        "reward": 0.040343061089515686,
        "val_loss": 0.7412342599460057,
        "train_loss": 0.7243311703205109
      },
      {
        "epoch": 1979,
        "reward": 0.040340594947338104,
        "val_loss": 0.7413286439010075,
        "train_loss": 0.7378661128190848
      },
      {
        "epoch": 1980,
        "reward": 0.04033661633729935,
        "val_loss": 0.7414812232766833,
        "train_loss": 0.7178072321873444
      },
      {
        "epoch": 1981,
        "reward": 0.04034152999520302,
        "val_loss": 0.741292940718787,
        "train_loss": 0.724093727194346
      },
      {
        "epoch": 1982,
        "reward": 0.04033637046813965,
        "val_loss": 0.7414905599185398,
        "train_loss": 0.786465083177273
      },
      {
        "epoch": 1983,
        "reward": 0.04034494608640671,
        "val_loss": 0.7411621553557259,
        "train_loss": 0.7130558209923598
      },
      {
        "epoch": 1984,
        "reward": 0.040351297706365585,
        "val_loss": 0.7409189598900932,
        "train_loss": 0.7483638456234565
      },
      {
        "epoch": 1985,
        "reward": 0.04035127907991409,
        "val_loss": 0.7409196623734066,
        "train_loss": 0.751864534157973
      },
      {
        "epoch": 1986,
        "reward": 0.040356338024139404,
        "val_loss": 0.7407262027263641,
        "train_loss": 0.7066849471571354
      },
      {
        "epoch": 1987,
        "reward": 0.04035802185535431,
        "val_loss": 0.7406616977282933,
        "train_loss": 0.7098700868395659
      },
      {
        "epoch": 1988,
        "reward": 0.040362175554037094,
        "val_loss": 0.7405030088765281,
        "train_loss": 0.7132132139343482
      },
      {
        "epoch": 1989,
        "reward": 0.04036511480808258,
        "val_loss": 0.7403904114450727,
        "train_loss": 0.7592498339139498
      },
      {
        "epoch": 1990,
        "reward": 0.04036944359540939,
        "val_loss": 0.7402250128132957,
        "train_loss": 0.7067374436614605
      },
      {
        "epoch": 1991,
        "reward": 0.04036809131503105,
        "val_loss": 0.7402766942977905,
        "train_loss": 0.7226115476626617
      },
      {
        "epoch": 1992,
        "reward": 0.0403670109808445,
        "val_loss": 0.7403180471488408,
        "train_loss": 0.708134547735636
      },
      {
        "epoch": 1993,
        "reward": 0.04036420211195946,
        "val_loss": 0.7404254121439797,
        "train_loss": 0.7279003973190601
      },
      {
        "epoch": 1994,
        "reward": 0.04036615416407585,
        "val_loss": 0.7403508254459926,
        "train_loss": 0.759657946916727
      },
      {
        "epoch": 1995,
        "reward": 0.04036588966846466,
        "val_loss": 0.7403609667505536,
        "train_loss": 0.7098170538934377
      },
      {
        "epoch": 1996,
        "reward": 0.0403657928109169,
        "val_loss": 0.7403645856039864,
        "train_loss": 0.7841974359292251
      },
      {
        "epoch": 1997,
        "reward": 0.040365587919950485,
        "val_loss": 0.7403725385665894,
        "train_loss": 0.7994687809393957
      },
      {
        "epoch": 1998,
        "reward": 0.040365446358919144,
        "val_loss": 0.7403778731822968,
        "train_loss": 0.7566516468158135
      },
      {
        "epoch": 1999,
        "reward": 0.04036540538072586,
        "val_loss": 0.7403794995376042,
        "train_loss": 0.7100197755946562
      }
    ]
  }
}