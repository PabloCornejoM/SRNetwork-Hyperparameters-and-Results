{
  "experiment_info": {
    "experiment_name": "Nguyen-4",
    "dataset_name": "Nguyen-4",
    "timestamp": "2025-08-30T19:45:41.715822",
    "random_seed": 42
  },
  "model_config": {
    "input_size": 1,
    "output_size": 1,
    "num_layers": 2,
    "nonlinear_info": [
      [
        6,
        0
      ],
      [
        0,
        0
      ],
      [
        0,
        0
      ]
    ],
    "function_set": [
      "SafeIdentityFunction",
      "SafeExp",
      "SafeLog",
      "SafeSin",
      "SafePower",
      "ExpSwitchActivation"
    ]
  },
  "training_config": {
    "num_epochs": 3000,
    "batch_size": 32,
    "learning_rate": 0.001,
    "reg_strength": 0.0,
    "scheduler": "none"
  },
  "final_equation": {
    "equation_string": "Matrix([[0.834248*x1**0.937422 + 1.27643*x1**1.91431 + 1.11974*x1**3.24094 + 0.948784*x1**4.1973 + 0.788629*x1**5.04728 + 1.03318*x1**5.99923]])",
    "equation_latex": "Matrix([[0.834248*x1**0.937422 + 1.27643*x1**1.91431 + 1.11974*x1**3.24094 + 0.948784*x1**4.1973 + 0.788629*x1**5.04728 + 1.03318*x1**5.99923]])"
  },
  "evaluation_metrics": {
    "mse": "1.007845e-06",
    "rmse": "0.0010039149",
    "mae": "0.000760921"
  },
  "data_info": {
    "train_ratio": 0.8,
    "uncertainty_value": 0.0,
    "path_to_data": "/Users/pablocornejo/Documents/Tesis/SRNetwork/data/raw/nguyen.txt"
  },
  "lbfgs_optimization": {
    "enabled": true,
    "success": true,
    "message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
    "function_evaluations": 15,
    "gradient_evaluations": 15,
    "final_loss": 0.0007795575010903021,
    "max_iterations": 1000,
    "tolerance": "1e-8",
    "criterion": "nrmse"
  },
  "lbfgs_topk_optimization": {
    "enabled": true,
    "num_models_optimized": 5,
    "optimization_summary": [
      {
        "rank": 1,
        "original_epoch": 2966,
        "original_val_loss": 0.008383572382237097,
        "optimized_val_loss": "1.007845e-06",
        "improvement_percent": "99.987976",
        "original_equation": "Matrix([[0.832635*x1**0.93575 + 1.27968*x1**1.91086 + 1.1194*x1**3.24038 + 0.948487*x1**4.19701 + 0.788381*x1**5.04711 + 1.0333*x1**5.99897]])",
        "optimized_equation": "Matrix([[0.834248*x1**0.937422 + 1.27643*x1**1.91431 + 1.11974*x1**3.24094 + 0.948784*x1**4.1973 + 0.788629*x1**5.04728 + 1.03318*x1**5.99923]])",
        "optimization_success": true,
        "function_evaluations": 15,
        "final_loss": 0.0007795575010903021
      },
      {
        "rank": 2,
        "original_epoch": 2917,
        "original_val_loss": 0.009502207343237907,
        "optimized_val_loss": "1.0350018e-06",
        "improvement_percent": "99.98911",
        "original_equation": "Matrix([[0.831883*x1**0.935647 + 1.27731*x1**1.90875 + 1.11887*x1**3.22969 + 0.949473*x1**4.20382 + 0.791771*x1**5.04849 + 1.03306*x1**5.9983]])",
        "optimized_equation": "Matrix([[0.833649*x1**0.937681 + 1.27392*x1**1.91162 + 1.11928*x1**3.23024 + 0.949644*x1**4.20409 + 0.791729*x1**5.04865 + 1.0322*x1**5.99855]])",
        "optimization_success": true,
        "function_evaluations": 15,
        "final_loss": 0.0007912233383505235
      },
      {
        "rank": 3,
        "original_epoch": 2995,
        "original_val_loss": 0.009039182709135016,
        "optimized_val_loss": "1.2014732e-06",
        "improvement_percent": "99.98671",
        "original_equation": "Matrix([[0.834732*x1**0.937986 + 1.28064*x1**1.91197 + 1.11877*x1**3.24472 + 0.94681*x1**4.1939 + 0.785743*x1**5.05051 + 1.03466*x1**6.0]])",
        "optimized_equation": "Matrix([[0.835833*x1**0.937964 + 1.2788*x1**1.91312 + 1.11851*x1**3.24494 + 0.946471*x1**4.19403 + 0.785363*x1**5.05061 + 1.03404*x1**6.0]])",
        "optimization_success": true,
        "function_evaluations": 13,
        "final_loss": 0.0008294236928819866
      },
      {
        "rank": 4,
        "original_epoch": 2843,
        "original_val_loss": 0.009776286327905837,
        "optimized_val_loss": "1.359825e-06",
        "improvement_percent": "99.98609",
        "original_equation": "Matrix([[0.828148*x1**0.935174 + 1.27399*x1**1.90788 + 1.11998*x1**3.2117 + 0.951938*x1**4.2091 + 0.796774*x1**5.04588 + 1.03093*x1**5.99985]])",
        "optimized_equation": "Matrix([[0.830214*x1**0.93478 + 1.2717*x1**1.90884 + 1.11956*x1**3.21186 + 0.951305*x1**4.20923 + 0.796025*x1**5.04599 + 1.02976*x1**6.0]])",
        "optimization_success": true,
        "function_evaluations": 12,
        "final_loss": 0.0008784515339039387
      },
      {
        "rank": 5,
        "original_epoch": 2989,
        "original_val_loss": 0.008453439992341114,
        "optimized_val_loss": "1.4497858e-06",
        "improvement_percent": "99.98285",
        "original_equation": "Matrix([[0.833686*x1**0.936812 + 1.28128*x1**1.91143 + 1.11896*x1**3.24535 + 0.9475*x1**4.19528 + 0.786642*x1**5.04997 + 1.03431*x1**5.99938]])",
        "optimized_equation": "Matrix([[0.835117*x1**0.936618 + 1.27901*x1**1.91234 + 1.1184*x1**3.24552 + 0.946777*x1**4.19542 + 0.785836*x1**5.05008 + 1.03315*x1**5.99955]])",
        "optimization_success": true,
        "function_evaluations": 13,
        "final_loss": 0.000944939801253183
      }
    ],
    "best_model": {
      "original_val_loss": 0.008383572382237097,
      "optimized_val_loss": "1.007845e-06",
      "improvement_percent": "99.987976",
      "equation": "Matrix([[0.834248*x1**0.937422 + 1.27643*x1**1.91431 + 1.11974*x1**3.24094 + 0.948784*x1**4.1973 + 0.788629*x1**5.04728 + 1.03318*x1**5.99923]])",
      "optimization_iterations": 7
    }
  },
  "reward_tracking": {
    "reward_type": "nrmse",
    "reward_interval": 1,
    "num_measurements": 3000,
    "initial_reward": 0.009999999776482582,
    "final_reward": 0.5984107851982117,
    "best_reward": 0.6361610293388367,
    "worst_reward": 0.009999999776482582,
    "average_reward": 0.3436314462125301,
    "reward_history": [
      {
        "epoch": 0,
        "reward": 0.009999999776482582,
        "val_loss": 1805.2685323442731,
        "train_loss": 10149.808578275717
      },
      {
        "epoch": 1,
        "reward": 0.009999999776482582,
        "val_loss": 1755.2105896132332,
        "train_loss": 38.86882057413459
      },
      {
        "epoch": 2,
        "reward": 0.009999999776482582,
        "val_loss": 1772.7090107372828,
        "train_loss": 364.9416605944817
      },
      {
        "epoch": 3,
        "reward": 0.009999999776482582,
        "val_loss": 1853.6510340145655,
        "train_loss": 1964.14995333581
      },
      {
        "epoch": 4,
        "reward": 0.009999999776482582,
        "val_loss": 1929.8236212730408,
        "train_loss": 83967.53739888364
      },
      {
        "epoch": 5,
        "reward": 0.009999999776482582,
        "val_loss": 1993.5464712551661,
        "train_loss": 55336.521258264926
      },
      {
        "epoch": 6,
        "reward": 0.009999999776482582,
        "val_loss": 2015.5821369034904,
        "train_loss": 315.0199755785557
      },
      {
        "epoch": 7,
        "reward": 0.009999999776482582,
        "val_loss": 2014.078883273261,
        "train_loss": 129.6976271283168
      },
      {
        "epoch": 8,
        "reward": 0.009999999776482582,
        "val_loss": 1942.5760656765528,
        "train_loss": 73.97765179265004
      },
      {
        "epoch": 9,
        "reward": 0.009999999776482582,
        "val_loss": 1831.3730346815926,
        "train_loss": 56.23976078701134
      },
      {
        "epoch": 10,
        "reward": 0.009999999776482582,
        "val_loss": 1766.4554405553001,
        "train_loss": 367.41352191911295
      },
      {
        "epoch": 11,
        "reward": 0.009999999776482582,
        "val_loss": 1711.999024936131,
        "train_loss": 23.698628743680622
      },
      {
        "epoch": 12,
        "reward": 0.009999999776482582,
        "val_loss": 1606.1408471039363,
        "train_loss": 456.96297039320837
      },
      {
        "epoch": 13,
        "reward": 0.009999999776482582,
        "val_loss": 1572.2260010923658,
        "train_loss": 210.56064679731543
      },
      {
        "epoch": 14,
        "reward": 0.009999999776482582,
        "val_loss": 1437.7292051996503,
        "train_loss": 2356.6091792914444
      },
      {
        "epoch": 15,
        "reward": 0.009999999776482582,
        "val_loss": 1327.2247250080109,
        "train_loss": 79.5106271694486
      },
      {
        "epoch": 16,
        "reward": 0.009999999776482582,
        "val_loss": 1248.5281574726105,
        "train_loss": 305.5251671442619
      },
      {
        "epoch": 17,
        "reward": 0.009999999776482582,
        "val_loss": 1159.0567022391729,
        "train_loss": 1306.6518817850604
      },
      {
        "epoch": 18,
        "reward": 0.009999999776482582,
        "val_loss": 1079.7797123704638,
        "train_loss": 43.38846471733772
      },
      {
        "epoch": 19,
        "reward": 0.009999999776482582,
        "val_loss": 968.1166171176093,
        "train_loss": 223.58595925985048
      },
      {
        "epoch": 20,
        "reward": 0.009999999776482582,
        "val_loss": 884.3602747406278,
        "train_loss": 29.79382384998294
      },
      {
        "epoch": 21,
        "reward": 0.009999999776482582,
        "val_loss": 808.8020728826523,
        "train_loss": 126.24820336527549
      },
      {
        "epoch": 22,
        "reward": 0.009999999776482582,
        "val_loss": 764.1794336523328,
        "train_loss": 27.552208624780178
      },
      {
        "epoch": 23,
        "reward": 0.009999999776482582,
        "val_loss": 699.4651171650205,
        "train_loss": 795.4151102350309
      },
      {
        "epoch": 24,
        "reward": 0.009999999776482582,
        "val_loss": 630.1954312665122,
        "train_loss": 285.86891498503974
      },
      {
        "epoch": 25,
        "reward": 0.009999999776482582,
        "val_loss": 592.4111815520695,
        "train_loss": 96.1718963467731
      },
      {
        "epoch": 26,
        "reward": 0.009999999776482582,
        "val_loss": 549.2636857713971,
        "train_loss": 27.14651287576327
      },
      {
        "epoch": 27,
        "reward": 0.009999999776482582,
        "val_loss": 501.67976430484225,
        "train_loss": 629.5379150842962
      },
      {
        "epoch": 28,
        "reward": 0.009999999776482582,
        "val_loss": 441.6414233446121,
        "train_loss": 13.740895357842628
      },
      {
        "epoch": 29,
        "reward": 0.009999999776482582,
        "val_loss": 397.9922525542123,
        "train_loss": 12.117519156720777
      },
      {
        "epoch": 30,
        "reward": 0.009999999776482582,
        "val_loss": 359.6440063714981,
        "train_loss": 65.69210985045021
      },
      {
        "epoch": 31,
        "reward": 0.009999999776482582,
        "val_loss": 332.253497847489,
        "train_loss": 404.5381257054038
      },
      {
        "epoch": 32,
        "reward": 0.009999999776482582,
        "val_loss": 309.27948957681656,
        "train_loss": 61.73274213356826
      },
      {
        "epoch": 33,
        "reward": 0.009999999776482582,
        "val_loss": 287.30594894715716,
        "train_loss": 7.66219427726733
      },
      {
        "epoch": 34,
        "reward": 0.009999999776482582,
        "val_loss": 262.80932730436325,
        "train_loss": 42.330648608004246
      },
      {
        "epoch": 35,
        "reward": 0.010124094784259796,
        "val_loss": 245.01568152223314,
        "train_loss": 8.764003640148216
      },
      {
        "epoch": 36,
        "reward": 0.010406452231109142,
        "val_loss": 231.76783361605234,
        "train_loss": 14.993466822681231
      },
      {
        "epoch": 37,
        "reward": 0.01073447521775961,
        "val_loss": 217.67524378640312,
        "train_loss": 10.077232112339585
      },
      {
        "epoch": 38,
        "reward": 0.010937835089862347,
        "val_loss": 209.57008244310106,
        "train_loss": 3359.3262316431096
      },
      {
        "epoch": 39,
        "reward": 0.011081934906542301,
        "val_loss": 204.09590831824713,
        "train_loss": 26.149607833689796
      },
      {
        "epoch": 40,
        "reward": 0.011307346634566784,
        "val_loss": 195.95036057489258,
        "train_loss": 357.90861647354006
      },
      {
        "epoch": 41,
        "reward": 0.011440400965511799,
        "val_loss": 191.3674596122333,
        "train_loss": 76.11263253844719
      },
      {
        "epoch": 42,
        "reward": 0.01207368727773428,
        "val_loss": 171.59876199279512,
        "train_loss": 7.474995910548246
      },
      {
        "epoch": 43,
        "reward": 0.012326322495937347,
        "val_loss": 164.5526031766619,
        "train_loss": 6.536135976346066
      },
      {
        "epoch": 44,
        "reward": 0.012246272526681423,
        "val_loss": 166.73791874306542,
        "train_loss": 43.725189256235566
      },
      {
        "epoch": 45,
        "reward": 0.01293241512030363,
        "val_loss": 149.30672501666206,
        "train_loss": 7.261525275911061
      },
      {
        "epoch": 46,
        "reward": 0.013076837174594402,
        "val_loss": 145.98428793890136,
        "train_loss": 229.4749405321916
      },
      {
        "epoch": 47,
        "reward": 0.013415890745818615,
        "val_loss": 138.60345057504517,
        "train_loss": 29.631259276479025
      },
      {
        "epoch": 48,
        "reward": 0.014104417525231838,
        "val_loss": 125.22656423704964,
        "train_loss": 4.818420621385974
      },
      {
        "epoch": 49,
        "reward": 0.013989361003041267,
        "val_loss": 127.32460124577794,
        "train_loss": 1.6599020017669177
      },
      {
        "epoch": 50,
        "reward": 0.015039975754916668,
        "val_loss": 109.92280709317752,
        "train_loss": 88.01076822209437
      },
      {
        "epoch": 51,
        "reward": 0.015338639728724957,
        "val_loss": 105.61971536917346,
        "train_loss": 13.812979537485052
      },
      {
        "epoch": 52,
        "reward": 0.017042135819792747,
        "val_loss": 85.2641859033278,
        "train_loss": 292.8824474514247
      },
      {
        "epoch": 53,
        "reward": 0.01761016808450222,
        "val_loss": 79.76007700817925,
        "train_loss": 624.3142152518004
      },
      {
        "epoch": 54,
        "reward": 0.019061526283621788,
        "val_loss": 67.87550127080509,
        "train_loss": 405.7615626849449
      },
      {
        "epoch": 55,
        "reward": 0.0201182272285223,
        "val_loss": 60.801307776144576,
        "train_loss": 8.042213437989211
      },
      {
        "epoch": 56,
        "reward": 0.021613704040646553,
        "val_loss": 52.51788769236633,
        "train_loss": 5.783843797380821
      },
      {
        "epoch": 57,
        "reward": 0.023034116253256798,
        "val_loss": 46.106325964842526,
        "train_loss": 2.4844842438514414
      },
      {
        "epoch": 58,
        "reward": 0.02514057233929634,
        "val_loss": 38.53706469706127,
        "train_loss": 43.2988168904916
      },
      {
        "epoch": 59,
        "reward": 0.02829102985560894,
        "val_loss": 30.235688785357134,
        "train_loss": 4.20359331873344
      },
      {
        "epoch": 60,
        "reward": 0.031120363622903824,
        "val_loss": 24.842497291309492,
        "train_loss": 4.379888194738529
      },
      {
        "epoch": 61,
        "reward": 0.03381536900997162,
        "val_loss": 20.92362174923931,
        "train_loss": 5.275802465400864
      },
      {
        "epoch": 62,
        "reward": 0.036224670708179474,
        "val_loss": 18.142105968935148,
        "train_loss": 2.9108559775452774
      },
      {
        "epoch": 63,
        "reward": 0.03888527676463127,
        "val_loss": 15.657593887831483,
        "train_loss": 0.7888284326674273
      },
      {
        "epoch": 64,
        "reward": 0.0416126511991024,
        "val_loss": 13.59490826513086,
        "train_loss": 2.1080614525036743
      },
      {
        "epoch": 65,
        "reward": 0.04412522539496422,
        "val_loss": 12.027434295309442,
        "train_loss": 6.705774532516863
      },
      {
        "epoch": 66,
        "reward": 0.045871373265981674,
        "val_loss": 11.08856428999986,
        "train_loss": 0.6383808889927772
      },
      {
        "epoch": 67,
        "reward": 0.04618803784251213,
        "val_loss": 10.929780315607786,
        "train_loss": 3.9136849737305264
      },
      {
        "epoch": 68,
        "reward": 0.04740706458687782,
        "val_loss": 10.348408579294171,
        "train_loss": 5.049772324739024
      },
      {
        "epoch": 69,
        "reward": 0.047425802797079086,
        "val_loss": 10.339824282165084,
        "train_loss": 5.836752570395429
      },
      {
        "epoch": 70,
        "reward": 0.04681830108165741,
        "val_loss": 10.623436648930822,
        "train_loss": 38.30457654208518
      },
      {
        "epoch": 71,
        "reward": 0.048764389008283615,
        "val_loss": 9.752491302256074,
        "train_loss": 107.35113017968476
      },
      {
        "epoch": 72,
        "reward": 0.04827651008963585,
        "val_loss": 9.960814105612892,
        "train_loss": 11.047694956579317
      },
      {
        "epoch": 73,
        "reward": 0.0470341257750988,
        "val_loss": 10.52139887825719,
        "train_loss": 1.9252848701211265
      },
      {
        "epoch": 74,
        "reward": 0.04545119032263756,
        "val_loss": 11.304482648681317,
        "train_loss": 8309.31511835774
      },
      {
        "epoch": 75,
        "reward": 0.04536185413599014,
        "val_loss": 11.351178220074091,
        "train_loss": 0.28456025614062896
      },
      {
        "epoch": 76,
        "reward": 0.04583101347088814,
        "val_loss": 11.109041461987156,
        "train_loss": 2.1393019668578814
      },
      {
        "epoch": 77,
        "reward": 0.049763426184654236,
        "val_loss": 9.345182066251125,
        "train_loss": 39.3222196820604
      },
      {
        "epoch": 78,
        "reward": 0.042963434010744095,
        "val_loss": 12.717566745355725,
        "train_loss": 11.916502330828315
      },
      {
        "epoch": 79,
        "reward": 0.04514101520180702,
        "val_loss": 11.467816579820854,
        "train_loss": 0.9538840935386431
      },
      {
        "epoch": 80,
        "reward": 0.04510125145316124,
        "val_loss": 11.489005499918546,
        "train_loss": 0.45636372064025355
      },
      {
        "epoch": 81,
        "reward": 0.048060640692710876,
        "val_loss": 10.055052861039128,
        "train_loss": 12.695109544089064
      },
      {
        "epoch": 82,
        "reward": 0.04867181181907654,
        "val_loss": 9.791530162096024,
        "train_loss": 4.584320442428669
      },
      {
        "epoch": 83,
        "reward": 0.04671534150838852,
        "val_loss": 10.672621131209391,
        "train_loss": 3.9832407141981934
      },
      {
        "epoch": 84,
        "reward": 0.04790589213371277,
        "val_loss": 10.123408114537597,
        "train_loss": 3.71422661966286
      },
      {
        "epoch": 85,
        "reward": 0.04956117272377014,
        "val_loss": 9.425624485792857,
        "train_loss": 2.383973537337554
      },
      {
        "epoch": 86,
        "reward": 0.04948326572775841,
        "val_loss": 9.456876644332494,
        "train_loss": 7.001260901604278
      },
      {
        "epoch": 87,
        "reward": 0.050764769315719604,
        "val_loss": 8.96122997733099,
        "train_loss": 2.0961093131694586
      },
      {
        "epoch": 88,
        "reward": 0.051342155784368515,
        "val_loss": 8.75015714019537,
        "train_loss": 0.1652271672635554
      },
      {
        "epoch": 89,
        "reward": 0.05374663695693016,
        "val_loss": 7.944328976795077,
        "train_loss": 0.897374520951976
      },
      {
        "epoch": 90,
        "reward": 0.05260133743286133,
        "val_loss": 8.314129724300333,
        "train_loss": 48.725752314104916
      },
      {
        "epoch": 91,
        "reward": 0.048864271491765976,
        "val_loss": 9.710620432559933,
        "train_loss": 91.18702412969637
      },
      {
        "epoch": 92,
        "reward": 0.051205556839704514,
        "val_loss": 8.79943803272077,
        "train_loss": 0.25624587890118933
      },
      {
        "epoch": 93,
        "reward": 0.05668335780501366,
        "val_loss": 7.098208757383483,
        "train_loss": 12272.069786927175
      },
      {
        "epoch": 94,
        "reward": 0.059377189725637436,
        "val_loss": 6.431860252948744,
        "train_loss": 2.6363755066100008
      },
      {
        "epoch": 95,
        "reward": 0.05994245409965515,
        "val_loss": 6.303542780290757,
        "train_loss": 0.6608575289383924
      },
      {
        "epoch": 96,
        "reward": 0.05844947695732117,
        "val_loss": 6.65075339323708,
        "train_loss": 8.223730702024813
      },
      {
        "epoch": 97,
        "reward": 0.05740564689040184,
        "val_loss": 6.910115189318146,
        "train_loss": 3.719709241717982
      },
      {
        "epoch": 98,
        "reward": 0.05725182220339775,
        "val_loss": 6.949564741658313,
        "train_loss": 0.7183917227577274
      },
      {
        "epoch": 99,
        "reward": 0.059815119951963425,
        "val_loss": 6.332122618997736,
        "train_loss": 0.10858892298822936
      },
      {
        "epoch": 100,
        "reward": 0.066737100481987,
        "val_loss": 5.01208257568734,
        "train_loss": 0.6353266009962402
      },
      {
        "epoch": 101,
        "reward": 0.05884378030896187,
        "val_loss": 6.556426391670747,
        "train_loss": 16.64297260624321
      },
      {
        "epoch": 102,
        "reward": 0.06701739132404327,
        "val_loss": 4.967260931618512,
        "train_loss": 0.21082735599842495
      },
      {
        "epoch": 103,
        "reward": 0.07243940979242325,
        "val_loss": 4.202227624399321,
        "train_loss": 189.25415232236713
      },
      {
        "epoch": 104,
        "reward": 0.06403414160013199,
        "val_loss": 5.475725300477019,
        "train_loss": 1.97420496147914
      },
      {
        "epoch": 105,
        "reward": 0.07123439013957977,
        "val_loss": 4.356900736024337,
        "train_loss": 0.41503354144067717
      },
      {
        "epoch": 106,
        "reward": 0.07525763660669327,
        "val_loss": 3.8697708742693067,
        "train_loss": 1.322543804452415
      },
      {
        "epoch": 107,
        "reward": 0.06951781362295151,
        "val_loss": 4.591650071819978,
        "train_loss": 43.32448059370598
      },
      {
        "epoch": 108,
        "reward": 0.07821522653102875,
        "val_loss": 3.5597648939916064,
        "train_loss": 5.529138905300583
      },
      {
        "epoch": 109,
        "reward": 0.08052671700716019,
        "val_loss": 3.341512734602605,
        "train_loss": 9.771758193994174
      },
      {
        "epoch": 110,
        "reward": 0.07759636640548706,
        "val_loss": 3.6216304786503315,
        "train_loss": 0.22846511727234778
      },
      {
        "epoch": 111,
        "reward": 0.07944108545780182,
        "val_loss": 3.441579045461757,
        "train_loss": 10.01754440442444
      },
      {
        "epoch": 112,
        "reward": 0.08213132619857788,
        "val_loss": 3.2010188241090094,
        "train_loss": 3.9337317658668884
      },
      {
        "epoch": 113,
        "reward": 0.0871637687087059,
        "val_loss": 2.8109854121825526,
        "train_loss": 0.6111194160408698
      },
      {
        "epoch": 114,
        "reward": 0.07278436422348022,
        "val_loss": 4.1593950733409395,
        "train_loss": 2.1080351129998096
      },
      {
        "epoch": 115,
        "reward": 0.08977284282445908,
        "val_loss": 2.634841682921563,
        "train_loss": 1.9725055626700991
      },
      {
        "epoch": 116,
        "reward": 0.08119677007198334,
        "val_loss": 3.281801989302039,
        "train_loss": 8.096193568557142
      },
      {
        "epoch": 117,
        "reward": 0.09615351259708405,
        "val_loss": 2.264664995484054,
        "train_loss": 0.3554894079391558
      },
      {
        "epoch": 118,
        "reward": 0.09292245656251907,
        "val_loss": 2.4422624948035394,
        "train_loss": 0.5987860040443663
      },
      {
        "epoch": 119,
        "reward": 0.09971043467521667,
        "val_loss": 2.0894314139815315,
        "train_loss": 0.460601430422125
      },
      {
        "epoch": 120,
        "reward": 0.09854578226804733,
        "val_loss": 2.1446487274287,
        "train_loss": 3.250432440966296
      },
      {
        "epoch": 121,
        "reward": 0.09547164291143417,
        "val_loss": 2.300596596939223,
        "train_loss": 1.550437416621627
      },
      {
        "epoch": 122,
        "reward": 0.10789060592651367,
        "val_loss": 1.7523216815399272,
        "train_loss": 0.2948586854438942
      },
      {
        "epoch": 123,
        "reward": 0.11112856864929199,
        "val_loss": 1.639726218501372,
        "train_loss": 1.015500441668197
      },
      {
        "epoch": 124,
        "reward": 0.10739560425281525,
        "val_loss": 1.770475035732878,
        "train_loss": 0.21159622201230377
      },
      {
        "epoch": 125,
        "reward": 0.10037516802549362,
        "val_loss": 2.058804730618639,
        "train_loss": 0.046253055826617546
      },
      {
        "epoch": 126,
        "reward": 0.11325012892484665,
        "val_loss": 1.571338303586734,
        "train_loss": 232.9959402892094
      },
      {
        "epoch": 127,
        "reward": 0.11705084890127182,
        "val_loss": 1.4583678118485426,
        "train_loss": 3.3229766723055105
      },
      {
        "epoch": 128,
        "reward": 0.11774089187383652,
        "val_loss": 1.439071826370699,
        "train_loss": 0.4083610749266182
      },
      {
        "epoch": 129,
        "reward": 0.11863230913877487,
        "val_loss": 1.4146637214081628,
        "train_loss": 0.0950148224633617
      },
      {
        "epoch": 130,
        "reward": 0.10513506084680557,
        "val_loss": 1.856797839182296,
        "train_loss": 1.1528416363020928
      },
      {
        "epoch": 131,
        "reward": 0.12077390402555466,
        "val_loss": 1.3583127606127943,
        "train_loss": 0.44389930894472995
      },
      {
        "epoch": 132,
        "reward": 0.11795705556869507,
        "val_loss": 1.4330997608069862,
        "train_loss": 0.17924479060233212
      },
      {
        "epoch": 133,
        "reward": 0.12027230113744736,
        "val_loss": 1.3712292185186274,
        "train_loss": 0.045567889214278415
      },
      {
        "epoch": 134,
        "reward": 0.12303303927183151,
        "val_loss": 1.3021701663466436,
        "train_loss": 0.12251764968879378
      },
      {
        "epoch": 135,
        "reward": 0.12365233153104782,
        "val_loss": 1.2873395225033164,
        "train_loss": 1.1339418563830594
      },
      {
        "epoch": 136,
        "reward": 0.12467845529317856,
        "val_loss": 1.2632730526716582,
        "train_loss": 2.340486308656042
      },
      {
        "epoch": 137,
        "reward": 0.12449641525745392,
        "val_loss": 1.267497313341924,
        "train_loss": 0.04644458736248243
      },
      {
        "epoch": 138,
        "reward": 0.12504133582115173,
        "val_loss": 1.2549107112655682,
        "train_loss": 0.07657617662334815
      },
      {
        "epoch": 139,
        "reward": 0.11832775175571442,
        "val_loss": 1.422937964488353,
        "train_loss": 0.21421165333595127
      },
      {
        "epoch": 140,
        "reward": 0.11536204069852829,
        "val_loss": 1.5071278717368841,
        "train_loss": 0.20894286194995332
      },
      {
        "epoch": 141,
        "reward": 0.12118138372898102,
        "val_loss": 1.3479432498237915,
        "train_loss": 0.13805778622218684
      },
      {
        "epoch": 142,
        "reward": 0.11390896886587143,
        "val_loss": 1.5509067574249846,
        "train_loss": 14.73770068952581
      },
      {
        "epoch": 143,
        "reward": 0.11250549554824829,
        "val_loss": 1.5948824134123112,
        "train_loss": 0.5574814598020077
      },
      {
        "epoch": 144,
        "reward": 0.11590100824832916,
        "val_loss": 1.4913246977542127,
        "train_loss": 0.06399900973953593
      },
      {
        "epoch": 145,
        "reward": 0.11476688832044601,
        "val_loss": 1.5248494394389647,
        "train_loss": 0.34023186332062605
      },
      {
        "epoch": 146,
        "reward": 0.12691357731819153,
        "val_loss": 1.212951042689383,
        "train_loss": 0.1452092907498949
      },
      {
        "epoch": 147,
        "reward": 0.09847524017095566,
        "val_loss": 2.1480588629575714,
        "train_loss": 0.05427798755296793
      },
      {
        "epoch": 148,
        "reward": 0.11820279806852341,
        "val_loss": 1.4263520261405833,
        "train_loss": 2.2082183001016698
      },
      {
        "epoch": 149,
        "reward": 0.11336427927017212,
        "val_loss": 1.567771612267409,
        "train_loss": 0.10037765576942967
      },
      {
        "epoch": 150,
        "reward": 0.10032391548156738,
        "val_loss": 2.0611436681688895,
        "train_loss": 0.6629879668202753
      },
      {
        "epoch": 151,
        "reward": 0.11120537668466568,
        "val_loss": 1.6371791643489684,
        "train_loss": 2.12767630270145
      },
      {
        "epoch": 152,
        "reward": 0.11192519962787628,
        "val_loss": 1.6135713380561876,
        "train_loss": 0.5037199476993499
      },
      {
        "epoch": 153,
        "reward": 0.10978882759809494,
        "val_loss": 1.6850575617780643,
        "train_loss": 0.5571978312979738
      },
      {
        "epoch": 154,
        "reward": 0.10539659112691879,
        "val_loss": 1.8465149476458984,
        "train_loss": 0.25260131608676883
      },
      {
        "epoch": 155,
        "reward": 0.10776541382074356,
        "val_loss": 1.7568886010641498,
        "train_loss": 0.031193445512774184
      },
      {
        "epoch": 156,
        "reward": 0.10058518499135971,
        "val_loss": 2.049259510223887,
        "train_loss": 0.16867415215417098
      },
      {
        "epoch": 157,
        "reward": 0.11148321628570557,
        "val_loss": 1.6280100830231927,
        "train_loss": 0.1605252324281117
      },
      {
        "epoch": 158,
        "reward": 0.10529395192861557,
        "val_loss": 1.8505408925536488,
        "train_loss": 1.6764202958572871
      },
      {
        "epoch": 159,
        "reward": 0.10900725424289703,
        "val_loss": 1.7123099224908012,
        "train_loss": 0.22584812644457158
      },
      {
        "epoch": 160,
        "reward": 0.11373960971832275,
        "val_loss": 1.5561235109344125,
        "train_loss": 0.07907839869865431
      },
      {
        "epoch": 161,
        "reward": 0.10437808185815811,
        "val_loss": 1.8870162513838815,
        "train_loss": 0.0912836596611529
      },
      {
        "epoch": 162,
        "reward": 0.09814412891864777,
        "val_loss": 2.1641659460895295,
        "train_loss": 0.4459851752169645
      },
      {
        "epoch": 163,
        "reward": 0.10337052494287491,
        "val_loss": 1.928312395233661,
        "train_loss": 0.19095852454372036
      },
      {
        "epoch": 164,
        "reward": 0.10730145126581192,
        "val_loss": 1.7739579565823078,
        "train_loss": 27.640749007423157
      },
      {
        "epoch": 165,
        "reward": 0.10523517429828644,
        "val_loss": 1.8528520143923484,
        "train_loss": 0.9382942062377249
      },
      {
        "epoch": 166,
        "reward": 0.10904295742511749,
        "val_loss": 1.711051686167983,
        "train_loss": 5.416169146370241
      },
      {
        "epoch": 167,
        "reward": 0.10089349001646042,
        "val_loss": 2.0353583897730068,
        "train_loss": 0.154820659233687
      },
      {
        "epoch": 168,
        "reward": 0.10446646064519882,
        "val_loss": 1.8834532801993191,
        "train_loss": 0.15094608568716256
      },
      {
        "epoch": 169,
        "reward": 0.09725967794656754,
        "val_loss": 2.2080298691123192,
        "train_loss": 0.3538361261912192
      },
      {
        "epoch": 170,
        "reward": 0.10108349472284317,
        "val_loss": 2.0268567435642972,
        "train_loss": 0.24622984777222603
      },
      {
        "epoch": 171,
        "reward": 0.09229674190282822,
        "val_loss": 2.4789050991779993,
        "train_loss": 0.0416999283255651
      },
      {
        "epoch": 172,
        "reward": 0.09160737693309784,
        "val_loss": 2.5201776071252033,
        "train_loss": 0.30665315107146923
      },
      {
        "epoch": 173,
        "reward": 0.10183890908956528,
        "val_loss": 1.9935439439889575,
        "train_loss": 0.26181354297575754
      },
      {
        "epoch": 174,
        "reward": 0.1093958243727684,
        "val_loss": 1.6986849442057843,
        "train_loss": 1.0218193774030975
      },
      {
        "epoch": 175,
        "reward": 0.10842647403478622,
        "val_loss": 1.732959899452648,
        "train_loss": 0.16631911372622618
      },
      {
        "epoch": 176,
        "reward": 0.09441295266151428,
        "val_loss": 2.3579911365107233,
        "train_loss": 0.029833532942575403
      },
      {
        "epoch": 177,
        "reward": 0.10368653386831284,
        "val_loss": 1.9152259336385344,
        "train_loss": 3.1604127624196163
      },
      {
        "epoch": 178,
        "reward": 0.09459507465362549,
        "val_loss": 2.347975420067087,
        "train_loss": 0.025663212024553034
      },
      {
        "epoch": 179,
        "reward": 0.09981757402420044,
        "val_loss": 2.0844525038929924,
        "train_loss": 0.16040314491748667
      },
      {
        "epoch": 180,
        "reward": 0.11341642588376999,
        "val_loss": 1.5661464457932328,
        "train_loss": 0.23925633035385266
      },
      {
        "epoch": 181,
        "reward": 0.10810748487710953,
        "val_loss": 1.7444492927752435,
        "train_loss": 0.14677674683312383
      },
      {
        "epoch": 182,
        "reward": 0.08607696741819382,
        "val_loss": 2.8892839033422724,
        "train_loss": 0.13725943388103937
      },
      {
        "epoch": 183,
        "reward": 0.09510938078165054,
        "val_loss": 2.3200130102756833,
        "train_loss": 17.154922906756
      },
      {
        "epoch": 184,
        "reward": 0.10092151165008545,
        "val_loss": 2.0341007971603955,
        "train_loss": 0.6618879979247979
      },
      {
        "epoch": 185,
        "reward": 0.10764125734567642,
        "val_loss": 1.7614336011133023,
        "train_loss": 0.13897359465660813
      },
      {
        "epoch": 186,
        "reward": 0.1058543249964714,
        "val_loss": 1.828707231208682,
        "train_loss": 0.5704468031792482
      },
      {
        "epoch": 187,
        "reward": 0.10004857927560806,
        "val_loss": 2.073772569652647,
        "train_loss": 0.9242776395806757
      },
      {
        "epoch": 188,
        "reward": 0.08595951646566391,
        "val_loss": 2.897929232966687,
        "train_loss": 0.07381670092581771
      },
      {
        "epoch": 189,
        "reward": 0.08233364671468735,
        "val_loss": 3.1839024829013005,
        "train_loss": 0.04745885110102021
      },
      {
        "epoch": 190,
        "reward": 0.0926000326871872,
        "val_loss": 2.4610486701130867,
        "train_loss": 0.27428761232071197
      },
      {
        "epoch": 191,
        "reward": 0.09313050657510757,
        "val_loss": 2.430247689364478,
        "train_loss": 12.13962665024715
      },
      {
        "epoch": 192,
        "reward": 0.08732950687408447,
        "val_loss": 2.7993088531241352,
        "train_loss": 0.1783605110652458
      },
      {
        "epoch": 193,
        "reward": 0.10528796166181564,
        "val_loss": 1.8507767032299722,
        "train_loss": 1.803196043709669
      },
      {
        "epoch": 194,
        "reward": 0.1078699454665184,
        "val_loss": 1.7530740576663189,
        "train_loss": 0.06389386986847967
      },
      {
        "epoch": 195,
        "reward": 0.11110232025384903,
        "val_loss": 1.6405980378788496,
        "train_loss": 0.582023030651796
      },
      {
        "epoch": 196,
        "reward": 0.10937662422657013,
        "val_loss": 1.6993543741160206,
        "train_loss": 0.12975759944618823
      },
      {
        "epoch": 197,
        "reward": 0.1009138971567154,
        "val_loss": 2.034443173624043,
        "train_loss": 396.72384846840356
      },
      {
        "epoch": 198,
        "reward": 0.11142822355031967,
        "val_loss": 1.6298189340491913,
        "train_loss": 1.8646125581290107
      },
      {
        "epoch": 199,
        "reward": 0.09621585160493851,
        "val_loss": 2.261419263003128,
        "train_loss": 0.034793997440829116
      },
      {
        "epoch": 200,
        "reward": 0.09724833816289902,
        "val_loss": 2.208600358538596,
        "train_loss": 0.7643860846829529
      },
      {
        "epoch": 201,
        "reward": 0.10697058588266373,
        "val_loss": 1.7862719058923955,
        "train_loss": 0.28122301823280466
      },
      {
        "epoch": 202,
        "reward": 0.10485146194696426,
        "val_loss": 1.868039516698835,
        "train_loss": 0.5000055969934553
      },
      {
        "epoch": 203,
        "reward": 0.10031671822071075,
        "val_loss": 2.0614725606116866,
        "train_loss": 0.22207991622473436
      },
      {
        "epoch": 204,
        "reward": 0.10058503597974777,
        "val_loss": 2.0492664028092156,
        "train_loss": 0.05575017307105904
      },
      {
        "epoch": 205,
        "reward": 0.08804023265838623,
        "val_loss": 2.750007211895926,
        "train_loss": 0.1542841280103088
      },
      {
        "epoch": 206,
        "reward": 0.09745044261217117,
        "val_loss": 2.198464206020747,
        "train_loss": 0.39143598809963664
      },
      {
        "epoch": 207,
        "reward": 0.10049263387918472,
        "val_loss": 2.053458205424249,
        "train_loss": 0.06430096786621456
      },
      {
        "epoch": 208,
        "reward": 0.10716064274311066,
        "val_loss": 1.7791840661915816,
        "train_loss": 0.10684729542565317
      },
      {
        "epoch": 209,
        "reward": 0.10278824716806412,
        "val_loss": 1.9527552873561425,
        "train_loss": 21.592423697029098
      },
      {
        "epoch": 210,
        "reward": 0.10478448122739792,
        "val_loss": 1.8707087629674268,
        "train_loss": 0.7627612189725579
      },
      {
        "epoch": 211,
        "reward": 0.113929383456707,
        "val_loss": 1.5502795948247825,
        "train_loss": 1.0857221096308562
      },
      {
        "epoch": 212,
        "reward": 0.10076379776000977,
        "val_loss": 2.041189666471577,
        "train_loss": 0.2361744393263227
      },
      {
        "epoch": 213,
        "reward": 0.10121779888868332,
        "val_loss": 2.020877543703786,
        "train_loss": 0.3439943085720118
      },
      {
        "epoch": 214,
        "reward": 0.0997990295290947,
        "val_loss": 2.0853128326790675,
        "train_loss": 0.05895749271215978
      },
      {
        "epoch": 215,
        "reward": 0.0959550142288208,
        "val_loss": 2.2750426668873325,
        "train_loss": 0.24816361507020282
      },
      {
        "epoch": 216,
        "reward": 0.10512874275445938,
        "val_loss": 1.8570478200979,
        "train_loss": 5.583505863506266
      },
      {
        "epoch": 217,
        "reward": 0.1106657162308693,
        "val_loss": 1.6551931624832963,
        "train_loss": 0.41540448842211986
      },
      {
        "epoch": 218,
        "reward": 0.11778565496206284,
        "val_loss": 1.4378322951961309,
        "train_loss": 0.059802520650779255
      },
      {
        "epoch": 219,
        "reward": 0.10531474649906158,
        "val_loss": 1.849724537892533,
        "train_loss": 4.058677176362835
      },
      {
        "epoch": 220,
        "reward": 0.09778834879398346,
        "val_loss": 2.181662400519209,
        "train_loss": 25.163224920871123
      },
      {
        "epoch": 221,
        "reward": 0.10032414644956589,
        "val_loss": 2.0611334196291864,
        "train_loss": 0.025431288954748128
      },
      {
        "epoch": 222,
        "reward": 0.10480965673923492,
        "val_loss": 1.8697047723191125,
        "train_loss": 0.05910752101492388
      },
      {
        "epoch": 223,
        "reward": 0.0931515172123909,
        "val_loss": 2.429038952769978,
        "train_loss": 0.08030068586678961
      },
      {
        "epoch": 224,
        "reward": 0.07836394011974335,
        "val_loss": 3.545122764040051,
        "train_loss": 1.8417260106205224
      },
      {
        "epoch": 225,
        "reward": 0.10700096935033798,
        "val_loss": 1.7851360990067147,
        "train_loss": 0.10238431799762811
      },
      {
        "epoch": 226,
        "reward": 0.12170831114053726,
        "val_loss": 1.3346944600343704,
        "train_loss": 0.021793030477755774
      },
      {
        "epoch": 227,
        "reward": 0.09913493692874908,
        "val_loss": 2.116464198533712,
        "train_loss": 1.1954111103427398
      },
      {
        "epoch": 228,
        "reward": 0.08988822251558304,
        "val_loss": 2.627415772959856,
        "train_loss": 0.23701091203838587
      },
      {
        "epoch": 229,
        "reward": 0.1099894642829895,
        "val_loss": 1.6781581418056573,
        "train_loss": 0.3469100763434723
      },
      {
        "epoch": 230,
        "reward": 0.10622043907642365,
        "val_loss": 1.8146356408085142,
        "train_loss": 0.01812755693166624
      },
      {
        "epoch": 231,
        "reward": 0.11154872179031372,
        "val_loss": 1.6258591621049814,
        "train_loss": 0.10279755831512515
      },
      {
        "epoch": 232,
        "reward": 0.0907173603773117,
        "val_loss": 2.574908646921228,
        "train_loss": 0.0686584267174252
      },
      {
        "epoch": 233,
        "reward": 0.11789067089557648,
        "val_loss": 1.4349305863891328,
        "train_loss": 0.02895126371004153
      },
      {
        "epoch": 234,
        "reward": 0.11311545222997665,
        "val_loss": 1.5755607238305467,
        "train_loss": 0.052456312130201556
      },
      {
        "epoch": 235,
        "reward": 0.09893374890089035,
        "val_loss": 2.126029912681718,
        "train_loss": 0.25079913369252327
      },
      {
        "epoch": 236,
        "reward": 0.11409691721200943,
        "val_loss": 1.5451457516755909,
        "train_loss": 0.7497472709891064
      },
      {
        "epoch": 237,
        "reward": 0.10261555016040802,
        "val_loss": 1.9600879125563162,
        "train_loss": 1.6114579309919814
      },
      {
        "epoch": 238,
        "reward": 0.10693524032831192,
        "val_loss": 1.7875947364872056,
        "train_loss": 0.02210999197156455
      },
      {
        "epoch": 239,
        "reward": 0.13153110444545746,
        "val_loss": 1.1173688467991139,
        "train_loss": 2.372502580262685
      },
      {
        "epoch": 240,
        "reward": 0.1006171703338623,
        "val_loss": 2.0478109158575535,
        "train_loss": 0.4036081013999557
      },
      {
        "epoch": 241,
        "reward": 0.09414268285036087,
        "val_loss": 2.3729653317547803,
        "train_loss": 0.1794018103873196
      },
      {
        "epoch": 242,
        "reward": 0.10254881531000137,
        "val_loss": 1.9629318280411618,
        "train_loss": 33.63185817509657
      },
      {
        "epoch": 243,
        "reward": 0.11800792068243027,
        "val_loss": 1.4316995144389304,
        "train_loss": 0.14841214154708163
      },
      {
        "epoch": 244,
        "reward": 0.09720980376005173,
        "val_loss": 2.210540261751573,
        "train_loss": 0.03595528299047146
      },
      {
        "epoch": 245,
        "reward": 0.11161357164382935,
        "val_loss": 1.6237330712444549,
        "train_loss": 0.3246140980224412
      },
      {
        "epoch": 246,
        "reward": 0.10870122909545898,
        "val_loss": 1.7231480235100858,
        "train_loss": 0.05207335272839723
      },
      {
        "epoch": 247,
        "reward": 0.11222628504037857,
        "val_loss": 1.6038370154066277,
        "train_loss": 0.3534364163575586
      },
      {
        "epoch": 248,
        "reward": 0.12360518425703049,
        "val_loss": 1.2884603680244513,
        "train_loss": 9.966113538317867
      },
      {
        "epoch": 249,
        "reward": 0.11486520618200302,
        "val_loss": 1.5219018400114561,
        "train_loss": 0.3126264215232088
      },
      {
        "epoch": 250,
        "reward": 0.10590654611587524,
        "val_loss": 1.826690790509539,
        "train_loss": 0.07223658712441997
      },
      {
        "epoch": 251,
        "reward": 0.13047991693019867,
        "val_loss": 1.138195333703022,
        "train_loss": 0.2072807022867402
      },
      {
        "epoch": 252,
        "reward": 0.09280180186033249,
        "val_loss": 2.4492683058405027,
        "train_loss": 5.590110967099183
      },
      {
        "epoch": 253,
        "reward": 0.1097671166062355,
        "val_loss": 1.6858061120313192,
        "train_loss": 0.17621463728853717
      },
      {
        "epoch": 254,
        "reward": 0.10610156506299973,
        "val_loss": 1.8191883035802416,
        "train_loss": 0.02442667565684622
      },
      {
        "epoch": 255,
        "reward": 0.1088673397898674,
        "val_loss": 1.7172532668669842,
        "train_loss": 0.20339945435094145
      },
      {
        "epoch": 256,
        "reward": 0.13557355105876923,
        "val_loss": 1.041959718468466,
        "train_loss": 0.3141702486061079
      },
      {
        "epoch": 257,
        "reward": 0.1056285873055458,
        "val_loss": 1.8374593272539121,
        "train_loss": 1165.1878166940644
      },
      {
        "epoch": 258,
        "reward": 0.10528043657541275,
        "val_loss": 1.8510725981821972,
        "train_loss": 0.18667585820255156
      },
      {
        "epoch": 259,
        "reward": 0.09362967312335968,
        "val_loss": 2.4017581785862734,
        "train_loss": 5.635043900986113
      },
      {
        "epoch": 260,
        "reward": 0.12188933044672012,
        "val_loss": 1.3301844206705158,
        "train_loss": 0.12140970106030671
      },
      {
        "epoch": 261,
        "reward": 0.10547041147947311,
        "val_loss": 1.8436269804369658,
        "train_loss": 4.051454669726529
      },
      {
        "epoch": 262,
        "reward": 0.11728668212890625,
        "val_loss": 1.4517332331077861,
        "train_loss": 0.26592030296720065
      },
      {
        "epoch": 263,
        "reward": 0.12499922513961792,
        "val_loss": 1.2558769484749064,
        "train_loss": 100.36911181407274
      },
      {
        "epoch": 264,
        "reward": 0.1129496619105339,
        "val_loss": 1.5807806747034192,
        "train_loss": 1.0106823010137305
      },
      {
        "epoch": 265,
        "reward": 0.12601636350154877,
        "val_loss": 1.2328139866003767,
        "train_loss": 0.5661724459518714
      },
      {
        "epoch": 266,
        "reward": 0.11015546321868896,
        "val_loss": 1.672480595880188,
        "train_loss": 0.025740617844768658
      },
      {
        "epoch": 267,
        "reward": 0.12965448200702667,
        "val_loss": 1.1549235861748457,
        "train_loss": 0.13850834406912327
      },
      {
        "epoch": 268,
        "reward": 0.10989063233137131,
        "val_loss": 1.6815520747165595,
        "train_loss": 0.5514616020943952
      },
      {
        "epoch": 269,
        "reward": 0.11048176139593124,
        "val_loss": 1.6613965184328012,
        "train_loss": 0.02409916412524091
      },
      {
        "epoch": 270,
        "reward": 0.13354778289794922,
        "val_loss": 1.0788491104197289,
        "train_loss": 1.5128591622241612
      },
      {
        "epoch": 271,
        "reward": 0.11698993295431137,
        "val_loss": 1.46008819504641,
        "train_loss": 1457.9488029044699
      },
      {
        "epoch": 272,
        "reward": 0.1210101991891861,
        "val_loss": 1.352286018331402,
        "train_loss": 0.046681068698839784
      },
      {
        "epoch": 273,
        "reward": 0.11565815657377243,
        "val_loss": 1.4984170491141933,
        "train_loss": 0.17846611986841218
      },
      {
        "epoch": 274,
        "reward": 0.12481744587421417,
        "val_loss": 1.26006127069039,
        "train_loss": 0.027571613037322935
      },
      {
        "epoch": 275,
        "reward": 0.1282690018415451,
        "val_loss": 1.183767664046692,
        "train_loss": 0.04480004083877877
      },
      {
        "epoch": 276,
        "reward": 0.1358685940504074,
        "val_loss": 1.036731498482238,
        "train_loss": 0.8756633930651543
      },
      {
        "epoch": 277,
        "reward": 0.1285271942615509,
        "val_loss": 1.1783181312660287,
        "train_loss": 17.476011292068645
      },
      {
        "epoch": 278,
        "reward": 0.12241607904434204,
        "val_loss": 1.3171799797232129,
        "train_loss": 0.20642264754412912
      },
      {
        "epoch": 279,
        "reward": 0.11998913437128067,
        "val_loss": 1.3785962859068863,
        "train_loss": 0.18307382531426042
      },
      {
        "epoch": 280,
        "reward": 0.1398269534111023,
        "val_loss": 0.9699172282125801,
        "train_loss": 0.10148925909015816
      },
      {
        "epoch": 281,
        "reward": 0.1278744786977768,
        "val_loss": 1.19216158404015,
        "train_loss": 1.5573119174939796
      },
      {
        "epoch": 282,
        "reward": 0.13376544415950775,
        "val_loss": 1.0748009426086875,
        "train_loss": 0.13352294682408683
      },
      {
        "epoch": 283,
        "reward": 0.14209772646427155,
        "val_loss": 0.9342135523911566,
        "train_loss": 0.33290865532762837
      },
      {
        "epoch": 284,
        "reward": 0.12101127207279205,
        "val_loss": 1.352258969896606,
        "train_loss": 0.26846972124006313
      },
      {
        "epoch": 285,
        "reward": 0.1186213418841362,
        "val_loss": 1.4149605274599577,
        "train_loss": 0.04169662359345239
      },
      {
        "epoch": 286,
        "reward": 0.11073799431324005,
        "val_loss": 1.6527647694373238,
        "train_loss": 0.07952514000331015
      },
      {
        "epoch": 287,
        "reward": 0.11691685020923615,
        "val_loss": 1.462156429753772,
        "train_loss": 0.42771762430381316
      },
      {
        "epoch": 288,
        "reward": 0.14341503381729126,
        "val_loss": 0.9143159707808601,
        "train_loss": 0.14429560221525697
      },
      {
        "epoch": 289,
        "reward": 0.1189635619521141,
        "val_loss": 1.4057387811065252,
        "train_loss": 0.08328474768271778
      },
      {
        "epoch": 290,
        "reward": 0.12733173370361328,
        "val_loss": 1.2038432573899627,
        "train_loss": 0.15891014672524761
      },
      {
        "epoch": 291,
        "reward": 0.14834292232990265,
        "val_loss": 0.8447743670216629,
        "train_loss": 0.04020753666274966
      },
      {
        "epoch": 292,
        "reward": 0.120429627597332,
        "val_loss": 1.3671602419677324,
        "train_loss": 3.052663323928405
      },
      {
        "epoch": 293,
        "reward": 0.13352113962173462,
        "val_loss": 1.0793459732750696,
        "train_loss": 0.05638612898586031
      },
      {
        "epoch": 294,
        "reward": 0.14326171576976776,
        "val_loss": 0.916602121998689,
        "train_loss": 0.06882585439934001
      },
      {
        "epoch": 295,
        "reward": 0.13815324008464813,
        "val_loss": 0.9974310086275052,
        "train_loss": 88.06350119505302
      },
      {
        "epoch": 296,
        "reward": 0.12707768380641937,
        "val_loss": 1.2093654146218407,
        "train_loss": 0.1091173295392834
      },
      {
        "epoch": 297,
        "reward": 0.12348514050245285,
        "val_loss": 1.2913203339225479,
        "train_loss": 0.09460165723262784
      },
      {
        "epoch": 298,
        "reward": 0.14010246098041534,
        "val_loss": 0.9654876749596691,
        "train_loss": 0.039621165120759264
      },
      {
        "epoch": 299,
        "reward": 0.11525905132293701,
        "val_loss": 1.5101739165506192,
        "train_loss": 7.167835658022131
      },
      {
        "epoch": 300,
        "reward": 0.1276940554380417,
        "val_loss": 1.196027620163347,
        "train_loss": 0.12819412129965713
      },
      {
        "epoch": 301,
        "reward": 0.1356716901063919,
        "val_loss": 1.0402167492679186,
        "train_loss": 0.4690570465273385
      },
      {
        "epoch": 302,
        "reward": 0.11318929493427277,
        "val_loss": 1.5732436395150475,
        "train_loss": 0.03728800872564674
      },
      {
        "epoch": 303,
        "reward": 0.12682895362377167,
        "val_loss": 1.2148053177432823,
        "train_loss": 0.10403995747149636
      },
      {
        "epoch": 304,
        "reward": 0.13242095708847046,
        "val_loss": 1.1001440567862508,
        "train_loss": 6.7841776218108585
      },
      {
        "epoch": 305,
        "reward": 0.1289733350276947,
        "val_loss": 1.1689821073585855,
        "train_loss": 0.024835051397251215
      },
      {
        "epoch": 306,
        "reward": 0.1204691082239151,
        "val_loss": 1.3661415490288553,
        "train_loss": 1.1492561163232984
      },
      {
        "epoch": 307,
        "reward": 0.13789235055446625,
        "val_loss": 1.0018149630299635,
        "train_loss": 0.25551903498573947
      },
      {
        "epoch": 308,
        "reward": 0.13995026051998138,
        "val_loss": 0.9679312671235364,
        "train_loss": 0.06351090289535932
      },
      {
        "epoch": 309,
        "reward": 0.13269610702991486,
        "val_loss": 1.0948914322070777,
        "train_loss": 0.34618784149531096
      },
      {
        "epoch": 310,
        "reward": 0.1309792697429657,
        "val_loss": 1.1282362669340469,
        "train_loss": 0.014278868185311485
      },
      {
        "epoch": 311,
        "reward": 0.1384245753288269,
        "val_loss": 0.9928989614958742,
        "train_loss": 0.4297112688789359
      },
      {
        "epoch": 312,
        "reward": 0.13015222549438477,
        "val_loss": 1.1447963672690094,
        "train_loss": 0.2897112579689397
      },
      {
        "epoch": 313,
        "reward": 0.1322736144065857,
        "val_loss": 1.102970674900072,
        "train_loss": 5.961421473989713
      },
      {
        "epoch": 314,
        "reward": 0.15114156901836395,
        "val_loss": 0.8084395496241216,
        "train_loss": 0.3220947014073877
      },
      {
        "epoch": 315,
        "reward": 0.13393144309520721,
        "val_loss": 1.0717270725539751,
        "train_loss": 0.14956488513025062
      },
      {
        "epoch": 316,
        "reward": 0.15357348322868347,
        "val_loss": 0.778558006476877,
        "train_loss": 0.32943891110838963
      },
      {
        "epoch": 317,
        "reward": 0.15819035470485687,
        "val_loss": 0.7257927362141865,
        "train_loss": 0.05649376981846917
      },
      {
        "epoch": 318,
        "reward": 0.16528595983982086,
        "val_loss": 0.6536546019072246,
        "train_loss": 0.07445664889270959
      },
      {
        "epoch": 319,
        "reward": 0.1363500952720642,
        "val_loss": 1.0282755171148372,
        "train_loss": 0.716617056604054
      },
      {
        "epoch": 320,
        "reward": 0.12808731198310852,
        "val_loss": 1.1876231162542743,
        "train_loss": 0.04469323793399291
      },
      {
        "epoch": 321,
        "reward": 0.14035815000534058,
        "val_loss": 0.9614012526913679,
        "train_loss": 1.7419708987346474
      },
      {
        "epoch": 322,
        "reward": 0.13956379890441895,
        "val_loss": 0.9741740821960515,
        "train_loss": 0.14128951905093765
      },
      {
        "epoch": 323,
        "reward": 0.15090151131153107,
        "val_loss": 0.8114724831123438,
        "train_loss": 0.8388983048431468
      },
      {
        "epoch": 324,
        "reward": 0.17411044239997864,
        "val_loss": 0.5766857443709991,
        "train_loss": 0.32851434470928953
      },
      {
        "epoch": 325,
        "reward": 0.1624077558517456,
        "val_loss": 0.6817051633261144,
        "train_loss": 25.08424721571254
      },
      {
        "epoch": 326,
        "reward": 0.14614422619342804,
        "val_loss": 0.8748842682024198,
        "train_loss": 0.030089216116511334
      },
      {
        "epoch": 327,
        "reward": 0.13630978763103485,
        "val_loss": 1.0289796712708525,
        "train_loss": 1.3143171259143855
      },
      {
        "epoch": 328,
        "reward": 0.15103892982006073,
        "val_loss": 0.8097344297649605,
        "train_loss": 4.884606661942178
      },
      {
        "epoch": 329,
        "reward": 0.14749443531036377,
        "val_loss": 0.8562251975527033,
        "train_loss": 0.7315934993429647
      },
      {
        "epoch": 330,
        "reward": 0.1619993895292282,
        "val_loss": 0.6858148029340165,
        "train_loss": 0.03585152653529523
      },
      {
        "epoch": 331,
        "reward": 0.154165580868721,
        "val_loss": 0.7715084352863154,
        "train_loss": 0.1978044542909349
      },
      {
        "epoch": 332,
        "reward": 0.12008952349424362,
        "val_loss": 1.3759783595866923,
        "train_loss": 3.2542636965159684
      },
      {
        "epoch": 333,
        "reward": 0.161378413438797,
        "val_loss": 0.6921273806198899,
        "train_loss": 2.3618205831791363
      },
      {
        "epoch": 334,
        "reward": 0.1381150484085083,
        "val_loss": 0.9980710224314991,
        "train_loss": 0.08234223419612345
      },
      {
        "epoch": 335,
        "reward": 0.1593141406774521,
        "val_loss": 0.7136802674337689,
        "train_loss": 0.15489595925968247
      },
      {
        "epoch": 336,
        "reward": 0.1712292730808258,
        "val_loss": 0.6004235668640051,
        "train_loss": 0.025429003574222755
      },
      {
        "epoch": 337,
        "reward": 0.17257538437843323,
        "val_loss": 0.5891746355087629,
        "train_loss": 0.4289433540577123
      },
      {
        "epoch": 338,
        "reward": 0.15136182308197021,
        "val_loss": 0.805670057207213,
        "train_loss": 0.9816235145923341
      },
      {
        "epoch": 339,
        "reward": 0.17129792273044586,
        "val_loss": 0.5998429291482482,
        "train_loss": 0.09432099450406475
      },
      {
        "epoch": 340,
        "reward": 0.15338173508644104,
        "val_loss": 0.7808593616854134,
        "train_loss": 0.07757011448848061
      },
      {
        "epoch": 341,
        "reward": 0.17438828945159912,
        "val_loss": 0.574462688128863,
        "train_loss": 13.799986079697891
      },
      {
        "epoch": 342,
        "reward": 0.13419322669506073,
        "val_loss": 1.0669045387767255,
        "train_loss": 21.430924204847543
      },
      {
        "epoch": 343,
        "reward": 0.16560545563697815,
        "val_loss": 0.6506367496580684,
        "train_loss": 2.3789404908445877
      },
      {
        "epoch": 344,
        "reward": 0.16928164660930634,
        "val_loss": 0.6172096980569352,
        "train_loss": 0.6357122406703778
      },
      {
        "epoch": 345,
        "reward": 0.17332541942596436,
        "val_loss": 0.5830281106256214,
        "train_loss": 0.01775577090582094
      },
      {
        "epoch": 346,
        "reward": 0.15710721909999847,
        "val_loss": 0.7377296380332804,
        "train_loss": 0.16105284417594354
      },
      {
        "epoch": 347,
        "reward": 0.14634673297405243,
        "val_loss": 0.8720507063969437,
        "train_loss": 0.20998342737584608
      },
      {
        "epoch": 348,
        "reward": 0.16235105693340302,
        "val_loss": 0.6822737478983721,
        "train_loss": 0.09449084408239426
      },
      {
        "epoch": 349,
        "reward": 0.1506534069776535,
        "val_loss": 0.8146233483816364,
        "train_loss": 10.703347108576473
      },
      {
        "epoch": 350,
        "reward": 0.15152646601200104,
        "val_loss": 0.8036084365199453,
        "train_loss": 0.016531121313724164
      },
      {
        "epoch": 351,
        "reward": 0.16208897531032562,
        "val_loss": 0.6849102302055273,
        "train_loss": 0.02057247204916516
      },
      {
        "epoch": 352,
        "reward": 0.1692182719707489,
        "val_loss": 0.6177664683200419,
        "train_loss": 0.03334309981101587
      },
      {
        "epoch": 353,
        "reward": 0.15076328814029694,
        "val_loss": 0.8132257880310395,
        "train_loss": 0.019928868723442204
      },
      {
        "epoch": 354,
        "reward": 0.18798069655895233,
        "val_loss": 0.47824569907970726,
        "train_loss": 0.06281214848702522
      },
      {
        "epoch": 355,
        "reward": 0.17770956456661224,
        "val_loss": 0.5487490827134545,
        "train_loss": 0.13782653670708755
      },
      {
        "epoch": 356,
        "reward": 0.16014303267002106,
        "val_loss": 0.7049192900386905,
        "train_loss": 0.36810275822286853
      },
      {
        "epoch": 357,
        "reward": 0.12131404131650925,
        "val_loss": 1.3445908027102373,
        "train_loss": 0.05920678399035331
      },
      {
        "epoch": 358,
        "reward": 0.16402114927768707,
        "val_loss": 0.665787633841059,
        "train_loss": 0.2258571416247063
      },
      {
        "epoch": 359,
        "reward": 0.10914275795221329,
        "val_loss": 1.7075416192778252,
        "train_loss": 0.1030037660261419
      },
      {
        "epoch": 360,
        "reward": 0.16249020397663116,
        "val_loss": 0.6808794237107837,
        "train_loss": 0.0969133410768476
      },
      {
        "epoch": 361,
        "reward": 0.15694569051265717,
        "val_loss": 0.7395324296750394,
        "train_loss": 0.019589580701274548
      },
      {
        "epoch": 362,
        "reward": 0.17737852036952972,
        "val_loss": 0.5512428491908524,
        "train_loss": 0.19755314886032677
      },
      {
        "epoch": 363,
        "reward": 0.1963551640510559,
        "val_loss": 0.4293273085578611,
        "train_loss": 0.07536907578133441
      },
      {
        "epoch": 364,
        "reward": 0.19184856116771698,
        "val_loss": 0.4547924457417269,
        "train_loss": 53.274545425054384
      },
      {
        "epoch": 365,
        "reward": 0.17875877022743225,
        "val_loss": 0.5409432153683156,
        "train_loss": 0.039495451944486164
      },
      {
        "epoch": 366,
        "reward": 0.16998691856861115,
        "val_loss": 0.6110598224082163,
        "train_loss": 0.1330738938083344
      },
      {
        "epoch": 367,
        "reward": 0.17566101253032684,
        "val_loss": 0.5644243969415713,
        "train_loss": 0.017010785722679708
      },
      {
        "epoch": 368,
        "reward": 0.16150301694869995,
        "val_loss": 0.6908543755832527,
        "train_loss": 5.2994871276068105
      },
      {
        "epoch": 369,
        "reward": 0.15420149266719818,
        "val_loss": 0.7710836573636958,
        "train_loss": 0.7080849105348954
      },
      {
        "epoch": 370,
        "reward": 0.16634683310985565,
        "val_loss": 0.6437045794446021,
        "train_loss": 0.028620971871042948
      },
      {
        "epoch": 371,
        "reward": 0.16747985780239105,
        "val_loss": 0.633299613953568,
        "train_loss": 0.04328795031716044
      },
      {
        "epoch": 372,
        "reward": 0.1519663780927658,
        "val_loss": 0.7981344586338049,
        "train_loss": 0.0812846473882718
      },
      {
        "epoch": 373,
        "reward": 0.15671592950820923,
        "val_loss": 0.7421066635454606,
        "train_loss": 0.010434437801730102
      },
      {
        "epoch": 374,
        "reward": 0.17254440486431122,
        "val_loss": 0.589430200784201,
        "train_loss": 0.051579820101883694
      },
      {
        "epoch": 375,
        "reward": 0.2022344321012497,
        "val_loss": 0.3988275887677446,
        "train_loss": 16.381945251615363
      },
      {
        "epoch": 376,
        "reward": 0.18221716582775116,
        "val_loss": 0.5162288077574756,
        "train_loss": 0.03941594545344392
      },
      {
        "epoch": 377,
        "reward": 0.1555265188217163,
        "val_loss": 0.7556278868079451,
        "train_loss": 0.29782901812779106
      },
      {
        "epoch": 378,
        "reward": 0.15295033156871796,
        "val_loss": 0.7860708547024322,
        "train_loss": 0.042744239492234416
      },
      {
        "epoch": 379,
        "reward": 0.19978944957256317,
        "val_loss": 0.41115764174277764,
        "train_loss": 0.03714652516422435
      },
      {
        "epoch": 380,
        "reward": 0.19243314862251282,
        "val_loss": 0.45137972035445273,
        "train_loss": 0.07822403295218604
      },
      {
        "epoch": 381,
        "reward": 0.1800711303949356,
        "val_loss": 0.5313847743839558,
        "train_loss": 1081.4602412768068
      },
      {
        "epoch": 382,
        "reward": 0.1641823798418045,
        "val_loss": 0.6642243068199605,
        "train_loss": 0.08273484942373426
      },
      {
        "epoch": 383,
        "reward": 0.16834019124507904,
        "val_loss": 0.6255480683009539,
        "train_loss": 0.08172284062311519
      },
      {
        "epoch": 384,
        "reward": 0.17992256581783295,
        "val_loss": 0.5324554479947048,
        "train_loss": 0.48246887130237437
      },
      {
        "epoch": 385,
        "reward": 0.1827341765165329,
        "val_loss": 0.5126630053023941,
        "train_loss": 0.021048430101263175
      },
      {
        "epoch": 386,
        "reward": 0.17508958280086517,
        "val_loss": 0.5689025563187897,
        "train_loss": 0.08729820721866698
      },
      {
        "epoch": 387,
        "reward": 0.14708106219768524,
        "val_loss": 0.8618800888736067,
        "train_loss": 0.9385211400434715
      },
      {
        "epoch": 388,
        "reward": 0.1438610553741455,
        "val_loss": 0.9077094958463151,
        "train_loss": 0.6689562034443952
      },
      {
        "epoch": 389,
        "reward": 0.20190441608428955,
        "val_loss": 0.40046357879016015,
        "train_loss": 1.2710324746540909
      },
      {
        "epoch": 390,
        "reward": 0.1916062980890274,
        "val_loss": 0.4562166613426858,
        "train_loss": 1712.1413779457316
      },
      {
        "epoch": 391,
        "reward": 0.2039259523153305,
        "val_loss": 0.39057725013533073,
        "train_loss": 0.12324985689841784
      },
      {
        "epoch": 392,
        "reward": 0.18317006528377533,
        "val_loss": 0.5096819423737803,
        "train_loss": 0.04847786950603432
      },
      {
        "epoch": 393,
        "reward": 0.1956692785024643,
        "val_loss": 0.43308082123153974,
        "train_loss": 0.49704976809376744
      },
      {
        "epoch": 394,
        "reward": 0.1974029392004013,
        "val_loss": 0.4236749481143696,
        "train_loss": 0.04952332677091293
      },
      {
        "epoch": 395,
        "reward": 0.19347815215587616,
        "val_loss": 0.4453621439835323,
        "train_loss": 0.027971189626931355
      },
      {
        "epoch": 396,
        "reward": 0.17874430119991302,
        "val_loss": 0.5410498849731604,
        "train_loss": 0.07822166632272107
      },
      {
        "epoch": 397,
        "reward": 0.20136629045009613,
        "val_loss": 0.4031499895832634,
        "train_loss": 0.030710513984488968
      },
      {
        "epoch": 398,
        "reward": 0.21132023632526398,
        "val_loss": 0.3569965560953798,
        "train_loss": 0.906533741711218
      },
      {
        "epoch": 399,
        "reward": 0.19930879771709442,
        "val_loss": 0.41363952638182255,
        "train_loss": 0.19543899842728235
      },
      {
        "epoch": 400,
        "reward": 0.1980200707912445,
        "val_loss": 0.4203910360728124,
        "train_loss": 0.7772439154628396
      },
      {
        "epoch": 401,
        "reward": 0.1858617514371872,
        "val_loss": 0.4917689636349678,
        "train_loss": 0.06838900016569263
      },
      {
        "epoch": 402,
        "reward": 0.19299152493476868,
        "val_loss": 0.44815120458536384,
        "train_loss": 0.2605810146834791
      },
      {
        "epoch": 403,
        "reward": 0.17697754502296448,
        "val_loss": 0.5542835009068118,
        "train_loss": 0.09289791281312668
      },
      {
        "epoch": 404,
        "reward": 0.16328005492687225,
        "val_loss": 0.6730369076498651,
        "train_loss": 0.011485185701950775
      },
      {
        "epoch": 405,
        "reward": 0.17878635227680206,
        "val_loss": 0.5407399345006395,
        "train_loss": 0.08502077297229195
      },
      {
        "epoch": 406,
        "reward": 0.180524542927742,
        "val_loss": 0.5281341917663147,
        "train_loss": 0.22925449364156839
      },
      {
        "epoch": 407,
        "reward": 0.18786196410655975,
        "val_loss": 0.4789904589082913,
        "train_loss": 0.12486663581960154
      },
      {
        "epoch": 408,
        "reward": 0.19471415877342224,
        "val_loss": 0.43837920356807963,
        "train_loss": 0.20523290548310166
      },
      {
        "epoch": 409,
        "reward": 0.19692714512348175,
        "val_loss": 0.42622960469452664,
        "train_loss": 0.42662072135919094
      },
      {
        "epoch": 410,
        "reward": 0.20511145889759064,
        "val_loss": 0.38492619038359926,
        "train_loss": 0.03345097248627728
      },
      {
        "epoch": 411,
        "reward": 0.21099047362804413,
        "val_loss": 0.3584128815980096,
        "train_loss": 0.009245149445352862
      },
      {
        "epoch": 412,
        "reward": 0.19065719842910767,
        "val_loss": 0.4618526522286369,
        "train_loss": 0.06839184508247015
      },
      {
        "epoch": 413,
        "reward": 0.21341419219970703,
        "val_loss": 0.3481692988425493,
        "train_loss": 0.1318392448492187
      },
      {
        "epoch": 414,
        "reward": 0.18782655894756317,
        "val_loss": 0.4792128557871495,
        "train_loss": 0.030246085591408282
      },
      {
        "epoch": 415,
        "reward": 0.20188632607460022,
        "val_loss": 0.40055361606313716,
        "train_loss": 0.02201657225109207
      },
      {
        "epoch": 416,
        "reward": 0.21310995519161224,
        "val_loss": 0.3494343848932268,
        "train_loss": 0.11823752893878219
      },
      {
        "epoch": 417,
        "reward": 0.16133473813533783,
        "val_loss": 0.6925744071070637,
        "train_loss": 0.05332640547287436
      },
      {
        "epoch": 418,
        "reward": 0.16698051989078522,
        "val_loss": 0.6378572732542774,
        "train_loss": 0.10826708174751659
      },
      {
        "epoch": 419,
        "reward": 0.22302590310573578,
        "val_loss": 0.3110623229877092,
        "train_loss": 1.172824032106571
      },
      {
        "epoch": 420,
        "reward": 0.17439962923526764,
        "val_loss": 0.5743723579008864,
        "train_loss": 113.94583069383785
      },
      {
        "epoch": 421,
        "reward": 0.18666742742061615,
        "val_loss": 0.48656857970802647,
        "train_loss": 1.4262460885942205
      },
      {
        "epoch": 422,
        "reward": 0.21324825286865234,
        "val_loss": 0.34885849573350114,
        "train_loss": 0.813969566013279
      },
      {
        "epoch": 423,
        "reward": 0.22022846341133118,
        "val_loss": 0.32131627725902945,
        "train_loss": 0.05352719277009153
      },
      {
        "epoch": 424,
        "reward": 0.2130369395017624,
        "val_loss": 0.34973876850147334,
        "train_loss": 0.5078973902569627
      },
      {
        "epoch": 425,
        "reward": 0.22625675797462463,
        "val_loss": 0.2997336363602829,
        "train_loss": 0.17080262900708476
      },
      {
        "epoch": 426,
        "reward": 0.20455467700958252,
        "val_loss": 0.3875669964722225,
        "train_loss": 0.16837371497352321
      },
      {
        "epoch": 427,
        "reward": 0.20587244629859924,
        "val_loss": 0.381354612215156,
        "train_loss": 0.018503277000630848
      },
      {
        "epoch": 428,
        "reward": 0.18946780264377594,
        "val_loss": 0.4690450601462674,
        "train_loss": 5.206009185091086
      },
      {
        "epoch": 429,
        "reward": 0.1905084103345871,
        "val_loss": 0.46274442331299986,
        "train_loss": 1893.9014584195513
      },
      {
        "epoch": 430,
        "reward": 0.20520387589931488,
        "val_loss": 0.3844902496119695,
        "train_loss": 0.15059091278145878
      },
      {
        "epoch": 431,
        "reward": 0.22494451701641083,
        "val_loss": 0.30427035236997263,
        "train_loss": 0.07230166382942116
      },
      {
        "epoch": 432,
        "reward": 0.21636466681957245,
        "val_loss": 0.33620190947216805,
        "train_loss": 0.070631699347779
      },
      {
        "epoch": 433,
        "reward": 0.23864082992076874,
        "val_loss": 0.2608762246174073,
        "train_loss": 0.01643593806343583
      },
      {
        "epoch": 434,
        "reward": 0.17218369245529175,
        "val_loss": 0.5924186299588265,
        "train_loss": 0.03853100050037028
      },
      {
        "epoch": 435,
        "reward": 0.1759796291589737,
        "val_loss": 0.5619478710162055,
        "train_loss": 0.06900399232724269
      },
      {
        "epoch": 436,
        "reward": 0.23832345008850098,
        "val_loss": 0.2617896373433593,
        "train_loss": 0.03155556870310997
      },
      {
        "epoch": 437,
        "reward": 0.20883384346961975,
        "val_loss": 0.36785661620420534,
        "train_loss": 1.706860948523032
      },
      {
        "epoch": 438,
        "reward": 0.20878536999225616,
        "val_loss": 0.36807247204290305,
        "train_loss": 0.2829083922789813
      },
      {
        "epoch": 439,
        "reward": 0.21508358418941498,
        "val_loss": 0.34133223296209636,
        "train_loss": 0.042778917467960406
      },
      {
        "epoch": 440,
        "reward": 0.231245756149292,
        "val_loss": 0.2832516045642218,
        "train_loss": 0.014231775580600906
      },
      {
        "epoch": 441,
        "reward": 0.21117320656776428,
        "val_loss": 0.35762729244639296,
        "train_loss": 0.0624803923710715
      },
      {
        "epoch": 442,
        "reward": 0.18934182822704315,
        "val_loss": 0.4698153113630334,
        "train_loss": 0.07102175479555556
      },
      {
        "epoch": 443,
        "reward": 0.22068874537944794,
        "val_loss": 0.3195997580769472,
        "train_loss": 0.007239635719787867
      },
      {
        "epoch": 444,
        "reward": 0.20610272884368896,
        "val_loss": 0.38028226639809354,
        "train_loss": 0.06497846301779366
      },
      {
        "epoch": 445,
        "reward": 0.2345532923936844,
        "val_loss": 0.27295544191396665,
        "train_loss": 0.4104105821153588
      },
      {
        "epoch": 446,
        "reward": 0.19430647790431976,
        "val_loss": 0.44066646996153785,
        "train_loss": 0.18011264479495226
      },
      {
        "epoch": 447,
        "reward": 0.2208656519651413,
        "val_loss": 0.31894311335469994,
        "train_loss": 0.046257750261037685
      },
      {
        "epoch": 448,
        "reward": 0.23426973819732666,
        "val_loss": 0.273819359900829,
        "train_loss": 0.010541037930894302
      },
      {
        "epoch": 449,
        "reward": 0.22281518578529358,
        "val_loss": 0.31182000509995433,
        "train_loss": 0.008640699666732242
      },
      {
        "epoch": 450,
        "reward": 0.22994136810302734,
        "val_loss": 0.2874473087057205,
        "train_loss": 0.032611927838073686
      },
      {
        "epoch": 451,
        "reward": 0.24098609387874603,
        "val_loss": 0.2542496844793537,
        "train_loss": 0.2987752922216224
      },
      {
        "epoch": 452,
        "reward": 0.24507799744606018,
        "val_loss": 0.2431870574697054,
        "train_loss": 0.03244965320594089
      },
      {
        "epoch": 453,
        "reward": 0.2076178789138794,
        "val_loss": 0.3733229553992195,
        "train_loss": 0.6854303310490371
      },
      {
        "epoch": 454,
        "reward": 0.2183869630098343,
        "val_loss": 0.3283031333204625,
        "train_loss": 1.1294667131277003
      },
      {
        "epoch": 455,
        "reward": 0.23901358246803284,
        "val_loss": 0.2598086078900711,
        "train_loss": 0.017785141916157536
      },
      {
        "epoch": 456,
        "reward": 0.1856941431760788,
        "val_loss": 0.4928600167789097,
        "train_loss": 0.06283287713281774
      },
      {
        "epoch": 457,
        "reward": 0.22051012516021729,
        "val_loss": 0.3202644577416192,
        "train_loss": 1.7465746153908326
      },
      {
        "epoch": 458,
        "reward": 0.23974668979644775,
        "val_loss": 0.2577248960483952,
        "train_loss": 0.17705733292565967
      },
      {
        "epoch": 459,
        "reward": 0.2517334520816803,
        "val_loss": 0.22645179455867037,
        "train_loss": 0.049738615119937234
      },
      {
        "epoch": 460,
        "reward": 0.2232629507780075,
        "val_loss": 0.3102126573960829,
        "train_loss": 0.025220689067142442
      },
      {
        "epoch": 461,
        "reward": 0.20846156775951385,
        "val_loss": 0.3695190818231952,
        "train_loss": 0.1247942496181797
      },
      {
        "epoch": 462,
        "reward": 0.21937234699726105,
        "val_loss": 0.32454049926517264,
        "train_loss": 0.004614092381626296
      },
      {
        "epoch": 463,
        "reward": 0.22215135395526886,
        "val_loss": 0.31422242355932084,
        "train_loss": 0.025884212110003527
      },
      {
        "epoch": 464,
        "reward": 0.23705191910266876,
        "val_loss": 0.2654898575440581,
        "train_loss": 0.012975686541512214
      },
      {
        "epoch": 465,
        "reward": 0.23562109470367432,
        "val_loss": 0.2697328902598071,
        "train_loss": 0.005164124365994492
      },
      {
        "epoch": 466,
        "reward": 0.21019791066646576,
        "val_loss": 0.3618468083482834,
        "train_loss": 1.2931928917566369
      },
      {
        "epoch": 467,
        "reward": 0.241571307182312,
        "val_loss": 0.2526292441096822,
        "train_loss": 0.04461831962852067
      },
      {
        "epoch": 468,
        "reward": 0.2327117770910263,
        "val_loss": 0.2786283686041965,
        "train_loss": 0.010111271717855393
      },
      {
        "epoch": 469,
        "reward": 0.2203698456287384,
        "val_loss": 0.32078772181245896,
        "train_loss": 0.018818699161224337
      },
      {
        "epoch": 470,
        "reward": 0.22617046535015106,
        "val_loss": 0.30002929128906025,
        "train_loss": 0.08966422233229074
      },
      {
        "epoch": 471,
        "reward": 0.22409498691558838,
        "val_loss": 0.30725412854059997,
        "train_loss": 0.6179823966365523
      },
      {
        "epoch": 472,
        "reward": 0.23849880695343018,
        "val_loss": 0.26128451082955245,
        "train_loss": 0.16507433547051803
      },
      {
        "epoch": 473,
        "reward": 0.25440526008605957,
        "val_loss": 0.22013968189379998,
        "train_loss": 0.047708953978144564
      },
      {
        "epoch": 474,
        "reward": 0.22672167420387268,
        "val_loss": 0.29814705978580086,
        "train_loss": 0.03446212378576792
      },
      {
        "epoch": 475,
        "reward": 0.18717060983181,
        "val_loss": 0.48335723609696807,
        "train_loss": 0.07160671651588647
      },
      {
        "epoch": 476,
        "reward": 0.21065573394298553,
        "val_loss": 0.3598581099483584,
        "train_loss": 0.05261634419086757
      },
      {
        "epoch": 477,
        "reward": 0.23721733689308167,
        "val_loss": 0.2650047157325649,
        "train_loss": 0.018574711554650163
      },
      {
        "epoch": 478,
        "reward": 0.2200889140367508,
        "val_loss": 0.321839073614683,
        "train_loss": 0.07598786161263259
      },
      {
        "epoch": 479,
        "reward": 0.20439250767230988,
        "val_loss": 0.38834053062601015,
        "train_loss": 0.12992970371851698
      },
      {
        "epoch": 480,
        "reward": 0.23551049828529358,
        "val_loss": 0.27006446161041303,
        "train_loss": 0.06120802227199489
      },
      {
        "epoch": 481,
        "reward": 0.23956862092018127,
        "val_loss": 0.25822903994204743,
        "train_loss": 0.006714545364957303
      },
      {
        "epoch": 482,
        "reward": 0.23626480996608734,
        "val_loss": 0.26781350946319954,
        "train_loss": 0.011993393194643431
      },
      {
        "epoch": 483,
        "reward": 0.1826207935810089,
        "val_loss": 0.5134423504600168,
        "train_loss": 0.11228014804468191
      },
      {
        "epoch": 484,
        "reward": 0.22598710656166077,
        "val_loss": 0.30065888272864477,
        "train_loss": 0.01981247750294502
      },
      {
        "epoch": 485,
        "reward": 0.2299683839082718,
        "val_loss": 0.28735959999695687,
        "train_loss": 0.01659282011230691
      },
      {
        "epoch": 486,
        "reward": 0.23750562965869904,
        "val_loss": 0.26416198741727775,
        "train_loss": 0.050170587879760066
      },
      {
        "epoch": 487,
        "reward": 0.24647307395935059,
        "val_loss": 0.23955400073568203,
        "train_loss": 0.07175106065551518
      },
      {
        "epoch": 488,
        "reward": 0.24045954644680023,
        "val_loss": 0.25571879179083873,
        "train_loss": 0.023963212990425885
      },
      {
        "epoch": 489,
        "reward": 0.2511230409145355,
        "val_loss": 0.22792540969177416,
        "train_loss": 0.025735527772877295
      },
      {
        "epoch": 490,
        "reward": 0.2118186205625534,
        "val_loss": 0.35486973848726067,
        "train_loss": 0.03851320221684336
      },
      {
        "epoch": 491,
        "reward": 0.24605219066143036,
        "val_loss": 0.24064287899195083,
        "train_loss": 0.025560100569586772
      },
      {
        "epoch": 492,
        "reward": 0.25618165731430054,
        "val_loss": 0.21606408281617664,
        "train_loss": 0.680078124227853
      },
      {
        "epoch": 493,
        "reward": 0.21641388535499573,
        "val_loss": 0.3360069172839368,
        "train_loss": 0.03761026675531936
      },
      {
        "epoch": 494,
        "reward": 0.2438553124666214,
        "val_loss": 0.24642812585391635,
        "train_loss": 0.028035881206261156
      },
      {
        "epoch": 495,
        "reward": 0.25146493315696716,
        "val_loss": 0.22709858937222244,
        "train_loss": 0.10695276314408357
      },
      {
        "epoch": 496,
        "reward": 0.26118871569633484,
        "val_loss": 0.20507045747945085,
        "train_loss": 0.7753602092074848
      },
      {
        "epoch": 497,
        "reward": 0.22502020001411438,
        "val_loss": 0.3040063979403515,
        "train_loss": 0.046809442651990066
      },
      {
        "epoch": 498,
        "reward": 0.2186209261417389,
        "val_loss": 0.3274047623687823,
        "train_loss": 0.024721449812624578
      },
      {
        "epoch": 499,
        "reward": 0.26039496064186096,
        "val_loss": 0.20676615670423157,
        "train_loss": 0.022902547835726112
      },
      {
        "epoch": 500,
        "reward": 0.2246500700712204,
        "val_loss": 0.30530035188088994,
        "train_loss": 0.07751211582609148
      },
      {
        "epoch": 501,
        "reward": 0.18417362868785858,
        "val_loss": 0.5029043984915396,
        "train_loss": 1.289525399853368
      },
      {
        "epoch": 502,
        "reward": 0.20075225830078125,
        "val_loss": 0.40624392284995076,
        "train_loss": 0.016416809823847592
      },
      {
        "epoch": 503,
        "reward": 0.22851982712745667,
        "val_loss": 0.2921102021687797,
        "train_loss": 1.0167935595415587
      },
      {
        "epoch": 504,
        "reward": 0.26068413257598877,
        "val_loss": 0.2061464121964361,
        "train_loss": 0.21524806390628398
      },
      {
        "epoch": 505,
        "reward": 0.22559066116809845,
        "val_loss": 0.3020256108720787,
        "train_loss": 0.03637207907181269
      },
      {
        "epoch": 506,
        "reward": 0.2407543957233429,
        "val_loss": 0.25489487426654833,
        "train_loss": 18.8159029359561
      },
      {
        "epoch": 507,
        "reward": 0.1952107697725296,
        "val_loss": 0.4356137804986377,
        "train_loss": 0.010924605179193
      },
      {
        "epoch": 508,
        "reward": 0.24735450744628906,
        "val_loss": 0.23729370275811693,
        "train_loss": 0.01171192353677515
      },
      {
        "epoch": 509,
        "reward": 0.24945583939552307,
        "val_loss": 0.2320117999915965,
        "train_loss": 0.009409119272626972
      },
      {
        "epoch": 510,
        "reward": 0.2513546645641327,
        "val_loss": 0.22736482093958849,
        "train_loss": 0.03271468624062926
      },
      {
        "epoch": 511,
        "reward": 0.2589177191257477,
        "val_loss": 0.20996858077290068,
        "train_loss": 324.1008378092072
      },
      {
        "epoch": 512,
        "reward": 0.23733000457286835,
        "val_loss": 0.2646749789876464,
        "train_loss": 0.02090799350452681
      },
      {
        "epoch": 513,
        "reward": 0.2645150125026703,
        "val_loss": 0.19814896180261193,
        "train_loss": 0.01890873098342966
      },
      {
        "epoch": 514,
        "reward": 0.24536430835723877,
        "val_loss": 0.24243580759502947,
        "train_loss": 0.16626639780756355
      },
      {
        "epoch": 515,
        "reward": 0.2526100277900696,
        "val_loss": 0.22435629642651683,
        "train_loss": 0.04032059829198541
      },
      {
        "epoch": 516,
        "reward": 0.23020140826702118,
        "val_loss": 0.28660458579958814,
        "train_loss": 0.06374943875058446
      },
      {
        "epoch": 517,
        "reward": 0.20516331493854523,
        "val_loss": 0.38468142077493084,
        "train_loss": 1.1817555683908443
      },
      {
        "epoch": 518,
        "reward": 0.24754683673381805,
        "val_loss": 0.23680397504774323,
        "train_loss": 0.3839721987247825
      },
      {
        "epoch": 519,
        "reward": 0.24572031199932098,
        "val_loss": 0.24150576622092298,
        "train_loss": 0.08305240279143461
      },
      {
        "epoch": 520,
        "reward": 0.23365449905395508,
        "val_loss": 0.27570579060037353,
        "train_loss": 0.003544875014855419
      },
      {
        "epoch": 521,
        "reward": 0.255065381526947,
        "val_loss": 0.21861409602154577,
        "train_loss": 0.061035481772985525
      },
      {
        "epoch": 522,
        "reward": 0.2132023423910141,
        "val_loss": 0.3490495386400393,
        "train_loss": 0.010412530659498142
      },
      {
        "epoch": 523,
        "reward": 0.2514592409133911,
        "val_loss": 0.22711223544320092,
        "train_loss": 0.04309640961974555
      },
      {
        "epoch": 524,
        "reward": 0.24687841534614563,
        "val_loss": 0.2385112526286061,
        "train_loss": 0.05745337376552365
      },
      {
        "epoch": 525,
        "reward": 0.26138824224472046,
        "val_loss": 0.20464700861235283,
        "train_loss": 0.03207126719644293
      },
      {
        "epoch": 526,
        "reward": 0.21094463765621185,
        "val_loss": 0.3586103894132456,
        "train_loss": 0.7868043584225094
      },
      {
        "epoch": 527,
        "reward": 0.254280686378479,
        "val_loss": 0.22042909420062123,
        "train_loss": 0.17647040498447425
      },
      {
        "epoch": 528,
        "reward": 0.2658008635044098,
        "val_loss": 0.19555091566871852,
        "train_loss": 1.5032862115098955
      },
      {
        "epoch": 529,
        "reward": 0.23007385432720184,
        "val_loss": 0.28701754875614177,
        "train_loss": 0.6757345891640468
      },
      {
        "epoch": 530,
        "reward": 0.2577473521232605,
        "val_loss": 0.21254947726681298,
        "train_loss": 0.5396759995178749
      },
      {
        "epoch": 531,
        "reward": 0.25631144642829895,
        "val_loss": 0.2157700342442175,
        "train_loss": 1.9197440490041886
      },
      {
        "epoch": 532,
        "reward": 0.27398356795310974,
        "val_loss": 0.17996530514626233,
        "train_loss": 0.0061414442859192885
      },
      {
        "epoch": 533,
        "reward": 0.27712729573249817,
        "val_loss": 0.1743853445264644,
        "train_loss": 27.64260274712041
      },
      {
        "epoch": 534,
        "reward": 0.2614412009716034,
        "val_loss": 0.20453474322234147,
        "train_loss": 0.3043859916571399
      },
      {
        "epoch": 535,
        "reward": 0.27013546228408813,
        "val_loss": 0.18709675319925217,
        "train_loss": 0.01560599593778114
      },
      {
        "epoch": 536,
        "reward": 0.25653406977653503,
        "val_loss": 0.2152667415045601,
        "train_loss": 0.03105706671955816
      },
      {
        "epoch": 537,
        "reward": 0.261553019285202,
        "val_loss": 0.20429793986425335,
        "train_loss": 2.400534590532166
      },
      {
        "epoch": 538,
        "reward": 0.2784198522567749,
        "val_loss": 0.1721526042799399,
        "train_loss": 0.042690054606982115
      },
      {
        "epoch": 539,
        "reward": 0.26689955592155457,
        "val_loss": 0.19336427490426494,
        "train_loss": 0.018558309249503788
      },
      {
        "epoch": 540,
        "reward": 0.28032582998275757,
        "val_loss": 0.1689236803795211,
        "train_loss": 0.00591165287747012
      },
      {
        "epoch": 541,
        "reward": 0.26954159140586853,
        "val_loss": 0.18822807490193685,
        "train_loss": 0.03126312713413007
      },
      {
        "epoch": 542,
        "reward": 0.24519796669483185,
        "val_loss": 0.24287190511989007,
        "train_loss": 0.1898472626257549
      },
      {
        "epoch": 543,
        "reward": 0.21833916008472443,
        "val_loss": 0.32848711920087226,
        "train_loss": 8.271707089334786
      },
      {
        "epoch": 544,
        "reward": 0.23010006546974182,
        "val_loss": 0.28693264697877957,
        "train_loss": 0.11530832449744384
      },
      {
        "epoch": 545,
        "reward": 0.259104460477829,
        "val_loss": 0.20956038677000574,
        "train_loss": 0.004427671222191958
      },
      {
        "epoch": 546,
        "reward": 0.23973293602466583,
        "val_loss": 0.25776376420565483,
        "train_loss": 3.4876408798006127
      },
      {
        "epoch": 547,
        "reward": 0.2568737864494324,
        "val_loss": 0.21450158647660697,
        "train_loss": 0.020748388789588016
      },
      {
        "epoch": 548,
        "reward": 0.2605604827404022,
        "val_loss": 0.20641116033324838,
        "train_loss": 0.0703960952705529
      },
      {
        "epoch": 549,
        "reward": 0.2539524734020233,
        "val_loss": 0.22119390085988147,
        "train_loss": 0.03352438213998819
      },
      {
        "epoch": 550,
        "reward": 0.2641032636165619,
        "val_loss": 0.19898996201560035,
        "train_loss": 1.8046845040223092
      },
      {
        "epoch": 551,
        "reward": 0.2566267251968384,
        "val_loss": 0.2150577132540223,
        "train_loss": 0.0032131654059832306
      },
      {
        "epoch": 552,
        "reward": 0.22169974446296692,
        "val_loss": 0.3158703081758826,
        "train_loss": 0.04341824419596098
      },
      {
        "epoch": 553,
        "reward": 0.26301848888397217,
        "val_loss": 0.20122666978776188,
        "train_loss": 0.05457020371704857
      },
      {
        "epoch": 554,
        "reward": 0.27759695053100586,
        "val_loss": 0.17356998190682912,
        "train_loss": 0.03884558423054001
      },
      {
        "epoch": 555,
        "reward": 0.26353901624679565,
        "val_loss": 0.20014950653837463,
        "train_loss": 0.02102617870192402
      },
      {
        "epoch": 556,
        "reward": 0.24003322422504425,
        "val_loss": 0.2569161658757366,
        "train_loss": 0.038464941640995676
      },
      {
        "epoch": 557,
        "reward": 0.22236044704914093,
        "val_loss": 0.31346314701451256,
        "train_loss": 0.008805179261309184
      },
      {
        "epoch": 558,
        "reward": 0.2682831287384033,
        "val_loss": 0.19065327747791475,
        "train_loss": 0.07557460250315601
      },
      {
        "epoch": 559,
        "reward": 0.22821472585201263,
        "val_loss": 0.29312346195885247,
        "train_loss": 0.005640811629396362
      },
      {
        "epoch": 560,
        "reward": 0.24937228858470917,
        "val_loss": 0.23221894485011166,
        "train_loss": 0.03001763540837251
      },
      {
        "epoch": 561,
        "reward": 0.27241986989974976,
        "val_loss": 0.18282221064354026,
        "train_loss": 0.029575062982565632
      },
      {
        "epoch": 562,
        "reward": 0.2481793612241745,
        "val_loss": 0.23520259306366956,
        "train_loss": 5.423127532040571
      },
      {
        "epoch": 563,
        "reward": 0.2502913773059845,
        "val_loss": 0.22995251450421555,
        "train_loss": 0.029157057317766324
      },
      {
        "epoch": 564,
        "reward": 0.2742778956890106,
        "val_loss": 0.17943365448237664,
        "train_loss": 0.016443190570638623
      },
      {
        "epoch": 565,
        "reward": 0.23014496266841888,
        "val_loss": 0.2867873248594281,
        "train_loss": 0.040878810835867904
      },
      {
        "epoch": 566,
        "reward": 0.2738876938819885,
        "val_loss": 0.1801388835218469,
        "train_loss": 0.014886837485951569
      },
      {
        "epoch": 567,
        "reward": 0.2664507329463959,
        "val_loss": 0.19425386973723238,
        "train_loss": 0.16222128219809606
      },
      {
        "epoch": 568,
        "reward": 0.2767852544784546,
        "val_loss": 0.1749820715381897,
        "train_loss": 0.21854063736603935
      },
      {
        "epoch": 569,
        "reward": 0.2326735556125641,
        "val_loss": 0.2787475944746153,
        "train_loss": 0.7332247943864226
      },
      {
        "epoch": 570,
        "reward": 0.28491994738578796,
        "val_loss": 0.16143900754312718,
        "train_loss": 0.08405709382658152
      },
      {
        "epoch": 571,
        "reward": 0.27826955914497375,
        "val_loss": 0.17241045516233758,
        "train_loss": 2.6292479686918133
      },
      {
        "epoch": 572,
        "reward": 0.2853284776210785,
        "val_loss": 0.1607931810098567,
        "train_loss": 9.341755230270511
      },
      {
        "epoch": 573,
        "reward": 0.24872727692127228,
        "val_loss": 0.23382630821600156,
        "train_loss": 0.13666780255488659
      },
      {
        "epoch": 574,
        "reward": 0.2973228394985199,
        "val_loss": 0.14315286519870693,
        "train_loss": 0.04419672434344717
      },
      {
        "epoch": 575,
        "reward": 0.29448702931404114,
        "val_loss": 0.14710332734726503,
        "train_loss": 0.036824288921847116
      },
      {
        "epoch": 576,
        "reward": 0.2732568681240082,
        "val_loss": 0.18128613618734693,
        "train_loss": 0.06649712383547851
      },
      {
        "epoch": 577,
        "reward": 0.272482305765152,
        "val_loss": 0.18270706993228356,
        "train_loss": 0.12905069349653786
      },
      {
        "epoch": 578,
        "reward": 0.30182889103889465,
        "val_loss": 0.13713458152363142,
        "train_loss": 0.010101153424609667
      },
      {
        "epoch": 579,
        "reward": 0.2600313127040863,
        "val_loss": 0.20754885055274436,
        "train_loss": 0.04751192953447641
      },
      {
        "epoch": 580,
        "reward": 0.26860857009887695,
        "val_loss": 0.19002244308025443,
        "train_loss": 0.013885563345516298
      },
      {
        "epoch": 581,
        "reward": 0.27166053652763367,
        "val_loss": 0.1842296027545152,
        "train_loss": 0.10875410892997305
      },
      {
        "epoch": 582,
        "reward": 0.2732350528240204,
        "val_loss": 0.18132600494677067,
        "train_loss": 0.06470976650094738
      },
      {
        "epoch": 583,
        "reward": 0.25720128417015076,
        "val_loss": 0.21376718816048065,
        "train_loss": 0.07100348185793756
      },
      {
        "epoch": 584,
        "reward": 0.2658863961696625,
        "val_loss": 0.19537963389718374,
        "train_loss": 0.03884184268603209
      },
      {
        "epoch": 585,
        "reward": 0.27409324049949646,
        "val_loss": 0.1797670246866931,
        "train_loss": 0.09076529971123538
      },
      {
        "epoch": 586,
        "reward": 0.27483996748924255,
        "val_loss": 0.17842378699320502,
        "train_loss": 0.04021815001263244
      },
      {
        "epoch": 587,
        "reward": 0.2674652934074402,
        "val_loss": 0.1922500218248128,
        "train_loss": 1.2405972457015826
      },
      {
        "epoch": 588,
        "reward": 0.26932892203330994,
        "val_loss": 0.18863519608774887,
        "train_loss": 0.0136102337788683
      },
      {
        "epoch": 589,
        "reward": 0.2595840394496918,
        "val_loss": 0.208516527075387,
        "train_loss": 0.2637723467492973
      },
      {
        "epoch": 590,
        "reward": 0.2764733135700226,
        "val_loss": 0.17552844708552584,
        "train_loss": 0.12574766445043048
      },
      {
        "epoch": 591,
        "reward": 0.2696767747402191,
        "val_loss": 0.18796980744394073,
        "train_loss": 0.00504544533760054
      },
      {
        "epoch": 592,
        "reward": 0.27867409586906433,
        "val_loss": 0.17171759786599847,
        "train_loss": 0.033176989647752356
      },
      {
        "epoch": 593,
        "reward": 0.24796126782894135,
        "val_loss": 0.23575321870989033,
        "train_loss": 0.008580607436740068
      },
      {
        "epoch": 594,
        "reward": 0.2495347112417221,
        "val_loss": 0.23181643287119055,
        "train_loss": 0.05244228348433703
      },
      {
        "epoch": 595,
        "reward": 0.26667410135269165,
        "val_loss": 0.19381048753192381,
        "train_loss": 0.011753667872443866
      },
      {
        "epoch": 596,
        "reward": 0.27685728669166565,
        "val_loss": 0.17485619251549775,
        "train_loss": 0.08941737613405656
      },
      {
        "epoch": 597,
        "reward": 0.27461621165275574,
        "val_loss": 0.1788250409548969,
        "train_loss": 0.05436568537026268
      },
      {
        "epoch": 598,
        "reward": 0.26881206035614014,
        "val_loss": 0.18962931148208945,
        "train_loss": 0.061141661567000065
      },
      {
        "epoch": 599,
        "reward": 0.27723512053489685,
        "val_loss": 0.17419772711998252,
        "train_loss": 0.055969327837933985
      },
      {
        "epoch": 600,
        "reward": 0.27126064896583557,
        "val_loss": 0.18497614650862357,
        "train_loss": 0.008056797445113681
      },
      {
        "epoch": 601,
        "reward": 0.2487538605928421,
        "val_loss": 0.2337597421636539,
        "train_loss": 0.044896928060167665
      },
      {
        "epoch": 602,
        "reward": 0.29418593645095825,
        "val_loss": 0.1475304641478163,
        "train_loss": 0.0031968958708323324
      },
      {
        "epoch": 603,
        "reward": 0.22135181725025177,
        "val_loss": 0.3171474189813515,
        "train_loss": 0.054117588338927956
      },
      {
        "epoch": 604,
        "reward": 0.25049063563346863,
        "val_loss": 0.2294647987499567,
        "train_loss": 0.02738677698560493
      },
      {
        "epoch": 605,
        "reward": 0.26672548055648804,
        "val_loss": 0.193708692785419,
        "train_loss": 0.0073969678742287215
      },
      {
        "epoch": 606,
        "reward": 0.25602826476097107,
        "val_loss": 0.21641228370052495,
        "train_loss": 0.23592227888730122
      },
      {
        "epoch": 607,
        "reward": 0.2597223222255707,
        "val_loss": 0.20821674149816058,
        "train_loss": 0.010506594035752355
      },
      {
        "epoch": 608,
        "reward": 0.2921556532382965,
        "val_loss": 0.15044988767476752,
        "train_loss": 0.3932987920870801
      },
      {
        "epoch": 609,
        "reward": 0.24609623849391937,
        "val_loss": 0.240528693397729,
        "train_loss": 0.45047445177428574
      },
      {
        "epoch": 610,
        "reward": 0.28061461448669434,
        "val_loss": 0.1684408633570586,
        "train_loss": 0.4374019054963495
      },
      {
        "epoch": 611,
        "reward": 0.2542358636856079,
        "val_loss": 0.22053332503751985,
        "train_loss": 0.03006004952000624
      },
      {
        "epoch": 612,
        "reward": 0.2870591878890991,
        "val_loss": 0.1580916608883334,
        "train_loss": 0.5912692412835335
      },
      {
        "epoch": 613,
        "reward": 0.28035151958465576,
        "val_loss": 0.16888064980074496,
        "train_loss": 0.01568154400613891
      },
      {
        "epoch": 614,
        "reward": 0.25660839676856995,
        "val_loss": 0.21509903317616721,
        "train_loss": 1.8849424865438777
      },
      {
        "epoch": 615,
        "reward": 0.25399249792099,
        "val_loss": 0.22110040106677584,
        "train_loss": 94.4503117370031
      },
      {
        "epoch": 616,
        "reward": 0.2802886664867401,
        "val_loss": 0.1689859455925346,
        "train_loss": 0.23442643482457454
      },
      {
        "epoch": 617,
        "reward": 0.2855904996395111,
        "val_loss": 0.16038061139572943,
        "train_loss": 0.03195119086404492
      },
      {
        "epoch": 618,
        "reward": 0.2884984612464905,
        "val_loss": 0.15588692417285138,
        "train_loss": 0.25376825402481
      },
      {
        "epoch": 619,
        "reward": 0.30347034335136414,
        "val_loss": 0.13501796047577436,
        "train_loss": 0.11008473864897567
      },
      {
        "epoch": 620,
        "reward": 0.22038638591766357,
        "val_loss": 0.3207260780285911,
        "train_loss": 1.5213271347677688
      },
      {
        "epoch": 621,
        "reward": 0.2916281819343567,
        "val_loss": 0.15121973633150837,
        "train_loss": 0.04125583062761087
      },
      {
        "epoch": 622,
        "reward": 0.2895748019218445,
        "val_loss": 0.15426239117680648,
        "train_loss": 0.01152896837139941
      },
      {
        "epoch": 623,
        "reward": 0.25412794947624207,
        "val_loss": 0.2207845555302421,
        "train_loss": 0.33771861124436187
      },
      {
        "epoch": 624,
        "reward": 0.266011118888855,
        "val_loss": 0.19513009893541625,
        "train_loss": 0.017109920673157412
      },
      {
        "epoch": 625,
        "reward": 0.2690410912036896,
        "val_loss": 0.18918802367157436,
        "train_loss": 0.1905845160167351
      },
      {
        "epoch": 626,
        "reward": 0.25068551301956177,
        "val_loss": 0.22898907716652112,
        "train_loss": 0.049407283852745496
      },
      {
        "epoch": 627,
        "reward": 0.2503420114517212,
        "val_loss": 0.22982838194418168,
        "train_loss": 2.5622066274092785
      },
      {
        "epoch": 628,
        "reward": 0.2764574885368347,
        "val_loss": 0.17555626269729277,
        "train_loss": 0.07919044323128989
      },
      {
        "epoch": 629,
        "reward": 0.3025975525379181,
        "val_loss": 0.13613850415900483,
        "train_loss": 0.02278760532373361
      },
      {
        "epoch": 630,
        "reward": 0.30772364139556885,
        "val_loss": 0.12971261764843284,
        "train_loss": 0.010122402578137834
      },
      {
        "epoch": 631,
        "reward": 0.28220033645629883,
        "val_loss": 0.16581980393051968,
        "train_loss": 0.017622003343533903
      },
      {
        "epoch": 632,
        "reward": 0.2858414947986603,
        "val_loss": 0.1599865875780649,
        "train_loss": 0.0675310153486722
      },
      {
        "epoch": 633,
        "reward": 0.2611459195613861,
        "val_loss": 0.20516148503104756,
        "train_loss": 0.04972657593484305
      },
      {
        "epoch": 634,
        "reward": 0.28729531168937683,
        "val_loss": 0.15772740510874428,
        "train_loss": 0.17001985797217528
      },
      {
        "epoch": 635,
        "reward": 0.306553453207016,
        "val_loss": 0.13114700628128567,
        "train_loss": 0.10429799544419019
      },
      {
        "epoch": 636,
        "reward": 0.2794983685016632,
        "val_loss": 0.170316317833827,
        "train_loss": 0.04066155419143168
      },
      {
        "epoch": 637,
        "reward": 0.25453415513038635,
        "val_loss": 0.21984082195974355,
        "train_loss": 782.508342279594
      },
      {
        "epoch": 638,
        "reward": 0.2701215445995331,
        "val_loss": 0.18712318024232186,
        "train_loss": 1.600229037814223
      },
      {
        "epoch": 639,
        "reward": 0.2663814425468445,
        "val_loss": 0.19439166332761357,
        "train_loss": 0.005144352066473892
      },
      {
        "epoch": 640,
        "reward": 0.23031114041805267,
        "val_loss": 0.2862499476510233,
        "train_loss": 0.6915607841793434
      },
      {
        "epoch": 641,
        "reward": 0.270986944437027,
        "val_loss": 0.18548927565903536,
        "train_loss": 0.014922628807163654
      },
      {
        "epoch": 642,
        "reward": 0.2826758325099945,
        "val_loss": 0.16504354123441903,
        "train_loss": 0.01472829598899877
      },
      {
        "epoch": 643,
        "reward": 0.2541176974773407,
        "val_loss": 0.22080845067310811,
        "train_loss": 0.02841004716649947
      },
      {
        "epoch": 644,
        "reward": 0.24811747670173645,
        "val_loss": 0.23535863311761723,
        "train_loss": 0.007034790062159748
      },
      {
        "epoch": 645,
        "reward": 0.300020694732666,
        "val_loss": 0.1395124212119429,
        "train_loss": 3.820222553927474
      },
      {
        "epoch": 646,
        "reward": 0.30198797583580017,
        "val_loss": 0.1369277186126315,
        "train_loss": 0.07743124264155855
      },
      {
        "epoch": 647,
        "reward": 0.2854183614253998,
        "val_loss": 0.16065150060083916,
        "train_loss": 0.5539262947531824
      },
      {
        "epoch": 648,
        "reward": 0.2990199029445648,
        "val_loss": 0.14084976728606438,
        "train_loss": 0.007053662820208746
      },
      {
        "epoch": 649,
        "reward": 0.2293923944234848,
        "val_loss": 0.28923672924533356,
        "train_loss": 0.23085350112345482
      },
      {
        "epoch": 650,
        "reward": 0.29166120290756226,
        "val_loss": 0.1511714229210546,
        "train_loss": 0.024492614127946302
      },
      {
        "epoch": 651,
        "reward": 0.2519899010658264,
        "val_loss": 0.22583622867906733,
        "train_loss": 0.7413839452422578
      },
      {
        "epoch": 652,
        "reward": 0.3128127157688141,
        "val_loss": 0.1236876335065712,
        "train_loss": 0.004202248360045884
      },
      {
        "epoch": 653,
        "reward": 0.2653811275959015,
        "val_loss": 0.19639432600316858,
        "train_loss": 0.17193945112335138
      },
      {
        "epoch": 654,
        "reward": 0.27765849232673645,
        "val_loss": 0.17346349279562542,
        "train_loss": 0.0023280850991096278
      },
      {
        "epoch": 655,
        "reward": 0.3087190091609955,
        "val_loss": 0.12850713192269073,
        "train_loss": 0.009707580337327762
      },
      {
        "epoch": 656,
        "reward": 0.28360745310783386,
        "val_loss": 0.16353540200257807,
        "train_loss": 0.033905174268091705
      },
      {
        "epoch": 657,
        "reward": 0.27388060092926025,
        "val_loss": 0.1801517163528063,
        "train_loss": 0.49054902484903534
      },
      {
        "epoch": 658,
        "reward": 0.2577126920223236,
        "val_loss": 0.21262646299354465,
        "train_loss": 0.04124425516811943
      },
      {
        "epoch": 659,
        "reward": 0.23899327218532562,
        "val_loss": 0.25986666577435763,
        "train_loss": 0.00438468098134483
      },
      {
        "epoch": 660,
        "reward": 0.2933974266052246,
        "val_loss": 0.14865607459380822,
        "train_loss": 0.17669405291571122
      },
      {
        "epoch": 661,
        "reward": 0.3011152446269989,
        "val_loss": 0.13806719019859365,
        "train_loss": 0.03990686734379359
      },
      {
        "epoch": 662,
        "reward": 0.30847790837287903,
        "val_loss": 0.12879792266176082,
        "train_loss": 0.005318887855817313
      },
      {
        "epoch": 663,
        "reward": 0.23496226966381073,
        "val_loss": 0.271715487041677,
        "train_loss": 0.028049967248639753
      },
      {
        "epoch": 664,
        "reward": 0.2631990611553192,
        "val_loss": 0.20085214701248333,
        "train_loss": 0.038056216558078844
      },
      {
        "epoch": 665,
        "reward": 0.2662113606929779,
        "val_loss": 0.19473043803009205,
        "train_loss": 0.033229588914134814
      },
      {
        "epoch": 666,
        "reward": 0.2808687686920166,
        "val_loss": 0.16801740615794966,
        "train_loss": 0.04497743498387326
      },
      {
        "epoch": 667,
        "reward": 0.2666698694229126,
        "val_loss": 0.1938188820204232,
        "train_loss": 0.004499260801250233
      },
      {
        "epoch": 668,
        "reward": 0.20467495918273926,
        "val_loss": 0.386994443659205,
        "train_loss": 0.03505660680373414
      },
      {
        "epoch": 669,
        "reward": 0.2668018639087677,
        "val_loss": 0.19355745420658163,
        "train_loss": 0.4401131152264078
      },
      {
        "epoch": 670,
        "reward": 0.3003048002719879,
        "val_loss": 0.13913555280305445,
        "train_loss": 0.012534924612107435
      },
      {
        "epoch": 671,
        "reward": 0.2834315001964569,
        "val_loss": 0.16381892818234128,
        "train_loss": 0.010273430405994497
      },
      {
        "epoch": 672,
        "reward": 0.26783692836761475,
        "val_loss": 0.19152240032313525,
        "train_loss": 0.0743294365204817
      },
      {
        "epoch": 673,
        "reward": 0.30830204486846924,
        "val_loss": 0.12901050011194976,
        "train_loss": 0.15115614859342502
      },
      {
        "epoch": 674,
        "reward": 0.2624213397502899,
        "val_loss": 0.20247120439723534,
        "train_loss": 0.011506369037446208
      },
      {
        "epoch": 675,
        "reward": 0.28702911734580994,
        "val_loss": 0.1581381246006848,
        "train_loss": 0.12222829235934814
      },
      {
        "epoch": 676,
        "reward": 0.2712440490722656,
        "val_loss": 0.1850072250485287,
        "train_loss": 0.07621499652766663
      },
      {
        "epoch": 677,
        "reward": 0.2768265902996063,
        "val_loss": 0.17490985079036495,
        "train_loss": 0.009523401504198913
      },
      {
        "epoch": 678,
        "reward": 0.2748176157474518,
        "val_loss": 0.17846385664389736,
        "train_loss": 0.003307767116823995
      },
      {
        "epoch": 679,
        "reward": 0.221696138381958,
        "val_loss": 0.31588354729215745,
        "train_loss": 0.10406813898281633
      },
      {
        "epoch": 680,
        "reward": 0.2942110002040863,
        "val_loss": 0.14749481573484705,
        "train_loss": 2.2590402498826734
      },
      {
        "epoch": 681,
        "reward": 0.2181577980518341,
        "val_loss": 0.3291862245116915,
        "train_loss": 0.010073710944337878
      },
      {
        "epoch": 682,
        "reward": 0.28797784447669983,
        "val_loss": 0.1566800666499018,
        "train_loss": 0.024747892906326834
      },
      {
        "epoch": 683,
        "reward": 0.28503432869911194,
        "val_loss": 0.16125787316663523,
        "train_loss": 478.1365402008299
      },
      {
        "epoch": 684,
        "reward": 0.24767203629016876,
        "val_loss": 0.23648593764353013,
        "train_loss": 0.07481256866902605
      },
      {
        "epoch": 685,
        "reward": 0.30749326944351196,
        "val_loss": 0.12999352548961593,
        "train_loss": 0.6009069654345904
      },
      {
        "epoch": 686,
        "reward": 0.2926529347896576,
        "val_loss": 0.1497284374116654,
        "train_loss": 0.10702331463555591
      },
      {
        "epoch": 687,
        "reward": 0.27436932921409607,
        "val_loss": 0.17926895553578756,
        "train_loss": 0.010324393769853767
      },
      {
        "epoch": 688,
        "reward": 0.29843565821647644,
        "val_loss": 0.14163759909985987,
        "train_loss": 0.20585121517909172
      },
      {
        "epoch": 689,
        "reward": 0.2705239951610565,
        "val_loss": 0.18636117549197348,
        "train_loss": 0.007387233308551144
      },
      {
        "epoch": 690,
        "reward": 0.28466683626174927,
        "val_loss": 0.1618407595046197,
        "train_loss": 0.04082614933884962
      },
      {
        "epoch": 691,
        "reward": 0.30513235926628113,
        "val_loss": 0.13291456317529082,
        "train_loss": 0.008663889298846837
      },
      {
        "epoch": 692,
        "reward": 0.26503434777259827,
        "val_loss": 0.19709456329500036,
        "train_loss": 0.3588896552319756
      },
      {
        "epoch": 693,
        "reward": 0.23699896037578583,
        "val_loss": 0.2656454176758416,
        "train_loss": 0.40155952206119905
      },
      {
        "epoch": 694,
        "reward": 0.2970525920391083,
        "val_loss": 0.14352381492998184,
        "train_loss": 0.03134817023629484
      },
      {
        "epoch": 695,
        "reward": 0.22093860805034637,
        "val_loss": 0.3186728504702582,
        "train_loss": 0.038498563613897065
      },
      {
        "epoch": 696,
        "reward": 0.29673871397972107,
        "val_loss": 0.14395599454292096,
        "train_loss": 0.012961166221290253
      },
      {
        "epoch": 697,
        "reward": 0.20636463165283203,
        "val_loss": 0.3790673410860888,
        "train_loss": 0.05734927589485149
      },
      {
        "epoch": 698,
        "reward": 0.2901194989681244,
        "val_loss": 0.15344810266105924,
        "train_loss": 0.01405205246136085
      },
      {
        "epoch": 699,
        "reward": 0.305100679397583,
        "val_loss": 0.132954288793761,
        "train_loss": 0.005732058107941367
      },
      {
        "epoch": 700,
        "reward": 0.21257098019123077,
        "val_loss": 0.3516898855907909,
        "train_loss": 0.01730368917616523
      },
      {
        "epoch": 701,
        "reward": 0.27807649970054626,
        "val_loss": 0.17274227484969223,
        "train_loss": 0.05175137688554689
      },
      {
        "epoch": 702,
        "reward": 0.292057603597641,
        "val_loss": 0.15059260688056902,
        "train_loss": 0.07776234677811981
      },
      {
        "epoch": 703,
        "reward": 0.30174002051353455,
        "val_loss": 0.13725030768130506,
        "train_loss": 0.1408099178771898
      },
      {
        "epoch": 704,
        "reward": 0.2404075711965561,
        "val_loss": 0.2558643680780993,
        "train_loss": 0.09327996434540882
      },
      {
        "epoch": 705,
        "reward": 0.2608417868614197,
        "val_loss": 0.20580950905735204,
        "train_loss": 0.041084804229180566
      },
      {
        "epoch": 706,
        "reward": 0.2822204530239105,
        "val_loss": 0.16578685412449495,
        "train_loss": 0.03966535030066062
      },
      {
        "epoch": 707,
        "reward": 0.27275434136390686,
        "val_loss": 0.18220648922059418,
        "train_loss": 0.15433802177190395
      },
      {
        "epoch": 708,
        "reward": 0.2324683964252472,
        "val_loss": 0.2793892232917382,
        "train_loss": 0.0357683144098141
      },
      {
        "epoch": 709,
        "reward": 0.3000034987926483,
        "val_loss": 0.1395352470592895,
        "train_loss": 0.011528171123735284
      },
      {
        "epoch": 710,
        "reward": 0.2691554129123688,
        "val_loss": 0.18896817512411093,
        "train_loss": 0.24081403413975538
      },
      {
        "epoch": 711,
        "reward": 0.304695188999176,
        "val_loss": 0.1334640211758337,
        "train_loss": 0.8411280242853536
      },
      {
        "epoch": 712,
        "reward": 0.2955038845539093,
        "val_loss": 0.14567189713956655,
        "train_loss": 0.00883601106882172
      },
      {
        "epoch": 713,
        "reward": 0.2994103729724884,
        "val_loss": 0.14032613153020584,
        "train_loss": 0.024089392573806927
      },
      {
        "epoch": 714,
        "reward": 0.2783934772014618,
        "val_loss": 0.17219782075595244,
        "train_loss": 0.04196256665510681
      },
      {
        "epoch": 715,
        "reward": 0.2957064211368561,
        "val_loss": 0.1453887675639375,
        "train_loss": 7.903748671306368
      },
      {
        "epoch": 716,
        "reward": 0.26954925060272217,
        "val_loss": 0.18821337883751507,
        "train_loss": 0.018125939334892722
      },
      {
        "epoch": 717,
        "reward": 0.3221721053123474,
        "val_loss": 0.11345088906403232,
        "train_loss": 0.13760662695354908
      },
      {
        "epoch": 718,
        "reward": 0.24820969998836517,
        "val_loss": 0.23512613520558392,
        "train_loss": 0.022554245462323215
      },
      {
        "epoch": 719,
        "reward": 0.2943931818008423,
        "val_loss": 0.14723629626678303,
        "train_loss": 0.03283911985630976
      },
      {
        "epoch": 720,
        "reward": 0.26846012473106384,
        "val_loss": 0.1903098921590884,
        "train_loss": 0.00451034460135046
      },
      {
        "epoch": 721,
        "reward": 0.3060784637928009,
        "val_loss": 0.1317346750937369,
        "train_loss": 0.004866335420047108
      },
      {
        "epoch": 722,
        "reward": 0.29352012276649475,
        "val_loss": 0.14848026713506052,
        "train_loss": 0.08421403710879251
      },
      {
        "epoch": 723,
        "reward": 0.28464430570602417,
        "val_loss": 0.16187657235838873,
        "train_loss": 0.04582511974681088
      },
      {
        "epoch": 724,
        "reward": 0.24415455758571625,
        "val_loss": 0.24562987208316503,
        "train_loss": 0.05905265114989351
      },
      {
        "epoch": 725,
        "reward": 0.3024543523788452,
        "val_loss": 0.1363233886825453,
        "train_loss": 0.06377464556862833
      },
      {
        "epoch": 726,
        "reward": 0.2608446180820465,
        "val_loss": 0.2058034535647104,
        "train_loss": 0.05449440126903937
      },
      {
        "epoch": 727,
        "reward": 0.2239450067281723,
        "val_loss": 0.30778476310245295,
        "train_loss": 0.015487523749750555
      },
      {
        "epoch": 728,
        "reward": 0.28135913610458374,
        "val_loss": 0.16720401713558072,
        "train_loss": 0.03331962727679638
      },
      {
        "epoch": 729,
        "reward": 0.28375688195228577,
        "val_loss": 0.163295053091133,
        "train_loss": 0.9426283667682862
      },
      {
        "epoch": 730,
        "reward": 0.30189141631126404,
        "val_loss": 0.13705324408199107,
        "train_loss": 0.002559466378163331
      },
      {
        "epoch": 731,
        "reward": 0.27781522274017334,
        "val_loss": 0.17319266473142697,
        "train_loss": 0.015605892578605562
      },
      {
        "epoch": 732,
        "reward": 0.2780912220478058,
        "val_loss": 0.17271697764850355,
        "train_loss": 0.0031629546958461454
      },
      {
        "epoch": 733,
        "reward": 0.27062493562698364,
        "val_loss": 0.18617061530988263,
        "train_loss": 5.49683115843688
      },
      {
        "epoch": 734,
        "reward": 0.2752309739589691,
        "val_loss": 0.17772545390263467,
        "train_loss": 8.512628468656029
      },
      {
        "epoch": 735,
        "reward": 0.31311699748039246,
        "val_loss": 0.1233380904678987,
        "train_loss": 0.16973537218823018
      },
      {
        "epoch": 736,
        "reward": 0.26042914390563965,
        "val_loss": 0.20669279109487043,
        "train_loss": 0.01163357391795636
      },
      {
        "epoch": 737,
        "reward": 0.31081563234329224,
        "val_loss": 0.12601147165072948,
        "train_loss": 0.32038398088885656
      },
      {
        "epoch": 738,
        "reward": 0.3103819191455841,
        "val_loss": 0.12652297300519422,
        "train_loss": 0.01911134929552925
      },
      {
        "epoch": 739,
        "reward": 0.23603235185146332,
        "val_loss": 0.2685046272817999,
        "train_loss": 0.010849023142817224
      },
      {
        "epoch": 740,
        "reward": 0.32522472739219666,
        "val_loss": 0.11033064541074314,
        "train_loss": 1.211458362110044
      },
      {
        "epoch": 741,
        "reward": 0.26932936906814575,
        "val_loss": 0.18863437511858397,
        "train_loss": 0.02223127209827698
      },
      {
        "epoch": 742,
        "reward": 0.30188828706741333,
        "val_loss": 0.1370573093445273,
        "train_loss": 0.016101961367789606
      },
      {
        "epoch": 743,
        "reward": 0.29250892996788025,
        "val_loss": 0.14993689606697963,
        "train_loss": 0.42941572657218785
      },
      {
        "epoch": 744,
        "reward": 0.2628777325153351,
        "val_loss": 0.20151916462262826,
        "train_loss": 0.20087557910595094
      },
      {
        "epoch": 745,
        "reward": 0.2985956370830536,
        "val_loss": 0.14142135819046026,
        "train_loss": 0.012527247230257043
      },
      {
        "epoch": 746,
        "reward": 0.22832095623016357,
        "val_loss": 0.29277007037308067,
        "train_loss": 0.008674609395746722
      },
      {
        "epoch": 747,
        "reward": 0.32567211985588074,
        "val_loss": 0.1098818432157194,
        "train_loss": 0.010122315112557071
      },
      {
        "epoch": 748,
        "reward": 0.26959481835365295,
        "val_loss": 0.18812626097185006,
        "train_loss": 0.03745592127345914
      },
      {
        "epoch": 749,
        "reward": 0.29647621512413025,
        "val_loss": 0.1443187166753757,
        "train_loss": 0.01736334293463397
      },
      {
        "epoch": 750,
        "reward": 0.26424095034599304,
        "val_loss": 0.19870822475890496,
        "train_loss": 0.00760743383748027
      },
      {
        "epoch": 751,
        "reward": 0.2837136387825012,
        "val_loss": 0.1633645894471556,
        "train_loss": 0.1595571164241654
      },
      {
        "epoch": 752,
        "reward": 0.2948492169380188,
        "val_loss": 0.14659156606025395,
        "train_loss": 0.6681656657435199
      },
      {
        "epoch": 753,
        "reward": 0.310907244682312,
        "val_loss": 0.1259036977841918,
        "train_loss": 0.020143545805834807
      },
      {
        "epoch": 754,
        "reward": 0.2865825593471527,
        "val_loss": 0.15883008340772772,
        "train_loss": 4.539960255960557
      },
      {
        "epoch": 755,
        "reward": 0.2833743691444397,
        "val_loss": 0.16391111294173502,
        "train_loss": 309.0475557070867
      },
      {
        "epoch": 756,
        "reward": 0.24371269345283508,
        "val_loss": 0.24680970552227727,
        "train_loss": 3.4454140850122292
      },
      {
        "epoch": 757,
        "reward": 0.2869527041912079,
        "val_loss": 0.1582562187104486,
        "train_loss": 0.01685183552259472
      },
      {
        "epoch": 758,
        "reward": 0.31898343563079834,
        "val_loss": 0.11682180916873872,
        "train_loss": 0.03674334428265306
      },
      {
        "epoch": 759,
        "reward": 0.3196858763694763,
        "val_loss": 0.11606922803912312,
        "train_loss": 3.1409354321454326
      },
      {
        "epoch": 760,
        "reward": 0.319320410490036,
        "val_loss": 0.11646007112826087,
        "train_loss": 0.010187789803379789
      },
      {
        "epoch": 761,
        "reward": 0.2822078466415405,
        "val_loss": 0.16580747521116532,
        "train_loss": 0.011956649016820638
      },
      {
        "epoch": 762,
        "reward": 0.302059143781662,
        "val_loss": 0.1368352933121579,
        "train_loss": 0.02211355588056344
      },
      {
        "epoch": 763,
        "reward": 0.30418574810028076,
        "val_loss": 0.13410771253984421,
        "train_loss": 0.1667101993905537
      },
      {
        "epoch": 764,
        "reward": 0.3302435874938965,
        "val_loss": 0.10541679349262267,
        "train_loss": 0.01070245823883362
      },
      {
        "epoch": 765,
        "reward": 0.22011175751686096,
        "val_loss": 0.32175340280186254,
        "train_loss": 0.013710037039485402
      },
      {
        "epoch": 766,
        "reward": 0.30680161714553833,
        "val_loss": 0.1308412573583025,
        "train_loss": 0.07349814849742241
      },
      {
        "epoch": 767,
        "reward": 0.29641786217689514,
        "val_loss": 0.14439953784208878,
        "train_loss": 0.015994436238263285
      },
      {
        "epoch": 768,
        "reward": 0.3287217617034912,
        "val_loss": 0.1068791853654797,
        "train_loss": 0.009556620316848589
      },
      {
        "epoch": 769,
        "reward": 0.29442790150642395,
        "val_loss": 0.14718706971117562,
        "train_loss": 0.09032583821821251
      },
      {
        "epoch": 770,
        "reward": 0.28471946716308594,
        "val_loss": 0.16175709935903018,
        "train_loss": 0.23834512160773066
      },
      {
        "epoch": 771,
        "reward": 0.2766253650188446,
        "val_loss": 0.1752618403656275,
        "train_loss": 0.2870526601624218
      },
      {
        "epoch": 772,
        "reward": 0.32960712909698486,
        "val_loss": 0.10602551555660154,
        "train_loss": 0.019732345883102635
      },
      {
        "epoch": 773,
        "reward": 0.2956540584564209,
        "val_loss": 0.14546189445952354,
        "train_loss": 0.018060754891848774
      },
      {
        "epoch": 774,
        "reward": 0.3142128586769104,
        "val_loss": 0.1220887676671347,
        "train_loss": 0.04149910181961157
      },
      {
        "epoch": 775,
        "reward": 0.3049800992012024,
        "val_loss": 0.13310559378130296,
        "train_loss": 0.6207461075296473
      },
      {
        "epoch": 776,
        "reward": 0.2634839713573456,
        "val_loss": 0.20026312875727723,
        "train_loss": 0.005253887434334432
      },
      {
        "epoch": 777,
        "reward": 0.29839640855789185,
        "val_loss": 0.14169070270768966,
        "train_loss": 0.056158399433194554
      },
      {
        "epoch": 778,
        "reward": 0.22184334695339203,
        "val_loss": 0.31534513575856443,
        "train_loss": 0.10162057079679261
      },
      {
        "epoch": 779,
        "reward": 0.25338366627693176,
        "val_loss": 0.22252699968105713,
        "train_loss": 0.1727606291289983
      },
      {
        "epoch": 780,
        "reward": 0.2924099862575531,
        "val_loss": 0.15008037103273505,
        "train_loss": 0.06702982525082636
      },
      {
        "epoch": 781,
        "reward": 0.2843664586544037,
        "val_loss": 0.1623190598038491,
        "train_loss": 0.0073412449041475505
      },
      {
        "epoch": 782,
        "reward": 0.2927764058113098,
        "val_loss": 0.14954992515933035,
        "train_loss": 53.73881521980981
      },
      {
        "epoch": 783,
        "reward": 0.2887794077396393,
        "val_loss": 0.15546088664892263,
        "train_loss": 0.1709649088932985
      },
      {
        "epoch": 784,
        "reward": 0.29788607358932495,
        "val_loss": 0.14238349887974827,
        "train_loss": 0.025325825029750167
      },
      {
        "epoch": 785,
        "reward": 0.30453112721443176,
        "val_loss": 0.13367091786598653,
        "train_loss": 0.050577824816942805
      },
      {
        "epoch": 786,
        "reward": 0.2810649573802948,
        "val_loss": 0.1676913953456928,
        "train_loss": 0.012708789949661318
      },
      {
        "epoch": 787,
        "reward": 0.26903221011161804,
        "val_loss": 0.18920514630735852,
        "train_loss": 0.001976228924132346
      },
      {
        "epoch": 788,
        "reward": 0.27584108710289,
        "val_loss": 0.17664234368878948,
        "train_loss": 0.10236533816259907
      },
      {
        "epoch": 789,
        "reward": 0.27494335174560547,
        "val_loss": 0.1782388317972488,
        "train_loss": 0.05991555160128952
      },
      {
        "epoch": 790,
        "reward": 0.31313765048980713,
        "val_loss": 0.1233143719000509,
        "train_loss": 0.13415450272945095
      },
      {
        "epoch": 791,
        "reward": 0.27037784457206726,
        "val_loss": 0.18663742922944948,
        "train_loss": 0.01638611790426344
      },
      {
        "epoch": 792,
        "reward": 0.2592093050479889,
        "val_loss": 0.20933160207433893,
        "train_loss": 0.4882901837520946
      },
      {
        "epoch": 793,
        "reward": 0.26408228278160095,
        "val_loss": 0.19903288957928972,
        "train_loss": 0.007786037304292939
      },
      {
        "epoch": 794,
        "reward": 0.3156002461910248,
        "val_loss": 0.1205285562152442,
        "train_loss": 0.0033554826060472245
      },
      {
        "epoch": 795,
        "reward": 0.3085585832595825,
        "val_loss": 0.1287005295661012,
        "train_loss": 0.01055171541800239
      },
      {
        "epoch": 796,
        "reward": 0.29218006134033203,
        "val_loss": 0.15041437494801357,
        "train_loss": 1.5207628971393905
      },
      {
        "epoch": 797,
        "reward": 0.25991740822792053,
        "val_loss": 0.20779474825082747,
        "train_loss": 0.021850098245032805
      },
      {
        "epoch": 798,
        "reward": 0.27469849586486816,
        "val_loss": 0.17867734743049368,
        "train_loss": 0.05595758057265462
      },
      {
        "epoch": 799,
        "reward": 0.3129071295261383,
        "val_loss": 0.12357905102128695,
        "train_loss": 0.025086985136183033
      },
      {
        "epoch": 800,
        "reward": 0.2914350926876068,
        "val_loss": 0.1515027595243217,
        "train_loss": 1.4219974977422418
      },
      {
        "epoch": 801,
        "reward": 0.32262593507766724,
        "val_loss": 0.11298047544966851,
        "train_loss": 0.08897802425074658
      },
      {
        "epoch": 802,
        "reward": 0.2804587781429291,
        "val_loss": 0.16870116294843943,
        "train_loss": 0.009290461188916547
      },
      {
        "epoch": 803,
        "reward": 0.30077704787254333,
        "val_loss": 0.13851187373178878,
        "train_loss": 0.00923429434456361
      },
      {
        "epoch": 804,
        "reward": 0.2373381108045578,
        "val_loss": 0.26465127449150067,
        "train_loss": 0.01385384336068595
      },
      {
        "epoch": 805,
        "reward": 0.3176850974559784,
        "val_loss": 0.118228173170272,
        "train_loss": 0.011779038464038213
      },
      {
        "epoch": 806,
        "reward": 0.32654663920402527,
        "val_loss": 0.10901078306155146,
        "train_loss": 0.08551646259645797
      },
      {
        "epoch": 807,
        "reward": 0.3080958127975464,
        "val_loss": 0.12926030123864102,
        "train_loss": 0.025187874568403528
      },
      {
        "epoch": 808,
        "reward": 0.2813678979873657,
        "val_loss": 0.16718950276429365,
        "train_loss": 0.006987115809728004
      },
      {
        "epoch": 809,
        "reward": 0.2872178256511688,
        "val_loss": 0.15784680076259455,
        "train_loss": 0.04806763511022347
      },
      {
        "epoch": 810,
        "reward": 0.2529262602329254,
        "val_loss": 0.22360628682820657,
        "train_loss": 0.055135950726393136
      },
      {
        "epoch": 811,
        "reward": 0.2955813705921173,
        "val_loss": 0.14556349812690833,
        "train_loss": 0.01653434153418997
      },
      {
        "epoch": 812,
        "reward": 0.2986610233783722,
        "val_loss": 0.14133304784939224,
        "train_loss": 0.661659488249615
      },
      {
        "epoch": 813,
        "reward": 0.3093797564506531,
        "val_loss": 0.1277143615110877,
        "train_loss": 0.019847719948861944
      },
      {
        "epoch": 814,
        "reward": 0.3087235689163208,
        "val_loss": 0.12850166385136877,
        "train_loss": 0.07548478024280204
      },
      {
        "epoch": 815,
        "reward": 0.22787582874298096,
        "val_loss": 0.2942541618249379,
        "train_loss": 9.335910527146133
      },
      {
        "epoch": 816,
        "reward": 0.27301767468452454,
        "val_loss": 0.181723491604706,
        "train_loss": 0.0955901948056215
      },
      {
        "epoch": 817,
        "reward": 0.23855428397655487,
        "val_loss": 0.26112488454340826,
        "train_loss": 0.004412971435731204
      },
      {
        "epoch": 818,
        "reward": 0.3063003718852997,
        "val_loss": 0.13145971955548572,
        "train_loss": 0.035969501375383024
      },
      {
        "epoch": 819,
        "reward": 0.28289684653282166,
        "val_loss": 0.1646841957491623,
        "train_loss": 0.048270089230230115
      },
      {
        "epoch": 820,
        "reward": 0.3171803653240204,
        "val_loss": 0.11878029576369695,
        "train_loss": 0.020319845241689248
      },
      {
        "epoch": 821,
        "reward": 0.28268563747406006,
        "val_loss": 0.16502756511908956,
        "train_loss": 0.002845216897080368
      },
      {
        "epoch": 822,
        "reward": 0.27697858214378357,
        "val_loss": 0.17464446231107494,
        "train_loss": 0.004187325274520285
      },
      {
        "epoch": 823,
        "reward": 0.2915545403957367,
        "val_loss": 0.1513275674244921,
        "train_loss": 0.019391113086595187
      },
      {
        "epoch": 824,
        "reward": 0.3248485028743744,
        "val_loss": 0.1107096432263331,
        "train_loss": 1.2847388789879495
      },
      {
        "epoch": 825,
        "reward": 0.3112565279006958,
        "val_loss": 0.12549399218862942,
        "train_loss": 0.02330596628036556
      },
      {
        "epoch": 826,
        "reward": 0.3144512176513672,
        "val_loss": 0.121819000254618,
        "train_loss": 0.009770013772140373
      },
      {
        "epoch": 827,
        "reward": 0.30201441049575806,
        "val_loss": 0.13689337255034065,
        "train_loss": 7.733352041627838
      },
      {
        "epoch": 828,
        "reward": 0.3198133707046509,
        "val_loss": 0.1159332002924722,
        "train_loss": 0.007030562621646543
      },
      {
        "epoch": 829,
        "reward": 0.26459285616874695,
        "val_loss": 0.19799056547760432,
        "train_loss": 0.011859196666171976
      },
      {
        "epoch": 830,
        "reward": 0.2868410348892212,
        "val_loss": 0.15842910395752238,
        "train_loss": 0.1368917692476456
      },
      {
        "epoch": 831,
        "reward": 0.3234890401363373,
        "val_loss": 0.11209222439044554,
        "train_loss": 0.026177482115319714
      },
      {
        "epoch": 832,
        "reward": 0.27880361676216125,
        "val_loss": 0.17149646946927533,
        "train_loss": 0.09706083343301614
      },
      {
        "epoch": 833,
        "reward": 0.2611452043056488,
        "val_loss": 0.20516299426838355,
        "train_loss": 0.0036234559698081845
      },
      {
        "epoch": 834,
        "reward": 0.25392946600914,
        "val_loss": 0.2212476073597957,
        "train_loss": 0.18097386314037486
      },
      {
        "epoch": 835,
        "reward": 0.2748440206050873,
        "val_loss": 0.17841655870766512,
        "train_loss": 0.13359908376738672
      },
      {
        "epoch": 836,
        "reward": 0.33620136976242065,
        "val_loss": 0.09991221921102676,
        "train_loss": 0.02353905744922276
      },
      {
        "epoch": 837,
        "reward": 0.2698381841182709,
        "val_loss": 0.18766201281271475,
        "train_loss": 0.004344459213126146
      },
      {
        "epoch": 838,
        "reward": 0.3234717547893524,
        "val_loss": 0.11210991356347222,
        "train_loss": 0.09094169937158697
      },
      {
        "epoch": 839,
        "reward": 0.3207012414932251,
        "val_loss": 0.11499135483921107,
        "train_loss": 0.010448466052016906
      },
      {
        "epoch": 840,
        "reward": 0.30448195338249207,
        "val_loss": 0.13373301206073457,
        "train_loss": 0.9373919336075442
      },
      {
        "epoch": 841,
        "reward": 0.2684559226036072,
        "val_loss": 0.19031803495766195,
        "train_loss": 0.33959380665888045
      },
      {
        "epoch": 842,
        "reward": 0.2517390549182892,
        "val_loss": 0.22643829983176797,
        "train_loss": 0.07450370624492454
      },
      {
        "epoch": 843,
        "reward": 0.2733915448188782,
        "val_loss": 0.1810404567887807,
        "train_loss": 0.006152829155535773
      },
      {
        "epoch": 844,
        "reward": 0.28488603234291077,
        "val_loss": 0.16149277625871555,
        "train_loss": 0.0077678420951682575
      },
      {
        "epoch": 845,
        "reward": 0.3014182448387146,
        "val_loss": 0.1376703295765245,
        "train_loss": 0.03143363256906294
      },
      {
        "epoch": 846,
        "reward": 0.2894308567047119,
        "val_loss": 0.15447844823938794,
        "train_loss": 0.34150496566424127
      },
      {
        "epoch": 847,
        "reward": 0.2956889271736145,
        "val_loss": 0.14541318937387718,
        "train_loss": 27.815084402309086
      },
      {
        "epoch": 848,
        "reward": 0.3390660583972931,
        "val_loss": 0.0973850739018027,
        "train_loss": 0.24657548472455695
      },
      {
        "epoch": 849,
        "reward": 0.2976619303226471,
        "val_loss": 0.14268908540751518,
        "train_loss": 0.010288146052167017
      },
      {
        "epoch": 850,
        "reward": 0.29377391934394836,
        "val_loss": 0.14811736053837063,
        "train_loss": 0.03635066333943261
      },
      {
        "epoch": 851,
        "reward": 0.2866235077381134,
        "val_loss": 0.1587665142017483,
        "train_loss": 0.009204406369043192
      },
      {
        "epoch": 852,
        "reward": 0.3045210838317871,
        "val_loss": 0.13368360268110077,
        "train_loss": 0.02242438802596343
      },
      {
        "epoch": 853,
        "reward": 0.21169207990169525,
        "val_loss": 0.35540826162157046,
        "train_loss": 0.2009544073138246
      },
      {
        "epoch": 854,
        "reward": 0.3131488263607025,
        "val_loss": 0.12330156202993489,
        "train_loss": 0.023410627756430376
      },
      {
        "epoch": 855,
        "reward": 0.3074249029159546,
        "val_loss": 0.13007700924312562,
        "train_loss": 0.007149045275022777
      },
      {
        "epoch": 856,
        "reward": 0.268449604511261,
        "val_loss": 0.19033032080291637,
        "train_loss": 0.6277092063982519
      },
      {
        "epoch": 857,
        "reward": 0.3147270679473877,
        "val_loss": 0.12150770736168072,
        "train_loss": 0.00878730670088911
      },
      {
        "epoch": 858,
        "reward": 0.20428466796875,
        "val_loss": 0.3888559848918313,
        "train_loss": 0.02703027959236911
      },
      {
        "epoch": 859,
        "reward": 0.2978275418281555,
        "val_loss": 0.14246322138517695,
        "train_loss": 0.026645459436622332
      },
      {
        "epoch": 860,
        "reward": 0.3356575667858124,
        "val_loss": 0.10040052282732047,
        "train_loss": 0.6843497347788519
      },
      {
        "epoch": 861,
        "reward": 0.265503853559494,
        "val_loss": 0.19614734548044258,
        "train_loss": 0.010149607522897406
      },
      {
        "epoch": 862,
        "reward": 0.3134675920009613,
        "val_loss": 0.12293674503702537,
        "train_loss": 0.33881955815419273
      },
      {
        "epoch": 863,
        "reward": 0.3120243549346924,
        "val_loss": 0.1245988226229591,
        "train_loss": 0.004967548111319677
      },
      {
        "epoch": 864,
        "reward": 0.295258492231369,
        "val_loss": 0.14601577319263015,
        "train_loss": 0.03447082844426264
      },
      {
        "epoch": 865,
        "reward": 0.33734050393104553,
        "val_loss": 0.09889828900382522,
        "train_loss": 0.0018712784700395647
      },
      {
        "epoch": 866,
        "reward": 0.31468841433525085,
        "val_loss": 0.12155127730927363,
        "train_loss": 1.8012810533568882
      },
      {
        "epoch": 867,
        "reward": 0.3033745586872101,
        "val_loss": 0.1351404261076823,
        "train_loss": 0.01965852145971999
      },
      {
        "epoch": 868,
        "reward": 0.2891511619091034,
        "val_loss": 0.15489930460794962,
        "train_loss": 0.04417866147391928
      },
      {
        "epoch": 869,
        "reward": 0.32067710161209106,
        "val_loss": 0.11501687847443723,
        "train_loss": 0.007902924730912603
      },
      {
        "epoch": 870,
        "reward": 0.2852989733219147,
        "val_loss": 0.1608396959116882,
        "train_loss": 0.07182996889493481
      },
      {
        "epoch": 871,
        "reward": 0.2987687885761261,
        "val_loss": 0.14118772639735003,
        "train_loss": 0.024187820442491032
      },
      {
        "epoch": 872,
        "reward": 0.2864438593387604,
        "val_loss": 0.15904574926493556,
        "train_loss": 0.007840270391310557
      },
      {
        "epoch": 873,
        "reward": 0.2848442792892456,
        "val_loss": 0.16155898019288933,
        "train_loss": 0.011149414944576655
      },
      {
        "epoch": 874,
        "reward": 0.30913588404655457,
        "val_loss": 0.12800632504513487,
        "train_loss": 0.01324047315896538
      },
      {
        "epoch": 875,
        "reward": 0.31311964988708496,
        "val_loss": 0.12333500084059779,
        "train_loss": 0.06076816673023062
      },
      {
        "epoch": 876,
        "reward": 0.2657109200954437,
        "val_loss": 0.1957313270041985,
        "train_loss": 0.009789083855279247
      },
      {
        "epoch": 877,
        "reward": 0.3367498219013214,
        "val_loss": 0.09942255389718671,
        "train_loss": 0.023532112875098113
      },
      {
        "epoch": 878,
        "reward": 0.25135931372642517,
        "val_loss": 0.22735363876979267,
        "train_loss": 0.13973307991559872
      },
      {
        "epoch": 879,
        "reward": 0.32520613074302673,
        "val_loss": 0.11034930917958263,
        "train_loss": 0.07331270733238153
      },
      {
        "epoch": 880,
        "reward": 0.24363408982753754,
        "val_loss": 0.24702036806931055,
        "train_loss": 0.007522107296608738
      },
      {
        "epoch": 881,
        "reward": 0.24843378365039825,
        "val_loss": 0.23456227793108805,
        "train_loss": 0.00426564507571269
      },
      {
        "epoch": 882,
        "reward": 0.32619374990463257,
        "val_loss": 0.10936129812450547,
        "train_loss": 0.049634521280845195
      },
      {
        "epoch": 883,
        "reward": 0.2766464650630951,
        "val_loss": 0.17522488423855975,
        "train_loss": 0.5470366608365461
      },
      {
        "epoch": 884,
        "reward": 0.29959529638290405,
        "val_loss": 0.14007901188077604,
        "train_loss": 1.0229865307908488
      },
      {
        "epoch": 885,
        "reward": 0.26833805441856384,
        "val_loss": 0.19054664881800168,
        "train_loss": 0.017604964877626535
      },
      {
        "epoch": 886,
        "reward": 0.3264501988887787,
        "val_loss": 0.10910649202872134,
        "train_loss": 0.009389227589403722
      },
      {
        "epoch": 887,
        "reward": 0.2902126610279083,
        "val_loss": 0.15330936602341744,
        "train_loss": 0.010163044743351817
      },
      {
        "epoch": 888,
        "reward": 0.2807791233062744,
        "val_loss": 0.16816667212073558,
        "train_loss": 0.00944183795581921
      },
      {
        "epoch": 889,
        "reward": 0.23771218955516815,
        "val_loss": 0.26356025235145353,
        "train_loss": 1.1719251610279922
      },
      {
        "epoch": 890,
        "reward": 0.3353109359741211,
        "val_loss": 0.10071321521536447,
        "train_loss": 0.08946220984496624
      },
      {
        "epoch": 891,
        "reward": 0.30233892798423767,
        "val_loss": 0.13647266831581614,
        "train_loss": 0.006233041756506561
      },
      {
        "epoch": 892,
        "reward": 0.30526790022850037,
        "val_loss": 0.1327447642252082,
        "train_loss": 1.0336314093681442
      },
      {
        "epoch": 893,
        "reward": 0.2644534111022949,
        "val_loss": 0.19827450943245953,
        "train_loss": 0.004224651547369481
      },
      {
        "epoch": 894,
        "reward": 0.32771798968315125,
        "val_loss": 0.10785673558296237,
        "train_loss": 0.00878143504122328
      },
      {
        "epoch": 895,
        "reward": 0.33970892429351807,
        "val_loss": 0.09682820045106512,
        "train_loss": 0.04610770280662389
      },
      {
        "epoch": 896,
        "reward": 0.3364267349243164,
        "val_loss": 0.09971065285623938,
        "train_loss": 0.005433006122984807
      },
      {
        "epoch": 897,
        "reward": 0.308940589427948,
        "val_loss": 0.1282406392752559,
        "train_loss": 0.22621792848894984
      },
      {
        "epoch": 898,
        "reward": 0.26303526759147644,
        "val_loss": 0.20119178666625107,
        "train_loss": 7.784730354969724
      },
      {
        "epoch": 899,
        "reward": 0.23825764656066895,
        "val_loss": 0.26197959355444517,
        "train_loss": 0.01563125430738392
      },
      {
        "epoch": 900,
        "reward": 0.33239123225212097,
        "val_loss": 0.1033926801506563,
        "train_loss": 0.027983957079413813
      },
      {
        "epoch": 901,
        "reward": 0.30020710825920105,
        "val_loss": 0.1392649853182125,
        "train_loss": 6.883654100639922
      },
      {
        "epoch": 902,
        "reward": 0.31192275881767273,
        "val_loss": 0.12471686025050335,
        "train_loss": 0.16443200952065895
      },
      {
        "epoch": 903,
        "reward": 0.2555028200149536,
        "val_loss": 0.21761040047775687,
        "train_loss": 0.006030766414579165
      },
      {
        "epoch": 904,
        "reward": 0.2995060682296753,
        "val_loss": 0.1401981778409598,
        "train_loss": 0.011805706077771342
      },
      {
        "epoch": 905,
        "reward": 0.3142974376678467,
        "val_loss": 0.12199297036983937,
        "train_loss": 0.09577140075271018
      },
      {
        "epoch": 906,
        "reward": 0.33662843704223633,
        "val_loss": 0.09953067534869271,
        "train_loss": 0.031927785699036364
      },
      {
        "epoch": 907,
        "reward": 0.27335044741630554,
        "val_loss": 0.1811154240941895,
        "train_loss": 0.01718226797703
      },
      {
        "epoch": 908,
        "reward": 0.29177165031433105,
        "val_loss": 0.15100986969524197,
        "train_loss": 0.7247809636619422
      },
      {
        "epoch": 909,
        "reward": 0.34509265422821045,
        "val_loss": 0.09230669460209485,
        "train_loss": 0.43724538083188236
      },
      {
        "epoch": 910,
        "reward": 0.27473315596580505,
        "val_loss": 0.17861520277594017,
        "train_loss": 0.2590416479509328
      },
      {
        "epoch": 911,
        "reward": 0.24199096858501434,
        "val_loss": 0.2514753167384437,
        "train_loss": 0.24748441699613558
      },
      {
        "epoch": 912,
        "reward": 0.3104109764099121,
        "val_loss": 0.12648859172726848,
        "train_loss": 0.046887844358270044
      },
      {
        "epoch": 913,
        "reward": 0.30808472633361816,
        "val_loss": 0.1292737477467329,
        "train_loss": 9.100512183633258
      },
      {
        "epoch": 914,
        "reward": 0.29271358251571655,
        "val_loss": 0.14964072111927504,
        "train_loss": 0.024350613587120488
      },
      {
        "epoch": 915,
        "reward": 0.2958631217479706,
        "val_loss": 0.14517018018939,
        "train_loss": 11.808385763535625
      },
      {
        "epoch": 916,
        "reward": 0.28377577662467957,
        "val_loss": 0.16326467043005063,
        "train_loss": 0.00850574985592035
      },
      {
        "epoch": 917,
        "reward": 0.33407458662986755,
        "val_loss": 0.10183781144483614,
        "train_loss": 0.0044745615205101785
      },
      {
        "epoch": 918,
        "reward": 0.3399343192577362,
        "val_loss": 0.09663383718205816,
        "train_loss": 0.0546152985619371
      },
      {
        "epoch": 919,
        "reward": 0.3170783817768097,
        "val_loss": 0.1188921983765405,
        "train_loss": 0.03229464126931047
      },
      {
        "epoch": 920,
        "reward": 0.3430282771587372,
        "val_loss": 0.0940109321672935,
        "train_loss": 0.25696105368898803
      },
      {
        "epoch": 921,
        "reward": 0.2791810631752014,
        "val_loss": 0.1708541097531062,
        "train_loss": 0.12330653566711519
      },
      {
        "epoch": 922,
        "reward": 0.3008647561073303,
        "val_loss": 0.13839633126709877,
        "train_loss": 0.01273466489535097
      },
      {
        "epoch": 923,
        "reward": 0.2929372489452362,
        "val_loss": 0.14931781266932376,
        "train_loss": 2152.5462357914516
      },
      {
        "epoch": 924,
        "reward": 0.22267870604991913,
        "val_loss": 0.3123120132700673,
        "train_loss": 0.20420978497615858
      },
      {
        "epoch": 925,
        "reward": 0.3360618054866791,
        "val_loss": 0.10003729892819788,
        "train_loss": 0.06956708302861724
      },
      {
        "epoch": 926,
        "reward": 0.31227436661720276,
        "val_loss": 0.12430903152978447,
        "train_loss": 0.08336854372209228
      },
      {
        "epoch": 927,
        "reward": 0.31555303931236267,
        "val_loss": 0.12058120995477241,
        "train_loss": 0.008714276718260057
      },
      {
        "epoch": 928,
        "reward": 0.30969545245170593,
        "val_loss": 0.1273376180761261,
        "train_loss": 0.04048957130523307
      },
      {
        "epoch": 929,
        "reward": 0.21804796159267426,
        "val_loss": 0.3296105899706682,
        "train_loss": 5.5401954072706125
      },
      {
        "epoch": 930,
        "reward": 0.24086299538612366,
        "val_loss": 0.25459216278561925,
        "train_loss": 0.010829927659730086
      },
      {
        "epoch": 931,
        "reward": 0.22989051043987274,
        "val_loss": 0.28761251581766245,
        "train_loss": 0.019524541638859843
      },
      {
        "epoch": 932,
        "reward": 0.35509011149406433,
        "val_loss": 0.08454067926504649,
        "train_loss": 1.6411610761209046
      },
      {
        "epoch": 933,
        "reward": 0.26958557963371277,
        "val_loss": 0.18814391010008485,
        "train_loss": 0.16427885190149447
      },
      {
        "epoch": 934,
        "reward": 0.2523428201675415,
        "val_loss": 0.2249924631947319,
        "train_loss": 0.765475150724989
      },
      {
        "epoch": 935,
        "reward": 0.30104678869247437,
        "val_loss": 0.1381570788341508,
        "train_loss": 0.02981879079841467
      },
      {
        "epoch": 936,
        "reward": 0.3264504373073578,
        "val_loss": 0.1091061729842165,
        "train_loss": 0.022147773506731028
      },
      {
        "epoch": 937,
        "reward": 0.32142412662506104,
        "val_loss": 0.11423119250061323,
        "train_loss": 0.012540261714933037
      },
      {
        "epoch": 938,
        "reward": 0.30662861466407776,
        "val_loss": 0.13105434306531347,
        "train_loss": 0.03840884214444556
      },
      {
        "epoch": 939,
        "reward": 0.26857098937034607,
        "val_loss": 0.19009518694448552,
        "train_loss": 0.01464504948713651
      },
      {
        "epoch": 940,
        "reward": 0.24426904320716858,
        "val_loss": 0.24532537547306024,
        "train_loss": 0.006082126769027896
      },
      {
        "epoch": 941,
        "reward": 0.279784232378006,
        "val_loss": 0.1698336502553762,
        "train_loss": 0.035232976428093164
      },
      {
        "epoch": 942,
        "reward": 0.2890286147594452,
        "val_loss": 0.15508413598789567,
        "train_loss": 0.010048755386378616
      },
      {
        "epoch": 943,
        "reward": 0.3242785632610321,
        "val_loss": 0.11128681740540612,
        "train_loss": 0.009194734601666053
      },
      {
        "epoch": 944,
        "reward": 0.3085099756717682,
        "val_loss": 0.12875922309675453,
        "train_loss": 0.018178136901741918
      },
      {
        "epoch": 945,
        "reward": 0.2540748119354248,
        "val_loss": 0.22090837192289264,
        "train_loss": 0.01854958467223556
      },
      {
        "epoch": 946,
        "reward": 0.2904610335826874,
        "val_loss": 0.1529401676546383,
        "train_loss": 0.028487599315457583
      },
      {
        "epoch": 947,
        "reward": 0.3467992842197418,
        "val_loss": 0.09092468895167778,
        "train_loss": 0.024995194139102332
      },
      {
        "epoch": 948,
        "reward": 0.24466876685619354,
        "val_loss": 0.244265820581599,
        "train_loss": 0.07559126662090421
      },
      {
        "epoch": 949,
        "reward": 0.2707781493663788,
        "val_loss": 0.1858818846521899,
        "train_loss": 0.023410645267386617
      },
      {
        "epoch": 950,
        "reward": 0.28916388750076294,
        "val_loss": 0.15488014774746262,
        "train_loss": 0.059147813445100346
      },
      {
        "epoch": 951,
        "reward": 0.2890712022781372,
        "val_loss": 0.15501986989069597,
        "train_loss": 0.03951513526520172
      },
      {
        "epoch": 952,
        "reward": 0.32908979058265686,
        "val_loss": 0.10652334622864146,
        "train_loss": 0.0681571122013338
      },
      {
        "epoch": 953,
        "reward": 0.27891281247138977,
        "val_loss": 0.1713103384660956,
        "train_loss": 0.005331445753024757
      },
      {
        "epoch": 954,
        "reward": 0.3166823089122772,
        "val_loss": 0.119328077886686,
        "train_loss": 0.046083421504940464
      },
      {
        "epoch": 955,
        "reward": 0.29642125964164734,
        "val_loss": 0.1443948077753053,
        "train_loss": 0.03843034991719973
      },
      {
        "epoch": 956,
        "reward": 0.29197442531585693,
        "val_loss": 0.15071381123353994,
        "train_loss": 0.008472403669517146
      },
      {
        "epoch": 957,
        "reward": 0.26581788063049316,
        "val_loss": 0.19551679695723578,
        "train_loss": 0.07031215118030769
      },
      {
        "epoch": 958,
        "reward": 0.28999555110931396,
        "val_loss": 0.1536329260686346,
        "train_loss": 0.032605368108656524
      },
      {
        "epoch": 959,
        "reward": 0.2688305974006653,
        "val_loss": 0.18959353606831947,
        "train_loss": 0.038344615657400445
      },
      {
        "epoch": 960,
        "reward": 0.3071826696395874,
        "val_loss": 0.1303734077810077,
        "train_loss": 0.010913162770660935
      },
      {
        "epoch": 961,
        "reward": 0.2878347337245941,
        "val_loss": 0.15689895776449703,
        "train_loss": 0.007625147040086561
      },
      {
        "epoch": 962,
        "reward": 0.32578858733177185,
        "val_loss": 0.10976536352661372,
        "train_loss": 0.5448237023038718
      },
      {
        "epoch": 963,
        "reward": 0.3494397699832916,
        "val_loss": 0.08883319400359012,
        "train_loss": 0.11778161961242753
      },
      {
        "epoch": 964,
        "reward": 0.27306970953941345,
        "val_loss": 0.1816282743280421,
        "train_loss": 0.02226673675949524
      },
      {
        "epoch": 965,
        "reward": 0.3102993369102478,
        "val_loss": 0.1266206575715582,
        "train_loss": 1.9900512580246028
      },
      {
        "epoch": 966,
        "reward": 0.3389037549495697,
        "val_loss": 0.09752623267663044,
        "train_loss": 0.009780216975159944
      },
      {
        "epoch": 967,
        "reward": 0.31991711258888245,
        "val_loss": 0.11582268170812833,
        "train_loss": 0.3159362066955789
      },
      {
        "epoch": 968,
        "reward": 0.2951149642467499,
        "val_loss": 0.14621736533341131,
        "train_loss": 0.00771541399304764
      },
      {
        "epoch": 969,
        "reward": 0.3268067538738251,
        "val_loss": 0.1087532738248618,
        "train_loss": 3.4943955786129663
      },
      {
        "epoch": 970,
        "reward": 0.26952144503593445,
        "val_loss": 0.1882665369152424,
        "train_loss": 0.11815424312933505
      },
      {
        "epoch": 971,
        "reward": 0.33781322836875916,
        "val_loss": 0.09848104630197797,
        "train_loss": 0.10013952319919693
      },
      {
        "epoch": 972,
        "reward": 0.29026803374290466,
        "val_loss": 0.153226933940979,
        "train_loss": 0.0036586009219508222
      },
      {
        "epoch": 973,
        "reward": 0.30712899565696716,
        "val_loss": 0.13043915891986607,
        "train_loss": 0.11934307708158415
      },
      {
        "epoch": 974,
        "reward": 0.25527721643447876,
        "val_loss": 0.21812736156945384,
        "train_loss": 0.021767134564400364
      },
      {
        "epoch": 975,
        "reward": 0.2813955545425415,
        "val_loss": 0.16714382312576553,
        "train_loss": 0.019969614015001122
      },
      {
        "epoch": 976,
        "reward": 0.3269214630126953,
        "val_loss": 0.1086399240386007,
        "train_loss": 0.009270044151540228
      },
      {
        "epoch": 977,
        "reward": 0.276957631111145,
        "val_loss": 0.17468101365375333,
        "train_loss": 0.019245648882413383
      },
      {
        "epoch": 978,
        "reward": 0.3249038755893707,
        "val_loss": 0.1106537893189982,
        "train_loss": 0.017566351103526428
      },
      {
        "epoch": 979,
        "reward": 0.24051129817962646,
        "val_loss": 0.2555739698998098,
        "train_loss": 0.014085364071434014
      },
      {
        "epoch": 980,
        "reward": 0.2385636419057846,
        "val_loss": 0.26109807446066824,
        "train_loss": 0.00842451996917449
      },
      {
        "epoch": 981,
        "reward": 0.3131597638130188,
        "val_loss": 0.12328902520571969,
        "train_loss": 0.009440286690593123
      },
      {
        "epoch": 982,
        "reward": 0.34836116433143616,
        "val_loss": 0.08968077880646368,
        "train_loss": 0.011101484977888713
      },
      {
        "epoch": 983,
        "reward": 0.3289458751678467,
        "val_loss": 0.10666234326656975,
        "train_loss": 0.08263103197154684
      },
      {
        "epoch": 984,
        "reward": 0.3237493336200714,
        "val_loss": 0.11182594215331067,
        "train_loss": 0.005682900160352871
      },
      {
        "epoch": 985,
        "reward": 0.31814703345298767,
        "val_loss": 0.11772552263989512,
        "train_loss": 0.0076776636153156755
      },
      {
        "epoch": 986,
        "reward": 0.31548547744750977,
        "val_loss": 0.12065671751458597,
        "train_loss": 0.01035597016687881
      },
      {
        "epoch": 987,
        "reward": 0.25160691142082214,
        "val_loss": 0.22675625631278049,
        "train_loss": 0.3673496394467992
      },
      {
        "epoch": 988,
        "reward": 0.322811096906662,
        "val_loss": 0.1127892342670488,
        "train_loss": 0.06982222731340489
      },
      {
        "epoch": 989,
        "reward": 0.33918875455856323,
        "val_loss": 0.09727852177664838,
        "train_loss": 0.019900016274522595
      },
      {
        "epoch": 990,
        "reward": 0.2606949806213379,
        "val_loss": 0.20612319553453876,
        "train_loss": 0.11606901648722083
      },
      {
        "epoch": 991,
        "reward": 0.34968283772468567,
        "val_loss": 0.08864344535686541,
        "train_loss": 0.0038756975233739535
      },
      {
        "epoch": 992,
        "reward": 0.22152185440063477,
        "val_loss": 0.3165225114166138,
        "train_loss": 0.05246289700985821
      },
      {
        "epoch": 993,
        "reward": 0.2300795316696167,
        "val_loss": 0.286999201859414,
        "train_loss": 0.010686685644871501
      },
      {
        "epoch": 994,
        "reward": 0.29292839765548706,
        "val_loss": 0.14933059324019787,
        "train_loss": 0.02503956712476233
      },
      {
        "epoch": 995,
        "reward": 0.32482680678367615,
        "val_loss": 0.1107315693183669,
        "train_loss": 4.381250317666085
      },
      {
        "epoch": 996,
        "reward": 0.28780481219291687,
        "val_loss": 0.15694481848705827,
        "train_loss": 0.0031801525527463616
      },
      {
        "epoch": 997,
        "reward": 0.27390429377555847,
        "val_loss": 0.18010884527965182,
        "train_loss": 0.01415507968536426
      },
      {
        "epoch": 998,
        "reward": 0.3158724009990692,
        "val_loss": 0.12022528697603516,
        "train_loss": 0.010600856707102278
      },
      {
        "epoch": 999,
        "reward": 0.3233102262020111,
        "val_loss": 0.11227556250482199,
        "train_loss": 0.31003993928432183
      },
      {
        "epoch": 1000,
        "reward": 0.3129625916481018,
        "val_loss": 0.12351534840334873,
        "train_loss": 0.19722141081169517
      },
      {
        "epoch": 1001,
        "reward": 0.33547505736351013,
        "val_loss": 0.10056504095388975,
        "train_loss": 0.019005526833797585
      },
      {
        "epoch": 1002,
        "reward": 0.2909824252128601,
        "val_loss": 0.15216873710908527,
        "train_loss": 0.044441722958184146
      },
      {
        "epoch": 1003,
        "reward": 0.2601306438446045,
        "val_loss": 0.20733467454140606,
        "train_loss": 1.3801634346032539
      },
      {
        "epoch": 1004,
        "reward": 0.3272514343261719,
        "val_loss": 0.10831466697189691,
        "train_loss": 0.02215766012369176
      },
      {
        "epoch": 1005,
        "reward": 0.29356545209884644,
        "val_loss": 0.14841539209217963,
        "train_loss": 7.925071583385943
      },
      {
        "epoch": 1006,
        "reward": 0.3366691470146179,
        "val_loss": 0.09949442573789773,
        "train_loss": 0.004830756950608562
      },
      {
        "epoch": 1007,
        "reward": 0.33991166949272156,
        "val_loss": 0.09665336043274562,
        "train_loss": 0.015713583230815578
      },
      {
        "epoch": 1008,
        "reward": 0.34554430842399597,
        "val_loss": 0.0919385878639462,
        "train_loss": 0.07052869764034907
      },
      {
        "epoch": 1009,
        "reward": 0.30763566493988037,
        "val_loss": 0.12981976167481793,
        "train_loss": 0.00747936054638278
      },
      {
        "epoch": 1010,
        "reward": 0.26353269815444946,
        "val_loss": 0.20016254664265684,
        "train_loss": 0.10106649866961212
      },
      {
        "epoch": 1011,
        "reward": 0.3097694516181946,
        "val_loss": 0.1272495109733427,
        "train_loss": 0.014634062684868136
      },
      {
        "epoch": 1012,
        "reward": 0.3270244002342224,
        "val_loss": 0.10853834983468655,
        "train_loss": 0.2552895779486754
      },
      {
        "epoch": 1013,
        "reward": 0.23670907318592072,
        "val_loss": 0.26649880676995963,
        "train_loss": 0.051508381407984416
      },
      {
        "epoch": 1014,
        "reward": 0.269407719373703,
        "val_loss": 0.188484272815653,
        "train_loss": 0.0073564988598753605
      },
      {
        "epoch": 1015,
        "reward": 0.2837941348552704,
        "val_loss": 0.1632351678979051,
        "train_loss": 0.00789486604520999
      },
      {
        "epoch": 1016,
        "reward": 0.3295999765396118,
        "val_loss": 0.10603239855845459,
        "train_loss": 0.7934347286850775
      },
      {
        "epoch": 1017,
        "reward": 0.2753567695617676,
        "val_loss": 0.17750139985998561,
        "train_loss": 0.17400476451103503
      },
      {
        "epoch": 1018,
        "reward": 0.3499123752117157,
        "val_loss": 0.08846472389580283,
        "train_loss": 0.26156484808584185
      },
      {
        "epoch": 1019,
        "reward": 0.23955845832824707,
        "val_loss": 0.25825784003245644,
        "train_loss": 0.04668276167733264
      },
      {
        "epoch": 1020,
        "reward": 0.30821865797042847,
        "val_loss": 0.12911144709297723,
        "train_loss": 0.039677978613606404
      },
      {
        "epoch": 1021,
        "reward": 0.3518920838832855,
        "val_loss": 0.08694017692427483,
        "train_loss": 0.8304168856154249
      },
      {
        "epoch": 1022,
        "reward": 0.2730829119682312,
        "val_loss": 0.18160408868737118,
        "train_loss": 0.019028874026564432
      },
      {
        "epoch": 1023,
        "reward": 0.23962195217609406,
        "val_loss": 0.25807785340709544,
        "train_loss": 3.9018032509090097
      },
      {
        "epoch": 1024,
        "reward": 0.32549816370010376,
        "val_loss": 0.1100561061861559,
        "train_loss": 0.5579153096095979
      },
      {
        "epoch": 1025,
        "reward": 0.35822972655296326,
        "val_loss": 0.08225850968613356,
        "train_loss": 0.01699808561212334
      },
      {
        "epoch": 1026,
        "reward": 0.2784845530986786,
        "val_loss": 0.17204178952462307,
        "train_loss": 0.012046871656716225
      },
      {
        "epoch": 1027,
        "reward": 0.32876914739608765,
        "val_loss": 0.10683326963875775,
        "train_loss": 0.005192381603662328
      },
      {
        "epoch": 1028,
        "reward": 0.3177621066570282,
        "val_loss": 0.1181441950279155,
        "train_loss": 0.06325206100126916
      },
      {
        "epoch": 1029,
        "reward": 0.292800635099411,
        "val_loss": 0.14951496595832786,
        "train_loss": 0.007993661710105907
      },
      {
        "epoch": 1030,
        "reward": 0.3626786172389984,
        "val_loss": 0.0791439830271494,
        "train_loss": 0.007308040856934475
      },
      {
        "epoch": 1031,
        "reward": 0.200703963637352,
        "val_loss": 0.40648852347762193,
        "train_loss": 0.008393710841897491
      },
      {
        "epoch": 1032,
        "reward": 0.3747154772281647,
        "val_loss": 0.0713669370099004,
        "train_loss": 9.149060294524064
      },
      {
        "epoch": 1033,
        "reward": 0.3115106523036957,
        "val_loss": 0.12519690569024533,
        "train_loss": 0.03525464759010132
      },
      {
        "epoch": 1034,
        "reward": 0.31050682067871094,
        "val_loss": 0.12637539722241595,
        "train_loss": 0.1682675169032651
      },
      {
        "epoch": 1035,
        "reward": 0.3304380178451538,
        "val_loss": 0.10523165826660781,
        "train_loss": 0.016604233530730338
      },
      {
        "epoch": 1036,
        "reward": 0.3029787242412567,
        "val_loss": 0.13564777933061123,
        "train_loss": 0.11821167143142912
      },
      {
        "epoch": 1037,
        "reward": 0.32344409823417664,
        "val_loss": 0.11213822632894985,
        "train_loss": 0.8415463776481584
      },
      {
        "epoch": 1038,
        "reward": 0.29678216576576233,
        "val_loss": 0.1438961073623172,
        "train_loss": 0.06800420075468047
      },
      {
        "epoch": 1039,
        "reward": 0.32947057485580444,
        "val_loss": 0.1061566961995725,
        "train_loss": 0.011621335763965571
      },
      {
        "epoch": 1040,
        "reward": 0.2870040833950043,
        "val_loss": 0.15817683114853157,
        "train_loss": 0.027895950715201952
      },
      {
        "epoch": 1041,
        "reward": 0.27025535702705383,
        "val_loss": 0.18686936414867109,
        "train_loss": 0.2721434160692017
      },
      {
        "epoch": 1042,
        "reward": 0.2768234312534332,
        "val_loss": 0.17491532704609977,
        "train_loss": 0.056079087319141345
      },
      {
        "epoch": 1043,
        "reward": 0.29804882407188416,
        "val_loss": 0.1421621383321638,
        "train_loss": 0.06813708200112299
      },
      {
        "epoch": 1044,
        "reward": 0.3364947736263275,
        "val_loss": 0.09964988685844998,
        "train_loss": 0.008165035927644428
      },
      {
        "epoch": 1045,
        "reward": 0.28252336382865906,
        "val_loss": 0.16529195857583545,
        "train_loss": 0.01022712066260895
      },
      {
        "epoch": 1046,
        "reward": 0.30840709805488586,
        "val_loss": 0.12888346698413702,
        "train_loss": 0.0358493737378292
      },
      {
        "epoch": 1047,
        "reward": 0.26616406440734863,
        "val_loss": 0.19482468176699644,
        "train_loss": 0.02022806096762399
      },
      {
        "epoch": 1048,
        "reward": 0.2878623902797699,
        "val_loss": 0.1568566691192765,
        "train_loss": 0.046702238985464925
      },
      {
        "epoch": 1049,
        "reward": 0.31105828285217285,
        "val_loss": 0.12572635363488058,
        "train_loss": 0.09167352247361403
      },
      {
        "epoch": 1050,
        "reward": 0.3160167932510376,
        "val_loss": 0.12006471655331552,
        "train_loss": 0.03972534846756249
      },
      {
        "epoch": 1051,
        "reward": 0.2792421281337738,
        "val_loss": 0.17075046011762293,
        "train_loss": 0.7080896709439213
      },
      {
        "epoch": 1052,
        "reward": 0.33704981207847595,
        "val_loss": 0.09915585771627125,
        "train_loss": 0.1582290713565901
      },
      {
        "epoch": 1053,
        "reward": 0.27600517868995667,
        "val_loss": 0.1763523735821114,
        "train_loss": 0.2239681120711164
      },
      {
        "epoch": 1054,
        "reward": 0.35060814023017883,
        "val_loss": 0.08792544540483505,
        "train_loss": 0.6547045179392555
      },
      {
        "epoch": 1055,
        "reward": 0.3404317796230316,
        "val_loss": 0.09620641524088569,
        "train_loss": 0.004351989246900372
      },
      {
        "epoch": 1056,
        "reward": 0.3083377778530121,
        "val_loss": 0.1289672365237493,
        "train_loss": 0.3194931435525807
      },
      {
        "epoch": 1057,
        "reward": 0.31787630915641785,
        "val_loss": 0.11801982490162898,
        "train_loss": 0.05825729032977296
      },
      {
        "epoch": 1058,
        "reward": 0.3371887505054474,
        "val_loss": 0.09903265088879769,
        "train_loss": 0.01572748900119992
      },
      {
        "epoch": 1059,
        "reward": 0.3063279986381531,
        "val_loss": 0.13142556456815718,
        "train_loss": 0.006294416350731178
      },
      {
        "epoch": 1060,
        "reward": 0.24548529088497162,
        "val_loss": 0.24211932312131726,
        "train_loss": 0.2179456497411033
      },
      {
        "epoch": 1061,
        "reward": 0.3285326659679413,
        "val_loss": 0.10706257255722969,
        "train_loss": 0.005967841866200056
      },
      {
        "epoch": 1062,
        "reward": 0.2841241955757141,
        "val_loss": 0.1627061156655795,
        "train_loss": 0.42348567881722726
      },
      {
        "epoch": 1063,
        "reward": 0.18913090229034424,
        "val_loss": 0.4711089182528667,
        "train_loss": 0.02944601900246478
      },
      {
        "epoch": 1064,
        "reward": 0.30471959710121155,
        "val_loss": 0.13343324765862366,
        "train_loss": 0.042503049905812634
      },
      {
        "epoch": 1065,
        "reward": 0.2809636890888214,
        "val_loss": 0.1678595994058664,
        "train_loss": 0.16522271061134794
      },
      {
        "epoch": 1066,
        "reward": 0.24985836446285248,
        "val_loss": 0.2310168558116337,
        "train_loss": 0.028670780427301697
      },
      {
        "epoch": 1067,
        "reward": 0.33747681975364685,
        "val_loss": 0.09877774416236207,
        "train_loss": 1024.782855793753
      },
      {
        "epoch": 1068,
        "reward": 0.329057902097702,
        "val_loss": 0.10655411949535067,
        "train_loss": 0.0031582796191287343
      },
      {
        "epoch": 1069,
        "reward": 0.3076685667037964,
        "val_loss": 0.12977968849424673,
        "train_loss": 0.05428337104436091
      },
      {
        "epoch": 1070,
        "reward": 0.33165210485458374,
        "val_loss": 0.10408415800442786,
        "train_loss": 0.07617737683379416
      },
      {
        "epoch": 1071,
        "reward": 0.271683007478714,
        "val_loss": 0.18418779071985877,
        "train_loss": 0.10811452764280077
      },
      {
        "epoch": 1072,
        "reward": 0.3499360978603363,
        "val_loss": 0.0884462718614876,
        "train_loss": 0.45622365274266485
      },
      {
        "epoch": 1073,
        "reward": 0.30053967237472534,
        "val_loss": 0.13882494935699338,
        "train_loss": 0.039078805645658576
      },
      {
        "epoch": 1074,
        "reward": 0.2671610713005066,
        "val_loss": 0.19284823415468313,
        "train_loss": 0.011158804002731743
      },
      {
        "epoch": 1075,
        "reward": 0.3588343560695648,
        "val_loss": 0.08182713288364798,
        "train_loss": 0.21929583119280183
      },
      {
        "epoch": 1076,
        "reward": 0.26061567664146423,
        "val_loss": 0.20629286364419386,
        "train_loss": 0.01783526882242698
      },
      {
        "epoch": 1077,
        "reward": 0.27493295073509216,
        "val_loss": 0.1782574297228296,
        "train_loss": 0.01358423531619862
      },
      {
        "epoch": 1078,
        "reward": 0.28270086646080017,
        "val_loss": 0.16500276722009793,
        "train_loss": 0.0073342381207252266
      },
      {
        "epoch": 1079,
        "reward": 0.353708952665329,
        "val_loss": 0.08556754564259401,
        "train_loss": 0.004366703250245616
      },
      {
        "epoch": 1080,
        "reward": 0.29828810691833496,
        "val_loss": 0.14183736948845244,
        "train_loss": 0.032985227227282636
      },
      {
        "epoch": 1081,
        "reward": 0.33989834785461426,
        "val_loss": 0.09666480695887003,
        "train_loss": 0.029984854484540007
      },
      {
        "epoch": 1082,
        "reward": 0.3190464377403259,
        "val_loss": 0.11675409786818948,
        "train_loss": 0.009707207148354567
      },
      {
        "epoch": 1083,
        "reward": 0.3556825518608093,
        "val_loss": 0.08410457555770076,
        "train_loss": 0.02572535386605943
      },
      {
        "epoch": 1084,
        "reward": 0.2995167672634125,
        "val_loss": 0.14018389601135692,
        "train_loss": 0.002094732300695166
      },
      {
        "epoch": 1085,
        "reward": 0.3003983199596405,
        "val_loss": 0.1390118170903796,
        "train_loss": 0.004669900674903497
      },
      {
        "epoch": 1086,
        "reward": 0.3407326936721802,
        "val_loss": 0.09594896990789234,
        "train_loss": 0.03765990673848417
      },
      {
        "epoch": 1087,
        "reward": 0.29501909017562866,
        "val_loss": 0.14635223299098601,
        "train_loss": 0.007501805687122844
      },
      {
        "epoch": 1088,
        "reward": 0.3219062089920044,
        "val_loss": 0.1137275406300822,
        "train_loss": 0.00824023949938307
      },
      {
        "epoch": 1089,
        "reward": 0.3355027437210083,
        "val_loss": 0.10054004211685554,
        "train_loss": 0.2520247696841999
      },
      {
        "epoch": 1090,
        "reward": 0.32502996921539307,
        "val_loss": 0.11052666571881023,
        "train_loss": 0.09147201925448965
      },
      {
        "epoch": 1091,
        "reward": 0.3027060627937317,
        "val_loss": 0.1359986213231293,
        "train_loss": 0.6590227359847807
      },
      {
        "epoch": 1092,
        "reward": 0.3081904351711273,
        "val_loss": 0.1291456294794833,
        "train_loss": 0.09814820768811981
      },
      {
        "epoch": 1093,
        "reward": 0.32498276233673096,
        "val_loss": 0.11057422779101346,
        "train_loss": 0.0225482927599457
      },
      {
        "epoch": 1094,
        "reward": 0.3017405867576599,
        "val_loss": 0.13724960732257127,
        "train_loss": 0.016069128082073385
      },
      {
        "epoch": 1095,
        "reward": 0.264682412147522,
        "val_loss": 0.19780834959653606,
        "train_loss": 0.005042438591212535
      },
      {
        "epoch": 1096,
        "reward": 0.3611844778060913,
        "val_loss": 0.08017474366144077,
        "train_loss": 0.008073971910142483
      },
      {
        "epoch": 1097,
        "reward": 0.28569841384887695,
        "val_loss": 0.16021107008730592,
        "train_loss": 0.042316174672473256
      },
      {
        "epoch": 1098,
        "reward": 0.2998448610305786,
        "val_loss": 0.13974627851608343,
        "train_loss": 0.008242335856266436
      },
      {
        "epoch": 1099,
        "reward": 0.26652926206588745,
        "val_loss": 0.1940978708069971,
        "train_loss": 0.018223261678455262
      },
      {
        "epoch": 1100,
        "reward": 0.3227052688598633,
        "val_loss": 0.11289848059823271,
        "train_loss": 0.0788048346915345
      },
      {
        "epoch": 1101,
        "reward": 0.2957322299480438,
        "val_loss": 0.1453527337642819,
        "train_loss": 0.157906037178481
      },
      {
        "epoch": 1102,
        "reward": 0.3455739915370941,
        "val_loss": 0.0919144701287483,
        "train_loss": 0.04115014904066182
      },
      {
        "epoch": 1103,
        "reward": 0.31645017862319946,
        "val_loss": 0.11958442284334783,
        "train_loss": 0.02278495517146859
      },
      {
        "epoch": 1104,
        "reward": 0.3194518983364105,
        "val_loss": 0.11631924909514575,
        "train_loss": 12.586431947436127
      },
      {
        "epoch": 1105,
        "reward": 0.2716261148452759,
        "val_loss": 0.18429376898815722,
        "train_loss": 0.022305444217408876
      },
      {
        "epoch": 1106,
        "reward": 0.33753594756126404,
        "val_loss": 0.09872552518208977,
        "train_loss": 41.277832291828766
      },
      {
        "epoch": 1107,
        "reward": 0.36111980676651,
        "val_loss": 0.08021971203977175,
        "train_loss": 0.011324811266848136
      },
      {
        "epoch": 1108,
        "reward": 0.23306410014629364,
        "val_loss": 0.27753146081730456,
        "train_loss": 0.031205891339219798
      },
      {
        "epoch": 1109,
        "reward": 0.3414369821548462,
        "val_loss": 0.09534949815549355,
        "train_loss": 0.003923696642372166
      },
      {
        "epoch": 1110,
        "reward": 0.34870976209640503,
        "val_loss": 0.08940582913471319,
        "train_loss": 0.07453822130046844
      },
      {
        "epoch": 1111,
        "reward": 0.3229229748249054,
        "val_loss": 0.11267384220056036,
        "train_loss": 0.661446025998255
      },
      {
        "epoch": 1112,
        "reward": 0.29590904712677,
        "val_loss": 0.14510616542455473,
        "train_loss": 0.025184700003968337
      },
      {
        "epoch": 1113,
        "reward": 0.3466753661632538,
        "val_loss": 0.09102419456342302,
        "train_loss": 0.2801334698017924
      },
      {
        "epoch": 1114,
        "reward": 0.2770625650882721,
        "val_loss": 0.17449805216996797,
        "train_loss": 0.02376838030424831
      },
      {
        "epoch": 1115,
        "reward": 0.3736635744571686,
        "val_loss": 0.07201097750761878,
        "train_loss": 0.003662188111985205
      },
      {
        "epoch": 1116,
        "reward": 0.3288347125053406,
        "val_loss": 0.10676984035360094,
        "train_loss": 0.10684979496436252
      },
      {
        "epoch": 1117,
        "reward": 0.34841641783714294,
        "val_loss": 0.0896371184041657,
        "train_loss": 2.532534023089205
      },
      {
        "epoch": 1118,
        "reward": 0.33313724398612976,
        "val_loss": 0.10270022972794582,
        "train_loss": 0.00599200493022286
      },
      {
        "epoch": 1119,
        "reward": 0.2749219834804535,
        "val_loss": 0.17827701045566105,
        "train_loss": 9.912019897459476
      },
      {
        "epoch": 1120,
        "reward": 0.36612772941589355,
        "val_loss": 0.07682153220542075,
        "train_loss": 0.013219665702868392
      },
      {
        "epoch": 1121,
        "reward": 0.2307632714509964,
        "val_loss": 0.28479447412454256,
        "train_loss": 0.5264820910700879
      },
      {
        "epoch": 1122,
        "reward": 0.3358912765979767,
        "val_loss": 0.10019032919080928,
        "train_loss": 0.4456473676042728
      },
      {
        "epoch": 1123,
        "reward": 0.36314043402671814,
        "val_loss": 0.07882846769436062,
        "train_loss": 1.4714422138015204
      },
      {
        "epoch": 1124,
        "reward": 0.23899300396442413,
        "val_loss": 0.2598673592853759,
        "train_loss": 0.007234593613387775
      },
      {
        "epoch": 1125,
        "reward": 0.2948980927467346,
        "val_loss": 0.14652267735800706,
        "train_loss": 0.08424412137145947
      },
      {
        "epoch": 1126,
        "reward": 0.3278610408306122,
        "val_loss": 0.10771678783515069,
        "train_loss": 0.0041325009064726494
      },
      {
        "epoch": 1127,
        "reward": 0.3117542564868927,
        "val_loss": 0.1249128567454006,
        "train_loss": 0.011303646911143845
      },
      {
        "epoch": 1128,
        "reward": 0.3323808014392853,
        "val_loss": 0.10340241282080699,
        "train_loss": 0.024690853934561555
      },
      {
        "epoch": 1129,
        "reward": 0.2825331687927246,
        "val_loss": 0.16527596225828997,
        "train_loss": 0.05290568939520968
      },
      {
        "epoch": 1130,
        "reward": 0.30881282687187195,
        "val_loss": 0.1283942615014634,
        "train_loss": 0.7264381026718463
      },
      {
        "epoch": 1131,
        "reward": 0.24938051402568817,
        "val_loss": 0.23219857194011898,
        "train_loss": 0.004261535206751432
      },
      {
        "epoch": 1132,
        "reward": 0.3583574593067169,
        "val_loss": 0.0821671668527415,
        "train_loss": 0.00864093529694051
      },
      {
        "epoch": 1133,
        "reward": 0.36073222756385803,
        "val_loss": 0.08048974201041606,
        "train_loss": 0.009918140764546899
      },
      {
        "epoch": 1134,
        "reward": 0.2372274398803711,
        "val_loss": 0.26497514963349594,
        "train_loss": 0.05773795177251136
      },
      {
        "epoch": 1135,
        "reward": 0.3267836272716522,
        "val_loss": 0.10877615869061888,
        "train_loss": 0.7429543548574972
      },
      {
        "epoch": 1136,
        "reward": 0.2878507971763611,
        "val_loss": 0.1568743836874741,
        "train_loss": 0.009411731860522056
      },
      {
        "epoch": 1137,
        "reward": 0.36854931712150574,
        "val_loss": 0.07523719371861912,
        "train_loss": 0.005914469698793185
      },
      {
        "epoch": 1138,
        "reward": 0.3490443527698517,
        "val_loss": 0.08914284059054418,
        "train_loss": 0.017150105588335955
      },
      {
        "epoch": 1139,
        "reward": 0.3642882704734802,
        "val_loss": 0.0780503684155909,
        "train_loss": 102.77658778305201
      },
      {
        "epoch": 1140,
        "reward": 0.34160494804382324,
        "val_loss": 0.09520717610472015,
        "train_loss": 0.00420021450470533
      },
      {
        "epoch": 1141,
        "reward": 0.36025166511535645,
        "val_loss": 0.08082600253692362,
        "train_loss": 0.005576823289419945
      },
      {
        "epoch": 1142,
        "reward": 0.3246570825576782,
        "val_loss": 0.11090314425278588,
        "train_loss": 0.009904211151968831
      },
      {
        "epoch": 1143,
        "reward": 0.3141884505748749,
        "val_loss": 0.12211643996956159,
        "train_loss": 0.0968125566958826
      },
      {
        "epoch": 1144,
        "reward": 0.36184635758399963,
        "val_loss": 0.07971628239777472,
        "train_loss": 805.8527292624295
      },
      {
        "epoch": 1145,
        "reward": 0.368551105260849,
        "val_loss": 0.0752360368891719,
        "train_loss": 0.4773979896220325
      },
      {
        "epoch": 1146,
        "reward": 0.31213465332984924,
        "val_loss": 0.12447084245754272,
        "train_loss": 0.030157235979135503
      },
      {
        "epoch": 1147,
        "reward": 0.31259265542030334,
        "val_loss": 0.12394119681682371,
        "train_loss": 0.09826009252160126
      },
      {
        "epoch": 1148,
        "reward": 0.2188088446855545,
        "val_loss": 0.326685473287528,
        "train_loss": 0.23840371779246758
      },
      {
        "epoch": 1149,
        "reward": 0.2649862766265869,
        "val_loss": 0.19719187905762478,
        "train_loss": 0.043472450178551995
      },
      {
        "epoch": 1150,
        "reward": 0.32650622725486755,
        "val_loss": 0.10905088126933801,
        "train_loss": 0.039870732629603584
      },
      {
        "epoch": 1151,
        "reward": 0.3368447721004486,
        "val_loss": 0.09933807959480744,
        "train_loss": 0.026356574793820843
      },
      {
        "epoch": 1152,
        "reward": 0.33386388421058655,
        "val_loss": 0.10203095300987895,
        "train_loss": 0.0024571328043608586
      },
      {
        "epoch": 1153,
        "reward": 0.3199039399623871,
        "val_loss": 0.11583670775871724,
        "train_loss": 0.006582605643276251
      },
      {
        "epoch": 1154,
        "reward": 0.324219673871994,
        "val_loss": 0.11134669239774146,
        "train_loss": 642.8775663030722
      },
      {
        "epoch": 1155,
        "reward": 0.32140272855758667,
        "val_loss": 0.11425362238618877,
        "train_loss": 0.16915740755156058
      },
      {
        "epoch": 1156,
        "reward": 0.2893001139163971,
        "val_loss": 0.15467500507864834,
        "train_loss": 0.03834104874071132
      },
      {
        "epoch": 1157,
        "reward": 0.3505881726741791,
        "val_loss": 0.08794085868950267,
        "train_loss": 0.04445117751779785
      },
      {
        "epoch": 1158,
        "reward": 0.2948223352432251,
        "val_loss": 0.14662943779590673,
        "train_loss": 0.15694873523230293
      },
      {
        "epoch": 1159,
        "reward": 0.32559841871261597,
        "val_loss": 0.10995565531525894,
        "train_loss": 58.72019829409377
      },
      {
        "epoch": 1160,
        "reward": 0.33416831493377686,
        "val_loss": 0.10175206171697937,
        "train_loss": 0.15656499203326418
      },
      {
        "epoch": 1161,
        "reward": 0.24301119148731232,
        "val_loss": 0.2486973888423693,
        "train_loss": 0.3085597243862839
      },
      {
        "epoch": 1162,
        "reward": 0.31931114196777344,
        "val_loss": 0.11646996418130584,
        "train_loss": 0.006811605079432271
      },
      {
        "epoch": 1163,
        "reward": 0.3643281161785126,
        "val_loss": 0.07802352388015217,
        "train_loss": 0.014194881769071799
      },
      {
        "epoch": 1164,
        "reward": 0.33916527032852173,
        "val_loss": 0.09729888686394718,
        "train_loss": 0.016836798380189484
      },
      {
        "epoch": 1165,
        "reward": 0.31818294525146484,
        "val_loss": 0.117686512293793,
        "train_loss": 0.0037210230397109766
      },
      {
        "epoch": 1166,
        "reward": 0.37435707449913025,
        "val_loss": 0.07158564096399848,
        "train_loss": 0.027993752034280287
      },
      {
        "epoch": 1167,
        "reward": 0.32772400975227356,
        "val_loss": 0.10785084876364895,
        "train_loss": 0.0067499397447276215
      },
      {
        "epoch": 1168,
        "reward": 0.35669153928756714,
        "val_loss": 0.08336772236257925,
        "train_loss": 0.013217807016889519
      },
      {
        "epoch": 1169,
        "reward": 0.32990142703056335,
        "val_loss": 0.10574355083060384,
        "train_loss": 0.10333373496107995
      },
      {
        "epoch": 1170,
        "reward": 0.29174867272377014,
        "val_loss": 0.15104345640117703,
        "train_loss": 0.061046641711376776
      },
      {
        "epoch": 1171,
        "reward": 0.35867151618003845,
        "val_loss": 0.08194305327197071,
        "train_loss": 0.6665348484148126
      },
      {
        "epoch": 1172,
        "reward": 0.326057493686676,
        "val_loss": 0.10949700424264718,
        "train_loss": 0.007960347438571401
      },
      {
        "epoch": 1173,
        "reward": 0.32723209261894226,
        "val_loss": 0.10833371804827559,
        "train_loss": 0.8078917394355253
      },
      {
        "epoch": 1174,
        "reward": 0.3511601686477661,
        "val_loss": 0.0875002720588652,
        "train_loss": 0.013742997111316631
      },
      {
        "epoch": 1175,
        "reward": 0.34888869524002075,
        "val_loss": 0.0892650675585693,
        "train_loss": 0.4323332830850771
      },
      {
        "epoch": 1176,
        "reward": 0.3693162798881531,
        "val_loss": 0.07474311791676362,
        "train_loss": 0.014560883843492215
      },
      {
        "epoch": 1177,
        "reward": 0.3126063644886017,
        "val_loss": 0.1239253703367597,
        "train_loss": 0.0920092661243381
      },
      {
        "epoch": 1178,
        "reward": 0.3646414279937744,
        "val_loss": 0.07781271537325145,
        "train_loss": 1.8253297709792464
      },
      {
        "epoch": 1179,
        "reward": 0.24663756787776947,
        "val_loss": 0.23913013752982287,
        "train_loss": 0.012780234353508254
      },
      {
        "epoch": 1180,
        "reward": 0.2953249216079712,
        "val_loss": 0.1459225640740312,
        "train_loss": 0.0077096420083342726
      },
      {
        "epoch": 1181,
        "reward": 0.36594250798225403,
        "val_loss": 0.07694430199418482,
        "train_loss": 0.026888538437265633
      },
      {
        "epoch": 1182,
        "reward": 0.3778117001056671,
        "val_loss": 0.06950846674901966,
        "train_loss": 0.1780280998093356
      },
      {
        "epoch": 1183,
        "reward": 0.28702598810195923,
        "val_loss": 0.15814297017433482,
        "train_loss": 0.048165237715063716
      },
      {
        "epoch": 1184,
        "reward": 0.2979744076728821,
        "val_loss": 0.14226330888258026,
        "train_loss": 0.13232994316310326
      },
      {
        "epoch": 1185,
        "reward": 0.32067570090293884,
        "val_loss": 0.11501834038478721,
        "train_loss": 0.005910546014092688
      },
      {
        "epoch": 1186,
        "reward": 0.2882077395915985,
        "val_loss": 0.1563292296736368,
        "train_loss": 0.695926611338179
      },
      {
        "epoch": 1187,
        "reward": 0.28651729226112366,
        "val_loss": 0.1589315686183649,
        "train_loss": 0.004011833257939985
      },
      {
        "epoch": 1188,
        "reward": 0.33928239345550537,
        "val_loss": 0.09719723308600285,
        "train_loss": 0.005370344211069795
      },
      {
        "epoch": 1189,
        "reward": 0.34008654952049255,
        "val_loss": 0.09650279707940561,
        "train_loss": 0.03454384430746744
      },
      {
        "epoch": 1190,
        "reward": 0.3657728433609009,
        "val_loss": 0.07705690707786873,
        "train_loss": 0.008014512378220108
      },
      {
        "epoch": 1191,
        "reward": 0.30293023586273193,
        "val_loss": 0.13571006072951214,
        "train_loss": 0.1694736614240705
      },
      {
        "epoch": 1192,
        "reward": 0.3637119233608246,
        "val_loss": 0.07843995922095408,
        "train_loss": 0.02506667669709154
      },
      {
        "epoch": 1193,
        "reward": 0.30673298239707947,
        "val_loss": 0.13092573109731478,
        "train_loss": 0.012902098097094075
      },
      {
        "epoch": 1194,
        "reward": 0.3583313822746277,
        "val_loss": 0.08218581319046539,
        "train_loss": 0.007204380545982321
      },
      {
        "epoch": 1195,
        "reward": 0.3731856048107147,
        "val_loss": 0.07230578952502194,
        "train_loss": 0.036113850340580726
      },
      {
        "epoch": 1196,
        "reward": 0.28011271357536316,
        "val_loss": 0.16928101110637986,
        "train_loss": 0.17985264163361045
      },
      {
        "epoch": 1197,
        "reward": 0.38707709312438965,
        "val_loss": 0.06426308417992134,
        "train_loss": 0.09096133957008043
      },
      {
        "epoch": 1198,
        "reward": 0.3324970602989197,
        "val_loss": 0.10329413997949034,
        "train_loss": 0.024245859757964075
      },
      {
        "epoch": 1199,
        "reward": 0.27753299474716187,
        "val_loss": 0.17368077138339036,
        "train_loss": 0.01411755906309946
      },
      {
        "epoch": 1200,
        "reward": 0.36412835121154785,
        "val_loss": 0.07815822487048406,
        "train_loss": 0.27002693275272366
      },
      {
        "epoch": 1201,
        "reward": 0.3417949378490448,
        "val_loss": 0.09504650092484164,
        "train_loss": 0.015269904799424694
      },
      {
        "epoch": 1202,
        "reward": 0.22384122014045715,
        "val_loss": 0.30815274086281924,
        "train_loss": 0.0294150165031729
      },
      {
        "epoch": 1203,
        "reward": 0.3387216627597809,
        "val_loss": 0.09768489611451514,
        "train_loss": 0.056114210271796486
      },
      {
        "epoch": 1204,
        "reward": 0.33907267451286316,
        "val_loss": 0.09737932680997931,
        "train_loss": 0.025759598767658296
      },
      {
        "epoch": 1205,
        "reward": 0.3432435691356659,
        "val_loss": 0.09383151370691069,
        "train_loss": 0.011512925082430368
      },
      {
        "epoch": 1206,
        "reward": 0.35583212971687317,
        "val_loss": 0.08399484542730663,
        "train_loss": 0.9670473066151037
      },
      {
        "epoch": 1207,
        "reward": 0.35565659403800964,
        "val_loss": 0.08412360510556027,
        "train_loss": 0.01315142643985522
      },
      {
        "epoch": 1208,
        "reward": 0.34749436378479004,
        "val_loss": 0.09036864133460247,
        "train_loss": 0.00819739898221227
      },
      {
        "epoch": 1209,
        "reward": 0.28591638803482056,
        "val_loss": 0.1598692544295253,
        "train_loss": 0.0022196980741612674
      },
      {
        "epoch": 1210,
        "reward": 0.2873227298259735,
        "val_loss": 0.15768507957857633,
        "train_loss": 0.05575907959106329
      },
      {
        "epoch": 1211,
        "reward": 0.30147016048431396,
        "val_loss": 0.13760242811154708,
        "train_loss": 0.25767594341826994
      },
      {
        "epoch": 1212,
        "reward": 0.2958110570907593,
        "val_loss": 0.14524273934616108,
        "train_loss": 5.161982458029552
      },
      {
        "epoch": 1213,
        "reward": 0.3490414023399353,
        "val_loss": 0.08914512908917718,
        "train_loss": 0.00519405205502083
      },
      {
        "epoch": 1214,
        "reward": 0.3308503031730652,
        "val_loss": 0.10484032816228657,
        "train_loss": 0.017523619396972487
      },
      {
        "epoch": 1215,
        "reward": 0.2684081196784973,
        "val_loss": 0.19041073292360775,
        "train_loss": 0.3834191893712649
      },
      {
        "epoch": 1216,
        "reward": 0.3587871491909027,
        "val_loss": 0.08186072354562514,
        "train_loss": 0.032868124545180205
      },
      {
        "epoch": 1217,
        "reward": 0.33998340368270874,
        "val_loss": 0.09659157570318452,
        "train_loss": 0.14348865686266576
      },
      {
        "epoch": 1218,
        "reward": 0.3554563522338867,
        "val_loss": 0.08427077621412796,
        "train_loss": 2.9168560660884544
      },
      {
        "epoch": 1219,
        "reward": 0.35146796703338623,
        "val_loss": 0.08726423511169352,
        "train_loss": 5.278302808525041
      },
      {
        "epoch": 1220,
        "reward": 0.3544823229312897,
        "val_loss": 0.08499081305178281,
        "train_loss": 0.032473050983613715
      },
      {
        "epoch": 1221,
        "reward": 0.31969204545021057,
        "val_loss": 0.11606259712633411,
        "train_loss": 0.07168324129011475
      },
      {
        "epoch": 1222,
        "reward": 0.31498295068740845,
        "val_loss": 0.1212198167153734,
        "train_loss": 0.10348488281127945
      },
      {
        "epoch": 1223,
        "reward": 0.37309515476226807,
        "val_loss": 0.07236171931643705,
        "train_loss": 0.017314082374538815
      },
      {
        "epoch": 1224,
        "reward": 0.3535871207714081,
        "val_loss": 0.08565878099242193,
        "train_loss": 0.003396376434885986
      },
      {
        "epoch": 1225,
        "reward": 0.3068763315677643,
        "val_loss": 0.13074932640717765,
        "train_loss": 0.07938854551998002
      },
      {
        "epoch": 1226,
        "reward": 0.3122733533382416,
        "val_loss": 0.12431016889500565,
        "train_loss": 0.04666840990438896
      },
      {
        "epoch": 1227,
        "reward": 0.34546640515327454,
        "val_loss": 0.09200197028569944,
        "train_loss": 0.02021096020745552
      },
      {
        "epoch": 1228,
        "reward": 0.24650231003761292,
        "val_loss": 0.23947866228991188,
        "train_loss": 0.3147350100404695
      },
      {
        "epoch": 1229,
        "reward": 0.3383317291736603,
        "val_loss": 0.09802569875526908,
        "train_loss": 0.22254521138372113
      },
      {
        "epoch": 1230,
        "reward": 0.34103164076805115,
        "val_loss": 0.0956939573474561,
        "train_loss": 0.07339556576362856
      },
      {
        "epoch": 1231,
        "reward": 0.35500308871269226,
        "val_loss": 0.08460496873677974,
        "train_loss": 0.011784351437969375
      },
      {
        "epoch": 1232,
        "reward": 0.3193587064743042,
        "val_loss": 0.1164190233996903,
        "train_loss": 0.007682485396519321
      },
      {
        "epoch": 1233,
        "reward": 0.22486603260040283,
        "val_loss": 0.3045444809041718,
        "train_loss": 0.011636383553475472
      },
      {
        "epoch": 1234,
        "reward": 0.3046046197414398,
        "val_loss": 0.13357818055997736,
        "train_loss": 0.04922433466820691
      },
      {
        "epoch": 1235,
        "reward": 0.3564937114715576,
        "val_loss": 0.08351158397272229,
        "train_loss": 0.03930702029734116
      },
      {
        "epoch": 1236,
        "reward": 0.29004332423210144,
        "val_loss": 0.153561640002798,
        "train_loss": 0.009985194810724352
      },
      {
        "epoch": 1237,
        "reward": 0.3232915699481964,
        "val_loss": 0.11229470285720058,
        "train_loss": 0.01559662651113915
      },
      {
        "epoch": 1238,
        "reward": 0.32175806164741516,
        "val_loss": 0.11388206850097049,
        "train_loss": 0.052312351011306206
      },
      {
        "epoch": 1239,
        "reward": 0.37488511204719543,
        "val_loss": 0.07126367047645285,
        "train_loss": 0.031213690318858987
      },
      {
        "epoch": 1240,
        "reward": 0.3054860532283783,
        "val_loss": 0.13247200061700173,
        "train_loss": 2.3629204142737135
      },
      {
        "epoch": 1241,
        "reward": 0.32849112153053284,
        "val_loss": 0.10710287004933759,
        "train_loss": 0.07066150219966752
      },
      {
        "epoch": 1242,
        "reward": 0.35822102427482605,
        "val_loss": 0.08226475402521569,
        "train_loss": 0.015530836690739026
      },
      {
        "epoch": 1243,
        "reward": 0.3321740925312042,
        "val_loss": 0.10359526552825368,
        "train_loss": 0.13125431829184192
      },
      {
        "epoch": 1244,
        "reward": 0.3572317063808441,
        "val_loss": 0.08297624051296484,
        "train_loss": 0.0017367998561894638
      },
      {
        "epoch": 1245,
        "reward": 0.31493493914604187,
        "val_loss": 0.12127378483169846,
        "train_loss": 0.20317132543692212
      },
      {
        "epoch": 1246,
        "reward": 0.3416556715965271,
        "val_loss": 0.09516425186510398,
        "train_loss": 0.2725726119647596
      },
      {
        "epoch": 1247,
        "reward": 0.3670691251754761,
        "val_loss": 0.07620118423697672,
        "train_loss": 0.028780634004411134
      },
      {
        "epoch": 1248,
        "reward": 0.3357435166835785,
        "val_loss": 0.10032316388346121,
        "train_loss": 0.0035374035433663334
      },
      {
        "epoch": 1249,
        "reward": 0.34412500262260437,
        "val_loss": 0.09310109162886095,
        "train_loss": 0.013331385585493431
      },
      {
        "epoch": 1250,
        "reward": 0.3518073260784149,
        "val_loss": 0.0870048155608986,
        "train_loss": 0.3516224583597858
      },
      {
        "epoch": 1251,
        "reward": 0.3506266474723816,
        "val_loss": 0.08791115840514456,
        "train_loss": 79.85082938913463
      },
      {
        "epoch": 1252,
        "reward": 0.3546240031719208,
        "val_loss": 0.08488564392817873,
        "train_loss": 0.00537116913185925
      },
      {
        "epoch": 1253,
        "reward": 0.3110126852989197,
        "val_loss": 0.12577989095630723,
        "train_loss": 0.015624303332935177
      },
      {
        "epoch": 1254,
        "reward": 0.3163521885871887,
        "val_loss": 0.11969282090389502,
        "train_loss": 0.010873734766741668
      },
      {
        "epoch": 1255,
        "reward": 0.23461425304412842,
        "val_loss": 0.27277015923755243,
        "train_loss": 1.4944641133608036
      },
      {
        "epoch": 1256,
        "reward": 0.2670581042766571,
        "val_loss": 0.19305123177556588,
        "train_loss": 0.009213689561175461
      },
      {
        "epoch": 1257,
        "reward": 0.349214643239975,
        "val_loss": 0.08900932539316793,
        "train_loss": 0.00912011136649828
      },
      {
        "epoch": 1258,
        "reward": 0.2976840138435364,
        "val_loss": 0.14265893233615706,
        "train_loss": 0.05126141578106259
      },
      {
        "epoch": 1259,
        "reward": 0.34999921917915344,
        "val_loss": 0.08839719801991512,
        "train_loss": 0.07254440811616056
      },
      {
        "epoch": 1260,
        "reward": 0.3388879597187042,
        "val_loss": 0.09753999826040984,
        "train_loss": 0.006343670591692129
      },
      {
        "epoch": 1261,
        "reward": 0.31990981101989746,
        "val_loss": 0.11583044256674059,
        "train_loss": 0.15279790945183216
      },
      {
        "epoch": 1262,
        "reward": 0.3369954228401184,
        "val_loss": 0.09920415612370041,
        "train_loss": 0.005985017366303789
      },
      {
        "epoch": 1263,
        "reward": 0.33407339453697205,
        "val_loss": 0.10183891952536735,
        "train_loss": 0.010948937530044462
      },
      {
        "epoch": 1264,
        "reward": 0.3504204750061035,
        "val_loss": 0.08807053099943525,
        "train_loss": 0.01478192822836578
      },
      {
        "epoch": 1265,
        "reward": 0.30583178997039795,
        "val_loss": 0.13204109689935908,
        "train_loss": 0.0049916772589383
      },
      {
        "epoch": 1266,
        "reward": 0.29054734110832214,
        "val_loss": 0.15281218014674128,
        "train_loss": 1.0997096020999186
      },
      {
        "epoch": 1267,
        "reward": 0.330299437046051,
        "val_loss": 0.10536358135868795,
        "train_loss": 0.19040746235385506
      },
      {
        "epoch": 1268,
        "reward": 0.3276846706867218,
        "val_loss": 0.1078893574886024,
        "train_loss": 0.008479832313101864
      },
      {
        "epoch": 1269,
        "reward": 0.26461055874824524,
        "val_loss": 0.19795452524808102,
        "train_loss": 0.11970317811434282
      },
      {
        "epoch": 1270,
        "reward": 0.298170804977417,
        "val_loss": 0.14199644804050746,
        "train_loss": 0.007202728706313512
      },
      {
        "epoch": 1271,
        "reward": 0.3733905553817749,
        "val_loss": 0.07217919645440166,
        "train_loss": 1.0007811176534023
      },
      {
        "epoch": 1272,
        "reward": 0.3118240535259247,
        "val_loss": 0.12483163024132539,
        "train_loss": 0.4120544897741529
      },
      {
        "epoch": 1273,
        "reward": 0.37101230025291443,
        "val_loss": 0.07366355874858398,
        "train_loss": 0.003360403043748542
      },
      {
        "epoch": 1274,
        "reward": 0.3793116509914398,
        "val_loss": 0.06862773783255502,
        "train_loss": 0.005589145278813353
      },
      {
        "epoch": 1275,
        "reward": 0.36788618564605713,
        "val_loss": 0.07566734006520294,
        "train_loss": 0.22505128424535753
      },
      {
        "epoch": 1276,
        "reward": 0.3445509374141693,
        "val_loss": 0.09275042653358209,
        "train_loss": 0.019742007592858848
      },
      {
        "epoch": 1277,
        "reward": 0.36384886503219604,
        "val_loss": 0.07834719484838258,
        "train_loss": 0.005886052066041605
      },
      {
        "epoch": 1278,
        "reward": 0.32264411449432373,
        "val_loss": 0.11296170182842095,
        "train_loss": 0.039652082905866755
      },
      {
        "epoch": 1279,
        "reward": 0.35630038380622864,
        "val_loss": 0.08365247579266517,
        "train_loss": 3.557332310982299
      },
      {
        "epoch": 1280,
        "reward": 0.30092498660087585,
        "val_loss": 0.13831713424588088,
        "train_loss": 0.2552499111736954
      },
      {
        "epoch": 1281,
        "reward": 0.29221829771995544,
        "val_loss": 0.1503587594738097,
        "train_loss": 0.046568101631565315
      },
      {
        "epoch": 1282,
        "reward": 0.26240473985671997,
        "val_loss": 0.2025059542751738,
        "train_loss": 0.03738460932884034
      },
      {
        "epoch": 1283,
        "reward": 0.34153708815574646,
        "val_loss": 0.09526466714201628,
        "train_loss": 0.0295095863345934
      },
      {
        "epoch": 1284,
        "reward": 0.36912694573402405,
        "val_loss": 0.0748647429988653,
        "train_loss": 0.02535152596437211
      },
      {
        "epoch": 1285,
        "reward": 0.3731200098991394,
        "val_loss": 0.07234636287362914,
        "train_loss": 0.14913888348746696
      },
      {
        "epoch": 1286,
        "reward": 0.29552364349365234,
        "val_loss": 0.1456441984378866,
        "train_loss": 0.07760510341316919
      },
      {
        "epoch": 1287,
        "reward": 0.36122608184814453,
        "val_loss": 0.08014583416557539,
        "train_loss": 0.015509075130327031
      },
      {
        "epoch": 1288,
        "reward": 0.30884847044944763,
        "val_loss": 0.12835138808337174,
        "train_loss": 0.004399694182211533
      },
      {
        "epoch": 1289,
        "reward": 0.26539748907089233,
        "val_loss": 0.19636138912340226,
        "train_loss": 0.24701041650797168
      },
      {
        "epoch": 1290,
        "reward": 0.35973629355430603,
        "val_loss": 0.0811884084437874,
        "train_loss": 0.003673666483616846
      },
      {
        "epoch": 1291,
        "reward": 0.3634736239910126,
        "val_loss": 0.07860167617452264,
        "train_loss": 0.0015899706107190398
      },
      {
        "epoch": 1292,
        "reward": 0.3690742254257202,
        "val_loss": 0.07489864782837685,
        "train_loss": 0.0018317909175143891
      },
      {
        "epoch": 1293,
        "reward": 0.3214024305343628,
        "val_loss": 0.11425392630709601,
        "train_loss": 0.010066065276250211
      },
      {
        "epoch": 1294,
        "reward": 0.32626625895500183,
        "val_loss": 0.10928917308878486,
        "train_loss": 0.014800086345775735
      },
      {
        "epoch": 1295,
        "reward": 0.34839603304862976,
        "val_loss": 0.08965322962571268,
        "train_loss": 0.004036175461946046
      },
      {
        "epoch": 1296,
        "reward": 0.34731388092041016,
        "val_loss": 0.09051264988374896,
        "train_loss": 0.00671976855066812
      },
      {
        "epoch": 1297,
        "reward": 0.3595818281173706,
        "val_loss": 0.08129741130895647,
        "train_loss": 7.685841288522379
      },
      {
        "epoch": 1298,
        "reward": 0.3480640947818756,
        "val_loss": 0.08991583191839579,
        "train_loss": 0.009174954870104557
      },
      {
        "epoch": 1299,
        "reward": 0.34186822175979614,
        "val_loss": 0.09498460133389537,
        "train_loss": 0.003924883785097895
      },
      {
        "epoch": 1300,
        "reward": 0.3496873080730438,
        "val_loss": 0.08863998256440807,
        "train_loss": 0.04121068614795849
      },
      {
        "epoch": 1301,
        "reward": 0.38041478395462036,
        "val_loss": 0.06798799084624209,
        "train_loss": 0.005890181892167535
      },
      {
        "epoch": 1302,
        "reward": 0.33963698148727417,
        "val_loss": 0.09689032958496162,
        "train_loss": 3.502955910309398
      },
      {
        "epoch": 1303,
        "reward": 0.3514987528324127,
        "val_loss": 0.08724065841774323,
        "train_loss": 0.005070827636665434
      },
      {
        "epoch": 1304,
        "reward": 0.38872286677360535,
        "val_loss": 0.0633783669161078,
        "train_loss": 0.008264985281549833
      },
      {
        "epoch": 1305,
        "reward": 0.31090614199638367,
        "val_loss": 0.12590500606373617,
        "train_loss": 0.01225869809192003
      },
      {
        "epoch": 1306,
        "reward": 0.36861759424209595,
        "val_loss": 0.07519306743467626,
        "train_loss": 0.023878490061039113
      },
      {
        "epoch": 1307,
        "reward": 0.3530268967151642,
        "val_loss": 0.08607991038921423,
        "train_loss": 0.001955591128570142
      },
      {
        "epoch": 1308,
        "reward": 0.35124459862709045,
        "val_loss": 0.08743543159965027,
        "train_loss": 0.01603510305337225
      },
      {
        "epoch": 1309,
        "reward": 0.36656394600868225,
        "val_loss": 0.07653338496207393,
        "train_loss": 7.8974729037087785
      },
      {
        "epoch": 1310,
        "reward": 0.35363835096359253,
        "val_loss": 0.08562041617863413,
        "train_loss": 0.019603341686188987
      },
      {
        "epoch": 1311,
        "reward": 0.31859931349754333,
        "val_loss": 0.11723585567129444,
        "train_loss": 1.6693571064830883
      },
      {
        "epoch": 1312,
        "reward": 0.37488803267478943,
        "val_loss": 0.07126188216872313,
        "train_loss": 0.3605521300250285
      },
      {
        "epoch": 1313,
        "reward": 0.3636963963508606,
        "val_loss": 0.07845049761402022,
        "train_loss": 0.008340399056578462
      },
      {
        "epoch": 1314,
        "reward": 0.4112265110015869,
        "val_loss": 0.05253867461994689,
        "train_loss": 0.05883081293079438
      },
      {
        "epoch": 1315,
        "reward": 0.3037208020687103,
        "val_loss": 0.13469844352636887,
        "train_loss": 0.0036446848282419243
      },
      {
        "epoch": 1316,
        "reward": 0.3158484101295471,
        "val_loss": 0.12025198547884688,
        "train_loss": 13.881577736325985
      },
      {
        "epoch": 1317,
        "reward": 0.2842768728733063,
        "val_loss": 0.1624620779849855,
        "train_loss": 0.023412947031208484
      },
      {
        "epoch": 1318,
        "reward": 0.34520190954208374,
        "val_loss": 0.0922175084394569,
        "train_loss": 0.03708610706165088
      },
      {
        "epoch": 1319,
        "reward": 0.35195687413215637,
        "val_loss": 0.08689079875018381,
        "train_loss": 0.011013582610058411
      },
      {
        "epoch": 1320,
        "reward": 0.3128452003002167,
        "val_loss": 0.1236502887581342,
        "train_loss": 0.040827210541185474
      },
      {
        "epoch": 1321,
        "reward": 0.31985077261924744,
        "val_loss": 0.11589335465396289,
        "train_loss": 0.0027697832202438102
      },
      {
        "epoch": 1322,
        "reward": 0.35205426812171936,
        "val_loss": 0.08681663979119289,
        "train_loss": 0.44209978151859386
      },
      {
        "epoch": 1323,
        "reward": 0.3653743267059326,
        "val_loss": 0.07732217495296416,
        "train_loss": 0.10264472881513378
      },
      {
        "epoch": 1324,
        "reward": 0.3583732545375824,
        "val_loss": 0.08215585621655919,
        "train_loss": 0.11804522057242978
      },
      {
        "epoch": 1325,
        "reward": 0.34012800455093384,
        "val_loss": 0.0964671927483453,
        "train_loss": 0.02710801296522137
      },
      {
        "epoch": 1326,
        "reward": 0.3207017779350281,
        "val_loss": 0.11499081406301619,
        "train_loss": 0.02298280252209504
      },
      {
        "epoch": 1327,
        "reward": 0.29277318716049194,
        "val_loss": 0.14955458525426885,
        "train_loss": 0.035962351670919955
      },
      {
        "epoch": 1328,
        "reward": 0.32789328694343567,
        "val_loss": 0.10768526184879842,
        "train_loss": 0.011170761957495974
      },
      {
        "epoch": 1329,
        "reward": 0.33593711256980896,
        "val_loss": 0.10014916200556659,
        "train_loss": 0.005992234762043853
      },
      {
        "epoch": 1330,
        "reward": 0.3550795018672943,
        "val_loss": 0.08454855143541604,
        "train_loss": 0.059958667338765266
      },
      {
        "epoch": 1331,
        "reward": 0.378111332654953,
        "val_loss": 0.06933152114340503,
        "train_loss": 0.013797154995420268
      },
      {
        "epoch": 1332,
        "reward": 0.3093017637729645,
        "val_loss": 0.12780762077142885,
        "train_loss": 0.008171063608397863
      },
      {
        "epoch": 1333,
        "reward": 0.4045163094997406,
        "val_loss": 0.05554083455353975,
        "train_loss": 0.016238082933516404
      },
      {
        "epoch": 1334,
        "reward": 0.33192554116249084,
        "val_loss": 0.10382769933702159,
        "train_loss": 0.15975303794116022
      },
      {
        "epoch": 1335,
        "reward": 0.3765661418437958,
        "val_loss": 0.07024946480565372,
        "train_loss": 0.022710163804871487
      },
      {
        "epoch": 1336,
        "reward": 0.3866439163684845,
        "val_loss": 0.06449825037166843,
        "train_loss": 0.010646273652757653
      },
      {
        "epoch": 1337,
        "reward": 0.27648282051086426,
        "val_loss": 0.17551178522574315,
        "train_loss": 0.060210233991920874
      },
      {
        "epoch": 1338,
        "reward": 0.354696661233902,
        "val_loss": 0.08483176068070211,
        "train_loss": 11.155168131910894
      },
      {
        "epoch": 1339,
        "reward": 0.26311951875686646,
        "val_loss": 0.20101703025284223,
        "train_loss": 0.25604069329445056
      },
      {
        "epoch": 1340,
        "reward": 0.25600215792655945,
        "val_loss": 0.2164716658506742,
        "train_loss": 0.009354614594905377
      },
      {
        "epoch": 1341,
        "reward": 0.31281036138534546,
        "val_loss": 0.12369035666259671,
        "train_loss": 0.034032085791525245
      },
      {
        "epoch": 1342,
        "reward": 0.349282443523407,
        "val_loss": 0.08895624619409707,
        "train_loss": 0.016760221413558332
      },
      {
        "epoch": 1343,
        "reward": 0.3158946633338928,
        "val_loss": 0.12020049065384748,
        "train_loss": 0.09868042587249175
      },
      {
        "epoch": 1344,
        "reward": 0.38172903656959534,
        "val_loss": 0.0672344925946423,
        "train_loss": 0.014606661919200493
      },
      {
        "epoch": 1345,
        "reward": 0.28636634349823,
        "val_loss": 0.1591664712011282,
        "train_loss": 0.05138574281667948
      },
      {
        "epoch": 1346,
        "reward": 0.31806573271751404,
        "val_loss": 0.11781376460151348,
        "train_loss": 0.06305726522889298
      },
      {
        "epoch": 1347,
        "reward": 0.3047787845134735,
        "val_loss": 0.1333587244069869,
        "train_loss": 0.04133650074884197
      },
      {
        "epoch": 1348,
        "reward": 0.27305087447166443,
        "val_loss": 0.1816627889285363,
        "train_loss": 0.08284034751075244
      },
      {
        "epoch": 1349,
        "reward": 0.3612346053123474,
        "val_loss": 0.08013993007105975,
        "train_loss": 1.2026466185496667
      },
      {
        "epoch": 1350,
        "reward": 0.4053206145763397,
        "val_loss": 0.055171317785737174,
        "train_loss": 0.0055101119140510075
      },
      {
        "epoch": 1351,
        "reward": 0.32904231548309326,
        "val_loss": 0.10656916426627763,
        "train_loss": 0.14039484862979196
      },
      {
        "epoch": 1352,
        "reward": 0.32969510555267334,
        "val_loss": 0.10594115290275243,
        "train_loss": 0.038572539753763874
      },
      {
        "epoch": 1353,
        "reward": 0.3090156018733978,
        "val_loss": 0.1281505374977964,
        "train_loss": 0.00884015625576222
      },
      {
        "epoch": 1354,
        "reward": 0.34723028540611267,
        "val_loss": 0.09057944680846829,
        "train_loss": 159.4590342617381
      },
      {
        "epoch": 1355,
        "reward": 0.36845663189888,
        "val_loss": 0.07529711857621026,
        "train_loss": 0.10617603341828587
      },
      {
        "epoch": 1356,
        "reward": 0.34454745054244995,
        "val_loss": 0.09275326946850068,
        "train_loss": 0.05665867514632667
      },
      {
        "epoch": 1357,
        "reward": 0.23638904094696045,
        "val_loss": 0.2674450521174419,
        "train_loss": 0.00488140537205394
      },
      {
        "epoch": 1358,
        "reward": 0.39463621377944946,
        "val_loss": 0.06030925189822613,
        "train_loss": 0.00510805827736204
      },
      {
        "epoch": 1359,
        "reward": 0.2890501320362091,
        "val_loss": 0.15505169987903042,
        "train_loss": 0.028254889901693156
      },
      {
        "epoch": 1360,
        "reward": 0.3037613332271576,
        "val_loss": 0.13464685244668675,
        "train_loss": 0.0065575425711498474
      },
      {
        "epoch": 1361,
        "reward": 0.36715707182884216,
        "val_loss": 0.07614352657193584,
        "train_loss": 2.746402270778722
      },
      {
        "epoch": 1362,
        "reward": 0.40269985795021057,
        "val_loss": 0.05638548384636773,
        "train_loss": 1.9942873363362685
      },
      {
        "epoch": 1363,
        "reward": 0.3982372581958771,
        "val_loss": 0.05852097571187187,
        "train_loss": 0.28339840710130093
      },
      {
        "epoch": 1364,
        "reward": 0.3586120307445526,
        "val_loss": 0.08198544359973832,
        "train_loss": 0.004207460981258639
      },
      {
        "epoch": 1365,
        "reward": 0.37909945845603943,
        "val_loss": 0.06875154759576876,
        "train_loss": 0.006556454589223484
      },
      {
        "epoch": 1366,
        "reward": 0.2950034439563751,
        "val_loss": 0.1463742657423219,
        "train_loss": 0.004823014039524983
      },
      {
        "epoch": 1367,
        "reward": 0.4067516326904297,
        "val_loss": 0.054520431899748346,
        "train_loss": 4.455086937854223
      },
      {
        "epoch": 1368,
        "reward": 0.3031970262527466,
        "val_loss": 0.1353677136794431,
        "train_loss": 0.021508206914789368
      },
      {
        "epoch": 1369,
        "reward": 0.39293715357780457,
        "val_loss": 0.06117388340602962,
        "train_loss": 0.08075653216166337
      },
      {
        "epoch": 1370,
        "reward": 0.3491854667663574,
        "val_loss": 0.08903217981112123,
        "train_loss": 0.0031101049246969456
      },
      {
        "epoch": 1371,
        "reward": 0.32772448658943176,
        "val_loss": 0.10785039023695779,
        "train_loss": 0.006639974492661447
      },
      {
        "epoch": 1372,
        "reward": 0.27736279368400574,
        "val_loss": 0.17397593389614485,
        "train_loss": 0.13800524436443923
      },
      {
        "epoch": 1373,
        "reward": 0.36683639883995056,
        "val_loss": 0.07635402583192834,
        "train_loss": 0.0051370482279498204
      },
      {
        "epoch": 1374,
        "reward": 0.31170204281806946,
        "val_loss": 0.12497364871212215,
        "train_loss": 0.010867588150876354
      },
      {
        "epoch": 1375,
        "reward": 0.29437723755836487,
        "val_loss": 0.14725890637574984,
        "train_loss": 0.1309080123208752
      },
      {
        "epoch": 1376,
        "reward": 0.2942573130130768,
        "val_loss": 0.14742906499512692,
        "train_loss": 0.03748217529356715
      },
      {
        "epoch": 1377,
        "reward": 0.30680155754089355,
        "val_loss": 0.13084133248776197,
        "train_loss": 0.01609601520137333
      },
      {
        "epoch": 1378,
        "reward": 0.33787834644317627,
        "val_loss": 0.09842367992054538,
        "train_loss": 0.020141786128358666
      },
      {
        "epoch": 1379,
        "reward": 0.39285847544670105,
        "val_loss": 0.06121422907329231,
        "train_loss": 0.024892760727023136
      },
      {
        "epoch": 1380,
        "reward": 0.3464772403240204,
        "val_loss": 0.09118364337440912,
        "train_loss": 15.662232016838411
      },
      {
        "epoch": 1381,
        "reward": 0.3796861469745636,
        "val_loss": 0.0684097944779621,
        "train_loss": 0.14893460693201632
      },
      {
        "epoch": 1382,
        "reward": 0.35113486647605896,
        "val_loss": 0.08751971413065414,
        "train_loss": 0.14980711329008045
      },
      {
        "epoch": 1383,
        "reward": 0.32092157006263733,
        "val_loss": 0.11475902761282798,
        "train_loss": 0.003110163044206834
      },
      {
        "epoch": 1384,
        "reward": 0.33446022868156433,
        "val_loss": 0.10148550556498646,
        "train_loss": 0.003978447577362833
      },
      {
        "epoch": 1385,
        "reward": 0.36212560534477234,
        "val_loss": 0.07952374176030778,
        "train_loss": 0.01709851136715174
      },
      {
        "epoch": 1386,
        "reward": 0.3133429288864136,
        "val_loss": 0.12307922891756919,
        "train_loss": 0.11664454173702464
      },
      {
        "epoch": 1387,
        "reward": 0.323070228099823,
        "val_loss": 0.11252222556088652,
        "train_loss": 0.012271959524591343
      },
      {
        "epoch": 1388,
        "reward": 0.3679066598415375,
        "val_loss": 0.07565402138113443,
        "train_loss": 0.0033916899033451606
      },
      {
        "epoch": 1389,
        "reward": 0.33209899067878723,
        "val_loss": 0.10366543609623997,
        "train_loss": 0.0345672222759871
      },
      {
        "epoch": 1390,
        "reward": 0.40925756096839905,
        "val_loss": 0.053400821068083006,
        "train_loss": 0.009791429523654816
      },
      {
        "epoch": 1391,
        "reward": 0.39924436807632446,
        "val_loss": 0.058031392834631594,
        "train_loss": 0.06931384496734748
      },
      {
        "epoch": 1392,
        "reward": 0.2601412534713745,
        "val_loss": 0.2073117997081551,
        "train_loss": 0.1769206911468735
      },
      {
        "epoch": 1393,
        "reward": 0.3705836236476898,
        "val_loss": 0.07393471726806768,
        "train_loss": 0.710118842711766
      },
      {
        "epoch": 1394,
        "reward": 0.30692365765571594,
        "val_loss": 0.13069116731432068,
        "train_loss": 0.07119667638258201
      },
      {
        "epoch": 1395,
        "reward": 0.3988400101661682,
        "val_loss": 0.05822743794747761,
        "train_loss": 0.005229316031300886
      },
      {
        "epoch": 1396,
        "reward": 0.3754439651966095,
        "val_loss": 0.07092470393607593,
        "train_loss": 0.02355492388584515
      },
      {
        "epoch": 1397,
        "reward": 0.33272334933280945,
        "val_loss": 0.10308372347312147,
        "train_loss": 0.05294733023541854
      },
      {
        "epoch": 1398,
        "reward": 0.3528284728527069,
        "val_loss": 0.0862295967672253,
        "train_loss": 0.007069725996958509
      },
      {
        "epoch": 1399,
        "reward": 0.29314684867858887,
        "val_loss": 0.14901597493527724,
        "train_loss": 0.0233793345648267
      },
      {
        "epoch": 1400,
        "reward": 0.3036231994628906,
        "val_loss": 0.13482288259547204,
        "train_loss": 0.027284314054703336
      },
      {
        "epoch": 1401,
        "reward": 0.35321423411369324,
        "val_loss": 0.08593878950757373,
        "train_loss": 0.06595849519488603
      },
      {
        "epoch": 1402,
        "reward": 0.37381184101104736,
        "val_loss": 0.07191978586862595,
        "train_loss": 0.015078476867739273
      },
      {
        "epoch": 1403,
        "reward": 0.36947062611579895,
        "val_loss": 0.07464411563497768,
        "train_loss": 0.02230538137491049
      },
      {
        "epoch": 1404,
        "reward": 0.39915814995765686,
        "val_loss": 0.05807312803621504,
        "train_loss": 0.018896144206127456
      },
      {
        "epoch": 1405,
        "reward": 0.3866654932498932,
        "val_loss": 0.06448649717536423,
        "train_loss": 5.3144086916752435
      },
      {
        "epoch": 1406,
        "reward": 0.3504456579685211,
        "val_loss": 0.08805105612762938,
        "train_loss": 483.5371596663091
      },
      {
        "epoch": 1407,
        "reward": 0.3645518720149994,
        "val_loss": 0.07787291102743309,
        "train_loss": 0.003220774778508957
      },
      {
        "epoch": 1408,
        "reward": 0.34417665004730225,
        "val_loss": 0.09305845379588261,
        "train_loss": 0.01893791521139904
      },
      {
        "epoch": 1409,
        "reward": 0.3276415169239044,
        "val_loss": 0.10793164664313995,
        "train_loss": 0.2756975824695823
      },
      {
        "epoch": 1410,
        "reward": 0.3984391391277313,
        "val_loss": 0.058422495024777685,
        "train_loss": 0.17005329478622747
      },
      {
        "epoch": 1411,
        "reward": 0.32178258895874023,
        "val_loss": 0.11385647646758505,
        "train_loss": 0.01472736438783893
      },
      {
        "epoch": 1412,
        "reward": 0.3578905463218689,
        "val_loss": 0.08250162610784173,
        "train_loss": 0.01739386410148514
      },
      {
        "epoch": 1413,
        "reward": 0.2995128333568573,
        "val_loss": 0.14018911611804338,
        "train_loss": 0.07080991477204616
      },
      {
        "epoch": 1414,
        "reward": 0.39419233798980713,
        "val_loss": 0.060533808816606846,
        "train_loss": 0.007943581909715319
      },
      {
        "epoch": 1415,
        "reward": 0.3923965096473694,
        "val_loss": 0.061451884184082574,
        "train_loss": 0.010179803605681697
      },
      {
        "epoch": 1416,
        "reward": 0.3946852385997772,
        "val_loss": 0.06028449198389093,
        "train_loss": 0.08840018782813366
      },
      {
        "epoch": 1417,
        "reward": 0.3593514859676361,
        "val_loss": 0.08146025885694794,
        "train_loss": 0.021601630544794786
      },
      {
        "epoch": 1418,
        "reward": 0.3683980405330658,
        "val_loss": 0.07533506711895045,
        "train_loss": 0.0032336749878035895
      },
      {
        "epoch": 1419,
        "reward": 0.3767103850841522,
        "val_loss": 0.07016321979920447,
        "train_loss": 0.03795219103692314
      },
      {
        "epoch": 1420,
        "reward": 0.36830005049705505,
        "val_loss": 0.07539856727817096,
        "train_loss": 0.008430275111375242
      },
      {
        "epoch": 1421,
        "reward": 0.33863532543182373,
        "val_loss": 0.09776024386623508,
        "train_loss": 0.032436715959892566
      },
      {
        "epoch": 1422,
        "reward": 0.3701460063457489,
        "val_loss": 0.07421273376634677,
        "train_loss": 0.06037780229046173
      },
      {
        "epoch": 1423,
        "reward": 0.3990219831466675,
        "val_loss": 0.05813911274058877,
        "train_loss": 0.25810948680233337
      },
      {
        "epoch": 1424,
        "reward": 0.36880967020988464,
        "val_loss": 0.07506907395561159,
        "train_loss": 3.074016513113048
      },
      {
        "epoch": 1425,
        "reward": 0.34125059843063354,
        "val_loss": 0.09550774134861838,
        "train_loss": 0.008212903655266227
      },
      {
        "epoch": 1426,
        "reward": 0.33989962935447693,
        "val_loss": 0.09666373168459229,
        "train_loss": 0.033606202664696654
      },
      {
        "epoch": 1427,
        "reward": 0.3159089982509613,
        "val_loss": 0.12018455683885675,
        "train_loss": 0.004316681958943473
      },
      {
        "epoch": 1428,
        "reward": 0.3795877695083618,
        "val_loss": 0.06846697117102199,
        "train_loss": 0.4674393429128171
      },
      {
        "epoch": 1429,
        "reward": 0.23853321373462677,
        "val_loss": 0.2611855374042144,
        "train_loss": 0.0822836396202127
      },
      {
        "epoch": 1430,
        "reward": 0.31909501552581787,
        "val_loss": 0.1167018996576579,
        "train_loss": 0.005385569378037102
      },
      {
        "epoch": 1431,
        "reward": 0.35513630509376526,
        "val_loss": 0.08450660716126938,
        "train_loss": 0.006405679806938189
      },
      {
        "epoch": 1432,
        "reward": 0.33201295137405396,
        "val_loss": 0.10374591734060752,
        "train_loss": 0.010633200074712827
      },
      {
        "epoch": 1433,
        "reward": 0.39286211133003235,
        "val_loss": 0.061212361544936096,
        "train_loss": 0.036669440996468856
      },
      {
        "epoch": 1434,
        "reward": 0.35527756810188293,
        "val_loss": 0.0844024191652092,
        "train_loss": 0.027426986866675388
      },
      {
        "epoch": 1435,
        "reward": 0.35247501730918884,
        "val_loss": 0.0864970352475731,
        "train_loss": 0.01961487791698766
      },
      {
        "epoch": 1436,
        "reward": 0.3441222608089447,
        "val_loss": 0.09310331718838175,
        "train_loss": 0.003822899851281993
      },
      {
        "epoch": 1437,
        "reward": 0.4106220304965973,
        "val_loss": 0.05280173719906348,
        "train_loss": 0.03980058212157299
      },
      {
        "epoch": 1438,
        "reward": 0.4036872386932373,
        "val_loss": 0.05592459958695274,
        "train_loss": 0.0024391421072428223
      },
      {
        "epoch": 1439,
        "reward": 0.39692988991737366,
        "val_loss": 0.05916336344671436,
        "train_loss": 0.004164124836786589
      },
      {
        "epoch": 1440,
        "reward": 0.37446221709251404,
        "val_loss": 0.07152139485905147,
        "train_loss": 0.013245598071552404
      },
      {
        "epoch": 1441,
        "reward": 0.37692931294441223,
        "val_loss": 0.07003250201731655,
        "train_loss": 0.007159544756107677
      },
      {
        "epoch": 1442,
        "reward": 0.4144398868083954,
        "val_loss": 0.05116403353375582,
        "train_loss": 0.3118171473065908
      },
      {
        "epoch": 1443,
        "reward": 0.29250073432922363,
        "val_loss": 0.1499487827365686,
        "train_loss": 0.002856806307485945
      },
      {
        "epoch": 1444,
        "reward": 0.31219497323036194,
        "val_loss": 0.12440095885748244,
        "train_loss": 0.06213019545891886
      },
      {
        "epoch": 1445,
        "reward": 0.35125815868377686,
        "val_loss": 0.08742502999458727,
        "train_loss": 0.004494001985187004
      },
      {
        "epoch": 1446,
        "reward": 0.38252124190330505,
        "val_loss": 0.06678479829653432,
        "train_loss": 0.004282492931521959
      },
      {
        "epoch": 1447,
        "reward": 0.32664644718170166,
        "val_loss": 0.10891192028481912,
        "train_loss": 0.00561383921198145
      },
      {
        "epoch": 1448,
        "reward": 0.3002215027809143,
        "val_loss": 0.1392459093393492,
        "train_loss": 0.03213143888360019
      },
      {
        "epoch": 1449,
        "reward": 0.3634340763092041,
        "val_loss": 0.07862857304488509,
        "train_loss": 17.60377887641296
      },
      {
        "epoch": 1450,
        "reward": 0.35671505331993103,
        "val_loss": 0.08335060077661183,
        "train_loss": 0.19537481412491894
      },
      {
        "epoch": 1451,
        "reward": 0.25229114294052124,
        "val_loss": 0.22511580877471715,
        "train_loss": 0.20003440621012095
      },
      {
        "epoch": 1452,
        "reward": 0.31820178031921387,
        "val_loss": 0.1176660919175317,
        "train_loss": 0.11540860492011863
      },
      {
        "epoch": 1453,
        "reward": 0.3751416504383087,
        "val_loss": 0.07110785253462382,
        "train_loss": 0.01072769405370239
      },
      {
        "epoch": 1454,
        "reward": 0.30405279994010925,
        "val_loss": 0.13427635992827294,
        "train_loss": 0.03490389262307977
      },
      {
        "epoch": 1455,
        "reward": 0.3830367922782898,
        "val_loss": 0.06649400334884246,
        "train_loss": 0.0038611470711727566
      },
      {
        "epoch": 1456,
        "reward": 0.40393587946891785,
        "val_loss": 0.05580922424477259,
        "train_loss": 0.06799806371936239
      },
      {
        "epoch": 1457,
        "reward": 0.33440446853637695,
        "val_loss": 0.10153633273772097,
        "train_loss": 0.016880404708899732
      },
      {
        "epoch": 1458,
        "reward": 0.2935055196285248,
        "val_loss": 0.1485011732791983,
        "train_loss": 0.013173960493846747
      },
      {
        "epoch": 1459,
        "reward": 0.3841078579425812,
        "val_loss": 0.06589429507896837,
        "train_loss": 0.025136656812089944
      },
      {
        "epoch": 1460,
        "reward": 0.338356614112854,
        "val_loss": 0.098003947581414,
        "train_loss": 0.02936676156265933
      },
      {
        "epoch": 1461,
        "reward": 0.3694566786289215,
        "val_loss": 0.07465308269352786,
        "train_loss": 0.06567256843691911
      },
      {
        "epoch": 1462,
        "reward": 0.3246540427207947,
        "val_loss": 0.11090621425994739,
        "train_loss": 0.045982144476511166
      },
      {
        "epoch": 1463,
        "reward": 0.37138745188713074,
        "val_loss": 0.07342712258936704,
        "train_loss": 0.2658967256690997
      },
      {
        "epoch": 1464,
        "reward": 0.3752734065055847,
        "val_loss": 0.07102796005243103,
        "train_loss": 0.3681900284329738
      },
      {
        "epoch": 1465,
        "reward": 0.2995932996273041,
        "val_loss": 0.14008166241442918,
        "train_loss": 4.595554826375099
      },
      {
        "epoch": 1466,
        "reward": 0.37551772594451904,
        "val_loss": 0.0708800756069,
        "train_loss": 0.01567251277737551
      },
      {
        "epoch": 1467,
        "reward": 0.3670811355113983,
        "val_loss": 0.07619330358491945,
        "train_loss": 0.5118652745053484
      },
      {
        "epoch": 1468,
        "reward": 0.3706553876399994,
        "val_loss": 0.0738892500885413,
        "train_loss": 0.23385510626128683
      },
      {
        "epoch": 1469,
        "reward": 0.42320308089256287,
        "val_loss": 0.047609437484685,
        "train_loss": 0.027900741691575186
      },
      {
        "epoch": 1470,
        "reward": 0.30386707186698914,
        "val_loss": 0.13451224932630015,
        "train_loss": 0.006877756224079908
      },
      {
        "epoch": 1471,
        "reward": 0.3104666471481323,
        "val_loss": 0.12642281434714928,
        "train_loss": 0.003536091064863565
      },
      {
        "epoch": 1472,
        "reward": 0.32801830768585205,
        "val_loss": 0.10756316249067563,
        "train_loss": 0.00355528417430133
      },
      {
        "epoch": 1473,
        "reward": 0.3427741527557373,
        "val_loss": 0.09422324825676956,
        "train_loss": 0.005458608139703686
      },
      {
        "epoch": 1474,
        "reward": 0.3007868528366089,
        "val_loss": 0.13849888200638816,
        "train_loss": 0.0041731115343282
      },
      {
        "epoch": 1475,
        "reward": 0.4029100835323334,
        "val_loss": 0.056286987045106276,
        "train_loss": 0.009806269779696427
      },
      {
        "epoch": 1476,
        "reward": 0.3552260100841522,
        "val_loss": 0.0844404321334358,
        "train_loss": 0.007983262873844628
      },
      {
        "epoch": 1477,
        "reward": 0.4108497202396393,
        "val_loss": 0.05270248835274417,
        "train_loss": 0.03329854279763822
      },
      {
        "epoch": 1478,
        "reward": 0.3287312984466553,
        "val_loss": 0.10686992223574114,
        "train_loss": 0.01620427446701237
      },
      {
        "epoch": 1479,
        "reward": 0.39445438981056213,
        "val_loss": 0.060401118834436475,
        "train_loss": 0.0788418476924842
      },
      {
        "epoch": 1480,
        "reward": 0.3730913996696472,
        "val_loss": 0.07236405455166407,
        "train_loss": 0.02172361701097823
      },
      {
        "epoch": 1481,
        "reward": 0.3361791670322418,
        "val_loss": 0.09993210322240234,
        "train_loss": 0.003645284394364213
      },
      {
        "epoch": 1482,
        "reward": 0.353743314743042,
        "val_loss": 0.08554181979187499,
        "train_loss": 2.7322740619231594
      },
      {
        "epoch": 1483,
        "reward": 0.29964932799339294,
        "val_loss": 0.14000686927049952,
        "train_loss": 0.023407753541155565
      },
      {
        "epoch": 1484,
        "reward": 0.39644667506217957,
        "val_loss": 0.059402751653189104,
        "train_loss": 0.029080204081275533
      },
      {
        "epoch": 1485,
        "reward": 0.3683193027973175,
        "val_loss": 0.07538608079942476,
        "train_loss": 2.0335826581532066
      },
      {
        "epoch": 1486,
        "reward": 0.3913477659225464,
        "val_loss": 0.06199512875796894,
        "train_loss": 0.8117216712686548
      },
      {
        "epoch": 1487,
        "reward": 0.38183102011680603,
        "val_loss": 0.06717640634451527,
        "train_loss": 0.33415195803304587
      },
      {
        "epoch": 1488,
        "reward": 0.40742871165275574,
        "val_loss": 0.05421544120638698,
        "train_loss": 0.0044936244107353
      },
      {
        "epoch": 1489,
        "reward": 0.41034671664237976,
        "val_loss": 0.052922028127276075,
        "train_loss": 0.01930661133421661
      },
      {
        "epoch": 1490,
        "reward": 0.2972697913646698,
        "val_loss": 0.14322561677233484,
        "train_loss": 0.0043724014539153495
      },
      {
        "epoch": 1491,
        "reward": 0.41788241267204285,
        "val_loss": 0.049734543650369493,
        "train_loss": 0.007498233552129163
      },
      {
        "epoch": 1492,
        "reward": 0.2545521557331085,
        "val_loss": 0.2197990573851192,
        "train_loss": 0.07399711319577854
      },
      {
        "epoch": 1493,
        "reward": 0.3895218074321747,
        "val_loss": 0.06295375185644454,
        "train_loss": 0.0072688363018712085
      },
      {
        "epoch": 1494,
        "reward": 0.29055705666542053,
        "val_loss": 0.15279776384288976,
        "train_loss": 0.03286005998793721
      },
      {
        "epoch": 1495,
        "reward": 0.3563442528247833,
        "val_loss": 0.08362047471538452,
        "train_loss": 0.007658420523792022
      },
      {
        "epoch": 1496,
        "reward": 0.436258465051651,
        "val_loss": 0.04279736714774377,
        "train_loss": 0.007450086411503994
      },
      {
        "epoch": 1497,
        "reward": 0.33933308720588684,
        "val_loss": 0.0971532980370934,
        "train_loss": 0.02234347672020494
      },
      {
        "epoch": 1498,
        "reward": 0.34921541810035706,
        "val_loss": 0.08900873791883766,
        "train_loss": 33.11777809255622
      },
      {
        "epoch": 1499,
        "reward": 0.3536212146282196,
        "val_loss": 0.08563324711368685,
        "train_loss": 0.41021182831473896
      },
      {
        "epoch": 1500,
        "reward": 0.42546185851097107,
        "val_loss": 0.0467370628383443,
        "train_loss": 0.0066203744848350584
      },
      {
        "epoch": 1501,
        "reward": 0.2517024278640747,
        "val_loss": 0.226526386495347,
        "train_loss": 0.16454587050429836
      },
      {
        "epoch": 1502,
        "reward": 0.3747163712978363,
        "val_loss": 0.0713663610929091,
        "train_loss": 0.017359342686736803
      },
      {
        "epoch": 1503,
        "reward": 0.3901113271713257,
        "val_loss": 0.06264246371158931,
        "train_loss": 0.03850206420695311
      },
      {
        "epoch": 1504,
        "reward": 0.3387924134731293,
        "val_loss": 0.09762323247351949,
        "train_loss": 0.3444012182121696
      },
      {
        "epoch": 1505,
        "reward": 0.3187817335128784,
        "val_loss": 0.11703899492775756,
        "train_loss": 0.2654930475231455
      },
      {
        "epoch": 1506,
        "reward": 0.4172394871711731,
        "val_loss": 0.04999819618387846,
        "train_loss": 0.03983558215552945
      },
      {
        "epoch": 1507,
        "reward": 0.4113016128540039,
        "val_loss": 0.05250611034197001,
        "train_loss": 0.007393702098432606
      },
      {
        "epoch": 1508,
        "reward": 0.38876697421073914,
        "val_loss": 0.06335482769853636,
        "train_loss": 0.0045470191800212395
      },
      {
        "epoch": 1509,
        "reward": 0.40388813614845276,
        "val_loss": 0.055831358354355744,
        "train_loss": 0.004182978753585933
      },
      {
        "epoch": 1510,
        "reward": 0.34566712379455566,
        "val_loss": 0.09183881141611241,
        "train_loss": 0.346515558727333
      },
      {
        "epoch": 1511,
        "reward": 0.36556267738342285,
        "val_loss": 0.07719668284075201,
        "train_loss": 0.0014595798370814568
      },
      {
        "epoch": 1512,
        "reward": 0.35084789991378784,
        "val_loss": 0.08774049632068325,
        "train_loss": 0.002418223705831224
      },
      {
        "epoch": 1513,
        "reward": 0.4288685917854309,
        "val_loss": 0.04545362962172866,
        "train_loss": 0.003336646819347012
      },
      {
        "epoch": 1514,
        "reward": 0.41152411699295044,
        "val_loss": 0.05240969834371104,
        "train_loss": 0.01157388414734529
      },
      {
        "epoch": 1515,
        "reward": 0.4140220284461975,
        "val_loss": 0.051340559389375685,
        "train_loss": 0.08622444581384435
      },
      {
        "epoch": 1516,
        "reward": 0.3678620755672455,
        "val_loss": 0.07568303267180454,
        "train_loss": 0.03324496091938901
      },
      {
        "epoch": 1517,
        "reward": 0.2940574586391449,
        "val_loss": 0.14771314166552788,
        "train_loss": 0.204679730614701
      },
      {
        "epoch": 1518,
        "reward": 0.3647800385951996,
        "val_loss": 0.07771971131192654,
        "train_loss": 0.016957567189295402
      },
      {
        "epoch": 1519,
        "reward": 0.3739209473133087,
        "val_loss": 0.07185279362498218,
        "train_loss": 0.013417638775815878
      },
      {
        "epoch": 1520,
        "reward": 0.2788756191730499,
        "val_loss": 0.17137366579845548,
        "train_loss": 0.027568430043314808
      },
      {
        "epoch": 1521,
        "reward": 0.407764196395874,
        "val_loss": 0.05406496851147884,
        "train_loss": 0.004105433485724811
      },
      {
        "epoch": 1522,
        "reward": 0.40875592827796936,
        "val_loss": 0.053622902048768344,
        "train_loss": 0.04463799893238292
      },
      {
        "epoch": 1523,
        "reward": 0.40089353919029236,
        "val_loss": 0.05723935320565943,
        "train_loss": 0.1053760578184805
      },
      {
        "epoch": 1524,
        "reward": 0.3238646984100342,
        "val_loss": 0.11170814092578699,
        "train_loss": 0.0106447174789187
      },
      {
        "epoch": 1525,
        "reward": 0.39442935585975647,
        "val_loss": 0.06041379332184858,
        "train_loss": 4.025842217512307
      },
      {
        "epoch": 1526,
        "reward": 0.3806247413158417,
        "val_loss": 0.06786699693475384,
        "train_loss": 0.017837520339902276
      },
      {
        "epoch": 1527,
        "reward": 0.3633415997028351,
        "val_loss": 0.07869146668859425,
        "train_loss": 0.004743946183995062
      },
      {
        "epoch": 1528,
        "reward": 0.38065579533576965,
        "val_loss": 0.0678491015340634,
        "train_loss": 0.0245696909758128
      },
      {
        "epoch": 1529,
        "reward": 0.40756478905677795,
        "val_loss": 0.0541543601835396,
        "train_loss": 0.28394632377855417
      },
      {
        "epoch": 1530,
        "reward": 0.4231124818325043,
        "val_loss": 0.04764480199186697,
        "train_loss": 0.28887027745342775
      },
      {
        "epoch": 1531,
        "reward": 0.35046151280403137,
        "val_loss": 0.08803877507203392,
        "train_loss": 0.026565348776369565
      },
      {
        "epoch": 1532,
        "reward": 0.3952140212059021,
        "val_loss": 0.0600182808349408,
        "train_loss": 0.010356714882408805
      },
      {
        "epoch": 1533,
        "reward": 0.4153328835964203,
        "val_loss": 0.050788982368041094,
        "train_loss": 0.3256309060827614
      },
      {
        "epoch": 1534,
        "reward": 0.3305782973766327,
        "val_loss": 0.10509829601090002,
        "train_loss": 0.006433325655822186
      },
      {
        "epoch": 1535,
        "reward": 0.36475932598114014,
        "val_loss": 0.07773357907509697,
        "train_loss": 0.0019020495304595477
      },
      {
        "epoch": 1536,
        "reward": 0.4366970658302307,
        "val_loss": 0.04264502221901369,
        "train_loss": 389.1797730845728
      },
      {
        "epoch": 1537,
        "reward": 0.344828337430954,
        "val_loss": 0.09252288948378659,
        "train_loss": 0.006040051569401
      },
      {
        "epoch": 1538,
        "reward": 0.3415507674217224,
        "val_loss": 0.0952530668291729,
        "train_loss": 0.008493998122363476
      },
      {
        "epoch": 1539,
        "reward": 0.36726123094558716,
        "val_loss": 0.07607527668421556,
        "train_loss": 0.09891398281608697
      },
      {
        "epoch": 1540,
        "reward": 0.3529776930809021,
        "val_loss": 0.08611699203694505,
        "train_loss": 0.010374209999554296
      },
      {
        "epoch": 1541,
        "reward": 0.264936238527298,
        "val_loss": 0.19729326899895178,
        "train_loss": 0.030368683642686498
      },
      {
        "epoch": 1542,
        "reward": 0.32730013132095337,
        "val_loss": 0.10826677463566219,
        "train_loss": 0.20914378381448928
      },
      {
        "epoch": 1543,
        "reward": 0.32742026448249817,
        "val_loss": 0.10814869468699076,
        "train_loss": 0.005558157189135762
      },
      {
        "epoch": 1544,
        "reward": 0.3844967782497406,
        "val_loss": 0.06567803214004796,
        "train_loss": 0.013062242724607551
      },
      {
        "epoch": 1545,
        "reward": 0.4253899157047272,
        "val_loss": 0.046764587483526805,
        "train_loss": 0.11644702178525151
      },
      {
        "epoch": 1546,
        "reward": 0.30373236536979675,
        "val_loss": 0.13468375003347838,
        "train_loss": 0.08397763715968792
      },
      {
        "epoch": 1547,
        "reward": 0.3767779767513275,
        "val_loss": 0.07012285040192572,
        "train_loss": 0.012209867520972204
      },
      {
        "epoch": 1548,
        "reward": 0.4146588444709778,
        "val_loss": 0.0510717962180414,
        "train_loss": 0.00672200821134958
      },
      {
        "epoch": 1549,
        "reward": 0.2810889184474945,
        "val_loss": 0.16765162248962692,
        "train_loss": 0.013112692755177372
      },
      {
        "epoch": 1550,
        "reward": 0.37890708446502686,
        "val_loss": 0.06886404205787196,
        "train_loss": 0.001744046521016921
      },
      {
        "epoch": 1551,
        "reward": 0.3967282772064209,
        "val_loss": 0.059263114513929134,
        "train_loss": 0.033414394613198686
      },
      {
        "epoch": 1552,
        "reward": 0.38140496611595154,
        "val_loss": 0.0674194403400179,
        "train_loss": 0.005476277736096773
      },
      {
        "epoch": 1553,
        "reward": 0.411447674036026,
        "val_loss": 0.05244280775929967,
        "train_loss": 0.007878733103727708
      },
      {
        "epoch": 1554,
        "reward": 0.41954946517944336,
        "val_loss": 0.049057905967596786,
        "train_loss": 0.16971719388157697
      },
      {
        "epoch": 1555,
        "reward": 0.4246581494808197,
        "val_loss": 0.04704547419117132,
        "train_loss": 0.0026906430989059186
      },
      {
        "epoch": 1556,
        "reward": 0.3887783885002136,
        "val_loss": 0.06334874344507366,
        "train_loss": 0.012870038786926531
      },
      {
        "epoch": 1557,
        "reward": 0.36212894320487976,
        "val_loss": 0.07952144173863676,
        "train_loss": 0.06491855980262838
      },
      {
        "epoch": 1558,
        "reward": 0.3182208836078644,
        "val_loss": 0.11764537862992645,
        "train_loss": 0.011843428762365268
      },
      {
        "epoch": 1559,
        "reward": 0.4250040650367737,
        "val_loss": 0.046912467323376665,
        "train_loss": 0.004943902915608935
      },
      {
        "epoch": 1560,
        "reward": 0.39915814995765686,
        "val_loss": 0.05807312636378421,
        "train_loss": 0.18288043232122128
      },
      {
        "epoch": 1561,
        "reward": 0.3829902708530426,
        "val_loss": 0.0665201797746704,
        "train_loss": 0.10225044010717109
      },
      {
        "epoch": 1562,
        "reward": 0.3847097158432007,
        "val_loss": 0.06555994820415176,
        "train_loss": 0.003693514974604393
      },
      {
        "epoch": 1563,
        "reward": 0.3925217092037201,
        "val_loss": 0.06138735602871748,
        "train_loss": 0.12576534515294321
      },
      {
        "epoch": 1564,
        "reward": 0.42414578795433044,
        "val_loss": 0.047243234835540146,
        "train_loss": 0.004419138693335229
      },
      {
        "epoch": 1565,
        "reward": 0.3568134009838104,
        "val_loss": 0.08327921830017918,
        "train_loss": 0.013434322397328148
      },
      {
        "epoch": 1566,
        "reward": 0.37479621171951294,
        "val_loss": 0.07131776272685134,
        "train_loss": 0.00895437481267436
      },
      {
        "epoch": 1567,
        "reward": 0.42472559213638306,
        "val_loss": 0.04701951380619513,
        "train_loss": 35.30914463234918
      },
      {
        "epoch": 1568,
        "reward": 0.4056268334388733,
        "val_loss": 0.05503131066507194,
        "train_loss": 0.0028936111525931316
      },
      {
        "epoch": 1569,
        "reward": 0.36612534523010254,
        "val_loss": 0.076823148414925,
        "train_loss": 0.004915806708677468
      },
      {
        "epoch": 1570,
        "reward": 0.42441821098327637,
        "val_loss": 0.047137964891070236,
        "train_loss": 0.005207401777450007
      },
      {
        "epoch": 1571,
        "reward": 0.38302358984947205,
        "val_loss": 0.06650143754086457,
        "train_loss": 0.0030779864045703455
      },
      {
        "epoch": 1572,
        "reward": 0.3586670160293579,
        "val_loss": 0.08194625953287218,
        "train_loss": 0.02539716017096138
      },
      {
        "epoch": 1573,
        "reward": 0.4351399540901184,
        "val_loss": 0.04318855800582761,
        "train_loss": 0.1184619702143069
      },
      {
        "epoch": 1574,
        "reward": 0.3617402911186218,
        "val_loss": 0.07978953129661802,
        "train_loss": 0.019491461988973943
      },
      {
        "epoch": 1575,
        "reward": 0.3124619722366333,
        "val_loss": 0.12409206558783938,
        "train_loss": 0.006902187438369695
      },
      {
        "epoch": 1576,
        "reward": 0.2521028518676758,
        "val_loss": 0.22556576739381334,
        "train_loss": 0.014562704536204434
      },
      {
        "epoch": 1577,
        "reward": 0.4015672206878662,
        "val_loss": 0.056919227618241815,
        "train_loss": 0.04277687577716559
      },
      {
        "epoch": 1578,
        "reward": 0.4264533221721649,
        "val_loss": 0.046359573727906014,
        "train_loss": 0.005944140627784341
      },
      {
        "epoch": 1579,
        "reward": 0.3458939492702484,
        "val_loss": 0.09165481781695105,
        "train_loss": 0.005771065738512194
      },
      {
        "epoch": 1580,
        "reward": 0.4256843030452728,
        "val_loss": 0.046652090305412584,
        "train_loss": 0.01664957372977719
      },
      {
        "epoch": 1581,
        "reward": 0.40173420310020447,
        "val_loss": 0.05684019460750278,
        "train_loss": 0.015240060880597203
      },
      {
        "epoch": 1582,
        "reward": 0.4407409131526947,
        "val_loss": 0.041267113503376356,
        "train_loss": 1.989548174884266
      },
      {
        "epoch": 1583,
        "reward": 0.3768474757671356,
        "val_loss": 0.07008133326287082,
        "train_loss": 0.005895613811739727
      },
      {
        "epoch": 1584,
        "reward": 0.41852566599845886,
        "val_loss": 0.04947226175655877,
        "train_loss": 7.144801287058936
      },
      {
        "epoch": 1585,
        "reward": 0.3785821497440338,
        "val_loss": 0.06905450645717792,
        "train_loss": 0.0231794226214259
      },
      {
        "epoch": 1586,
        "reward": 0.40291664004325867,
        "val_loss": 0.05628395022358745,
        "train_loss": 0.0030410936115703615
      },
      {
        "epoch": 1587,
        "reward": 0.3324120044708252,
        "val_loss": 0.10337332441122271,
        "train_loss": 0.01864357093414198
      },
      {
        "epoch": 1588,
        "reward": 0.41187983751296997,
        "val_loss": 0.05225597914665871,
        "train_loss": 0.010821332741845534
      },
      {
        "epoch": 1589,
        "reward": 0.41225868463516235,
        "val_loss": 0.05209279631838269,
        "train_loss": 1.0190913357268632
      },
      {
        "epoch": 1590,
        "reward": 0.3981721103191376,
        "val_loss": 0.058552840202797336,
        "train_loss": 0.059703886489938456
      },
      {
        "epoch": 1591,
        "reward": 0.37762078642845154,
        "val_loss": 0.06962146492982615,
        "train_loss": 0.015744659869177176
      },
      {
        "epoch": 1592,
        "reward": 0.3620651960372925,
        "val_loss": 0.07956532714472685,
        "train_loss": 0.0032942266800371446
      },
      {
        "epoch": 1593,
        "reward": 0.3264201879501343,
        "val_loss": 0.10913622862218679,
        "train_loss": 0.027651992146205045
      },
      {
        "epoch": 1594,
        "reward": 0.397700697183609,
        "val_loss": 0.058783704150950404,
        "train_loss": 0.12815844593135878
      },
      {
        "epoch": 1595,
        "reward": 0.41468772292137146,
        "val_loss": 0.051059639567808644,
        "train_loss": 0.03440962885920621
      },
      {
        "epoch": 1596,
        "reward": 0.35127970576286316,
        "val_loss": 0.08740851747903175,
        "train_loss": 0.016720090910859235
      },
      {
        "epoch": 1597,
        "reward": 0.36671507358551025,
        "val_loss": 0.07643385453931321,
        "train_loss": 0.017281725526939996
      },
      {
        "epoch": 1598,
        "reward": 0.3547937273979187,
        "val_loss": 0.08475985337489485,
        "train_loss": 0.005551399191640135
      },
      {
        "epoch": 1599,
        "reward": 0.4231342375278473,
        "val_loss": 0.0476362978567652,
        "train_loss": 0.050114702442932375
      },
      {
        "epoch": 1600,
        "reward": 0.34070464968681335,
        "val_loss": 0.09597291949986746,
        "train_loss": 0.0028766272148459393
      },
      {
        "epoch": 1601,
        "reward": 0.3339909315109253,
        "val_loss": 0.1019144675519783,
        "train_loss": 0.2650051752422699
      },
      {
        "epoch": 1602,
        "reward": 0.33636489510536194,
        "val_loss": 0.09976593447832524,
        "train_loss": 0.2756539145926721
      },
      {
        "epoch": 1603,
        "reward": 0.36585476994514465,
        "val_loss": 0.07700251682711366,
        "train_loss": 0.027962682431349934
      },
      {
        "epoch": 1604,
        "reward": 0.43001896142959595,
        "val_loss": 0.045028808019456586,
        "train_loss": 0.014839448205608417
      },
      {
        "epoch": 1605,
        "reward": 0.33497855067253113,
        "val_loss": 0.10101413767967772,
        "train_loss": 0.04288409879659237
      },
      {
        "epoch": 1606,
        "reward": 0.3678675591945648,
        "val_loss": 0.07567945820794973,
        "train_loss": 0.11463425659829997
      },
      {
        "epoch": 1607,
        "reward": 0.3456120193004608,
        "val_loss": 0.09188354688064594,
        "train_loss": 85.06840216659069
      },
      {
        "epoch": 1608,
        "reward": 0.39167436957359314,
        "val_loss": 0.061825400621663515,
        "train_loss": 0.0069583529399936265
      },
      {
        "epoch": 1609,
        "reward": 0.41631656885147095,
        "val_loss": 0.05037931590777589,
        "train_loss": 0.006416515115312485
      },
      {
        "epoch": 1610,
        "reward": 0.41530004143714905,
        "val_loss": 0.050802741573923935,
        "train_loss": 0.004512602012272719
      },
      {
        "epoch": 1611,
        "reward": 0.4020596146583557,
        "val_loss": 0.05668651276209857,
        "train_loss": 0.0497139212696381
      },
      {
        "epoch": 1612,
        "reward": 0.4183306396007538,
        "val_loss": 0.04955162987607764,
        "train_loss": 0.0015092474578313369
      },
      {
        "epoch": 1613,
        "reward": 0.4135340750217438,
        "val_loss": 0.051547524075431284,
        "train_loss": 0.003273927434957631
      },
      {
        "epoch": 1614,
        "reward": 0.27739816904067993,
        "val_loss": 0.1739145181823655,
        "train_loss": 0.025944007747564404
      },
      {
        "epoch": 1615,
        "reward": 0.3457748591899872,
        "val_loss": 0.09175135695425395,
        "train_loss": 0.119273637655694
      },
      {
        "epoch": 1616,
        "reward": 0.3859052360057831,
        "val_loss": 0.06490144625110718,
        "train_loss": 0.028914599240754166
      },
      {
        "epoch": 1617,
        "reward": 0.3844998776912689,
        "val_loss": 0.0656763046499691,
        "train_loss": 0.01547212063297383
      },
      {
        "epoch": 1618,
        "reward": 0.36553123593330383,
        "val_loss": 0.07721762431486111,
        "train_loss": 0.21478728520276036
      },
      {
        "epoch": 1619,
        "reward": 0.40270161628723145,
        "val_loss": 0.056384626694905036,
        "train_loss": 0.003695888569032272
      },
      {
        "epoch": 1620,
        "reward": 0.4209338128566742,
        "val_loss": 0.048503562502446584,
        "train_loss": 0.0026744106849037053
      },
      {
        "epoch": 1621,
        "reward": 0.38432225584983826,
        "val_loss": 0.06577498158731032,
        "train_loss": 0.004578198623886027
      },
      {
        "epoch": 1622,
        "reward": 0.3642491102218628,
        "val_loss": 0.07807676328645487,
        "train_loss": 0.006233092388137825
      },
      {
        "epoch": 1623,
        "reward": 0.39930781722068787,
        "val_loss": 0.0580006907797984,
        "train_loss": 0.011726413614234424
      },
      {
        "epoch": 1624,
        "reward": 0.40091070532798767,
        "val_loss": 0.057231172158416097,
        "train_loss": 2.123509231713762
      },
      {
        "epoch": 1625,
        "reward": 0.4169181287288666,
        "val_loss": 0.050130537985491434,
        "train_loss": 0.009749759628623277
      },
      {
        "epoch": 1626,
        "reward": 0.33247989416122437,
        "val_loss": 0.10331009228788648,
        "train_loss": 0.16788967791902765
      },
      {
        "epoch": 1627,
        "reward": 0.38128432631492615,
        "val_loss": 0.06748841631217926,
        "train_loss": 0.004084508658199691
      },
      {
        "epoch": 1628,
        "reward": 0.4206927418708801,
        "val_loss": 0.0485996171035887,
        "train_loss": 0.0019669734114918704
      },
      {
        "epoch": 1629,
        "reward": 0.4172411859035492,
        "val_loss": 0.049997497742879204,
        "train_loss": 0.008721014117047442
      },
      {
        "epoch": 1630,
        "reward": 0.37119928002357483,
        "val_loss": 0.07354560524566166,
        "train_loss": 437.67888944414324
      },
      {
        "epoch": 1631,
        "reward": 0.35593241453170776,
        "val_loss": 0.08392137680701646,
        "train_loss": 3.319760787168119
      },
      {
        "epoch": 1632,
        "reward": 0.41359978914260864,
        "val_loss": 0.05151960642147709,
        "train_loss": 0.025347528590058434
      },
      {
        "epoch": 1633,
        "reward": 0.39544227719306946,
        "val_loss": 0.059903766075357065,
        "train_loss": 0.04433860522464364
      },
      {
        "epoch": 1634,
        "reward": 0.33647966384887695,
        "val_loss": 0.09966338859521784,
        "train_loss": 0.0834653262421013
      },
      {
        "epoch": 1635,
        "reward": 0.4045840799808502,
        "val_loss": 0.05550961020136518,
        "train_loss": 0.0013104974574476868
      },
      {
        "epoch": 1636,
        "reward": 0.34386321902275085,
        "val_loss": 0.0933172859991568,
        "train_loss": 0.005658524849283053
      },
      {
        "epoch": 1637,
        "reward": 0.4103116989135742,
        "val_loss": 0.052937355665822645,
        "train_loss": 0.051237792872069136
      },
      {
        "epoch": 1638,
        "reward": 0.4094614088535309,
        "val_loss": 0.05331082986543022,
        "train_loss": 0.2245757098149065
      },
      {
        "epoch": 1639,
        "reward": 0.4153801500797272,
        "val_loss": 0.0507692284528665,
        "train_loss": 0.0013910918761701817
      },
      {
        "epoch": 1640,
        "reward": 0.42735448479652405,
        "val_loss": 0.046019314890145324,
        "train_loss": 0.01391138219816245
      },
      {
        "epoch": 1641,
        "reward": 0.3014443814754486,
        "val_loss": 0.13763614968047477,
        "train_loss": 5.783347504623705
      },
      {
        "epoch": 1642,
        "reward": 0.4127625524997711,
        "val_loss": 0.051876649523494835,
        "train_loss": 0.02922608797500568
      },
      {
        "epoch": 1643,
        "reward": 0.4234473705291748,
        "val_loss": 0.04751425373667319,
        "train_loss": 0.008191169799916818
      },
      {
        "epoch": 1644,
        "reward": 0.32926955819129944,
        "val_loss": 0.10635006657061499,
        "train_loss": 99.77603609083508
      },
      {
        "epoch": 1645,
        "reward": 0.39488667249679565,
        "val_loss": 0.060182946540797796,
        "train_loss": 0.04943551512587874
      },
      {
        "epoch": 1646,
        "reward": 0.43736129999160767,
        "val_loss": 0.042415388245509736,
        "train_loss": 0.004830539612577503
      },
      {
        "epoch": 1647,
        "reward": 0.29085829854011536,
        "val_loss": 0.15235191268064746,
        "train_loss": 0.009296083885251742
      },
      {
        "epoch": 1648,
        "reward": 0.33565816283226013,
        "val_loss": 0.10040000990557019,
        "train_loss": 0.017555446636763988
      },
      {
        "epoch": 1649,
        "reward": 0.38705071806907654,
        "val_loss": 0.06427739637521361,
        "train_loss": 0.003614179191362592
      },
      {
        "epoch": 1650,
        "reward": 0.3932647705078125,
        "val_loss": 0.06100610044710005,
        "train_loss": 0.24072751450404
      },
      {
        "epoch": 1651,
        "reward": 0.3929494023323059,
        "val_loss": 0.061167583308166025,
        "train_loss": 0.02778579970100299
      },
      {
        "epoch": 1652,
        "reward": 0.3869805932044983,
        "val_loss": 0.06431540673033201,
        "train_loss": 0.039833808807893195
      },
      {
        "epoch": 1653,
        "reward": 0.28932055830955505,
        "val_loss": 0.1546442396107263,
        "train_loss": 0.6521204843157438
      },
      {
        "epoch": 1654,
        "reward": 0.37507757544517517,
        "val_loss": 0.07114670282005266,
        "train_loss": 0.0031170770089374855
      },
      {
        "epoch": 1655,
        "reward": 0.32440346479415894,
        "val_loss": 0.11116003515573018,
        "train_loss": 0.013336640578595156
      },
      {
        "epoch": 1656,
        "reward": 0.3233136832714081,
        "val_loss": 0.11227199045866396,
        "train_loss": 0.25449483055806993
      },
      {
        "epoch": 1657,
        "reward": 0.3476192355155945,
        "val_loss": 0.09026920866952944,
        "train_loss": 0.002518479827043708
      },
      {
        "epoch": 1658,
        "reward": 0.41106781363487244,
        "val_loss": 0.05260757996334827,
        "train_loss": 0.014317404707141507
      },
      {
        "epoch": 1659,
        "reward": 0.3962447941303253,
        "val_loss": 0.05950309472869516,
        "train_loss": 0.01163284140824754
      },
      {
        "epoch": 1660,
        "reward": 0.38358768820762634,
        "val_loss": 0.06618479892495088,
        "train_loss": 0.20610864656884167
      },
      {
        "epoch": 1661,
        "reward": 0.4016478657722473,
        "val_loss": 0.05688106555940716,
        "train_loss": 0.02240271214612641
      },
      {
        "epoch": 1662,
        "reward": 0.37197354435920715,
        "val_loss": 0.07305947564184732,
        "train_loss": 0.17782947126817397
      },
      {
        "epoch": 1663,
        "reward": 0.3046788275241852,
        "val_loss": 0.13348462199376496,
        "train_loss": 0.0036722110294424336
      },
      {
        "epoch": 1664,
        "reward": 0.44098469614982605,
        "val_loss": 0.04118558451695468,
        "train_loss": 0.10987183959220531
      },
      {
        "epoch": 1665,
        "reward": 0.35159775614738464,
        "val_loss": 0.08716493131630289,
        "train_loss": 0.0065090276751176976
      },
      {
        "epoch": 1666,
        "reward": 0.41072750091552734,
        "val_loss": 0.052755734321960644,
        "train_loss": 0.06864673675213104
      },
      {
        "epoch": 1667,
        "reward": 0.3387889564037323,
        "val_loss": 0.09762622712046973,
        "train_loss": 0.00813285457717519
      },
      {
        "epoch": 1668,
        "reward": 0.3798595368862152,
        "val_loss": 0.06830917354922608,
        "train_loss": 0.03534858575130784
      },
      {
        "epoch": 1669,
        "reward": 0.3447432219982147,
        "val_loss": 0.09259264384413005,
        "train_loss": 0.007108164557114203
      },
      {
        "epoch": 1670,
        "reward": 0.43459412455558777,
        "val_loss": 0.04338083350947792,
        "train_loss": 3.401503671021776
      },
      {
        "epoch": 1671,
        "reward": 0.35433229804039,
        "val_loss": 0.08510234428311898,
        "train_loss": 0.0007244888583954889
      },
      {
        "epoch": 1672,
        "reward": 0.3810599148273468,
        "val_loss": 0.06761695562246521,
        "train_loss": 1.6250176476646279
      },
      {
        "epoch": 1673,
        "reward": 0.42023664712905884,
        "val_loss": 0.04878190010536595,
        "train_loss": 0.005129615328349666
      },
      {
        "epoch": 1674,
        "reward": 0.419689416885376,
        "val_loss": 0.04900154907539088,
        "train_loss": 0.7040607679667888
      },
      {
        "epoch": 1675,
        "reward": 0.405781090259552,
        "val_loss": 0.054960949799611365,
        "train_loss": 0.022092780691659406
      },
      {
        "epoch": 1676,
        "reward": 0.38750404119491577,
        "val_loss": 0.06403227339199345,
        "train_loss": 0.009698659098550987
      },
      {
        "epoch": 1677,
        "reward": 0.4255344867706299,
        "val_loss": 0.04670928486198785,
        "train_loss": 2.7656254216459764
      },
      {
        "epoch": 1678,
        "reward": 0.3654768466949463,
        "val_loss": 0.07725384120047758,
        "train_loss": 0.01561471390896958
      },
      {
        "epoch": 1679,
        "reward": 0.42022132873535156,
        "val_loss": 0.0487880212177905,
        "train_loss": 0.0020229166310365633
      },
      {
        "epoch": 1680,
        "reward": 0.3902903199195862,
        "val_loss": 0.06254831101770313,
        "train_loss": 0.11881046949208841
      },
      {
        "epoch": 1681,
        "reward": 0.42325717210769653,
        "val_loss": 0.04758833563079991,
        "train_loss": 0.05833781313089485
      },
      {
        "epoch": 1682,
        "reward": 0.4514969289302826,
        "val_loss": 0.037826253007681644,
        "train_loss": 0.2653521396512308
      },
      {
        "epoch": 1683,
        "reward": 0.3592732846736908,
        "val_loss": 0.0815155927037787,
        "train_loss": 0.0046053957860119855
      },
      {
        "epoch": 1684,
        "reward": 0.35685619711875916,
        "val_loss": 0.08324812348291744,
        "train_loss": 0.012635232887497785
      },
      {
        "epoch": 1685,
        "reward": 0.39903968572616577,
        "val_loss": 0.05813054786995053,
        "train_loss": 0.022297195616234743
      },
      {
        "epoch": 1686,
        "reward": 0.3766272962093353,
        "val_loss": 0.07021289868238714,
        "train_loss": 0.0027233598452067573
      },
      {
        "epoch": 1687,
        "reward": 0.33836472034454346,
        "val_loss": 0.09799683520395774,
        "train_loss": 0.04257057920865638
      },
      {
        "epoch": 1688,
        "reward": 0.35040804743766785,
        "val_loss": 0.08808014926242842,
        "train_loss": 0.006669909076943161
      },
      {
        "epoch": 1689,
        "reward": 0.2626349925994873,
        "val_loss": 0.20202479766781575,
        "train_loss": 0.2400686067094984
      },
      {
        "epoch": 1690,
        "reward": 0.37380754947662354,
        "val_loss": 0.0719224299121249,
        "train_loss": 0.022522272586273245
      },
      {
        "epoch": 1691,
        "reward": 0.3641997277736664,
        "val_loss": 0.07811005867967781,
        "train_loss": 0.48759470786761155
      },
      {
        "epoch": 1692,
        "reward": 0.41720110177993774,
        "val_loss": 0.050013992482230867,
        "train_loss": 0.04285907994604853
      },
      {
        "epoch": 1693,
        "reward": 0.3998238742351532,
        "val_loss": 0.05775169213510318,
        "train_loss": 0.0039003701156467775
      },
      {
        "epoch": 1694,
        "reward": 0.42290589213371277,
        "val_loss": 0.04772550905077618,
        "train_loss": 0.44986397820754903
      },
      {
        "epoch": 1695,
        "reward": 0.4080440104007721,
        "val_loss": 0.053939864525870816,
        "train_loss": 0.10122420406822549
      },
      {
        "epoch": 1696,
        "reward": 0.44488707184791565,
        "val_loss": 0.03990321941715332,
        "train_loss": 0.003949943779214384
      },
      {
        "epoch": 1697,
        "reward": 0.35672974586486816,
        "val_loss": 0.08333994304432833,
        "train_loss": 0.004914064880862357
      },
      {
        "epoch": 1698,
        "reward": 0.44620251655578613,
        "val_loss": 0.03948050826355549,
        "train_loss": 0.003855581016173696
      },
      {
        "epoch": 1699,
        "reward": 0.2877732813358307,
        "val_loss": 0.15699310218457999,
        "train_loss": 0.017893992372312192
      },
      {
        "epoch": 1700,
        "reward": 0.3808356523513794,
        "val_loss": 0.0677456607518252,
        "train_loss": 0.020578285949900767
      },
      {
        "epoch": 1701,
        "reward": 0.36670202016830444,
        "val_loss": 0.07644243879310254,
        "train_loss": 0.009286136098510794
      },
      {
        "epoch": 1702,
        "reward": 0.4524402320384979,
        "val_loss": 0.03753924728204895,
        "train_loss": 0.005224983635798708
      },
      {
        "epoch": 1703,
        "reward": 0.2799726724624634,
        "val_loss": 0.16951630368047127,
        "train_loss": 0.7475153949512438
      },
      {
        "epoch": 1704,
        "reward": 0.41202035546302795,
        "val_loss": 0.05219538044392331,
        "train_loss": 0.011680298187037317
      },
      {
        "epoch": 1705,
        "reward": 0.3719504773616791,
        "val_loss": 0.07307394146586635,
        "train_loss": 0.029537995218491302
      },
      {
        "epoch": 1706,
        "reward": 0.4493270814418793,
        "val_loss": 0.038495244991541507,
        "train_loss": 0.005064686690205305
      },
      {
        "epoch": 1707,
        "reward": 0.37542223930358887,
        "val_loss": 0.0709378421348187,
        "train_loss": 95.60679808174308
      },
      {
        "epoch": 1708,
        "reward": 0.3956817090511322,
        "val_loss": 0.0597839397336689,
        "train_loss": 0.4220868991889032
      },
      {
        "epoch": 1709,
        "reward": 0.36300286650657654,
        "val_loss": 0.07892229018865951,
        "train_loss": 0.19950933773249674
      },
      {
        "epoch": 1710,
        "reward": 0.39774808287620544,
        "val_loss": 0.05876044680189807,
        "train_loss": 0.05874503490517432
      },
      {
        "epoch": 1711,
        "reward": 0.3418101668357849,
        "val_loss": 0.09503362031162917,
        "train_loss": 0.03438048704097477
      },
      {
        "epoch": 1712,
        "reward": 0.37868747115135193,
        "val_loss": 0.06899271982339476,
        "train_loss": 0.019242874373188758
      },
      {
        "epoch": 1713,
        "reward": 0.38693171739578247,
        "val_loss": 0.064341909891352,
        "train_loss": 0.015767222903762628
      },
      {
        "epoch": 1714,
        "reward": 0.4451260268688202,
        "val_loss": 0.03982609007964909,
        "train_loss": 0.020562772100631194
      },
      {
        "epoch": 1715,
        "reward": 0.3697147071361542,
        "val_loss": 0.07448791850142047,
        "train_loss": 0.02087152619557086
      },
      {
        "epoch": 1716,
        "reward": 0.41892009973526,
        "val_loss": 0.04931216531570369,
        "train_loss": 0.011225114321860019
      },
      {
        "epoch": 1717,
        "reward": 0.3621390759944916,
        "val_loss": 0.07951446776132798,
        "train_loss": 0.004948832914054107
      },
      {
        "epoch": 1718,
        "reward": 0.38163942098617554,
        "val_loss": 0.06728557508280833,
        "train_loss": 0.002408538187185518
      },
      {
        "epoch": 1719,
        "reward": 0.3526555597782135,
        "val_loss": 0.08636032245496088,
        "train_loss": 5.152133115276613
      },
      {
        "epoch": 1720,
        "reward": 0.4284454882144928,
        "val_loss": 0.0456109489771604,
        "train_loss": 0.1414628884459979
      },
      {
        "epoch": 1721,
        "reward": 0.42391595244407654,
        "val_loss": 0.04733222755541127,
        "train_loss": 1.1610196194743332
      },
      {
        "epoch": 1722,
        "reward": 0.29419347643852234,
        "val_loss": 0.14751971339657238,
        "train_loss": 0.014054560074642862
      },
      {
        "epoch": 1723,
        "reward": 0.36785265803337097,
        "val_loss": 0.0756891622191428,
        "train_loss": 0.011429085866089176
      },
      {
        "epoch": 1724,
        "reward": 0.3315346837043762,
        "val_loss": 0.10419447598854147,
        "train_loss": 0.012585566105651825
      },
      {
        "epoch": 1725,
        "reward": 0.36869433522224426,
        "val_loss": 0.07514349612236922,
        "train_loss": 0.0041187990649492485
      },
      {
        "epoch": 1726,
        "reward": 0.3409042954444885,
        "val_loss": 0.09580253216803872,
        "train_loss": 0.006681345373740792
      },
      {
        "epoch": 1727,
        "reward": 0.4264347553253174,
        "val_loss": 0.046366619185261825,
        "train_loss": 0.006339728797010698
      },
      {
        "epoch": 1728,
        "reward": 0.3389562964439392,
        "val_loss": 0.09748050797497854,
        "train_loss": 363.3998326055115
      },
      {
        "epoch": 1729,
        "reward": 0.4364337623119354,
        "val_loss": 0.04273642343053195,
        "train_loss": 0.0042195654611987266
      },
      {
        "epoch": 1730,
        "reward": 0.42766520380973816,
        "val_loss": 0.04590260865682337,
        "train_loss": 0.01134837414310998
      },
      {
        "epoch": 1731,
        "reward": 0.37471944093704224,
        "val_loss": 0.07136449533157117,
        "train_loss": 0.014891199208031699
      },
      {
        "epoch": 1732,
        "reward": 0.4562441408634186,
        "val_loss": 0.03640475772200651,
        "train_loss": 0.06452286341086969
      },
      {
        "epoch": 1733,
        "reward": 0.45220404863357544,
        "val_loss": 0.037610875603734585,
        "train_loss": 0.12748900500418342
      },
      {
        "epoch": 1734,
        "reward": 0.4251162111759186,
        "val_loss": 0.04686941655173931,
        "train_loss": 0.1687297262743641
      },
      {
        "epoch": 1735,
        "reward": 0.39009740948677063,
        "val_loss": 0.06264980586170818,
        "train_loss": 0.00401570947759375
      },
      {
        "epoch": 1736,
        "reward": 0.3858729600906372,
        "val_loss": 0.06491911174297067,
        "train_loss": 0.058893950141492284
      },
      {
        "epoch": 1737,
        "reward": 0.34612125158309937,
        "val_loss": 0.09147088746664979,
        "train_loss": 0.003951723687630595
      },
      {
        "epoch": 1738,
        "reward": 0.380386084318161,
        "val_loss": 0.06800453637073847,
        "train_loss": 0.012744718214889872
      },
      {
        "epoch": 1739,
        "reward": 0.369279682636261,
        "val_loss": 0.07476660903193988,
        "train_loss": 0.47308713363407573
      },
      {
        "epoch": 1740,
        "reward": 0.35809025168418884,
        "val_loss": 0.08235837401506226,
        "train_loss": 0.007253386681441043
      },
      {
        "epoch": 1741,
        "reward": 0.41822752356529236,
        "val_loss": 0.049593638333525245,
        "train_loss": 2.585892221512993
      },
      {
        "epoch": 1742,
        "reward": 0.3441091477870941,
        "val_loss": 0.09311413013451134,
        "train_loss": 0.018378410445131103
      },
      {
        "epoch": 1743,
        "reward": 0.3915198743343353,
        "val_loss": 0.06190562051779125,
        "train_loss": 0.032463072428911874
      },
      {
        "epoch": 1744,
        "reward": 0.2703888416290283,
        "val_loss": 0.18661662786325905,
        "train_loss": 0.011355818920002583
      },
      {
        "epoch": 1745,
        "reward": 0.4145056903362274,
        "val_loss": 0.05113630940987995,
        "train_loss": 0.1838884279083004
      },
      {
        "epoch": 1746,
        "reward": 0.37727639079093933,
        "val_loss": 0.06982586893510805,
        "train_loss": 3.5678511721386292
      },
      {
        "epoch": 1747,
        "reward": 0.4566832482814789,
        "val_loss": 0.03627612925941191,
        "train_loss": 0.003942006700666612
      },
      {
        "epoch": 1748,
        "reward": 0.3977534770965576,
        "val_loss": 0.05875779205546548,
        "train_loss": 0.35979052762443714
      },
      {
        "epoch": 1749,
        "reward": 0.44915905594825745,
        "val_loss": 0.038547569328719486,
        "train_loss": 0.017956096667043873
      },
      {
        "epoch": 1750,
        "reward": 0.41147375106811523,
        "val_loss": 0.05243150896006098,
        "train_loss": 0.0015747650956147762
      },
      {
        "epoch": 1751,
        "reward": 0.4505084156990051,
        "val_loss": 0.03812951289832459,
        "train_loss": 0.0014114802840525114
      },
      {
        "epoch": 1752,
        "reward": 0.28248295187950134,
        "val_loss": 0.1653578727335636,
        "train_loss": 0.013561970386245566
      },
      {
        "epoch": 1753,
        "reward": 0.28828462958335876,
        "val_loss": 0.15621208435914014,
        "train_loss": 0.16250741532509821
      },
      {
        "epoch": 1754,
        "reward": 0.43160364031791687,
        "val_loss": 0.04445055884986816,
        "train_loss": 0.0023836290926318236
      },
      {
        "epoch": 1755,
        "reward": 0.4502792954444885,
        "val_loss": 0.038200154674996156,
        "train_loss": 0.004540225869592318
      },
      {
        "epoch": 1756,
        "reward": 0.3254168927669525,
        "val_loss": 0.1101376084032901,
        "train_loss": 0.20037799480073423
      },
      {
        "epoch": 1757,
        "reward": 0.4167981743812561,
        "val_loss": 0.05018003354780376,
        "train_loss": 0.015495286639293226
      },
      {
        "epoch": 1758,
        "reward": 0.33958181738853455,
        "val_loss": 0.09693800461432797,
        "train_loss": 0.007740048930127859
      },
      {
        "epoch": 1759,
        "reward": 0.33667173981666565,
        "val_loss": 0.09949209286839635,
        "train_loss": 0.23815835648389777
      },
      {
        "epoch": 1760,
        "reward": 0.4229259192943573,
        "val_loss": 0.04771770859848142,
        "train_loss": 0.015023732939320885
      },
      {
        "epoch": 1761,
        "reward": 0.45327672362327576,
        "val_loss": 0.0372866222896846,
        "train_loss": 0.04096122987588247
      },
      {
        "epoch": 1762,
        "reward": 0.374165803194046,
        "val_loss": 0.07170266448208297,
        "train_loss": 0.288713004316308
      },
      {
        "epoch": 1763,
        "reward": 0.37200358510017395,
        "val_loss": 0.07304071152507927,
        "train_loss": 0.13785479048706642
      },
      {
        "epoch": 1764,
        "reward": 0.38708144426345825,
        "val_loss": 0.06426074523603477,
        "train_loss": 1.5274958738624054
      },
      {
        "epoch": 1765,
        "reward": 0.33694180846214294,
        "val_loss": 0.09925177231031869,
        "train_loss": 0.09227329954690223
      },
      {
        "epoch": 1766,
        "reward": 0.3390878140926361,
        "val_loss": 0.0973661670702443,
        "train_loss": 0.10746962824172876
      },
      {
        "epoch": 1767,
        "reward": 0.3960481286048889,
        "val_loss": 0.05960100694106326,
        "train_loss": 0.018531196649396755
      },
      {
        "epoch": 1768,
        "reward": 0.3265228271484375,
        "val_loss": 0.1090343906086803,
        "train_loss": 0.0036823918787306934
      },
      {
        "epoch": 1769,
        "reward": 0.39727845788002014,
        "val_loss": 0.0589913463357204,
        "train_loss": 0.0069579528658673204
      },
      {
        "epoch": 1770,
        "reward": 0.35356971621513367,
        "val_loss": 0.08567187230385441,
        "train_loss": 0.00827595170690424
      },
      {
        "epoch": 1771,
        "reward": 0.423351913690567,
        "val_loss": 0.04755143199872691,
        "train_loss": 0.006399547762122473
      },
      {
        "epoch": 1772,
        "reward": 0.34323763847351074,
        "val_loss": 0.09383643744097624,
        "train_loss": 0.005085917168431619
      },
      {
        "epoch": 1773,
        "reward": 0.3874605894088745,
        "val_loss": 0.06405570899784964,
        "train_loss": 0.01718138044175423
      },
      {
        "epoch": 1774,
        "reward": 0.46473953127861023,
        "val_loss": 0.033998205236067794,
        "train_loss": 0.1740601361330461
      },
      {
        "epoch": 1775,
        "reward": 0.44959622621536255,
        "val_loss": 0.038411594985518605,
        "train_loss": 0.026865814805205446
      },
      {
        "epoch": 1776,
        "reward": 0.43625590205192566,
        "val_loss": 0.04279829662326457,
        "train_loss": 0.05997914719424758
      },
      {
        "epoch": 1777,
        "reward": 0.4146103858947754,
        "val_loss": 0.05109217647986952,
        "train_loss": 0.013392913809394277
      },
      {
        "epoch": 1778,
        "reward": 0.2259005308151245,
        "val_loss": 0.3009566257491575,
        "train_loss": 0.003774432953343001
      },
      {
        "epoch": 1779,
        "reward": 0.4503805637359619,
        "val_loss": 0.03816891490818567,
        "train_loss": 0.009873390729493482
      },
      {
        "epoch": 1780,
        "reward": 0.3506830334663391,
        "val_loss": 0.0878676275273652,
        "train_loss": 0.004076824057497456
      },
      {
        "epoch": 1781,
        "reward": 0.3556743264198303,
        "val_loss": 0.08411058523467675,
        "train_loss": 0.18638431546675677
      },
      {
        "epoch": 1782,
        "reward": 0.3974093496799469,
        "val_loss": 0.058926881575774005,
        "train_loss": 0.0313575723393849
      },
      {
        "epoch": 1783,
        "reward": 0.40181174874305725,
        "val_loss": 0.056803529547843415,
        "train_loss": 0.15102042571463523
      },
      {
        "epoch": 1784,
        "reward": 0.3810378313064575,
        "val_loss": 0.06762960528015226,
        "train_loss": 0.015440919031812191
      },
      {
        "epoch": 1785,
        "reward": 0.449991375207901,
        "val_loss": 0.038289132484351285,
        "train_loss": 0.03340659519405493
      },
      {
        "epoch": 1786,
        "reward": 0.4227658212184906,
        "val_loss": 0.047780342444769176,
        "train_loss": 0.014100798028336543
      },
      {
        "epoch": 1787,
        "reward": 0.4777928292751312,
        "val_loss": 0.030616192279142394,
        "train_loss": 0.015828168384149858
      },
      {
        "epoch": 1788,
        "reward": 0.36959490180015564,
        "val_loss": 0.07456454465656341,
        "train_loss": 0.026162706566118195
      },
      {
        "epoch": 1789,
        "reward": 0.3682612478733063,
        "val_loss": 0.0754237084786707,
        "train_loss": 0.14349638738342316
      },
      {
        "epoch": 1790,
        "reward": 0.45969516038894653,
        "val_loss": 0.035406483656385844,
        "train_loss": 0.012353554682144581
      },
      {
        "epoch": 1791,
        "reward": 0.38033488392829895,
        "val_loss": 0.0680341021361528,
        "train_loss": 0.0015672701035039328
      },
      {
        "epoch": 1792,
        "reward": 0.37745240330696106,
        "val_loss": 0.06972132684313692,
        "train_loss": 0.012547222701659148
      },
      {
        "epoch": 1793,
        "reward": 0.4053976535797119,
        "val_loss": 0.05513603572035208,
        "train_loss": 0.004521673296319652
      },
      {
        "epoch": 1794,
        "reward": 0.40599966049194336,
        "val_loss": 0.054861392181399946,
        "train_loss": 0.026101881190951505
      },
      {
        "epoch": 1795,
        "reward": 0.4510364532470703,
        "val_loss": 0.03796720565047248,
        "train_loss": 0.43931238608778445
      },
      {
        "epoch": 1796,
        "reward": 0.38761237263679504,
        "val_loss": 0.06397383801959222,
        "train_loss": 0.005761179043754685
      },
      {
        "epoch": 1797,
        "reward": 0.4437815248966217,
        "val_loss": 0.0402621789585932,
        "train_loss": 0.0038713205883442905
      },
      {
        "epoch": 1798,
        "reward": 0.3232588768005371,
        "val_loss": 0.11232828146811309,
        "train_loss": 0.2337807731779811
      },
      {
        "epoch": 1799,
        "reward": 0.39170050621032715,
        "val_loss": 0.06181182786739165,
        "train_loss": 0.004041676873804625
      },
      {
        "epoch": 1800,
        "reward": 0.3337150514125824,
        "val_loss": 0.10216763116685408,
        "train_loss": 0.3377074675698981
      },
      {
        "epoch": 1801,
        "reward": 0.4772578775882721,
        "val_loss": 0.03074776527085175,
        "train_loss": 0.00381879385461686
      },
      {
        "epoch": 1802,
        "reward": 0.46111008524894714,
        "val_loss": 0.035005462211432005,
        "train_loss": 0.00590960032554204
      },
      {
        "epoch": 1803,
        "reward": 0.46200084686279297,
        "val_loss": 0.03475541361383096,
        "train_loss": 0.005137812238864661
      },
      {
        "epoch": 1804,
        "reward": 0.4419907033443451,
        "val_loss": 0.04085088554919431,
        "train_loss": 1.001157914203794
      },
      {
        "epoch": 1805,
        "reward": 0.377910852432251,
        "val_loss": 0.06944985599173899,
        "train_loss": 0.04134394804088096
      },
      {
        "epoch": 1806,
        "reward": 0.44216418266296387,
        "val_loss": 0.04079345960365442,
        "train_loss": 0.01693168096365018
      },
      {
        "epoch": 1807,
        "reward": 0.3289029002189636,
        "val_loss": 0.10670388090615493,
        "train_loss": 0.025003258672873365
      },
      {
        "epoch": 1808,
        "reward": 0.47554832696914673,
        "val_loss": 0.031172140456744404,
        "train_loss": 0.08499976409647249
      },
      {
        "epoch": 1809,
        "reward": 0.2642687261104584,
        "val_loss": 0.1986515057651559,
        "train_loss": 0.2916104770109506
      },
      {
        "epoch": 1810,
        "reward": 0.4547214210033417,
        "val_loss": 0.03685454410255521,
        "train_loss": 0.011692439784129559
      },
      {
        "epoch": 1811,
        "reward": 0.36028793454170227,
        "val_loss": 0.08080059155846746,
        "train_loss": 0.04208381569808877
      },
      {
        "epoch": 1812,
        "reward": 0.41815802454948425,
        "val_loss": 0.049621988448572144,
        "train_loss": 0.0012875286218489307
      },
      {
        "epoch": 1813,
        "reward": 0.3643377721309662,
        "val_loss": 0.07801699799165362,
        "train_loss": 0.07047577135153915
      },
      {
        "epoch": 1814,
        "reward": 0.2762140929698944,
        "val_loss": 0.1759840782740087,
        "train_loss": 0.018224956867243236
      },
      {
        "epoch": 1815,
        "reward": 0.41830068826675415,
        "val_loss": 0.04956382261298131,
        "train_loss": 0.014709038411148448
      },
      {
        "epoch": 1816,
        "reward": 0.3982319235801697,
        "val_loss": 0.05852359524370903,
        "train_loss": 2.6297032517263688
      },
      {
        "epoch": 1817,
        "reward": 0.44652363657951355,
        "val_loss": 0.03937803450493708,
        "train_loss": 1.581247948700838
      },
      {
        "epoch": 1818,
        "reward": 0.29822176694869995,
        "val_loss": 0.1419273263038901,
        "train_loss": 0.8489831782054842
      },
      {
        "epoch": 1819,
        "reward": 0.43101224303245544,
        "val_loss": 0.04466543634875312,
        "train_loss": 0.0052324887966068885
      },
      {
        "epoch": 1820,
        "reward": 0.3675265610218048,
        "val_loss": 0.07590177104326098,
        "train_loss": 0.06483605206744869
      },
      {
        "epoch": 1821,
        "reward": 0.4571515619754791,
        "val_loss": 0.036139458694378845,
        "train_loss": 0.003987930171923346
      },
      {
        "epoch": 1822,
        "reward": 0.4398970603942871,
        "val_loss": 0.04155070246841725,
        "train_loss": 0.0043617144693388794
      },
      {
        "epoch": 1823,
        "reward": 0.3425857722759247,
        "val_loss": 0.09438098389364313,
        "train_loss": 0.11475143784194258
      },
      {
        "epoch": 1824,
        "reward": 0.4370792806148529,
        "val_loss": 0.04251272602933958,
        "train_loss": 0.004311109776678607
      },
      {
        "epoch": 1825,
        "reward": 0.4692457616329193,
        "val_loss": 0.032789218902637786,
        "train_loss": 0.013124816181678293
      },
      {
        "epoch": 1826,
        "reward": 0.48832806944847107,
        "val_loss": 0.02813874348898285,
        "train_loss": 0.007595962163017807
      },
      {
        "epoch": 1827,
        "reward": 0.4329100251197815,
        "val_loss": 0.04397981458376827,
        "train_loss": 0.013203755251687163
      },
      {
        "epoch": 1828,
        "reward": 0.4622840881347656,
        "val_loss": 0.03467629836606128,
        "train_loss": 0.018793980545244546
      },
      {
        "epoch": 1829,
        "reward": 0.46037837862968445,
        "val_loss": 0.03521225432008838,
        "train_loss": 0.06666395871502136
      },
      {
        "epoch": 1830,
        "reward": 0.3023107945919037,
        "val_loss": 0.13650905889101392,
        "train_loss": 0.012142586388008043
      },
      {
        "epoch": 1831,
        "reward": 0.35544532537460327,
        "val_loss": 0.08427888202796956,
        "train_loss": 0.03525317309220974
      },
      {
        "epoch": 1832,
        "reward": 0.40037471055984497,
        "val_loss": 0.05748725114868388,
        "train_loss": 0.0010943938474296234
      },
      {
        "epoch": 1833,
        "reward": 0.4672672748565674,
        "val_loss": 0.033314465164689215,
        "train_loss": 0.01757108852031636
      },
      {
        "epoch": 1834,
        "reward": 0.35344231128692627,
        "val_loss": 0.08576740991234796,
        "train_loss": 2.0612031927319707
      },
      {
        "epoch": 1835,
        "reward": 0.4445754587650299,
        "val_loss": 0.04000406097994918,
        "train_loss": 0.09541683524051993
      },
      {
        "epoch": 1836,
        "reward": 0.3812107443809509,
        "val_loss": 0.06753052881478132,
        "train_loss": 0.013109116026953416
      },
      {
        "epoch": 1837,
        "reward": 0.43713828921318054,
        "val_loss": 0.04249235007695721,
        "train_loss": 0.004346432261688558
      },
      {
        "epoch": 1838,
        "reward": 0.42516836524009705,
        "val_loss": 0.04684942686019765,
        "train_loss": 0.12843587498330705
      },
      {
        "epoch": 1839,
        "reward": 0.35659259557724,
        "val_loss": 0.08343963684040188,
        "train_loss": 0.005447804881021931
      },
      {
        "epoch": 1840,
        "reward": 0.42629700899124146,
        "val_loss": 0.04641886980139783,
        "train_loss": 0.0034681266161774495
      },
      {
        "epoch": 1841,
        "reward": 0.34233546257019043,
        "val_loss": 0.09459099983255978,
        "train_loss": 0.0022003577110948614
      },
      {
        "epoch": 1842,
        "reward": 0.29148954153060913,
        "val_loss": 0.15142289226475572,
        "train_loss": 0.02491177783888186
      },
      {
        "epoch": 1843,
        "reward": 0.4148658215999603,
        "val_loss": 0.05098476858776329,
        "train_loss": 0.0054246405259338925
      },
      {
        "epoch": 1844,
        "reward": 0.3778455853462219,
        "val_loss": 0.06948843694512366,
        "train_loss": 0.009805654028171445
      },
      {
        "epoch": 1845,
        "reward": 0.4420015811920166,
        "val_loss": 0.040847271918859666,
        "train_loss": 0.000798546603855007
      },
      {
        "epoch": 1846,
        "reward": 0.37173399329185486,
        "val_loss": 0.07320948719071955,
        "train_loss": 0.3052473525231457
      },
      {
        "epoch": 1847,
        "reward": 0.44743284583091736,
        "val_loss": 0.0390894258681718,
        "train_loss": 0.04916230494273595
      },
      {
        "epoch": 1848,
        "reward": 0.3793955445289612,
        "val_loss": 0.0685788650340068,
        "train_loss": 0.030528002017193172
      },
      {
        "epoch": 1849,
        "reward": 0.36414313316345215,
        "val_loss": 0.07814826656873006,
        "train_loss": 0.02598060332778774
      },
      {
        "epoch": 1850,
        "reward": 0.4718920886516571,
        "val_loss": 0.032099990412202066,
        "train_loss": 0.3574962373584535
      },
      {
        "epoch": 1851,
        "reward": 0.36568278074264526,
        "val_loss": 0.07711680118102647,
        "train_loss": 0.002024351800243424
      },
      {
        "epoch": 1852,
        "reward": 0.3744449317455292,
        "val_loss": 0.07153194953571074,
        "train_loss": 0.05814720449363729
      },
      {
        "epoch": 1853,
        "reward": 0.4361208975315094,
        "val_loss": 0.04284527745975148,
        "train_loss": 0.005199552031346964
      },
      {
        "epoch": 1854,
        "reward": 0.35431525111198425,
        "val_loss": 0.08511505141879232,
        "train_loss": 0.1869206112291802
      },
      {
        "epoch": 1855,
        "reward": 0.47725215554237366,
        "val_loss": 0.030749183461011853,
        "train_loss": 0.013512018767064897
      },
      {
        "epoch": 1856,
        "reward": 0.41670122742652893,
        "val_loss": 0.05022008162840003,
        "train_loss": 0.011861029808117634
      },
      {
        "epoch": 1857,
        "reward": 0.3588397204875946,
        "val_loss": 0.08182330509381634,
        "train_loss": 4.642124490406086
      },
      {
        "epoch": 1858,
        "reward": 0.47458526492118835,
        "val_loss": 0.03141382991348759,
        "train_loss": 0.005685381638543801
      },
      {
        "epoch": 1859,
        "reward": 0.4130550026893616,
        "val_loss": 0.05175161410962963,
        "train_loss": 0.29504974350001806
      },
      {
        "epoch": 1860,
        "reward": 0.3897380530834198,
        "val_loss": 0.06283935629471671,
        "train_loss": 0.003079224838599587
      },
      {
        "epoch": 1861,
        "reward": 0.4103716015815735,
        "val_loss": 0.05291112071427051,
        "train_loss": 0.40751074477965143
      },
      {
        "epoch": 1862,
        "reward": 0.42720261216163635,
        "val_loss": 0.04607646178607995,
        "train_loss": 0.02330435654866747
      },
      {
        "epoch": 1863,
        "reward": 0.4009304940700531,
        "val_loss": 0.05722174186874846,
        "train_loss": 0.0026345905930961287
      },
      {
        "epoch": 1864,
        "reward": 0.3232082724571228,
        "val_loss": 0.11238025607183642,
        "train_loss": 0.0028622341065224297
      },
      {
        "epoch": 1865,
        "reward": 0.4247346818447113,
        "val_loss": 0.0470160071501076,
        "train_loss": 0.7236979389155592
      },
      {
        "epoch": 1866,
        "reward": 0.3497391641139984,
        "val_loss": 0.08859956371972137,
        "train_loss": 0.2453741422744385
      },
      {
        "epoch": 1867,
        "reward": 0.4278493821620941,
        "val_loss": 0.04583357149385847,
        "train_loss": 0.06946156825940236
      },
      {
        "epoch": 1868,
        "reward": 0.36068448424339294,
        "val_loss": 0.08052308503829408,
        "train_loss": 0.08965226085081869
      },
      {
        "epoch": 1869,
        "reward": 0.43133315443992615,
        "val_loss": 0.04454870355402818,
        "train_loss": 0.008675756558908723
      },
      {
        "epoch": 1870,
        "reward": 0.42851290106773376,
        "val_loss": 0.04558584900535477,
        "train_loss": 0.01752949873648154
      },
      {
        "epoch": 1871,
        "reward": 0.39453086256980896,
        "val_loss": 0.06036245602341036,
        "train_loss": 0.0032023114813192967
      },
      {
        "epoch": 1872,
        "reward": 0.32120954990386963,
        "val_loss": 0.11445623975097467,
        "train_loss": 0.08984222804399276
      },
      {
        "epoch": 1873,
        "reward": 0.4317016303539276,
        "val_loss": 0.044415069280408455,
        "train_loss": 0.008892515526615451
      },
      {
        "epoch": 1874,
        "reward": 0.3094634413719177,
        "val_loss": 0.12761438378947787,
        "train_loss": 0.009867040899804964
      },
      {
        "epoch": 1875,
        "reward": 0.4171794354915619,
        "val_loss": 0.050022884899850135,
        "train_loss": 0.03531970060014199
      },
      {
        "epoch": 1876,
        "reward": 0.40703001618385315,
        "val_loss": 0.05439479139126239,
        "train_loss": 0.34421106728704076
      },
      {
        "epoch": 1877,
        "reward": 0.4442092478275299,
        "val_loss": 0.04012290129737396,
        "train_loss": 0.0029517872357980824
      },
      {
        "epoch": 1878,
        "reward": 0.3834365904331207,
        "val_loss": 0.06626944817149447,
        "train_loss": 0.06507632200100488
      },
      {
        "epoch": 1879,
        "reward": 0.4231642782688141,
        "val_loss": 0.047624580826128034,
        "train_loss": 0.01189734643349556
      },
      {
        "epoch": 1880,
        "reward": 0.3218941390514374,
        "val_loss": 0.11374016585926126,
        "train_loss": 0.018810670471723894
      },
      {
        "epoch": 1881,
        "reward": 0.4760071933269501,
        "val_loss": 0.031057636875630124,
        "train_loss": 0.006775627591475943
      },
      {
        "epoch": 1882,
        "reward": 0.2772868871688843,
        "val_loss": 0.1741077312492832,
        "train_loss": 0.0047938727071736
      },
      {
        "epoch": 1883,
        "reward": 0.3193441331386566,
        "val_loss": 0.1164346207390606,
        "train_loss": 0.014390194961816424
      },
      {
        "epoch": 1884,
        "reward": 0.48087945580482483,
        "val_loss": 0.029868187041886683,
        "train_loss": 0.0025772525212302685
      },
      {
        "epoch": 1885,
        "reward": 0.47314295172691345,
        "val_loss": 0.0317794013400479,
        "train_loss": 0.015365820132396598
      },
      {
        "epoch": 1886,
        "reward": 0.42079707980155945,
        "val_loss": 0.048558025159374144,
        "train_loss": 0.011974185494977974
      },
      {
        "epoch": 1887,
        "reward": 0.45914870500564575,
        "val_loss": 0.03556262268726381,
        "train_loss": 0.016527722471577223
      },
      {
        "epoch": 1888,
        "reward": 0.2740929424762726,
        "val_loss": 0.17976753973302298,
        "train_loss": 0.06580921365429486
      },
      {
        "epoch": 1889,
        "reward": 0.29413172602653503,
        "val_loss": 0.14760752591869927,
        "train_loss": 0.008318369660698339
      },
      {
        "epoch": 1890,
        "reward": 0.3680056035518646,
        "val_loss": 0.07558969446628387,
        "train_loss": 0.26078405553752976
      },
      {
        "epoch": 1891,
        "reward": 0.4353807866573334,
        "val_loss": 0.043104005399592485,
        "train_loss": 0.0039027809738609695
      },
      {
        "epoch": 1892,
        "reward": 0.4125474989414215,
        "val_loss": 0.051968774032762406,
        "train_loss": 11.939585205528601
      },
      {
        "epoch": 1893,
        "reward": 0.46162429451942444,
        "val_loss": 0.03486087814443246,
        "train_loss": 0.047996298507156934
      },
      {
        "epoch": 1894,
        "reward": 0.36683303117752075,
        "val_loss": 0.07635624238589246,
        "train_loss": 0.004758497853310053
      },
      {
        "epoch": 1895,
        "reward": 0.4130586087703705,
        "val_loss": 0.05175006576402146,
        "train_loss": 0.15075842517643862
      },
      {
        "epoch": 1896,
        "reward": 0.40702658891677856,
        "val_loss": 0.05439634876945222,
        "train_loss": 0.009431239000220488
      },
      {
        "epoch": 1897,
        "reward": 0.39347267150878906,
        "val_loss": 0.06089989255789468,
        "train_loss": 0.0023909552072697037
      },
      {
        "epoch": 1898,
        "reward": 0.306209534406662,
        "val_loss": 0.13157220485196117,
        "train_loss": 0.003924372807712364
      },
      {
        "epoch": 1899,
        "reward": 0.4199922978878021,
        "val_loss": 0.048879844662483914,
        "train_loss": 0.0022921320405832656
      },
      {
        "epoch": 1900,
        "reward": 0.4803357720375061,
        "val_loss": 0.02999857171900138,
        "train_loss": 0.004923267436512246
      },
      {
        "epoch": 1901,
        "reward": 0.3982393741607666,
        "val_loss": 0.058519940898154994,
        "train_loss": 0.010218907605611513
      },
      {
        "epoch": 1902,
        "reward": 0.4841974377632141,
        "val_loss": 0.02908485182394673,
        "train_loss": 0.027183115215115967
      },
      {
        "epoch": 1903,
        "reward": 0.4238230884075165,
        "val_loss": 0.04736825869414523,
        "train_loss": 0.22287873305000316
      },
      {
        "epoch": 1904,
        "reward": 0.4527764320373535,
        "val_loss": 0.03743749656860018,
        "train_loss": 0.0008882781816492542
      },
      {
        "epoch": 1905,
        "reward": 0.3919502794742584,
        "val_loss": 0.06168238403708009,
        "train_loss": 0.001040825334782242
      },
      {
        "epoch": 1906,
        "reward": 0.4545595347881317,
        "val_loss": 0.0369026998534017,
        "train_loss": 0.027533776970603167
      },
      {
        "epoch": 1907,
        "reward": 0.4359719753265381,
        "val_loss": 0.042897196729817164,
        "train_loss": 0.0009297629012507969
      },
      {
        "epoch": 1908,
        "reward": 0.4572058320045471,
        "val_loss": 0.03612365436544808,
        "train_loss": 0.0019794865645683156
      },
      {
        "epoch": 1909,
        "reward": 0.24397149682044983,
        "val_loss": 0.24611784765563374,
        "train_loss": 0.3462038607345116
      },
      {
        "epoch": 1910,
        "reward": 0.44374915957450867,
        "val_loss": 0.04027274388395848,
        "train_loss": 2.2180310321775427
      },
      {
        "epoch": 1911,
        "reward": 0.4352272152900696,
        "val_loss": 0.04315790407105981,
        "train_loss": 0.006985273180534845
      },
      {
        "epoch": 1912,
        "reward": 0.41420871019363403,
        "val_loss": 0.05126161779376811,
        "train_loss": 0.007401104897850858
      },
      {
        "epoch": 1913,
        "reward": 0.38821956515312195,
        "val_loss": 0.06364749610241104,
        "train_loss": 0.007854727287254858
      },
      {
        "epoch": 1914,
        "reward": 0.41588935256004333,
        "val_loss": 0.05055678656208329,
        "train_loss": 0.010602267120523616
      },
      {
        "epoch": 1915,
        "reward": 0.35217157006263733,
        "val_loss": 0.0867273915230596,
        "train_loss": 0.020019695142247194
      },
      {
        "epoch": 1916,
        "reward": 0.4650757908821106,
        "val_loss": 0.0339064199693634,
        "train_loss": 1.7632755470573243
      },
      {
        "epoch": 1917,
        "reward": 0.392940491437912,
        "val_loss": 0.06117218280477183,
        "train_loss": 3.1250518443759856
      },
      {
        "epoch": 1918,
        "reward": 0.3647567927837372,
        "val_loss": 0.07773529415135272,
        "train_loss": 0.010017298075231688
      },
      {
        "epoch": 1919,
        "reward": 0.477573961019516,
        "val_loss": 0.030669951075521697,
        "train_loss": 0.001972090952711789
      },
      {
        "epoch": 1920,
        "reward": 0.4748441278934479,
        "val_loss": 0.03134867427122247,
        "train_loss": 0.22620087058986918
      },
      {
        "epoch": 1921,
        "reward": 0.2873228192329407,
        "val_loss": 0.1576850186788111,
        "train_loss": 0.20409635707950166
      },
      {
        "epoch": 1922,
        "reward": 0.46383801102638245,
        "val_loss": 0.03424555025204817,
        "train_loss": 0.005501243319083817
      },
      {
        "epoch": 1923,
        "reward": 0.40626025199890137,
        "val_loss": 0.054742968741006086,
        "train_loss": 0.0028284358301194656
      },
      {
        "epoch": 1924,
        "reward": 0.4488068222999573,
        "val_loss": 0.03865749867899077,
        "train_loss": 0.02289022432619211
      },
      {
        "epoch": 1925,
        "reward": 0.49010545015335083,
        "val_loss": 0.027741281214860334,
        "train_loss": 0.4290752670718715
      },
      {
        "epoch": 1926,
        "reward": 0.4204956591129303,
        "val_loss": 0.048678278829486644,
        "train_loss": 0.0074656869446348886
      },
      {
        "epoch": 1927,
        "reward": 0.464862197637558,
        "val_loss": 0.03396468553026872,
        "train_loss": 0.006408398747776818
      },
      {
        "epoch": 1928,
        "reward": 0.3422951400279999,
        "val_loss": 0.09462491138401674,
        "train_loss": 0.004345954317290517
      },
      {
        "epoch": 1929,
        "reward": 0.32022711634635925,
        "val_loss": 0.11549317013330958,
        "train_loss": 0.01758534561038407
      },
      {
        "epoch": 1930,
        "reward": 0.36999213695526123,
        "val_loss": 0.074310770237519,
        "train_loss": 0.024134220636065826
      },
      {
        "epoch": 1931,
        "reward": 0.4325011670589447,
        "val_loss": 0.0441265666533062,
        "train_loss": 0.004101247068669741
      },
      {
        "epoch": 1932,
        "reward": 0.41519761085510254,
        "val_loss": 0.05084560973981362,
        "train_loss": 0.006403778015011925
      },
      {
        "epoch": 1933,
        "reward": 0.4279802441596985,
        "val_loss": 0.0457846256166314,
        "train_loss": 0.022703343972685055
      },
      {
        "epoch": 1934,
        "reward": 0.432566374540329,
        "val_loss": 0.044103154595567115,
        "train_loss": 0.14493700209840638
      },
      {
        "epoch": 1935,
        "reward": 0.36655890941619873,
        "val_loss": 0.07653669631067064,
        "train_loss": 0.002758084409623944
      },
      {
        "epoch": 1936,
        "reward": 0.4910676181316376,
        "val_loss": 0.027528495438413562,
        "train_loss": 0.02201181292095428
      },
      {
        "epoch": 1937,
        "reward": 0.44178539514541626,
        "val_loss": 0.04091894469768574,
        "train_loss": 0.12212515565182422
      },
      {
        "epoch": 1938,
        "reward": 0.4162794053554535,
        "val_loss": 0.050394718304492665,
        "train_loss": 0.011342752024610001
      },
      {
        "epoch": 1939,
        "reward": 0.35025858879089355,
        "val_loss": 0.08819590531181477,
        "train_loss": 0.025975728748947473
      },
      {
        "epoch": 1940,
        "reward": 0.2775416076183319,
        "val_loss": 0.1736658014935009,
        "train_loss": 0.020059512148306497
      },
      {
        "epoch": 1941,
        "reward": 0.45159831643104553,
        "val_loss": 0.037795299772239686,
        "train_loss": 0.14749925748912154
      },
      {
        "epoch": 1942,
        "reward": 0.3715267777442932,
        "val_loss": 0.07333954345085658,
        "train_loss": 0.055792543048710286
      },
      {
        "epoch": 1943,
        "reward": 0.3968380391597748,
        "val_loss": 0.0592088074647888,
        "train_loss": 0.041944394822306864
      },
      {
        "epoch": 1944,
        "reward": 0.3646603524684906,
        "val_loss": 0.07780003945975165,
        "train_loss": 0.029226905064346144
      },
      {
        "epoch": 1945,
        "reward": 0.4175542891025543,
        "val_loss": 0.04986892043130605,
        "train_loss": 0.020883307225141416
      },
      {
        "epoch": 1946,
        "reward": 0.4340483844280243,
        "val_loss": 0.04357398013442954,
        "train_loss": 0.3593631281535706
      },
      {
        "epoch": 1947,
        "reward": 0.4129062294960022,
        "val_loss": 0.05181517262410905,
        "train_loss": 0.021835275202477078
      },
      {
        "epoch": 1948,
        "reward": 0.41514211893081665,
        "val_loss": 0.050868877398897894,
        "train_loss": 0.4757115036090209
      },
      {
        "epoch": 1949,
        "reward": 0.4122784733772278,
        "val_loss": 0.05208430820701843,
        "train_loss": 0.008008919348132902
      },
      {
        "epoch": 1950,
        "reward": 0.4994235038757324,
        "val_loss": 0.025748256904729976,
        "train_loss": 0.017758230126516467
      },
      {
        "epoch": 1951,
        "reward": 0.3444143831729889,
        "val_loss": 0.09286267203632244,
        "train_loss": 0.9126594689321512
      },
      {
        "epoch": 1952,
        "reward": 0.46853873133659363,
        "val_loss": 0.03297593935245199,
        "train_loss": 0.005794747484952285
      },
      {
        "epoch": 1953,
        "reward": 0.4907223880290985,
        "val_loss": 0.027604660860171343,
        "train_loss": 0.009147111811846397
      },
      {
        "epoch": 1954,
        "reward": 0.38494187593460083,
        "val_loss": 0.06543148855104976,
        "train_loss": 0.005594126010123546
      },
      {
        "epoch": 1955,
        "reward": 0.3054521679878235,
        "val_loss": 0.13251429595402442,
        "train_loss": 0.026056827974990975
      },
      {
        "epoch": 1956,
        "reward": 0.43179938197135925,
        "val_loss": 0.04437970677307541,
        "train_loss": 0.035121531923113465
      },
      {
        "epoch": 1957,
        "reward": 0.38579922914505005,
        "val_loss": 0.0649595339730565,
        "train_loss": 0.4342863833254481
      },
      {
        "epoch": 1958,
        "reward": 0.4242198169231415,
        "val_loss": 0.047214628579760234,
        "train_loss": 0.05354105451869355
      },
      {
        "epoch": 1959,
        "reward": 0.3800572454929352,
        "val_loss": 0.06819461281078734,
        "train_loss": 0.6683348368420551
      },
      {
        "epoch": 1960,
        "reward": 0.39040496945381165,
        "val_loss": 0.062488073834434284,
        "train_loss": 0.5474899232871604
      },
      {
        "epoch": 1961,
        "reward": 0.43410250544548035,
        "val_loss": 0.04355479197900942,
        "train_loss": 0.0029708639032118246
      },
      {
        "epoch": 1962,
        "reward": 0.41312915086746216,
        "val_loss": 0.05171997444787329,
        "train_loss": 0.001450758405326269
      },
      {
        "epoch": 1963,
        "reward": 0.48831653594970703,
        "val_loss": 0.02814134435798873,
        "train_loss": 0.16763105335903325
      },
      {
        "epoch": 1964,
        "reward": 0.4120517373085022,
        "val_loss": 0.052181852320375456,
        "train_loss": 0.02190067887215063
      },
      {
        "epoch": 1965,
        "reward": 0.4958798885345459,
        "val_loss": 0.026488655069052975,
        "train_loss": 0.001259374776684406
      },
      {
        "epoch": 1966,
        "reward": 0.42968782782554626,
        "val_loss": 0.04515063354691457,
        "train_loss": 0.001966168490595849
      },
      {
        "epoch": 1967,
        "reward": 0.48111701011657715,
        "val_loss": 0.029811395707968456,
        "train_loss": 0.01890609053049712
      },
      {
        "epoch": 1968,
        "reward": 0.4411490559577942,
        "val_loss": 0.041130713108162,
        "train_loss": 0.6439323566267796
      },
      {
        "epoch": 1969,
        "reward": 0.33189845085144043,
        "val_loss": 0.10385307670471125,
        "train_loss": 0.018259447733481256
      },
      {
        "epoch": 1970,
        "reward": 0.49135324358940125,
        "val_loss": 0.027465646008619973,
        "train_loss": 0.003892149304612338
      },
      {
        "epoch": 1971,
        "reward": 0.39553937315940857,
        "val_loss": 0.05985514597237592,
        "train_loss": 0.13924630680029046
      },
      {
        "epoch": 1972,
        "reward": 0.3663007915019989,
        "val_loss": 0.07670705853213024,
        "train_loss": 0.020270717951251963
      },
      {
        "epoch": 1973,
        "reward": 0.34171614050865173,
        "val_loss": 0.0951130585329208,
        "train_loss": 0.007947458430049455
      },
      {
        "epoch": 1974,
        "reward": 0.49697670340538025,
        "val_loss": 0.026257228397298604,
        "train_loss": 0.188895053754095
      },
      {
        "epoch": 1975,
        "reward": 0.50333571434021,
        "val_loss": 0.024954865173120715,
        "train_loss": 0.21733778734988635
      },
      {
        "epoch": 1976,
        "reward": 0.4924120008945465,
        "val_loss": 0.027233932181843556,
        "train_loss": 3.7285867579595595
      },
      {
        "epoch": 1977,
        "reward": 0.4414616525173187,
        "val_loss": 0.04102653094845924,
        "train_loss": 0.015310869263596661
      },
      {
        "epoch": 1978,
        "reward": 0.34925761818885803,
        "val_loss": 0.08897568768588826,
        "train_loss": 0.006254145484562584
      },
      {
        "epoch": 1979,
        "reward": 0.3938758969306946,
        "val_loss": 0.06069448121395128,
        "train_loss": 0.010952957182290937
      },
      {
        "epoch": 1980,
        "reward": 0.3421408236026764,
        "val_loss": 0.09475473860428403,
        "train_loss": 0.03198950842609131
      },
      {
        "epoch": 1981,
        "reward": 0.2824161946773529,
        "val_loss": 0.16546679760046704,
        "train_loss": 0.005968584588257587
      },
      {
        "epoch": 1982,
        "reward": 0.4298919141292572,
        "val_loss": 0.04507550202210301,
        "train_loss": 0.019891829205798437
      },
      {
        "epoch": 1983,
        "reward": 0.4060300290584564,
        "val_loss": 0.05484758617655773,
        "train_loss": 0.058255050396557914
      },
      {
        "epoch": 1984,
        "reward": 0.4664912223815918,
        "val_loss": 0.033522855934279505,
        "train_loss": 0.011029917386622401
      },
      {
        "epoch": 1985,
        "reward": 0.43672624230384827,
        "val_loss": 0.04263491888611627,
        "train_loss": 1.2854200285416413
      },
      {
        "epoch": 1986,
        "reward": 0.42486223578453064,
        "val_loss": 0.046966945139242204,
        "train_loss": 0.012309581719049535
      },
      {
        "epoch": 1987,
        "reward": 0.4782067835330963,
        "val_loss": 0.030514773358715632,
        "train_loss": 0.007673091800195555
      },
      {
        "epoch": 1988,
        "reward": 0.39832156896591187,
        "val_loss": 0.0584798486109191,
        "train_loss": 0.014873812031580131
      },
      {
        "epoch": 1989,
        "reward": 0.39221659302711487,
        "val_loss": 0.0615446984925906,
        "train_loss": 0.017905072623132304
      },
      {
        "epoch": 1990,
        "reward": 0.45514988899230957,
        "val_loss": 0.036727378457726445,
        "train_loss": 0.0012107895986796042
      },
      {
        "epoch": 1991,
        "reward": 0.3466063141822815,
        "val_loss": 0.09107975113147404,
        "train_loss": 0.004645472509274931
      },
      {
        "epoch": 1992,
        "reward": 0.4657592475414276,
        "val_loss": 0.033720646548317745,
        "train_loss": 0.001104323595637442
      },
      {
        "epoch": 1993,
        "reward": 0.49326416850090027,
        "val_loss": 0.027048862605754818,
        "train_loss": 0.09827320920159256
      },
      {
        "epoch": 1994,
        "reward": 0.34580132365226746,
        "val_loss": 0.09172992410146565,
        "train_loss": 0.023269530833308984
      },
      {
        "epoch": 1995,
        "reward": 0.41605493426322937,
        "val_loss": 0.050487930913472416,
        "train_loss": 0.011119212572988492
      },
      {
        "epoch": 1996,
        "reward": 0.30996373295783997,
        "val_loss": 0.12701850828099331,
        "train_loss": 0.0020907344515028225
      },
      {
        "epoch": 1997,
        "reward": 0.41230398416519165,
        "val_loss": 0.05207332637551839,
        "train_loss": 0.22597180170487263
      },
      {
        "epoch": 1998,
        "reward": 0.38253360986709595,
        "val_loss": 0.06677784192600354,
        "train_loss": 0.1435979763272581
      },
      {
        "epoch": 1999,
        "reward": 0.45478692650794983,
        "val_loss": 0.03683506725688598,
        "train_loss": 0.014987981277954532
      },
      {
        "epoch": 2000,
        "reward": 0.45167842507362366,
        "val_loss": 0.037770865043317566,
        "train_loss": 0.03924032200576186
      },
      {
        "epoch": 2001,
        "reward": 0.4197373390197754,
        "val_loss": 0.04898227808007505,
        "train_loss": 0.021732833859249904
      },
      {
        "epoch": 2002,
        "reward": 0.43599939346313477,
        "val_loss": 0.042887636397998516,
        "train_loss": 0.0011444522962427493
      },
      {
        "epoch": 2003,
        "reward": 0.43009158968925476,
        "val_loss": 0.04500214218153685,
        "train_loss": 0.0011284580706999875
      },
      {
        "epoch": 2004,
        "reward": 0.4572528302669525,
        "val_loss": 0.03610996764473384,
        "train_loss": 0.006955842721778866
      },
      {
        "epoch": 2005,
        "reward": 0.44195857644081116,
        "val_loss": 0.040861533163739035,
        "train_loss": 0.005022809973192684
      },
      {
        "epoch": 2006,
        "reward": 0.2897650897502899,
        "val_loss": 0.1539773027429224,
        "train_loss": 0.002831362912939557
      },
      {
        "epoch": 2007,
        "reward": 0.38778412342071533,
        "val_loss": 0.06388134785395648,
        "train_loss": 0.008599957133023613
      },
      {
        "epoch": 2008,
        "reward": 0.36462143063545227,
        "val_loss": 0.07782618255337834,
        "train_loss": 0.15254815708478567
      },
      {
        "epoch": 2009,
        "reward": 0.38421666622161865,
        "val_loss": 0.06583372393963925,
        "train_loss": 0.005043072163728696
      },
      {
        "epoch": 2010,
        "reward": 0.5023483633995056,
        "val_loss": 0.02515277083771902,
        "train_loss": 0.006155519791858611
      },
      {
        "epoch": 2011,
        "reward": 0.43490955233573914,
        "val_loss": 0.043269612429347556,
        "train_loss": 0.00519408889872116
      },
      {
        "epoch": 2012,
        "reward": 0.3934464156627655,
        "val_loss": 0.06091329495081611,
        "train_loss": 0.13991582251152906
      },
      {
        "epoch": 2013,
        "reward": 0.41945406794548035,
        "val_loss": 0.049096348466784026,
        "train_loss": 0.1277914455793227
      },
      {
        "epoch": 2014,
        "reward": 0.4373907148838043,
        "val_loss": 0.0424052316115454,
        "train_loss": 0.26398729104943625
      },
      {
        "epoch": 2015,
        "reward": 0.3986052870750427,
        "val_loss": 0.05834155313537589,
        "train_loss": 0.005146081802630457
      },
      {
        "epoch": 2016,
        "reward": 0.4768121838569641,
        "val_loss": 0.030857833284244407,
        "train_loss": 0.005711259835781955
      },
      {
        "epoch": 2017,
        "reward": 0.34729456901550293,
        "val_loss": 0.09052806836552918,
        "train_loss": 0.0028830858549239425
      },
      {
        "epoch": 2018,
        "reward": 0.43008729815483093,
        "val_loss": 0.045003712319677494,
        "train_loss": 0.0034509169554089916
      },
      {
        "epoch": 2019,
        "reward": 0.4121761918067932,
        "val_loss": 0.052128268331996096,
        "train_loss": 0.12964543650897353
      },
      {
        "epoch": 2020,
        "reward": 0.4757207930088043,
        "val_loss": 0.03112905919260811,
        "train_loss": 6.0014783747065374
      },
      {
        "epoch": 2021,
        "reward": 0.4170541763305664,
        "val_loss": 0.05007445505803584,
        "train_loss": 0.023858956607490163
      },
      {
        "epoch": 2022,
        "reward": 0.39248642325401306,
        "val_loss": 0.06140556205147212,
        "train_loss": 0.043281337168346784
      },
      {
        "epoch": 2023,
        "reward": 0.40525075793266296,
        "val_loss": 0.055203299586927254,
        "train_loss": 0.005184291587533188
      },
      {
        "epoch": 2024,
        "reward": 0.4672514498233795,
        "val_loss": 0.03331871005606705,
        "train_loss": 0.011490888408668699
      },
      {
        "epoch": 2025,
        "reward": 0.35557082295417786,
        "val_loss": 0.08418662245510079,
        "train_loss": 0.013647488901089954
      },
      {
        "epoch": 2026,
        "reward": 0.42799732089042664,
        "val_loss": 0.04577823374295674,
        "train_loss": 1.927091444378675
      },
      {
        "epoch": 2027,
        "reward": 0.4828372597694397,
        "val_loss": 0.02940341160553674,
        "train_loss": 0.022995971965219023
      },
      {
        "epoch": 2028,
        "reward": 0.41453248262405396,
        "val_loss": 0.05112500485224051,
        "train_loss": 0.14586919797256298
      },
      {
        "epoch": 2029,
        "reward": 0.3964492976665497,
        "val_loss": 0.0594014571293623,
        "train_loss": 0.007955176990680438
      },
      {
        "epoch": 2030,
        "reward": 0.45113107562065125,
        "val_loss": 0.037938191969130584,
        "train_loss": 0.022427736556577517
      },
      {
        "epoch": 2031,
        "reward": 0.3708859086036682,
        "val_loss": 0.0737433796291173,
        "train_loss": 0.003934081598380055
      },
      {
        "epoch": 2032,
        "reward": 0.5029498934745789,
        "val_loss": 0.025032010140421335,
        "train_loss": 0.009099513680588154
      },
      {
        "epoch": 2033,
        "reward": 0.40946951508522034,
        "val_loss": 0.05330726688303652,
        "train_loss": 0.016849733531610303
      },
      {
        "epoch": 2034,
        "reward": 0.37971144914627075,
        "val_loss": 0.06839511054983761,
        "train_loss": 0.11490013628715062
      },
      {
        "epoch": 2035,
        "reward": 0.5094239115715027,
        "val_loss": 0.02376834723171279,
        "train_loss": 0.032107835458574
      },
      {
        "epoch": 2036,
        "reward": 0.4176040291786194,
        "val_loss": 0.04984852102539402,
        "train_loss": 0.03353422432768674
      },
      {
        "epoch": 2037,
        "reward": 0.4156244695186615,
        "val_loss": 0.050667176693553174,
        "train_loss": 0.4976269985818712
      },
      {
        "epoch": 2038,
        "reward": 0.41451311111450195,
        "val_loss": 0.051133142335207334,
        "train_loss": 0.09946111370293063
      },
      {
        "epoch": 2039,
        "reward": 0.4428883492946625,
        "val_loss": 0.04055466320590183,
        "train_loss": 0.0026631627409345196
      },
      {
        "epoch": 2040,
        "reward": 0.39960914850234985,
        "val_loss": 0.05785516483280974,
        "train_loss": 0.23318155105688185
      },
      {
        "epoch": 2041,
        "reward": 0.472496896982193,
        "val_loss": 0.03194456762970991,
        "train_loss": 0.0030189101095437275
      },
      {
        "epoch": 2042,
        "reward": 0.43043336272239685,
        "val_loss": 0.04487683327585858,
        "train_loss": 0.00445572038867025
      },
      {
        "epoch": 2043,
        "reward": 0.48980674147605896,
        "val_loss": 0.02780768278067366,
        "train_loss": 0.0032588728543207534
      },
      {
        "epoch": 2044,
        "reward": 0.5078410506248474,
        "val_loss": 0.02407132875565107,
        "train_loss": 0.0010838553187201027
      },
      {
        "epoch": 2045,
        "reward": 0.39118292927742004,
        "val_loss": 0.062080992256856656,
        "train_loss": 0.06610669055876664
      },
      {
        "epoch": 2046,
        "reward": 0.41263872385025024,
        "val_loss": 0.0519296633844663,
        "train_loss": 0.001748784631462723
      },
      {
        "epoch": 2047,
        "reward": 0.42518875002861023,
        "val_loss": 0.04684161569145674,
        "train_loss": 0.31036588941800314
      },
      {
        "epoch": 2048,
        "reward": 0.4920416474342346,
        "val_loss": 0.02731475763513507,
        "train_loss": 0.005385098349017006
      },
      {
        "epoch": 2049,
        "reward": 0.3736288249492645,
        "val_loss": 0.07203233695950725,
        "train_loss": 0.0030388791600881424
      },
      {
        "epoch": 2050,
        "reward": 0.4288434684276581,
        "val_loss": 0.04546294199203008,
        "train_loss": 0.007498487894036561
      },
      {
        "epoch": 2051,
        "reward": 0.4201076626777649,
        "val_loss": 0.04883354729723318,
        "train_loss": 0.05404804234436037
      },
      {
        "epoch": 2052,
        "reward": 0.4350810945034027,
        "val_loss": 0.04320925078874487,
        "train_loss": 0.0031125566100014953
      },
      {
        "epoch": 2053,
        "reward": 0.45261308550834656,
        "val_loss": 0.037486894341002754,
        "train_loss": 89.42115400688911
      },
      {
        "epoch": 2054,
        "reward": 0.47153520584106445,
        "val_loss": 0.032192065843056686,
        "train_loss": 0.005015697443713389
      },
      {
        "epoch": 2055,
        "reward": 0.443832129240036,
        "val_loss": 0.040245673022582196,
        "train_loss": 0.037479684477462936
      },
      {
        "epoch": 2056,
        "reward": 0.4543289244174957,
        "val_loss": 0.03697140809734784,
        "train_loss": 0.04968525249072487
      },
      {
        "epoch": 2057,
        "reward": 0.4913039207458496,
        "val_loss": 0.027476481316885577,
        "train_loss": 0.004325474660513114
      },
      {
        "epoch": 2058,
        "reward": 0.417180597782135,
        "val_loss": 0.050022415897858864,
        "train_loss": 0.056036035860765526
      },
      {
        "epoch": 2059,
        "reward": 0.48824939131736755,
        "val_loss": 0.028156468499219045,
        "train_loss": 2.2209096069372856
      },
      {
        "epoch": 2060,
        "reward": 0.4574527442455292,
        "val_loss": 0.03605185303916057,
        "train_loss": 0.0016842566593508169
      },
      {
        "epoch": 2061,
        "reward": 0.42185813188552856,
        "val_loss": 0.048137200366389674,
        "train_loss": 0.01541902914536527
      },
      {
        "epoch": 2062,
        "reward": 0.359048992395401,
        "val_loss": 0.08167463330651767,
        "train_loss": 0.2524088251049167
      },
      {
        "epoch": 2063,
        "reward": 0.39393794536590576,
        "val_loss": 0.06066293493495323,
        "train_loss": 0.22030804572002055
      },
      {
        "epoch": 2064,
        "reward": 0.40749022364616394,
        "val_loss": 0.05418778760940768,
        "train_loss": 0.004435712891174367
      },
      {
        "epoch": 2065,
        "reward": 0.436023086309433,
        "val_loss": 0.042879378622663875,
        "train_loss": 0.00408828694938935
      },
      {
        "epoch": 2066,
        "reward": 0.466706246137619,
        "val_loss": 0.033464991461577095,
        "train_loss": 0.005155181200367364
      },
      {
        "epoch": 2067,
        "reward": 0.4541598856449127,
        "val_loss": 0.03702186511301469,
        "train_loss": 0.0016675263922514626
      },
      {
        "epoch": 2068,
        "reward": 0.4358038604259491,
        "val_loss": 0.04295593109730232,
        "train_loss": 0.06429088306019537
      },
      {
        "epoch": 2069,
        "reward": 0.41248321533203125,
        "val_loss": 0.05199636110877951,
        "train_loss": 0.007340467531671143
      },
      {
        "epoch": 2070,
        "reward": 0.4244067668914795,
        "val_loss": 0.047142378602334896,
        "train_loss": 0.007751565412141085
      },
      {
        "epoch": 2071,
        "reward": 0.4270941913127899,
        "val_loss": 0.0461173205954505,
        "train_loss": 0.012539447333525598
      },
      {
        "epoch": 2072,
        "reward": 0.4603111743927002,
        "val_loss": 0.035231305675032284,
        "train_loss": 0.013893377474162732
      },
      {
        "epoch": 2073,
        "reward": 0.47937607765197754,
        "val_loss": 0.03023015267120042,
        "train_loss": 0.035115632481489016
      },
      {
        "epoch": 2074,
        "reward": 0.4680093824863434,
        "val_loss": 0.03311644216280131,
        "train_loss": 0.16383848599004452
      },
      {
        "epoch": 2075,
        "reward": 0.4632643759250641,
        "val_loss": 0.034403923896856474,
        "train_loss": 0.010383005823699092
      },
      {
        "epoch": 2076,
        "reward": 0.3330555260181427,
        "val_loss": 0.1027758275283434,
        "train_loss": 0.05917564101820552
      },
      {
        "epoch": 2077,
        "reward": 0.4825468063354492,
        "val_loss": 0.029471895593035567,
        "train_loss": 0.0028566933995604745
      },
      {
        "epoch": 2078,
        "reward": 0.468351811170578,
        "val_loss": 0.03302548212377587,
        "train_loss": 0.002914673386980072
      },
      {
        "epoch": 2079,
        "reward": 0.38632604479789734,
        "val_loss": 0.06467141473279168,
        "train_loss": 0.006858649234975298
      },
      {
        "epoch": 2080,
        "reward": 0.3548682630062103,
        "val_loss": 0.08470468246793773,
        "train_loss": 0.0012929178940514529
      },
      {
        "epoch": 2081,
        "reward": 0.4258398115634918,
        "val_loss": 0.04659275334935436,
        "train_loss": 7.257548520261655
      },
      {
        "epoch": 2082,
        "reward": 0.40744882822036743,
        "val_loss": 0.054206394645526804,
        "train_loss": 0.005298614423806542
      },
      {
        "epoch": 2083,
        "reward": 0.45516881346702576,
        "val_loss": 0.03672177297890552,
        "train_loss": 0.002463006555777051
      },
      {
        "epoch": 2084,
        "reward": 0.374960333108902,
        "val_loss": 0.07121792251824186,
        "train_loss": 0.038656105838526855
      },
      {
        "epoch": 2085,
        "reward": 0.2854934632778168,
        "val_loss": 0.1605332930318712,
        "train_loss": 0.42286941832138
      },
      {
        "epoch": 2086,
        "reward": 0.455209881067276,
        "val_loss": 0.03670962051546667,
        "train_loss": 0.0011560248352417636
      },
      {
        "epoch": 2087,
        "reward": 0.4886150062084198,
        "val_loss": 0.028074193501587224,
        "train_loss": 1.94586130137593
      },
      {
        "epoch": 2088,
        "reward": 0.47531720995903015,
        "val_loss": 0.031229966943750957,
        "train_loss": 0.006195531720349068
      },
      {
        "epoch": 2089,
        "reward": 0.4075600802898407,
        "val_loss": 0.05415646372733006,
        "train_loss": 0.0433435950420132
      },
      {
        "epoch": 2090,
        "reward": 0.42894163727760315,
        "val_loss": 0.045426513168162534,
        "train_loss": 0.0007091089755179452
      },
      {
        "epoch": 2091,
        "reward": 0.4547930657863617,
        "val_loss": 0.03683324692818652,
        "train_loss": 0.035410023987144365
      },
      {
        "epoch": 2092,
        "reward": 0.43511316180229187,
        "val_loss": 0.043197978844026305,
        "train_loss": 0.38009985187627887
      },
      {
        "epoch": 2093,
        "reward": 0.4846390187740326,
        "val_loss": 0.028982194579189775,
        "train_loss": 0.0025742375306750686
      },
      {
        "epoch": 2094,
        "reward": 0.37940070033073425,
        "val_loss": 0.06857584949674285,
        "train_loss": 0.009782033195628733
      },
      {
        "epoch": 2095,
        "reward": 0.38303956389427185,
        "val_loss": 0.06649242308880535,
        "train_loss": 0.005931292106861992
      },
      {
        "epoch": 2096,
        "reward": 0.5026388168334961,
        "val_loss": 0.025094385877829545,
        "train_loss": 151.40857842714564
      },
      {
        "epoch": 2097,
        "reward": 0.33157190680503845,
        "val_loss": 0.10415948925947305,
        "train_loss": 0.5386510950330297
      },
      {
        "epoch": 2098,
        "reward": 0.5076282620429993,
        "val_loss": 0.024112354388697504,
        "train_loss": 0.01484095118107339
      },
      {
        "epoch": 2099,
        "reward": 0.4452948272228241,
        "val_loss": 0.03977169670542935,
        "train_loss": 0.1969484079489628
      },
      {
        "epoch": 2100,
        "reward": 0.41921016573905945,
        "val_loss": 0.04919480025897168,
        "train_loss": 255.4843040140778
      },
      {
        "epoch": 2101,
        "reward": 0.3982184827327728,
        "val_loss": 0.058530166556010954,
        "train_loss": 0.12876830426664626
      },
      {
        "epoch": 2102,
        "reward": 0.4767989218235016,
        "val_loss": 0.030861113751598168,
        "train_loss": 0.45101715564277683
      },
      {
        "epoch": 2103,
        "reward": 0.4940493106842041,
        "val_loss": 0.02687945788212736,
        "train_loss": 0.13893616271796488
      },
      {
        "epoch": 2104,
        "reward": 0.43742427229881287,
        "val_loss": 0.042393672288328944,
        "train_loss": 0.0006525282388583247
      },
      {
        "epoch": 2105,
        "reward": 0.4809766709804535,
        "val_loss": 0.029844929851865994,
        "train_loss": 0.0025319466714196237
      },
      {
        "epoch": 2106,
        "reward": 0.47383639216423035,
        "val_loss": 0.031603100522521084,
        "train_loss": 0.04801214113789543
      },
      {
        "epoch": 2107,
        "reward": 0.4561166763305664,
        "val_loss": 0.03644218260056472,
        "train_loss": 0.0032170501328717084
      },
      {
        "epoch": 2108,
        "reward": 0.461283415555954,
        "val_loss": 0.03495666029006576,
        "train_loss": 0.05559182802473062
      },
      {
        "epoch": 2109,
        "reward": 0.4134783446788788,
        "val_loss": 0.051571232973531424,
        "train_loss": 0.613797767262755
      },
      {
        "epoch": 2110,
        "reward": 0.44469913840293884,
        "val_loss": 0.03996400789245464,
        "train_loss": 0.011877489427451319
      },
      {
        "epoch": 2111,
        "reward": 0.3873988091945648,
        "val_loss": 0.06408906324941199,
        "train_loss": 0.002332271006987587
      },
      {
        "epoch": 2112,
        "reward": 0.4678986966609955,
        "val_loss": 0.03314589698961105,
        "train_loss": 0.3833287482049435
      },
      {
        "epoch": 2113,
        "reward": 0.41246095299720764,
        "val_loss": 0.0520059126439654,
        "train_loss": 0.00655675173704122
      },
      {
        "epoch": 2114,
        "reward": 0.39659467339515686,
        "val_loss": 0.05932932953874115,
        "train_loss": 0.02986266317132574
      },
      {
        "epoch": 2115,
        "reward": 0.49193572998046875,
        "val_loss": 0.027337920295914437,
        "train_loss": 0.0023187102548350735
      },
      {
        "epoch": 2116,
        "reward": 0.4378698766231537,
        "val_loss": 0.04224045007660087,
        "train_loss": 0.011277070177584392
      },
      {
        "epoch": 2117,
        "reward": 0.4415869414806366,
        "val_loss": 0.04098487206023752,
        "train_loss": 0.0030912679401113178
      },
      {
        "epoch": 2118,
        "reward": 0.3429241478443146,
        "val_loss": 0.09409786221034924,
        "train_loss": 0.03132437287843004
      },
      {
        "epoch": 2119,
        "reward": 0.4312395751476288,
        "val_loss": 0.044582706188001406,
        "train_loss": 0.003235950856623486
      },
      {
        "epoch": 2120,
        "reward": 0.4112255275249481,
        "val_loss": 0.05253909934721638,
        "train_loss": 0.013325332713975513
      },
      {
        "epoch": 2121,
        "reward": 0.42153945565223694,
        "val_loss": 0.04826316907981111,
        "train_loss": 0.0038394251507900034
      },
      {
        "epoch": 2122,
        "reward": 0.3917785584926605,
        "val_loss": 0.0617713390643725,
        "train_loss": 8.710641986695158
      },
      {
        "epoch": 2123,
        "reward": 0.29627951979637146,
        "val_loss": 0.14459126671343775,
        "train_loss": 0.012207927532402279
      },
      {
        "epoch": 2124,
        "reward": 0.4709910452365875,
        "val_loss": 0.032332982291076666,
        "train_loss": 27.006652940283402
      },
      {
        "epoch": 2125,
        "reward": 0.4860096573829651,
        "val_loss": 0.028665859951745785,
        "train_loss": 0.019123981540290585
      },
      {
        "epoch": 2126,
        "reward": 0.4425375163555145,
        "val_loss": 0.040670166504112,
        "train_loss": 0.026047805691494938
      },
      {
        "epoch": 2127,
        "reward": 0.33122044801712036,
        "val_loss": 0.10449043355142099,
        "train_loss": 0.08211082566115763
      },
      {
        "epoch": 2128,
        "reward": 0.2876913547515869,
        "val_loss": 0.1571186382435761,
        "train_loss": 0.014613752306349152
      },
      {
        "epoch": 2129,
        "reward": 0.40033838152885437,
        "val_loss": 0.057504643636223464,
        "train_loss": 0.012372423660211167
      },
      {
        "epoch": 2130,
        "reward": 0.5108014345169067,
        "val_loss": 0.02350775081556224,
        "train_loss": 0.2988966038660342
      },
      {
        "epoch": 2131,
        "reward": 0.33686894178390503,
        "val_loss": 0.09931657782934573,
        "train_loss": 0.005053469325905378
      },
      {
        "epoch": 2132,
        "reward": 0.3727060556411743,
        "val_loss": 0.0726029425703538,
        "train_loss": 160.71023081569214
      },
      {
        "epoch": 2133,
        "reward": 0.37931907176971436,
        "val_loss": 0.0686234146123752,
        "train_loss": 0.25109939527814834
      },
      {
        "epoch": 2134,
        "reward": 0.47900867462158203,
        "val_loss": 0.030319299772340207,
        "train_loss": 0.004336589285370652
      },
      {
        "epoch": 2135,
        "reward": 0.496878057718277,
        "val_loss": 0.02627797277662986,
        "train_loss": 0.011437728381478197
      },
      {
        "epoch": 2136,
        "reward": 0.380662202835083,
        "val_loss": 0.06784542356035672,
        "train_loss": 0.010112373854239055
      },
      {
        "epoch": 2137,
        "reward": 0.5212016701698303,
        "val_loss": 0.021629103502034144,
        "train_loss": 0.6283084289183395
      },
      {
        "epoch": 2138,
        "reward": 0.4282856583595276,
        "val_loss": 0.04567053147599966,
        "train_loss": 0.007301914521996458
      },
      {
        "epoch": 2139,
        "reward": 0.4280262589454651,
        "val_loss": 0.0457674131685053,
        "train_loss": 0.00871092163791113
      },
      {
        "epoch": 2140,
        "reward": 0.38094526529312134,
        "val_loss": 0.06768272011374522,
        "train_loss": 0.00444750513857938
      },
      {
        "epoch": 2141,
        "reward": 0.44643983244895935,
        "val_loss": 0.039404752015668364,
        "train_loss": 0.004879044324280375
      },
      {
        "epoch": 2142,
        "reward": 0.2727150321006775,
        "val_loss": 0.18227869858882123,
        "train_loss": 0.3555527288601577
      },
      {
        "epoch": 2143,
        "reward": 0.46843647956848145,
        "val_loss": 0.03300302577762133,
        "train_loss": 3.757242181757157
      },
      {
        "epoch": 2144,
        "reward": 0.45673152804374695,
        "val_loss": 0.03626201156813685,
        "train_loss": 0.001405791648162099
      },
      {
        "epoch": 2145,
        "reward": 0.5205425024032593,
        "val_loss": 0.021743665777778785,
        "train_loss": 0.0031116078137032152
      },
      {
        "epoch": 2146,
        "reward": 0.41393977403640747,
        "val_loss": 0.05137538879872799,
        "train_loss": 0.006302500247257443
      },
      {
        "epoch": 2147,
        "reward": 0.5053441524505615,
        "val_loss": 0.024557075758431374,
        "train_loss": 0.007010506890030508
      },
      {
        "epoch": 2148,
        "reward": 0.4521796405315399,
        "val_loss": 0.03761831157836631,
        "train_loss": 0.005835933306063732
      },
      {
        "epoch": 2149,
        "reward": 0.4848778247833252,
        "val_loss": 0.0289268135576484,
        "train_loss": 0.014494906873372097
      },
      {
        "epoch": 2150,
        "reward": 0.43805965781211853,
        "val_loss": 0.042175362883426715,
        "train_loss": 0.021380817883744803
      },
      {
        "epoch": 2151,
        "reward": 0.5246805548667908,
        "val_loss": 0.021034207145151283,
        "train_loss": 0.009358216774636765
      },
      {
        "epoch": 2152,
        "reward": 0.42294421792030334,
        "val_loss": 0.04771053297528332,
        "train_loss": 0.018439090590417297
      },
      {
        "epoch": 2153,
        "reward": 0.31051337718963623,
        "val_loss": 0.12636766461322882,
        "train_loss": 0.015710957986672068
      },
      {
        "epoch": 2154,
        "reward": 0.3314606249332428,
        "val_loss": 0.10426413482803452,
        "train_loss": 0.002847142937106093
      },
      {
        "epoch": 2155,
        "reward": 0.33668211102485657,
        "val_loss": 0.09948285560156885,
        "train_loss": 0.10398272762719324
      },
      {
        "epoch": 2156,
        "reward": 0.44459351897239685,
        "val_loss": 0.039998208970895836,
        "train_loss": 0.00876906841821997
      },
      {
        "epoch": 2157,
        "reward": 0.44438478350639343,
        "val_loss": 0.04006588388542046,
        "train_loss": 0.0053393248188233254
      },
      {
        "epoch": 2158,
        "reward": 0.42348480224609375,
        "val_loss": 0.04749968358165851,
        "train_loss": 0.005958348104487554
      },
      {
        "epoch": 2159,
        "reward": 0.3880881667137146,
        "val_loss": 0.06371795714845316,
        "train_loss": 0.005598659305370837
      },
      {
        "epoch": 2160,
        "reward": 0.5187613368034363,
        "val_loss": 0.022056204277760116,
        "train_loss": 0.005281869544188129
      },
      {
        "epoch": 2161,
        "reward": 0.3595831096172333,
        "val_loss": 0.08129651290489294,
        "train_loss": 0.01178738001719309
      },
      {
        "epoch": 2162,
        "reward": 0.5109745264053345,
        "val_loss": 0.023475209079541464,
        "train_loss": 0.0014685268733606231
      },
      {
        "epoch": 2163,
        "reward": 0.4187002182006836,
        "val_loss": 0.04940133620506718,
        "train_loss": 0.0028778729494034995
      },
      {
        "epoch": 2164,
        "reward": 0.39395031332969666,
        "val_loss": 0.06065666850398494,
        "train_loss": 14.464481616365923
      },
      {
        "epoch": 2165,
        "reward": 0.380734920501709,
        "val_loss": 0.06780358555364988,
        "train_loss": 0.008613969810102599
      },
      {
        "epoch": 2166,
        "reward": 0.44101378321647644,
        "val_loss": 0.04117586131230512,
        "train_loss": 0.018656526191368636
      },
      {
        "epoch": 2167,
        "reward": 0.5176035165786743,
        "val_loss": 0.02226172151339207,
        "train_loss": 0.0028326406736596255
      },
      {
        "epoch": 2168,
        "reward": 0.4961479604244232,
        "val_loss": 0.026431906255311333,
        "train_loss": 0.0037346513434805763
      },
      {
        "epoch": 2169,
        "reward": 0.45900431275367737,
        "val_loss": 0.03560401039534814,
        "train_loss": 0.012885558448313251
      },
      {
        "epoch": 2170,
        "reward": 0.5238314867019653,
        "val_loss": 0.021177913723866886,
        "train_loss": 0.026828627781014802
      },
      {
        "epoch": 2171,
        "reward": 0.4554536044597626,
        "val_loss": 0.03663755086225657,
        "train_loss": 0.0034299524580861684
      },
      {
        "epoch": 2172,
        "reward": 0.47121453285217285,
        "val_loss": 0.03227501459852127,
        "train_loss": 0.0018709288189379199
      },
      {
        "epoch": 2173,
        "reward": 0.3773380517959595,
        "val_loss": 0.06978919447179319,
        "train_loss": 0.017730916633695415
      },
      {
        "epoch": 2174,
        "reward": 0.40183964371681213,
        "val_loss": 0.056790371354769116,
        "train_loss": 0.0006201700025135673
      },
      {
        "epoch": 2175,
        "reward": 0.3928624987602234,
        "val_loss": 0.06121218797592779,
        "train_loss": 0.006094246311372094
      },
      {
        "epoch": 2176,
        "reward": 0.40448901057243347,
        "val_loss": 0.05555345504087329,
        "train_loss": 0.0008335124886028867
      },
      {
        "epoch": 2177,
        "reward": 0.3430534601211548,
        "val_loss": 0.09398992350907065,
        "train_loss": 0.21971215266963695
      },
      {
        "epoch": 2178,
        "reward": 0.4843491017818451,
        "val_loss": 0.02904955656932933,
        "train_loss": 0.05310763329589463
      },
      {
        "epoch": 2179,
        "reward": 0.470743328332901,
        "val_loss": 0.032397338049902046,
        "train_loss": 0.0025394769510197735
      },
      {
        "epoch": 2180,
        "reward": 0.3467807173728943,
        "val_loss": 0.09093958702578675,
        "train_loss": 0.04659031412875965
      },
      {
        "epoch": 2181,
        "reward": 0.460994154214859,
        "val_loss": 0.035038128343460685,
        "train_loss": 0.014073024221987068
      },
      {
        "epoch": 2182,
        "reward": 0.5103480219841003,
        "val_loss": 0.023593210869876202,
        "train_loss": 0.006513906118595532
      },
      {
        "epoch": 2183,
        "reward": 0.4867868423461914,
        "val_loss": 0.02848805351979016,
        "train_loss": 0.005037404629162596
      },
      {
        "epoch": 2184,
        "reward": 0.46103334426879883,
        "val_loss": 0.03502708606226536,
        "train_loss": 0.005063185620507773
      },
      {
        "epoch": 2185,
        "reward": 0.4236662983894348,
        "val_loss": 0.0474291294854733,
        "train_loss": 207.6847169117687
      },
      {
        "epoch": 2186,
        "reward": 0.41370946168899536,
        "val_loss": 0.051473032128082456,
        "train_loss": 0.00920117832422945
      },
      {
        "epoch": 2187,
        "reward": 0.3764124810695648,
        "val_loss": 0.07034150827010828,
        "train_loss": 0.3816455059418681
      },
      {
        "epoch": 2188,
        "reward": 0.4647737145423889,
        "val_loss": 0.03398886447653889,
        "train_loss": 0.0038651452884393553
      },
      {
        "epoch": 2189,
        "reward": 0.3469581604003906,
        "val_loss": 0.0907972397960423,
        "train_loss": 0.3170451521128388
      },
      {
        "epoch": 2190,
        "reward": 0.5303539633750916,
        "val_loss": 0.020098084174865756,
        "train_loss": 0.0035020820044757363
      },
      {
        "epoch": 2191,
        "reward": 0.4107643663883209,
        "val_loss": 0.05273966867805159,
        "train_loss": 0.004794613889526562
      },
      {
        "epoch": 2192,
        "reward": 0.41294437646865845,
        "val_loss": 0.05179885613740355,
        "train_loss": 0.009024549973319678
      },
      {
        "epoch": 2193,
        "reward": 0.43012186884880066,
        "val_loss": 0.044991023720025884,
        "train_loss": 0.0031974312356536617
      },
      {
        "epoch": 2194,
        "reward": 0.443832129240036,
        "val_loss": 0.04024566640042134,
        "train_loss": 0.017477991117394034
      },
      {
        "epoch": 2195,
        "reward": 0.3623253107070923,
        "val_loss": 0.07938635987946847,
        "train_loss": 0.5503553975172158
      },
      {
        "epoch": 2196,
        "reward": 0.36773428320884705,
        "val_loss": 0.07576628914102912,
        "train_loss": 0.04703552068597743
      },
      {
        "epoch": 2197,
        "reward": 0.3225398361682892,
        "val_loss": 0.11306953268441637,
        "train_loss": 0.3127084791952906
      },
      {
        "epoch": 2198,
        "reward": 0.5067800283432007,
        "val_loss": 0.024276564466293036,
        "train_loss": 1.5281244730521952
      },
      {
        "epoch": 2199,
        "reward": 0.4784735143184662,
        "val_loss": 0.030449611490309638,
        "train_loss": 0.010470369110259106
      },
      {
        "epoch": 2200,
        "reward": 0.44846612215042114,
        "val_loss": 0.038764128648576195,
        "train_loss": 2.580876296060279
      },
      {
        "epoch": 2201,
        "reward": 0.4440018832683563,
        "val_loss": 0.04019037784434788,
        "train_loss": 0.0024239702418246733
      },
      {
        "epoch": 2202,
        "reward": 0.43628692626953125,
        "val_loss": 0.042787472790223546,
        "train_loss": 21.31904738540953
      },
      {
        "epoch": 2203,
        "reward": 0.4583127498626709,
        "val_loss": 0.03580289825809554,
        "train_loss": 0.001108149954916371
      },
      {
        "epoch": 2204,
        "reward": 0.4474109709262848,
        "val_loss": 0.03909633887295578,
        "train_loss": 0.016541857753719132
      },
      {
        "epoch": 2205,
        "reward": 0.48510000109672546,
        "val_loss": 0.02887540946539957,
        "train_loss": 0.00859771348165649
      },
      {
        "epoch": 2206,
        "reward": 0.4843909740447998,
        "val_loss": 0.029039804779001446,
        "train_loss": 0.026003342732915023
      },
      {
        "epoch": 2207,
        "reward": 0.46978598833084106,
        "val_loss": 0.03264728495560121,
        "train_loss": 0.004853365841602051
      },
      {
        "epoch": 2208,
        "reward": 0.44796499609947205,
        "val_loss": 0.03892153030132509,
        "train_loss": 0.010327011928613782
      },
      {
        "epoch": 2209,
        "reward": 0.49711647629737854,
        "val_loss": 0.02622789702062229,
        "train_loss": 0.00123739532442535
      },
      {
        "epoch": 2210,
        "reward": 0.48525992035865784,
        "val_loss": 0.028838463881194393,
        "train_loss": 0.008081383180043443
      },
      {
        "epoch": 2211,
        "reward": 0.44059833884239197,
        "val_loss": 0.04131490169779032,
        "train_loss": 0.029959174355956117
      },
      {
        "epoch": 2212,
        "reward": 0.4645780026912689,
        "val_loss": 0.03404238718628351,
        "train_loss": 0.008094190795103574
      },
      {
        "epoch": 2213,
        "reward": 0.45969539880752563,
        "val_loss": 0.03540641433937708,
        "train_loss": 0.060130932062048274
      },
      {
        "epoch": 2214,
        "reward": 0.4024674892425537,
        "val_loss": 0.05649451268254779,
        "train_loss": 0.19947653601305915
      },
      {
        "epoch": 2215,
        "reward": 0.39475908875465393,
        "val_loss": 0.060247227981952686,
        "train_loss": 0.011905892498090837
      },
      {
        "epoch": 2216,
        "reward": 0.46344491839408875,
        "val_loss": 0.03435400140006095,
        "train_loss": 0.061877072592566924
      },
      {
        "epoch": 2217,
        "reward": 0.4251047670841217,
        "val_loss": 0.04687382675911067,
        "train_loss": 0.05060148910017513
      },
      {
        "epoch": 2218,
        "reward": 0.5041510462760925,
        "val_loss": 0.024792612808856314,
        "train_loss": 0.2806860393913203
      },
      {
        "epoch": 2219,
        "reward": 0.40064460039138794,
        "val_loss": 0.057358156793010755,
        "train_loss": 0.0016146584549250503
      },
      {
        "epoch": 2220,
        "reward": 0.45731401443481445,
        "val_loss": 0.036092179767105596,
        "train_loss": 0.12654760954629077
      },
      {
        "epoch": 2221,
        "reward": 0.42676910758018494,
        "val_loss": 0.046240011876631924,
        "train_loss": 0.0019971042366320876
      },
      {
        "epoch": 2222,
        "reward": 0.4447939395904541,
        "val_loss": 0.03993332826731993,
        "train_loss": 0.13799710665961568
      },
      {
        "epoch": 2223,
        "reward": 0.4577046036720276,
        "val_loss": 0.03597876387357246,
        "train_loss": 0.004246994616306228
      },
      {
        "epoch": 2224,
        "reward": 0.5074883103370667,
        "val_loss": 0.02413936332803652,
        "train_loss": 0.10464287466121701
      },
      {
        "epoch": 2225,
        "reward": 0.3551304042339325,
        "val_loss": 0.08451095954348732,
        "train_loss": 0.0031335936886701067
      },
      {
        "epoch": 2226,
        "reward": 0.4166417121887207,
        "val_loss": 0.050244669735548086,
        "train_loss": 0.00228470248058644
      },
      {
        "epoch": 2227,
        "reward": 0.49574729800224304,
        "val_loss": 0.026516765592012752,
        "train_loss": 0.01766642298333374
      },
      {
        "epoch": 2228,
        "reward": 0.5007361769676208,
        "val_loss": 0.025479276636490664,
        "train_loss": 0.0013603603584066639
      },
      {
        "epoch": 2229,
        "reward": 0.4751909375190735,
        "val_loss": 0.0312616083319881,
        "train_loss": 0.02635585860869364
      },
      {
        "epoch": 2230,
        "reward": 0.44020992517471313,
        "val_loss": 0.04144532718055416,
        "train_loss": 0.002075034436179871
      },
      {
        "epoch": 2231,
        "reward": 0.34462738037109375,
        "val_loss": 0.09268765327786761,
        "train_loss": 0.14988293880570872
      },
      {
        "epoch": 2232,
        "reward": 0.5050652027130127,
        "val_loss": 0.02461193825729424,
        "train_loss": 0.008706529945820525
      },
      {
        "epoch": 2233,
        "reward": 0.420550674200058,
        "val_loss": 0.04865630811192594,
        "train_loss": 0.010694639412369393
      },
      {
        "epoch": 2234,
        "reward": 0.5180421471595764,
        "val_loss": 0.022183635956025682,
        "train_loss": 3.2030918523181264
      },
      {
        "epoch": 2235,
        "reward": 0.3974199593067169,
        "val_loss": 0.05892167110765253,
        "train_loss": 0.015545586279097497
      },
      {
        "epoch": 2236,
        "reward": 0.4469185769557953,
        "val_loss": 0.03925239609712402,
        "train_loss": 0.023927088413302045
      },
      {
        "epoch": 2237,
        "reward": 0.4819866716861725,
        "val_loss": 0.029604425566503778,
        "train_loss": 0.01189177965032356
      },
      {
        "epoch": 2238,
        "reward": 0.33665022253990173,
        "val_loss": 0.09951125803802695,
        "train_loss": 60.298838555522494
      },
      {
        "epoch": 2239,
        "reward": 0.24904108047485352,
        "val_loss": 0.233042524015348,
        "train_loss": 0.023219506224380054
      },
      {
        "epoch": 2240,
        "reward": 0.33665862679481506,
        "val_loss": 0.09950378893699963,
        "train_loss": 0.1316231606509355
      },
      {
        "epoch": 2241,
        "reward": 0.49560290575027466,
        "val_loss": 0.026547424929698797,
        "train_loss": 0.005707182483127746
      },
      {
        "epoch": 2242,
        "reward": 0.43637052178382874,
        "val_loss": 0.042758402937449445,
        "train_loss": 0.15811645194629328
      },
      {
        "epoch": 2243,
        "reward": 0.42570924758911133,
        "val_loss": 0.046642558995310016,
        "train_loss": 0.6174355716668918
      },
      {
        "epoch": 2244,
        "reward": 0.4495924413204193,
        "val_loss": 0.038412768892677765,
        "train_loss": 0.47209283023193377
      },
      {
        "epoch": 2245,
        "reward": 0.5453268885612488,
        "val_loss": 0.017816794996178942,
        "train_loss": 0.002817833338510284
      },
      {
        "epoch": 2246,
        "reward": 0.5459850430488586,
        "val_loss": 0.017722447017149534,
        "train_loss": 1.2521770450820826
      },
      {
        "epoch": 2247,
        "reward": 0.5392067432403564,
        "val_loss": 0.018717443939489646,
        "train_loss": 0.009804749951723143
      },
      {
        "epoch": 2248,
        "reward": 0.45956116914749146,
        "val_loss": 0.03544470597366204,
        "train_loss": 0.12487259271525684
      },
      {
        "epoch": 2249,
        "reward": 0.5022372603416443,
        "val_loss": 0.02517512719246692,
        "train_loss": 0.0018001805031837227
      },
      {
        "epoch": 2250,
        "reward": 0.26599058508872986,
        "val_loss": 0.19517114478575032,
        "train_loss": 0.01914197165325067
      },
      {
        "epoch": 2251,
        "reward": 0.4451037049293518,
        "val_loss": 0.03983327840043265,
        "train_loss": 0.026311915210530838
      },
      {
        "epoch": 2252,
        "reward": 0.3035258948802948,
        "val_loss": 0.13494702109268733,
        "train_loss": 0.13836369178516003
      },
      {
        "epoch": 2253,
        "reward": 0.25213727355003357,
        "val_loss": 0.22548342852470732,
        "train_loss": 0.03677931564327362
      },
      {
        "epoch": 2254,
        "reward": 0.3973308503627777,
        "val_loss": 0.058965538315533195,
        "train_loss": 0.0011968145999022594
      },
      {
        "epoch": 2255,
        "reward": 0.4212282598018646,
        "val_loss": 0.048386539977010604,
        "train_loss": 0.004419149379163383
      },
      {
        "epoch": 2256,
        "reward": 0.5129832625389099,
        "val_loss": 0.02310075114240005,
        "train_loss": 0.3139296832024019
      },
      {
        "epoch": 2257,
        "reward": 0.49978572130203247,
        "val_loss": 0.025673762239291267,
        "train_loss": 0.0013943403535169917
      },
      {
        "epoch": 2258,
        "reward": 0.3754834830760956,
        "val_loss": 0.07090078389176467,
        "train_loss": 0.013353434445189823
      },
      {
        "epoch": 2259,
        "reward": 0.5308524370193481,
        "val_loss": 0.020017800134935117,
        "train_loss": 0.0035546174184184144
      },
      {
        "epoch": 2260,
        "reward": 0.4712265133857727,
        "val_loss": 0.0322719220743498,
        "train_loss": 0.08823008671481603
      },
      {
        "epoch": 2261,
        "reward": 0.483558714389801,
        "val_loss": 0.029234010254835345,
        "train_loss": 0.01107237235928201
      },
      {
        "epoch": 2262,
        "reward": 0.5260196924209595,
        "val_loss": 0.020809493661675203,
        "train_loss": 0.0016724175492824473
      },
      {
        "epoch": 2263,
        "reward": 0.45340409874916077,
        "val_loss": 0.03724833572778152,
        "train_loss": 0.006968301098201944
      },
      {
        "epoch": 2264,
        "reward": 0.5142020583152771,
        "val_loss": 0.022876453072447994,
        "train_loss": 0.0009503554477375404
      },
      {
        "epoch": 2265,
        "reward": 0.4574415385723114,
        "val_loss": 0.03605511904398944,
        "train_loss": 0.1961926113021246
      },
      {
        "epoch": 2266,
        "reward": 0.5453290939331055,
        "val_loss": 0.017816477814838954,
        "train_loss": 0.01434962484281991
      },
      {
        "epoch": 2267,
        "reward": 0.4411996304988861,
        "val_loss": 0.041113842055243106,
        "train_loss": 0.2607202960554017
      },
      {
        "epoch": 2268,
        "reward": 0.3639804422855377,
        "val_loss": 0.0782581785460934,
        "train_loss": 0.004825100752703712
      },
      {
        "epoch": 2269,
        "reward": 0.33837711811065674,
        "val_loss": 0.09798598196149604,
        "train_loss": 0.0024932348740968825
      },
      {
        "epoch": 2270,
        "reward": 0.42328080534935,
        "val_loss": 0.04757912249936323,
        "train_loss": 0.011553927016074375
      },
      {
        "epoch": 2271,
        "reward": 0.4928823411464691,
        "val_loss": 0.02713162208133976,
        "train_loss": 0.030257512909473077
      },
      {
        "epoch": 2272,
        "reward": 0.46545305848121643,
        "val_loss": 0.03380374119504787,
        "train_loss": 0.02118806359578387
      },
      {
        "epoch": 2273,
        "reward": 0.4189452826976776,
        "val_loss": 0.049301988927514424,
        "train_loss": 0.002404214343572383
      },
      {
        "epoch": 2274,
        "reward": 0.4785902202129364,
        "val_loss": 0.030421153279478728,
        "train_loss": 0.007039669849308876
      },
      {
        "epoch": 2275,
        "reward": 0.2765085697174072,
        "val_loss": 0.17546660715015605,
        "train_loss": 0.03905557268878441
      },
      {
        "epoch": 2276,
        "reward": 0.515186607837677,
        "val_loss": 0.022696819018684828,
        "train_loss": 0.028740444937642887
      },
      {
        "epoch": 2277,
        "reward": 0.3929708003997803,
        "val_loss": 0.06115661671148181,
        "train_loss": 0.0885764128949474
      },
      {
        "epoch": 2278,
        "reward": 0.4449843466281891,
        "val_loss": 0.03987179228819774,
        "train_loss": 0.0018118349837812696
      },
      {
        "epoch": 2279,
        "reward": 0.45913147926330566,
        "val_loss": 0.03556756239933228,
        "train_loss": 0.0006142874812772229
      },
      {
        "epoch": 2280,
        "reward": 0.45107126235961914,
        "val_loss": 0.03795652084850839,
        "train_loss": 0.08253055068317175
      },
      {
        "epoch": 2281,
        "reward": 0.43389302492141724,
        "val_loss": 0.04362913430408558,
        "train_loss": 0.009823627436652225
      },
      {
        "epoch": 2282,
        "reward": 0.4664112627506256,
        "val_loss": 0.03354439895026319,
        "train_loss": 0.007173461759311277
      },
      {
        "epoch": 2283,
        "reward": 0.4759127199649811,
        "val_loss": 0.031081172755096174,
        "train_loss": 0.010332290796170058
      },
      {
        "epoch": 2284,
        "reward": 0.42727723717689514,
        "val_loss": 0.04604836924720855,
        "train_loss": 0.0064095478304067545
      },
      {
        "epoch": 2285,
        "reward": 0.4498504102230072,
        "val_loss": 0.038332763667442905,
        "train_loss": 0.006920962830690769
      },
      {
        "epoch": 2286,
        "reward": 0.5455800890922546,
        "val_loss": 0.017780436400373998,
        "train_loss": 0.012120492228842313
      },
      {
        "epoch": 2287,
        "reward": 0.5187823176383972,
        "val_loss": 0.022052499051954198,
        "train_loss": 22.03463706767331
      },
      {
        "epoch": 2288,
        "reward": 0.36279913783073425,
        "val_loss": 0.07906151076063647,
        "train_loss": 0.024125720497356548
      },
      {
        "epoch": 2289,
        "reward": 0.549548864364624,
        "val_loss": 0.017219781657331623,
        "train_loss": 0.21739288866851544
      },
      {
        "epoch": 2290,
        "reward": 0.3758923411369324,
        "val_loss": 0.07065403699484055,
        "train_loss": 0.014192357536488159
      },
      {
        "epoch": 2291,
        "reward": 0.4098338782787323,
        "val_loss": 0.05314686236878125,
        "train_loss": 0.007122449322458544
      },
      {
        "epoch": 2292,
        "reward": 0.4012184143066406,
        "val_loss": 0.05708474664217127,
        "train_loss": 0.03238265047429405
      },
      {
        "epoch": 2293,
        "reward": 0.4720611572265625,
        "val_loss": 0.032056454828437254,
        "train_loss": 0.003043535361397377
      },
      {
        "epoch": 2294,
        "reward": 0.4349982440471649,
        "val_loss": 0.04323838522291875,
        "train_loss": 0.003619064022866671
      },
      {
        "epoch": 2295,
        "reward": 0.41756153106689453,
        "val_loss": 0.0498659363407309,
        "train_loss": 0.005329757956587855
      },
      {
        "epoch": 2296,
        "reward": 0.4845341742038727,
        "val_loss": 0.029006528854162234,
        "train_loss": 13.98055193277957
      },
      {
        "epoch": 2297,
        "reward": 0.4866475760936737,
        "val_loss": 0.0285198338679038,
        "train_loss": 0.1899419071738311
      },
      {
        "epoch": 2298,
        "reward": 0.5382727980613708,
        "val_loss": 0.018858660853376414,
        "train_loss": 0.03749496371217621
      },
      {
        "epoch": 2299,
        "reward": 0.48989057540893555,
        "val_loss": 0.027789035400408984,
        "train_loss": 0.00841399961131646
      },
      {
        "epoch": 2300,
        "reward": 0.45313867926597595,
        "val_loss": 0.03732819257337334,
        "train_loss": 0.009419804678832232
      },
      {
        "epoch": 2301,
        "reward": 0.36634787917137146,
        "val_loss": 0.07667595934929393,
        "train_loss": 0.00215667214433779
      },
      {
        "epoch": 2302,
        "reward": 0.2210734635591507,
        "val_loss": 0.31817400280436103,
        "train_loss": 0.27734344052463744
      },
      {
        "epoch": 2303,
        "reward": 0.3857801854610443,
        "val_loss": 0.06496998278245363,
        "train_loss": 0.015142105763323763
      },
      {
        "epoch": 2304,
        "reward": 0.5181558132171631,
        "val_loss": 0.022163444628988924,
        "train_loss": 0.011316008561624794
      },
      {
        "epoch": 2305,
        "reward": 0.5211579203605652,
        "val_loss": 0.021636696418032182,
        "train_loss": 0.002583889384963046
      },
      {
        "epoch": 2306,
        "reward": 0.4967237114906311,
        "val_loss": 0.026310436643793116,
        "train_loss": 0.002611510671202338
      },
      {
        "epoch": 2307,
        "reward": 0.5254918336868286,
        "val_loss": 0.020897789953908483,
        "train_loss": 0.0014185793786159943
      },
      {
        "epoch": 2308,
        "reward": 0.4300553500652313,
        "val_loss": 0.04501543779562261,
        "train_loss": 0.7314586379931755
      },
      {
        "epoch": 2309,
        "reward": 0.3747422397136688,
        "val_loss": 0.07135061873434877,
        "train_loss": 0.002741710030818467
      },
      {
        "epoch": 2310,
        "reward": 0.4075944423675537,
        "val_loss": 0.054141062807112963,
        "train_loss": 0.002041302436107519
      },
      {
        "epoch": 2311,
        "reward": 0.5068579316139221,
        "val_loss": 0.02426143713091733,
        "train_loss": 18.279848275707625
      },
      {
        "epoch": 2312,
        "reward": 0.5213589072227478,
        "val_loss": 0.021601858704733395,
        "train_loss": 0.0013608138158885525
      },
      {
        "epoch": 2313,
        "reward": 0.43854832649230957,
        "val_loss": 0.042008260761836676,
        "train_loss": 0.0018906930137675842
      },
      {
        "epoch": 2314,
        "reward": 0.4322902262210846,
        "val_loss": 0.04420249121696023,
        "train_loss": 0.016263872132710206
      },
      {
        "epoch": 2315,
        "reward": 0.3601388931274414,
        "val_loss": 0.08090515032693345,
        "train_loss": 0.07477273896690279
      },
      {
        "epoch": 2316,
        "reward": 0.4623391628265381,
        "val_loss": 0.03466093280076166,
        "train_loss": 0.008175959450883195
      },
      {
        "epoch": 2317,
        "reward": 0.34882307052612305,
        "val_loss": 0.08931666315869993,
        "train_loss": 0.0015036066611698446
      },
      {
        "epoch": 2318,
        "reward": 0.4716992974281311,
        "val_loss": 0.032149700425049686,
        "train_loss": 0.011129145121580782
      },
      {
        "epoch": 2319,
        "reward": 0.4743851125240326,
        "val_loss": 0.03146429243393608,
        "train_loss": 0.01862654136311903
      },
      {
        "epoch": 2320,
        "reward": 0.40237531065940857,
        "val_loss": 0.05653784057566164,
        "train_loss": 0.047568342420661866
      },
      {
        "epoch": 2321,
        "reward": 0.5018683671951294,
        "val_loss": 0.0252495437671314,
        "train_loss": 0.0038318129863470153
      },
      {
        "epoch": 2322,
        "reward": 0.4262791574001312,
        "val_loss": 0.04642563136440003,
        "train_loss": 0.006926275602329322
      },
      {
        "epoch": 2323,
        "reward": 0.4111332893371582,
        "val_loss": 0.05257917218010074,
        "train_loss": 0.09201575735684085
      },
      {
        "epoch": 2324,
        "reward": 0.41032639145851135,
        "val_loss": 0.052930908768238236,
        "train_loss": 0.48107619201059254
      },
      {
        "epoch": 2325,
        "reward": 0.33969351649284363,
        "val_loss": 0.09684149890485319,
        "train_loss": 0.193701022084147
      },
      {
        "epoch": 2326,
        "reward": 0.5261106491088867,
        "val_loss": 0.020794309416877304,
        "train_loss": 0.001217937426664898
      },
      {
        "epoch": 2327,
        "reward": 0.3198561370372772,
        "val_loss": 0.11588763679174008,
        "train_loss": 0.007629448413957527
      },
      {
        "epoch": 2328,
        "reward": 0.4674778878688812,
        "val_loss": 0.03325814473230691,
        "train_loss": 0.00834102898061946
      },
      {
        "epoch": 2329,
        "reward": 0.5042362809181213,
        "val_loss": 0.024775719540359984,
        "train_loss": 0.0021245695744133066
      },
      {
        "epoch": 2330,
        "reward": 0.4539075791835785,
        "val_loss": 0.037097293994780296,
        "train_loss": 0.0016587097995327965
      },
      {
        "epoch": 2331,
        "reward": 0.46781715750694275,
        "val_loss": 0.03316761849107154,
        "train_loss": 0.003167118948235489
      },
      {
        "epoch": 2332,
        "reward": 0.4828524589538574,
        "val_loss": 0.029399835451580918,
        "train_loss": 0.005002382336906171
      },
      {
        "epoch": 2333,
        "reward": 0.4126308858394623,
        "val_loss": 0.051933012551411854,
        "train_loss": 0.005629832603281452
      },
      {
        "epoch": 2334,
        "reward": 0.34058913588523865,
        "val_loss": 0.09607171076433067,
        "train_loss": 0.005502124623427234
      },
      {
        "epoch": 2335,
        "reward": 0.47371959686279297,
        "val_loss": 0.03163272173177185,
        "train_loss": 0.5425540729407535
      },
      {
        "epoch": 2336,
        "reward": 0.37390416860580444,
        "val_loss": 0.07186309374602777,
        "train_loss": 0.001974387323326272
      },
      {
        "epoch": 2337,
        "reward": 0.4949367940425873,
        "val_loss": 0.026689280005354834,
        "train_loss": 0.0012545989396200569
      },
      {
        "epoch": 2338,
        "reward": 0.45823463797569275,
        "val_loss": 0.035825450574131015,
        "train_loss": 0.011096600876324093
      },
      {
        "epoch": 2339,
        "reward": 0.4997147023677826,
        "val_loss": 0.025688336992711162,
        "train_loss": 0.0007285042484699471
      },
      {
        "epoch": 2340,
        "reward": 0.5279704928398132,
        "val_loss": 0.02048631529344545,
        "train_loss": 0.004380790049301945
      },
      {
        "epoch": 2341,
        "reward": 0.44004932045936584,
        "val_loss": 0.04149939969647676,
        "train_loss": 0.002722491248260457
      },
      {
        "epoch": 2342,
        "reward": 0.5375290513038635,
        "val_loss": 0.018971863740132124,
        "train_loss": 0.002774725177040147
      },
      {
        "epoch": 2343,
        "reward": 0.48863711953163147,
        "val_loss": 0.028069228244671,
        "train_loss": 0.009636285589609682
      },
      {
        "epoch": 2344,
        "reward": 0.4262727200984955,
        "val_loss": 0.046428084814189266,
        "train_loss": 0.004108289179061313
      },
      {
        "epoch": 2345,
        "reward": 0.45743080973625183,
        "val_loss": 0.0360582335872875,
        "train_loss": 0.009920960870081567
      },
      {
        "epoch": 2346,
        "reward": 0.38985711336135864,
        "val_loss": 0.06277647654185005,
        "train_loss": 0.004409204679305936
      },
      {
        "epoch": 2347,
        "reward": 0.4764270484447479,
        "val_loss": 0.030953266395954415,
        "train_loss": 0.010686930033139653
      },
      {
        "epoch": 2348,
        "reward": 0.4829160273075104,
        "val_loss": 0.02938486845128604,
        "train_loss": 0.3692825149168689
      },
      {
        "epoch": 2349,
        "reward": 0.5266095399856567,
        "val_loss": 0.020711258310516963,
        "train_loss": 0.0010722743074368807
      },
      {
        "epoch": 2350,
        "reward": 0.3313817083835602,
        "val_loss": 0.10433844024581569,
        "train_loss": 0.0091014393709394
      },
      {
        "epoch": 2351,
        "reward": 0.41965800523757935,
        "val_loss": 0.04901418078848759,
        "train_loss": 0.003680060311860591
      },
      {
        "epoch": 2352,
        "reward": 0.3786245584487915,
        "val_loss": 0.06902961645183885,
        "train_loss": 0.0013995041496697852
      },
      {
        "epoch": 2353,
        "reward": 0.48373982310295105,
        "val_loss": 0.02919163943546924,
        "train_loss": 0.00607360061282564
      },
      {
        "epoch": 2354,
        "reward": 0.454496294260025,
        "val_loss": 0.036921515689755324,
        "train_loss": 0.005476131206513366
      },
      {
        "epoch": 2355,
        "reward": 0.4088403284549713,
        "val_loss": 0.053585464885275415,
        "train_loss": 0.0018934183349039392
      },
      {
        "epoch": 2356,
        "reward": 0.44937261939048767,
        "val_loss": 0.03848108215710714,
        "train_loss": 0.03581666942762004
      },
      {
        "epoch": 2357,
        "reward": 0.44416332244873047,
        "val_loss": 0.04013783773344975,
        "train_loss": 0.08666522786359984
      },
      {
        "epoch": 2358,
        "reward": 0.4128402769565582,
        "val_loss": 0.05184337752871215,
        "train_loss": 0.012077749066083224
      },
      {
        "epoch": 2359,
        "reward": 0.48505669832229614,
        "val_loss": 0.02888542654649687,
        "train_loss": 0.0026110989480929883
      },
      {
        "epoch": 2360,
        "reward": 0.4121316075325012,
        "val_loss": 0.052147481912730394,
        "train_loss": 0.04805954277807919
      },
      {
        "epoch": 2361,
        "reward": 0.4061296880245209,
        "val_loss": 0.05480227180253548,
        "train_loss": 0.0030058507098654165
      },
      {
        "epoch": 2362,
        "reward": 0.4390987455844879,
        "val_loss": 0.0418209049197945,
        "train_loss": 0.018877910312244676
      },
      {
        "epoch": 2363,
        "reward": 0.46202635765075684,
        "val_loss": 0.03474828880592083,
        "train_loss": 0.00302514446121467
      },
      {
        "epoch": 2364,
        "reward": 0.5276784300804138,
        "val_loss": 0.020534378601171608,
        "train_loss": 0.005287351274563872
      },
      {
        "epoch": 2365,
        "reward": 0.49156737327575684,
        "val_loss": 0.027418626732209565,
        "train_loss": 10.372530898917445
      },
      {
        "epoch": 2366,
        "reward": 0.5110614895820618,
        "val_loss": 0.02345886653659233,
        "train_loss": 0.0027818010965679953
      },
      {
        "epoch": 2367,
        "reward": 0.41604310274124146,
        "val_loss": 0.050492860023950925,
        "train_loss": 0.010322672396813896
      },
      {
        "epoch": 2368,
        "reward": 0.5183875560760498,
        "val_loss": 0.0221223455971215,
        "train_loss": 0.005409010078682723
      },
      {
        "epoch": 2369,
        "reward": 0.5055118799209595,
        "val_loss": 0.024524140570844923,
        "train_loss": 0.01965409422391181
      },
      {
        "epoch": 2370,
        "reward": 0.44933468103408813,
        "val_loss": 0.038492893579781855,
        "train_loss": 0.0176042136599309
      },
      {
        "epoch": 2371,
        "reward": 0.4661926329135895,
        "val_loss": 0.033603411114849484,
        "train_loss": 0.0026055744622313936
      },
      {
        "epoch": 2372,
        "reward": 0.5296187996864319,
        "val_loss": 0.02021706552165727,
        "train_loss": 0.018427529656631893
      },
      {
        "epoch": 2373,
        "reward": 0.4527134597301483,
        "val_loss": 0.037456533441270166,
        "train_loss": 0.12041227547364577
      },
      {
        "epoch": 2374,
        "reward": 0.3253113329410553,
        "val_loss": 0.11024358190479688,
        "train_loss": 0.03534218155859419
      },
      {
        "epoch": 2375,
        "reward": 0.2185816764831543,
        "val_loss": 0.32755527765922515,
        "train_loss": 0.033228460202315964
      },
      {
        "epoch": 2376,
        "reward": 0.4418083131313324,
        "val_loss": 0.04091133992499506,
        "train_loss": 0.001425083663264104
      },
      {
        "epoch": 2377,
        "reward": 0.46051397919654846,
        "val_loss": 0.03517382621170587,
        "train_loss": 0.1621786594882206
      },
      {
        "epoch": 2378,
        "reward": 0.4295961558818817,
        "val_loss": 0.04518446125439368,
        "train_loss": 0.1286899245144993
      },
      {
        "epoch": 2379,
        "reward": 0.33959105610847473,
        "val_loss": 0.09693000320008391,
        "train_loss": 0.012702292750805536
      },
      {
        "epoch": 2380,
        "reward": 0.4641510546207428,
        "val_loss": 0.034159459227729325,
        "train_loss": 0.05427018032873303
      },
      {
        "epoch": 2381,
        "reward": 0.4213941693305969,
        "val_loss": 0.048320731247908304,
        "train_loss": 0.027952229232981223
      },
      {
        "epoch": 2382,
        "reward": 0.4519514739513397,
        "val_loss": 0.0376876692379093,
        "train_loss": 0.003328870157772074
      },
      {
        "epoch": 2383,
        "reward": 0.3510887026786804,
        "val_loss": 0.08755517997529491,
        "train_loss": 0.004632702464531983
      },
      {
        "epoch": 2384,
        "reward": 0.48508086800575256,
        "val_loss": 0.028879830351797864,
        "train_loss": 0.005705271335395641
      },
      {
        "epoch": 2385,
        "reward": 0.4041363298892975,
        "val_loss": 0.05571638575513914,
        "train_loss": 0.003458379696439806
      },
      {
        "epoch": 2386,
        "reward": 0.38118940591812134,
        "val_loss": 0.06754274025193549,
        "train_loss": 0.0015979597406892655
      },
      {
        "epoch": 2387,
        "reward": 0.5303670167922974,
        "val_loss": 0.020095980452294628,
        "train_loss": 0.0499754303924734
      },
      {
        "epoch": 2388,
        "reward": 0.47822093963623047,
        "val_loss": 0.030511321922468988,
        "train_loss": 0.007565870369973027
      },
      {
        "epoch": 2389,
        "reward": 0.47164925932884216,
        "val_loss": 0.03216259260807419,
        "train_loss": 0.009878328363977463
      },
      {
        "epoch": 2390,
        "reward": 0.39230069518089294,
        "val_loss": 0.061501271868889616,
        "train_loss": 0.07629914009848668
      },
      {
        "epoch": 2391,
        "reward": 0.3876284062862396,
        "val_loss": 0.06396521995130959,
        "train_loss": 0.3950210711296117
      },
      {
        "epoch": 2392,
        "reward": 0.5055879950523376,
        "val_loss": 0.02450921241688775,
        "train_loss": 0.004220541003187113
      },
      {
        "epoch": 2393,
        "reward": 0.506967306137085,
        "val_loss": 0.02424021521281767,
        "train_loss": 0.13379088754621848
      },
      {
        "epoch": 2394,
        "reward": 0.5586766004562378,
        "val_loss": 0.015993290319914064,
        "train_loss": 0.011773622691049031
      },
      {
        "epoch": 2395,
        "reward": 0.5302553176879883,
        "val_loss": 0.020114002472837456,
        "train_loss": 0.004490439237193082
      },
      {
        "epoch": 2396,
        "reward": 0.4808255732059479,
        "val_loss": 0.029881078732224915,
        "train_loss": 0.013032096221588919
      },
      {
        "epoch": 2397,
        "reward": 0.5355584025382996,
        "val_loss": 0.01927495229444633,
        "train_loss": 0.003181451841206021
      },
      {
        "epoch": 2398,
        "reward": 0.4365553855895996,
        "val_loss": 0.0426941879496943,
        "train_loss": 0.11063373979412133
      },
      {
        "epoch": 2399,
        "reward": 0.4436378479003906,
        "val_loss": 0.040309080652410297,
        "train_loss": 0.00823066339879338
      },
      {
        "epoch": 2400,
        "reward": 0.4079957902431488,
        "val_loss": 0.053961380361995125,
        "train_loss": 0.11117761857356247
      },
      {
        "epoch": 2401,
        "reward": 0.41213083267211914,
        "val_loss": 0.05214780478542837,
        "train_loss": 0.012410404835472596
      },
      {
        "epoch": 2402,
        "reward": 0.484932005405426,
        "val_loss": 0.028914283201239805,
        "train_loss": 0.2650457317656149
      },
      {
        "epoch": 2403,
        "reward": 0.4554269313812256,
        "val_loss": 0.036645427176803684,
        "train_loss": 0.010828222888134266
      },
      {
        "epoch": 2404,
        "reward": 0.49752193689346313,
        "val_loss": 0.026142956707709736,
        "train_loss": 0.00091411958851495
      },
      {
        "epoch": 2405,
        "reward": 0.43254023790359497,
        "val_loss": 0.044112540660924945,
        "train_loss": 0.06960426737326159
      },
      {
        "epoch": 2406,
        "reward": 0.44291242957115173,
        "val_loss": 0.04054673360328057,
        "train_loss": 0.007860277557483641
      },
      {
        "epoch": 2407,
        "reward": 0.42449232935905457,
        "val_loss": 0.047109400583264814,
        "train_loss": 0.013556958523294655
      },
      {
        "epoch": 2408,
        "reward": 0.31808385252952576,
        "val_loss": 0.11779408931449455,
        "train_loss": 0.016295594353568258
      },
      {
        "epoch": 2409,
        "reward": 0.2527187466621399,
        "val_loss": 0.22409811250067183,
        "train_loss": 0.0021256322270346573
      },
      {
        "epoch": 2410,
        "reward": 0.4082247316837311,
        "val_loss": 0.053859196171937844,
        "train_loss": 0.0018935215271610034
      },
      {
        "epoch": 2411,
        "reward": 0.5149104595184326,
        "val_loss": 0.02274705674478485,
        "train_loss": 0.023433314932404175
      },
      {
        "epoch": 2412,
        "reward": 0.34083983302116394,
        "val_loss": 0.09585750925595805,
        "train_loss": 0.012717461243972559
      },
      {
        "epoch": 2413,
        "reward": 0.46476316452026367,
        "val_loss": 0.03399174651297342,
        "train_loss": 0.014001430100664108
      },
      {
        "epoch": 2414,
        "reward": 0.443634957075119,
        "val_loss": 0.04031001343433412,
        "train_loss": 0.03326344473573674
      },
      {
        "epoch": 2415,
        "reward": 0.500909686088562,
        "val_loss": 0.02544394114426853,
        "train_loss": 87.37718078822253
      },
      {
        "epoch": 2416,
        "reward": 0.5018724799156189,
        "val_loss": 0.025248708025173983,
        "train_loss": 0.018530666184609856
      },
      {
        "epoch": 2417,
        "reward": 0.35479873418807983,
        "val_loss": 0.08475616044389815,
        "train_loss": 0.021604757758583358
      },
      {
        "epoch": 2418,
        "reward": 0.5045661330223083,
        "val_loss": 0.024710413948923815,
        "train_loss": 0.008363542669170644
      },
      {
        "epoch": 2419,
        "reward": 0.5031962990760803,
        "val_loss": 0.024982717445319786,
        "train_loss": 0.11964536101084797
      },
      {
        "epoch": 2420,
        "reward": 0.5099641680717468,
        "val_loss": 0.02366580583267413,
        "train_loss": 0.0012090225907111464
      },
      {
        "epoch": 2421,
        "reward": 0.47980767488479614,
        "val_loss": 0.03012579293447613,
        "train_loss": 0.0050173950410401
      },
      {
        "epoch": 2422,
        "reward": 0.4992956817150116,
        "val_loss": 0.025774597070786904,
        "train_loss": 0.0019714147616608758
      },
      {
        "epoch": 2423,
        "reward": 0.5313789248466492,
        "val_loss": 0.01993332926316985,
        "train_loss": 0.0031870414444571137
      },
      {
        "epoch": 2424,
        "reward": 0.46571069955825806,
        "val_loss": 0.03373381360558726,
        "train_loss": 0.0020778757972834683
      },
      {
        "epoch": 2425,
        "reward": 0.48296019434928894,
        "val_loss": 0.029374480964699096,
        "train_loss": 0.010205060549021884
      },
      {
        "epoch": 2426,
        "reward": 0.515557050704956,
        "val_loss": 0.022629595619426773,
        "train_loss": 0.005397826027267281
      },
      {
        "epoch": 2427,
        "reward": 0.46625494956970215,
        "val_loss": 0.03358656782594543,
        "train_loss": 0.0012231763810199516
      },
      {
        "epoch": 2428,
        "reward": 0.3387129008769989,
        "val_loss": 0.09769258469584331,
        "train_loss": 2.5930169902043625
      },
      {
        "epoch": 2429,
        "reward": 0.5388618111610413,
        "val_loss": 0.01876948135967333,
        "train_loss": 0.0021413315115611253
      },
      {
        "epoch": 2430,
        "reward": 0.5115122199058533,
        "val_loss": 0.0233743926011292,
        "train_loss": 0.0012846482772969326
      },
      {
        "epoch": 2431,
        "reward": 0.5045552253723145,
        "val_loss": 0.024712576407182496,
        "train_loss": 0.06284562912896245
      },
      {
        "epoch": 2432,
        "reward": 0.404606431722641,
        "val_loss": 0.055499314897003514,
        "train_loss": 0.09809427178764124
      },
      {
        "epoch": 2433,
        "reward": 0.5637078881263733,
        "val_loss": 0.01535293422265178,
        "train_loss": 0.051749445484312255
      },
      {
        "epoch": 2434,
        "reward": 0.46082282066345215,
        "val_loss": 0.035086490349515644,
        "train_loss": 0.01213547672617866
      },
      {
        "epoch": 2435,
        "reward": 0.3894136846065521,
        "val_loss": 0.06301102553074348,
        "train_loss": 0.004921411248206963
      },
      {
        "epoch": 2436,
        "reward": 0.4299955368041992,
        "val_loss": 0.045037401962742606,
        "train_loss": 0.01043071567211047
      },
      {
        "epoch": 2437,
        "reward": 0.4918350279331207,
        "val_loss": 0.027359953135601245,
        "train_loss": 0.004538340908294021
      },
      {
        "epoch": 2438,
        "reward": 0.42571550607681274,
        "val_loss": 0.04664017464009313,
        "train_loss": 0.004636812391348362
      },
      {
        "epoch": 2439,
        "reward": 0.4384101331233978,
        "val_loss": 0.04205543299134921,
        "train_loss": 0.006307035147389028
      },
      {
        "epoch": 2440,
        "reward": 0.5598358511924744,
        "val_loss": 0.01584356408316775,
        "train_loss": 0.05042066622898416
      },
      {
        "epoch": 2441,
        "reward": 0.5127597451210022,
        "val_loss": 0.023142141087841343,
        "train_loss": 0.01407009139018975
      },
      {
        "epoch": 2442,
        "reward": 0.4784907400608063,
        "val_loss": 0.030445408400347724,
        "train_loss": 0.12259402824888464
      },
      {
        "epoch": 2443,
        "reward": 0.5441829562187195,
        "val_loss": 0.017981916240907076,
        "train_loss": 0.009051937246699008
      },
      {
        "epoch": 2444,
        "reward": 0.4300665557384491,
        "val_loss": 0.045011332622899705,
        "train_loss": 0.061556376189138555
      },
      {
        "epoch": 2445,
        "reward": 0.4775545597076416,
        "val_loss": 0.030674731518956833,
        "train_loss": 0.002718282989322828
      },
      {
        "epoch": 2446,
        "reward": 0.33594274520874023,
        "val_loss": 0.10014409890157237,
        "train_loss": 0.17607959283094926
      },
      {
        "epoch": 2447,
        "reward": 0.44667521119117737,
        "val_loss": 0.03932977583982782,
        "train_loss": 0.006310911275914595
      },
      {
        "epoch": 2448,
        "reward": 0.5531108975410461,
        "val_loss": 0.016730931142124712,
        "train_loss": 0.04921521596053516
      },
      {
        "epoch": 2449,
        "reward": 0.4359905421733856,
        "val_loss": 0.04289075324777514,
        "train_loss": 0.010718467653628768
      },
      {
        "epoch": 2450,
        "reward": 0.4565828740596771,
        "val_loss": 0.03630547204478977,
        "train_loss": 0.017193623703161184
      },
      {
        "epoch": 2451,
        "reward": 0.4530457556247711,
        "val_loss": 0.03735619671039915,
        "train_loss": 0.49116955191226014
      },
      {
        "epoch": 2452,
        "reward": 0.39682018756866455,
        "val_loss": 0.059217611288269315,
        "train_loss": 0.0049487885307651315
      },
      {
        "epoch": 2453,
        "reward": 0.5304795503616333,
        "val_loss": 0.02007783059473565,
        "train_loss": 0.0024453059200263503
      },
      {
        "epoch": 2454,
        "reward": 0.5784056186676025,
        "val_loss": 0.01361662076565803,
        "train_loss": 0.006568073275241422
      },
      {
        "epoch": 2455,
        "reward": 0.4029719829559326,
        "val_loss": 0.05625804678649209,
        "train_loss": 0.44888085026538577
      },
      {
        "epoch": 2456,
        "reward": 0.45704004168510437,
        "val_loss": 0.03617195806197872,
        "train_loss": 0.0007405371602194813
      },
      {
        "epoch": 2457,
        "reward": 0.4953167140483856,
        "val_loss": 0.026608281382193257,
        "train_loss": 0.004927964804437579
      },
      {
        "epoch": 2458,
        "reward": 0.4798617362976074,
        "val_loss": 0.030112733781736876,
        "train_loss": 0.03003417900546223
      },
      {
        "epoch": 2459,
        "reward": 0.4580744206905365,
        "val_loss": 0.035871708439247287,
        "train_loss": 0.012717675915303936
      },
      {
        "epoch": 2460,
        "reward": 0.3180945813655853,
        "val_loss": 0.11778246393078007,
        "train_loss": 0.010550311056957841
      },
      {
        "epoch": 2461,
        "reward": 0.40204840898513794,
        "val_loss": 0.05669181227858644,
        "train_loss": 0.4645495222519877
      },
      {
        "epoch": 2462,
        "reward": 0.5137878060340881,
        "val_loss": 0.022952450678401095,
        "train_loss": 0.008260681808272134
      },
      {
        "epoch": 2463,
        "reward": 0.5073841214179993,
        "val_loss": 0.024159501223558828,
        "train_loss": 0.042020853746145385
      },
      {
        "epoch": 2464,
        "reward": 0.5160860419273376,
        "val_loss": 0.022533941402278806,
        "train_loss": 0.0014735731529684087
      },
      {
        "epoch": 2465,
        "reward": 0.5274131894111633,
        "val_loss": 0.020578144776663976,
        "train_loss": 5.699746613638144
      },
      {
        "epoch": 2466,
        "reward": 0.47910651564598083,
        "val_loss": 0.030295534819223185,
        "train_loss": 0.21862828323055686
      },
      {
        "epoch": 2467,
        "reward": 0.5135500431060791,
        "val_loss": 0.022996180586882735,
        "train_loss": 0.002231290258801157
      },
      {
        "epoch": 2468,
        "reward": 0.45857954025268555,
        "val_loss": 0.03572604147796353,
        "train_loss": 0.0015401403683899144
      },
      {
        "epoch": 2469,
        "reward": 0.5829070806503296,
        "val_loss": 0.013122362752775578,
        "train_loss": 0.008921816813890123
      },
      {
        "epoch": 2470,
        "reward": 0.44725868105888367,
        "val_loss": 0.03914454711567877,
        "train_loss": 0.007391394971613443
      },
      {
        "epoch": 2471,
        "reward": 0.46740293502807617,
        "val_loss": 0.033278177320815824,
        "train_loss": 0.0010362784038919087
      },
      {
        "epoch": 2472,
        "reward": 0.5348386168479919,
        "val_loss": 0.0193868252068309,
        "train_loss": 0.029837481712277736
      },
      {
        "epoch": 2473,
        "reward": 0.41903647780418396,
        "val_loss": 0.0492650386648685,
        "train_loss": 0.003779829919199511
      },
      {
        "epoch": 2474,
        "reward": 0.4436708390712738,
        "val_loss": 0.04029829878709279,
        "train_loss": 0.18824363888154522
      },
      {
        "epoch": 2475,
        "reward": 0.3456477224826813,
        "val_loss": 0.09185457756393589,
        "train_loss": 0.004988159576511792
      },
      {
        "epoch": 2476,
        "reward": 0.3634741008281708,
        "val_loss": 0.07860137467754871,
        "train_loss": 0.04258819181744072
      },
      {
        "epoch": 2477,
        "reward": 0.517137885093689,
        "val_loss": 0.022344904751662398,
        "train_loss": 0.020697812600806522
      },
      {
        "epoch": 2478,
        "reward": 0.37342774868011475,
        "val_loss": 0.07215626515556194,
        "train_loss": 0.08382723731581511
      },
      {
        "epoch": 2479,
        "reward": 0.4812697470188141,
        "val_loss": 0.029774937016814614,
        "train_loss": 0.09578608480997602
      },
      {
        "epoch": 2480,
        "reward": 0.5683543086051941,
        "val_loss": 0.014782956012952906,
        "train_loss": 0.18411096266622123
      },
      {
        "epoch": 2481,
        "reward": 0.44814997911453247,
        "val_loss": 0.03886334941749477,
        "train_loss": 0.005245058439326245
      },
      {
        "epoch": 2482,
        "reward": 0.43754082918167114,
        "val_loss": 0.042353539774921956,
        "train_loss": 0.031035690199841016
      },
      {
        "epoch": 2483,
        "reward": 0.48874911665916443,
        "val_loss": 0.028044066654859177,
        "train_loss": 0.41658885520522604
      },
      {
        "epoch": 2484,
        "reward": 0.4665272831916809,
        "val_loss": 0.033513156281385036,
        "train_loss": 0.02568890999098655
      },
      {
        "epoch": 2485,
        "reward": 0.5631248950958252,
        "val_loss": 0.015425887521165091,
        "train_loss": 0.022877775891931133
      },
      {
        "epoch": 2486,
        "reward": 0.4572046399116516,
        "val_loss": 0.036124007165199146,
        "train_loss": 0.00084063369578976
      },
      {
        "epoch": 2487,
        "reward": 0.4251612722873688,
        "val_loss": 0.04685214571405335,
        "train_loss": 0.014178520034315275
      },
      {
        "epoch": 2488,
        "reward": 0.5562528967857361,
        "val_loss": 0.01631065885729705,
        "train_loss": 0.009907853529739441
      },
      {
        "epoch": 2489,
        "reward": 0.4508257508277893,
        "val_loss": 0.038031883242573325,
        "train_loss": 0.012396378488557066
      },
      {
        "epoch": 2490,
        "reward": 0.5019562840461731,
        "val_loss": 0.025231786645495698,
        "train_loss": 0.032250974693218165
      },
      {
        "epoch": 2491,
        "reward": 0.47432246804237366,
        "val_loss": 0.03148011957091512,
        "train_loss": 0.000751859030340431
      },
      {
        "epoch": 2492,
        "reward": 0.45366668701171875,
        "val_loss": 0.037169485557699646,
        "train_loss": 0.0011453519347154584
      },
      {
        "epoch": 2493,
        "reward": 0.3633945882320404,
        "val_loss": 0.07865542476169399,
        "train_loss": 0.14484747669135126
      },
      {
        "epoch": 2494,
        "reward": 0.5500672459602356,
        "val_loss": 0.017147803708732163,
        "train_loss": 0.001654142186313178
      },
      {
        "epoch": 2495,
        "reward": 0.5027502179145813,
        "val_loss": 0.025072042450899192,
        "train_loss": 0.04658940993165463
      },
      {
        "epoch": 2496,
        "reward": 0.5211266875267029,
        "val_loss": 0.02164210473347339,
        "train_loss": 0.005002611740481965
      },
      {
        "epoch": 2497,
        "reward": 0.4971074163913727,
        "val_loss": 0.026229794460440253,
        "train_loss": 0.001301961271635194
      },
      {
        "epoch": 2498,
        "reward": 0.540848433971405,
        "val_loss": 0.018471663114074284,
        "train_loss": 0.02665467937528704
      },
      {
        "epoch": 2499,
        "reward": 0.3832029700279236,
        "val_loss": 0.06640054244988798,
        "train_loss": 0.004291636564420724
      },
      {
        "epoch": 2500,
        "reward": 0.4062538743019104,
        "val_loss": 0.054745872349095795,
        "train_loss": 1.1744131448544561
      },
      {
        "epoch": 2501,
        "reward": 0.5523568987846375,
        "val_loss": 0.016833294543695438,
        "train_loss": 0.009933194905740423
      },
      {
        "epoch": 2502,
        "reward": 0.30689576268196106,
        "val_loss": 0.13072546798503026,
        "train_loss": 0.0012682674636153024
      },
      {
        "epoch": 2503,
        "reward": 0.5663723349571228,
        "val_loss": 0.015023626088805031,
        "train_loss": 0.002549132248217435
      },
      {
        "epoch": 2504,
        "reward": 0.33284178376197815,
        "val_loss": 0.10297383630365532,
        "train_loss": 0.0007315319393840652
      },
      {
        "epoch": 2505,
        "reward": 0.5162040591239929,
        "val_loss": 0.022512639611834726,
        "train_loss": 0.06791196702909894
      },
      {
        "epoch": 2506,
        "reward": 0.5643372535705566,
        "val_loss": 0.015274544514146069,
        "train_loss": 0.021695077421274897
      },
      {
        "epoch": 2507,
        "reward": 0.5012584924697876,
        "val_loss": 0.025373039408545343,
        "train_loss": 0.5073014924254005
      },
      {
        "epoch": 2508,
        "reward": 0.43300557136535645,
        "val_loss": 0.043945602193291834,
        "train_loss": 0.002310131943904008
      },
      {
        "epoch": 2509,
        "reward": 0.4478886127471924,
        "val_loss": 0.038945587126363534,
        "train_loss": 0.06487762751137674
      },
      {
        "epoch": 2510,
        "reward": 0.5517055988311768,
        "val_loss": 0.01692219178949017,
        "train_loss": 0.03956574329509539
      },
      {
        "epoch": 2511,
        "reward": 0.4762151837348938,
        "val_loss": 0.031005895309915234,
        "train_loss": 0.013444501886034197
      },
      {
        "epoch": 2512,
        "reward": 0.561215341091156,
        "val_loss": 0.01566710761471768,
        "train_loss": 0.028287283536236336
      },
      {
        "epoch": 2513,
        "reward": 0.4354495108127594,
        "val_loss": 0.04307991783883024,
        "train_loss": 0.0018843278508865724
      },
      {
        "epoch": 2514,
        "reward": 0.5517222285270691,
        "val_loss": 0.0169199236089688,
        "train_loss": 0.09931145394062486
      },
      {
        "epoch": 2515,
        "reward": 0.3722907602787018,
        "val_loss": 0.0728613875024686,
        "train_loss": 0.003299176991163222
      },
      {
        "epoch": 2516,
        "reward": 0.5655640363693237,
        "val_loss": 0.01512282431472808,
        "train_loss": 0.0059458070225691
      },
      {
        "epoch": 2517,
        "reward": 0.5015262961387634,
        "val_loss": 0.025318732076682084,
        "train_loss": 0.0008405417696403325
      },
      {
        "epoch": 2518,
        "reward": 0.4356651306152344,
        "val_loss": 0.043004421357181855,
        "train_loss": 0.009748329533524523
      },
      {
        "epoch": 2519,
        "reward": 0.4752023220062256,
        "val_loss": 0.031258731800854936,
        "train_loss": 0.003987786301684957
      },
      {
        "epoch": 2520,
        "reward": 0.4906143248081207,
        "val_loss": 0.02762853797841152,
        "train_loss": 0.0012150851682603248
      },
      {
        "epoch": 2521,
        "reward": 0.45188745856285095,
        "val_loss": 0.03770716243161587,
        "train_loss": 0.0033697585991818027
      },
      {
        "epoch": 2522,
        "reward": 0.4505002200603485,
        "val_loss": 0.03813203324690611,
        "train_loss": 0.0014232743243295632
      },
      {
        "epoch": 2523,
        "reward": 0.5058221220970154,
        "val_loss": 0.024463349013136133,
        "train_loss": 0.0008517349875402347
      },
      {
        "epoch": 2524,
        "reward": 0.47721749544143677,
        "val_loss": 0.030757729618926533,
        "train_loss": 14.542115464938984
      },
      {
        "epoch": 2525,
        "reward": 0.5138170719146729,
        "val_loss": 0.02294706150860293,
        "train_loss": 0.0005680228825741989
      },
      {
        "epoch": 2526,
        "reward": 0.5094863772392273,
        "val_loss": 0.023756466148500164,
        "train_loss": 0.0014930629579251987
      },
      {
        "epoch": 2527,
        "reward": 0.555926501750946,
        "val_loss": 0.01635384056187052,
        "train_loss": 0.005018776192033469
      },
      {
        "epoch": 2528,
        "reward": 0.4413924813270569,
        "val_loss": 0.04104956944398249,
        "train_loss": 0.023549035274990835
      },
      {
        "epoch": 2529,
        "reward": 0.46678605675697327,
        "val_loss": 0.033443529626570774,
        "train_loss": 0.03991043005712177
      },
      {
        "epoch": 2530,
        "reward": 0.53009432554245,
        "val_loss": 0.020140033283366523,
        "train_loss": 0.008563085372595826
      },
      {
        "epoch": 2531,
        "reward": 0.3513885736465454,
        "val_loss": 0.08732504261674226,
        "train_loss": 0.0011781777534889233
      },
      {
        "epoch": 2532,
        "reward": 0.4648556709289551,
        "val_loss": 0.03396647320602954,
        "train_loss": 0.006805175699268007
      },
      {
        "epoch": 2533,
        "reward": 0.47070765495300293,
        "val_loss": 0.03240660970498409,
        "train_loss": 0.003481390039597115
      },
      {
        "epoch": 2534,
        "reward": 0.48001834750175476,
        "val_loss": 0.03007497742925937,
        "train_loss": 0.0008910434073291421
      },
      {
        "epoch": 2535,
        "reward": 0.42474159598350525,
        "val_loss": 0.04701334515474238,
        "train_loss": 0.00481409053180379
      },
      {
        "epoch": 2536,
        "reward": 0.5361806750297546,
        "val_loss": 0.019178748760688386,
        "train_loss": 0.008646940275158298
      },
      {
        "epoch": 2537,
        "reward": 0.48728832602500916,
        "val_loss": 0.028373910368827637,
        "train_loss": 0.0017359172644109304
      },
      {
        "epoch": 2538,
        "reward": 0.4796251952648163,
        "val_loss": 0.03016986715686341,
        "train_loss": 0.02159621585998978
      },
      {
        "epoch": 2539,
        "reward": 0.5581461191177368,
        "val_loss": 0.016062247141235275,
        "train_loss": 1.1296795499973749
      },
      {
        "epoch": 2540,
        "reward": 0.5813657641410828,
        "val_loss": 0.013289706469679783,
        "train_loss": 0.003872621669905549
      },
      {
        "epoch": 2541,
        "reward": 0.4739460051059723,
        "val_loss": 0.031575324158828674,
        "train_loss": 0.0013202351295011393
      },
      {
        "epoch": 2542,
        "reward": 0.49248358607292175,
        "val_loss": 0.02721833206721515,
        "train_loss": 0.1351549521740568
      },
      {
        "epoch": 2543,
        "reward": 0.5627079010009766,
        "val_loss": 0.015478259403607808,
        "train_loss": 0.05446429104682256
      },
      {
        "epoch": 2544,
        "reward": 0.45097872614860535,
        "val_loss": 0.037984914389588606,
        "train_loss": 0.0005392655052324139
      },
      {
        "epoch": 2545,
        "reward": 0.5110062956809998,
        "val_loss": 0.023469237461540615,
        "train_loss": 0.005665628970123093
      },
      {
        "epoch": 2546,
        "reward": 0.3094883859157562,
        "val_loss": 0.12758457998695252,
        "train_loss": 0.5385718974822851
      },
      {
        "epoch": 2547,
        "reward": 0.5064255595207214,
        "val_loss": 0.024345506960214282,
        "train_loss": 0.02221680271342253
      },
      {
        "epoch": 2548,
        "reward": 0.5294185876846313,
        "val_loss": 0.020249587001412044,
        "train_loss": 0.0007505474780705649
      },
      {
        "epoch": 2549,
        "reward": 0.37884923815727234,
        "val_loss": 0.06889790374719139,
        "train_loss": 0.0030377289370755113
      },
      {
        "epoch": 2550,
        "reward": 0.4012509286403656,
        "val_loss": 0.05706928388826782,
        "train_loss": 53.16865168281293
      },
      {
        "epoch": 2551,
        "reward": 0.5280805230140686,
        "val_loss": 0.02046823560626113,
        "train_loss": 0.14767088983340343
      },
      {
        "epoch": 2552,
        "reward": 0.5656915903091431,
        "val_loss": 0.015107129329408053,
        "train_loss": 0.004961416866841808
      },
      {
        "epoch": 2553,
        "reward": 0.4893777072429657,
        "val_loss": 0.027903323178179562,
        "train_loss": 0.0014177380002050855
      },
      {
        "epoch": 2554,
        "reward": 0.4242572486400604,
        "val_loss": 0.04720015414568479,
        "train_loss": 0.009269669108793831
      },
      {
        "epoch": 2555,
        "reward": 0.5675092339515686,
        "val_loss": 0.014885130589391338,
        "train_loss": 0.003946499923133528
      },
      {
        "epoch": 2556,
        "reward": 0.5203340649604797,
        "val_loss": 0.021780018481617196,
        "train_loss": 0.0011868584457488396
      },
      {
        "epoch": 2557,
        "reward": 0.5324268937110901,
        "val_loss": 0.01976623690123753,
        "train_loss": 0.0024285560968145057
      },
      {
        "epoch": 2558,
        "reward": 0.48446574807167053,
        "val_loss": 0.029022434709206988,
        "train_loss": 0.13119801600052702
      },
      {
        "epoch": 2559,
        "reward": 0.4513613283634186,
        "val_loss": 0.037867707649378905,
        "train_loss": 0.008534528683779942
      },
      {
        "epoch": 2560,
        "reward": 0.4256421625614166,
        "val_loss": 0.046668152121128514,
        "train_loss": 0.006064752014026453
      },
      {
        "epoch": 2561,
        "reward": 0.5567930936813354,
        "val_loss": 0.016239418080658652,
        "train_loss": 24.237243467483147
      },
      {
        "epoch": 2562,
        "reward": 0.5384826064109802,
        "val_loss": 0.01882685045295927,
        "train_loss": 0.0016875265203271266
      },
      {
        "epoch": 2563,
        "reward": 0.30606770515441895,
        "val_loss": 0.13174801964903185,
        "train_loss": 0.0026019151555374265
      },
      {
        "epoch": 2564,
        "reward": 0.37991130352020264,
        "val_loss": 0.06827913880364836,
        "train_loss": 0.005479172915399361
      },
      {
        "epoch": 2565,
        "reward": 0.26499468088150024,
        "val_loss": 0.19717489161329077,
        "train_loss": 0.004292199266615171
      },
      {
        "epoch": 2566,
        "reward": 0.3441224992275238,
        "val_loss": 0.09310309499518812,
        "train_loss": 0.038782401141571214
      },
      {
        "epoch": 2567,
        "reward": 0.5896924734115601,
        "val_loss": 0.012408313367944044,
        "train_loss": 0.0012703782053554628
      },
      {
        "epoch": 2568,
        "reward": 0.49527135491371155,
        "val_loss": 0.026617939427004394,
        "train_loss": 0.36778565954184284
      },
      {
        "epoch": 2569,
        "reward": 0.40230464935302734,
        "val_loss": 0.05657108437922683,
        "train_loss": 0.015289436706264216
      },
      {
        "epoch": 2570,
        "reward": 0.309931218624115,
        "val_loss": 0.12705712662344532,
        "train_loss": 0.1716929618066908
      },
      {
        "epoch": 2571,
        "reward": 0.5668234825134277,
        "val_loss": 0.014968524136098236,
        "train_loss": 0.004852766707744449
      },
      {
        "epoch": 2572,
        "reward": 0.5369955897331238,
        "val_loss": 0.019053450553266366,
        "train_loss": 0.010013786914398155
      },
      {
        "epoch": 2573,
        "reward": 0.5606434345245361,
        "val_loss": 0.015740028612656585,
        "train_loss": 0.0074273389712927315
      },
      {
        "epoch": 2574,
        "reward": 0.48439303040504456,
        "val_loss": 0.02903934435224593,
        "train_loss": 0.8421684590151087
      },
      {
        "epoch": 2575,
        "reward": 0.5857666730880737,
        "val_loss": 0.012816981839153283,
        "train_loss": 0.0031530376092778925
      },
      {
        "epoch": 2576,
        "reward": 0.566028892993927,
        "val_loss": 0.015065699409335918,
        "train_loss": 0.01375526586625798
      },
      {
        "epoch": 2577,
        "reward": 0.41590410470962524,
        "val_loss": 0.05055064528590135,
        "train_loss": 0.006251994344805867
      },
      {
        "epoch": 2578,
        "reward": 0.5361529588699341,
        "val_loss": 0.019183023315625696,
        "train_loss": 0.006022998900185974
      },
      {
        "epoch": 2579,
        "reward": 0.396369993686676,
        "val_loss": 0.05944085534013409,
        "train_loss": 0.0016908871758326645
      },
      {
        "epoch": 2580,
        "reward": 0.5025774836540222,
        "val_loss": 0.025106717590720758,
        "train_loss": 0.00955611796958832
      },
      {
        "epoch": 2581,
        "reward": 0.38030293583869934,
        "val_loss": 0.06805253982020076,
        "train_loss": 21.998790706488727
      },
      {
        "epoch": 2582,
        "reward": 0.4736768305301666,
        "val_loss": 0.03164357834404135,
        "train_loss": 0.004193984669742489
      },
      {
        "epoch": 2583,
        "reward": 0.3580590784549713,
        "val_loss": 0.08238071927189594,
        "train_loss": 0.003967624330698527
      },
      {
        "epoch": 2584,
        "reward": 0.45789939165115356,
        "val_loss": 0.03592232656956185,
        "train_loss": 0.002002700859884171
      },
      {
        "epoch": 2585,
        "reward": 0.41284528374671936,
        "val_loss": 0.05184123305454185,
        "train_loss": 0.015722594037694416
      },
      {
        "epoch": 2586,
        "reward": 0.49504849314689636,
        "val_loss": 0.026665440459120355,
        "train_loss": 0.010713184335550898
      },
      {
        "epoch": 2587,
        "reward": 0.3691016435623169,
        "val_loss": 0.07488101147672362,
        "train_loss": 0.0021151170283071853
      },
      {
        "epoch": 2588,
        "reward": 0.42563873529434204,
        "val_loss": 0.04666948412549183,
        "train_loss": 0.06052494115346445
      },
      {
        "epoch": 2589,
        "reward": 0.556042492389679,
        "val_loss": 0.016338482079195922,
        "train_loss": 0.005724522621632717
      },
      {
        "epoch": 2590,
        "reward": 0.36567455530166626,
        "val_loss": 0.07712224913016794,
        "train_loss": 2.6487281476778173
      },
      {
        "epoch": 2591,
        "reward": 0.4734223484992981,
        "val_loss": 0.031708246907718216,
        "train_loss": 0.000773644812870071
      },
      {
        "epoch": 2592,
        "reward": 0.4542595446109772,
        "val_loss": 0.03699209560311699,
        "train_loss": 0.013077431439586899
      },
      {
        "epoch": 2593,
        "reward": 0.4650069773197174,
        "val_loss": 0.0339251854217894,
        "train_loss": 90.77314445351043
      },
      {
        "epoch": 2594,
        "reward": 0.5314297676086426,
        "val_loss": 0.01992519666237058,
        "train_loss": 0.0019839896283920886
      },
      {
        "epoch": 2595,
        "reward": 0.5673937797546387,
        "val_loss": 0.014899142479407601,
        "train_loss": 0.43178861307473465
      },
      {
        "epoch": 2596,
        "reward": 0.3880126178264618,
        "val_loss": 0.06375848282706491,
        "train_loss": 0.34281215058693376
      },
      {
        "epoch": 2597,
        "reward": 0.48237061500549316,
        "val_loss": 0.02951351868978236,
        "train_loss": 0.004698168625282051
      },
      {
        "epoch": 2598,
        "reward": 0.5570554137229919,
        "val_loss": 0.016204924902662503,
        "train_loss": 0.34341984434819584
      },
      {
        "epoch": 2599,
        "reward": 0.47818323969841003,
        "val_loss": 0.030520541982176446,
        "train_loss": 0.022675830585783912
      },
      {
        "epoch": 2600,
        "reward": 0.49575087428092957,
        "val_loss": 0.02651600451489295,
        "train_loss": 0.0040694770065757575
      },
      {
        "epoch": 2601,
        "reward": 0.5002937316894531,
        "val_loss": 0.02556961513879027,
        "train_loss": 0.002838065477834999
      },
      {
        "epoch": 2602,
        "reward": 0.313361257314682,
        "val_loss": 0.1230583212621111,
        "train_loss": 0.008346021691767628
      },
      {
        "epoch": 2603,
        "reward": 0.5182597041130066,
        "val_loss": 0.022145023801775614,
        "train_loss": 116.28330154175147
      },
      {
        "epoch": 2604,
        "reward": 0.4965619742870331,
        "val_loss": 0.026344504034828527,
        "train_loss": 0.0034556323714521288
      },
      {
        "epoch": 2605,
        "reward": 0.4250130355358124,
        "val_loss": 0.04690903214629673,
        "train_loss": 0.043574677747983515
      },
      {
        "epoch": 2606,
        "reward": 0.5845115184783936,
        "val_loss": 0.012950207259044484,
        "train_loss": 0.004897131151070566
      },
      {
        "epoch": 2607,
        "reward": 0.5551058053970337,
        "val_loss": 0.01646292031520196,
        "train_loss": 0.04387135309773909
      },
      {
        "epoch": 2608,
        "reward": 0.5158030986785889,
        "val_loss": 0.022585050456525226,
        "train_loss": 0.00477013491166098
      },
      {
        "epoch": 2609,
        "reward": 0.4875025749206543,
        "val_loss": 0.02832529606998183,
        "train_loss": 0.0008056303026058651
      },
      {
        "epoch": 2610,
        "reward": 0.5159141421318054,
        "val_loss": 0.022564967051688915,
        "train_loss": 0.0008333921612470127
      },
      {
        "epoch": 2611,
        "reward": 0.45220547914505005,
        "val_loss": 0.0376104561712834,
        "train_loss": 0.003323756565342032
      },
      {
        "epoch": 2612,
        "reward": 0.433089017868042,
        "val_loss": 0.043915746308422446,
        "train_loss": 0.01702328876329445
      },
      {
        "epoch": 2613,
        "reward": 0.5784475207328796,
        "val_loss": 0.013611948708005781,
        "train_loss": 0.0025094702854263373
      },
      {
        "epoch": 2614,
        "reward": 0.4142496585845947,
        "val_loss": 0.051244323079507534,
        "train_loss": 0.0028010985084497755
      },
      {
        "epoch": 2615,
        "reward": 0.4947309195995331,
        "val_loss": 0.02673328233140637,
        "train_loss": 0.001276186699914643
      },
      {
        "epoch": 2616,
        "reward": 0.43282538652420044,
        "val_loss": 0.0440101600626284,
        "train_loss": 0.004193091041333201
      },
      {
        "epoch": 2617,
        "reward": 0.4554627537727356,
        "val_loss": 0.03663484341294471,
        "train_loss": 0.004536631464553955
      },
      {
        "epoch": 2618,
        "reward": 0.4075777530670166,
        "val_loss": 0.0541485386441179,
        "train_loss": 0.37043929413748344
      },
      {
        "epoch": 2619,
        "reward": 0.5029820203781128,
        "val_loss": 0.025025579846572197,
        "train_loss": 4.447073043633063
      },
      {
        "epoch": 2620,
        "reward": 0.52115398645401,
        "val_loss": 0.021637368709239775,
        "train_loss": 8.788363267730189
      },
      {
        "epoch": 2621,
        "reward": 0.3413793742656708,
        "val_loss": 0.09539837697749524,
        "train_loss": 0.0012743528823018725
      },
      {
        "epoch": 2622,
        "reward": 0.5276567339897156,
        "val_loss": 0.020537961932339904,
        "train_loss": 13.265103187164364
      },
      {
        "epoch": 2623,
        "reward": 0.5796157717704773,
        "val_loss": 0.013482092473298377,
        "train_loss": 0.052809916290003076
      },
      {
        "epoch": 2624,
        "reward": 0.4251374304294586,
        "val_loss": 0.04686127603885585,
        "train_loss": 0.0025218214553800722
      },
      {
        "epoch": 2625,
        "reward": 0.5974027514457703,
        "val_loss": 0.011639977919652924,
        "train_loss": 0.002883615056606896
      },
      {
        "epoch": 2626,
        "reward": 0.4782055914402008,
        "val_loss": 0.030515077509335242,
        "train_loss": 0.0187738850509749
      },
      {
        "epoch": 2627,
        "reward": 0.4177384376525879,
        "val_loss": 0.04979344248671883,
        "train_loss": 0.004131273120318468
      },
      {
        "epoch": 2628,
        "reward": 0.46579477190971375,
        "val_loss": 0.0337110276679076,
        "train_loss": 0.2154313339804748
      },
      {
        "epoch": 2629,
        "reward": 0.34840893745422363,
        "val_loss": 0.0896430210518052,
        "train_loss": 0.011645068722924198
      },
      {
        "epoch": 2630,
        "reward": 0.5198439955711365,
        "val_loss": 0.021865700177191423,
        "train_loss": 0.020805397694429163
      },
      {
        "epoch": 2631,
        "reward": 0.5591315031051636,
        "val_loss": 0.015934383068919748,
        "train_loss": 0.015429951273482892
      },
      {
        "epoch": 2632,
        "reward": 0.43279537558555603,
        "val_loss": 0.04402092574413733,
        "train_loss": 0.0032809136284343435
      },
      {
        "epoch": 2633,
        "reward": 0.530688464641571,
        "val_loss": 0.020044169877240035,
        "train_loss": 0.0010317707787215534
      },
      {
        "epoch": 2634,
        "reward": 0.5362499952316284,
        "val_loss": 0.019168060075441775,
        "train_loss": 0.02079683347694929
      },
      {
        "epoch": 2635,
        "reward": 0.5443851947784424,
        "val_loss": 0.01795261725367579,
        "train_loss": 0.0011815525647154328
      },
      {
        "epoch": 2636,
        "reward": 0.4764831066131592,
        "val_loss": 0.03093934824054096,
        "train_loss": 8.099732681460733
      },
      {
        "epoch": 2637,
        "reward": 0.5468177199363708,
        "val_loss": 0.017603761473895117,
        "train_loss": 0.007287865737951576
      },
      {
        "epoch": 2638,
        "reward": 0.4039377272129059,
        "val_loss": 0.05580836304112121,
        "train_loss": 0.027457830097144045
      },
      {
        "epoch": 2639,
        "reward": 0.46299275755882263,
        "val_loss": 0.03447916867766513,
        "train_loss": 0.004436896879435783
      },
      {
        "epoch": 2640,
        "reward": 0.43555861711502075,
        "val_loss": 0.043041690491788485,
        "train_loss": 0.004796500540718485
      },
      {
        "epoch": 2641,
        "reward": 0.5557990670204163,
        "val_loss": 0.016370732164172556,
        "train_loss": 0.027357576270263122
      },
      {
        "epoch": 2642,
        "reward": 0.49074721336364746,
        "val_loss": 0.027599167747082123,
        "train_loss": 0.003350617666438456
      },
      {
        "epoch": 2643,
        "reward": 0.4676709771156311,
        "val_loss": 0.033206595258109574,
        "train_loss": 0.009971583575739155
      },
      {
        "epoch": 2644,
        "reward": 0.5744458436965942,
        "val_loss": 0.014065539246075787,
        "train_loss": 0.31836322798267247
      },
      {
        "epoch": 2645,
        "reward": 0.484138160943985,
        "val_loss": 0.02909866689255328,
        "train_loss": 0.07493175560613544
      },
      {
        "epoch": 2646,
        "reward": 0.486391544342041,
        "val_loss": 0.028578354398112942,
        "train_loss": 0.00409781568548449
      },
      {
        "epoch": 2647,
        "reward": 0.4911268353462219,
        "val_loss": 0.027515453059874875,
        "train_loss": 0.011983622752626825
      },
      {
        "epoch": 2648,
        "reward": 0.396406888961792,
        "val_loss": 0.05942251249819362,
        "train_loss": 0.004804358549685835
      },
      {
        "epoch": 2649,
        "reward": 0.41642704606056213,
        "val_loss": 0.05033352234334286,
        "train_loss": 0.21883045883530136
      },
      {
        "epoch": 2650,
        "reward": 0.5334309935569763,
        "val_loss": 0.019607396136312412,
        "train_loss": 0.0010208668293129309
      },
      {
        "epoch": 2651,
        "reward": 0.4888971745967865,
        "val_loss": 0.028010850915701928,
        "train_loss": 0.0021260522350307664
      },
      {
        "epoch": 2652,
        "reward": 0.5164598226547241,
        "val_loss": 0.022466581718098105,
        "train_loss": 0.009353143256108663
      },
      {
        "epoch": 2653,
        "reward": 0.4664192199707031,
        "val_loss": 0.033542253332728124,
        "train_loss": 0.06453016289614985
      },
      {
        "epoch": 2654,
        "reward": 0.5658044815063477,
        "val_loss": 0.01509325000318183,
        "train_loss": 0.01607151852789894
      },
      {
        "epoch": 2655,
        "reward": 0.492183119058609,
        "val_loss": 0.027283860847611714,
        "train_loss": 0.005210703356056001
      },
      {
        "epoch": 2656,
        "reward": 0.514892041683197,
        "val_loss": 0.02275041661362463,
        "train_loss": 0.0033089308440489382
      },
      {
        "epoch": 2657,
        "reward": 0.55520099401474,
        "val_loss": 0.016450238044074337,
        "train_loss": 0.0010244695560966367
      },
      {
        "epoch": 2658,
        "reward": 0.4009823799133301,
        "val_loss": 0.057197003698092885,
        "train_loss": 0.051212993709056645
      },
      {
        "epoch": 2659,
        "reward": 0.4550305902957916,
        "val_loss": 0.03676274168174132,
        "train_loss": 0.004488120245442728
      },
      {
        "epoch": 2660,
        "reward": 0.5404247641563416,
        "val_loss": 0.018534794643658512,
        "train_loss": 0.01809498430949274
      },
      {
        "epoch": 2661,
        "reward": 0.47478896379470825,
        "val_loss": 0.031362549639327754,
        "train_loss": 0.1346976304801571
      },
      {
        "epoch": 2662,
        "reward": 0.5657246112823486,
        "val_loss": 0.015103063677608069,
        "train_loss": 0.0120993406838225
      },
      {
        "epoch": 2663,
        "reward": 0.4996584951877594,
        "val_loss": 0.02569990322340995,
        "train_loss": 0.05313194017475535
      },
      {
        "epoch": 2664,
        "reward": 0.47272229194641113,
        "val_loss": 0.03188684036493734,
        "train_loss": 0.0087499066865593
      },
      {
        "epoch": 2665,
        "reward": 0.5671898722648621,
        "val_loss": 0.014923917997553613,
        "train_loss": 55.2789810900237
      },
      {
        "epoch": 2666,
        "reward": 0.3244665563106537,
        "val_loss": 0.11109607236202075,
        "train_loss": 45.740946247014634
      },
      {
        "epoch": 2667,
        "reward": 0.4034576117992401,
        "val_loss": 0.05603141547492539,
        "train_loss": 0.4059456578944754
      },
      {
        "epoch": 2668,
        "reward": 0.3685912787914276,
        "val_loss": 0.07521004005684517,
        "train_loss": 0.2071368087328245
      },
      {
        "epoch": 2669,
        "reward": 0.5713288187980652,
        "val_loss": 0.014428494058977646,
        "train_loss": 0.0021408183863251486
      },
      {
        "epoch": 2670,
        "reward": 0.41036519408226013,
        "val_loss": 0.05291394088375715,
        "train_loss": 0.00480655349731653
      },
      {
        "epoch": 2671,
        "reward": 0.4394932687282562,
        "val_loss": 0.04168713166343098,
        "train_loss": 0.0009981926211690524
      },
      {
        "epoch": 2672,
        "reward": 0.44105538725852966,
        "val_loss": 0.04116196152504666,
        "train_loss": 0.012803905155744989
      },
      {
        "epoch": 2673,
        "reward": 0.4404604136943817,
        "val_loss": 0.041361168129826965,
        "train_loss": 0.05959851265946817
      },
      {
        "epoch": 2674,
        "reward": 0.4277678430080414,
        "val_loss": 0.04586412563678875,
        "train_loss": 0.0033003172050554827
      },
      {
        "epoch": 2675,
        "reward": 0.5417726039886475,
        "val_loss": 0.01833465914803258,
        "train_loss": 0.3793553124348381
      },
      {
        "epoch": 2676,
        "reward": 0.36145514249801636,
        "val_loss": 0.07998692431387358,
        "train_loss": 0.007500600842280829
      },
      {
        "epoch": 2677,
        "reward": 0.5363839268684387,
        "val_loss": 0.01914742063880632,
        "train_loss": 0.02573898000479438
      },
      {
        "epoch": 2678,
        "reward": 0.3013967275619507,
        "val_loss": 0.13769846343867748,
        "train_loss": 0.003228468108650654
      },
      {
        "epoch": 2679,
        "reward": 0.3664472699165344,
        "val_loss": 0.0766103354191208,
        "train_loss": 0.03179363769903777
      },
      {
        "epoch": 2680,
        "reward": 0.47967424988746643,
        "val_loss": 0.030158004347738045,
        "train_loss": 0.0031602629494500434
      },
      {
        "epoch": 2681,
        "reward": 0.4635538160800934,
        "val_loss": 0.034323919000079126,
        "train_loss": 0.003755773924658056
      },
      {
        "epoch": 2682,
        "reward": 0.4136500954627991,
        "val_loss": 0.05149822006205795,
        "train_loss": 0.06032387679829736
      },
      {
        "epoch": 2683,
        "reward": 0.5131978392601013,
        "val_loss": 0.023061109819017083,
        "train_loss": 0.00951400615984382
      },
      {
        "epoch": 2684,
        "reward": 0.5544368624687195,
        "val_loss": 0.016552329076408308,
        "train_loss": 0.0015025655085222612
      },
      {
        "epoch": 2685,
        "reward": 0.4691026210784912,
        "val_loss": 0.03282692744739636,
        "train_loss": 0.0748773723823713
      },
      {
        "epoch": 2686,
        "reward": 0.4864865243434906,
        "val_loss": 0.028556617764219742,
        "train_loss": 0.16345922138359234
      },
      {
        "epoch": 2687,
        "reward": 0.5535051226615906,
        "val_loss": 0.01667764429501923,
        "train_loss": 0.009561096360797067
      },
      {
        "epoch": 2688,
        "reward": 0.47806593775749207,
        "val_loss": 0.030549258742082332,
        "train_loss": 0.005599549867208855
      },
      {
        "epoch": 2689,
        "reward": 0.43714824318885803,
        "val_loss": 0.04248888905359698,
        "train_loss": 0.0021685937068958504
      },
      {
        "epoch": 2690,
        "reward": 0.5318841338157654,
        "val_loss": 0.019852608918881742,
        "train_loss": 0.001178215289480879
      },
      {
        "epoch": 2691,
        "reward": 0.5495216250419617,
        "val_loss": 0.017223576447057503,
        "train_loss": 0.0024153813579564833
      },
      {
        "epoch": 2692,
        "reward": 0.5535416007041931,
        "val_loss": 0.016672719326119738,
        "train_loss": 0.017870336259967153
      },
      {
        "epoch": 2693,
        "reward": 0.4570563733577728,
        "val_loss": 0.03616718967844333,
        "train_loss": 0.013263105188072517
      },
      {
        "epoch": 2694,
        "reward": 0.5943177938461304,
        "val_loss": 0.011942064306952358,
        "train_loss": 0.0021759912640259946
      },
      {
        "epoch": 2695,
        "reward": 0.5646786689758301,
        "val_loss": 0.015232177578582196,
        "train_loss": 0.8209190397187521
      },
      {
        "epoch": 2696,
        "reward": 0.5631983280181885,
        "val_loss": 0.015416680164240202,
        "train_loss": 0.0019690254480687706
      },
      {
        "epoch": 2697,
        "reward": 0.4694206416606903,
        "val_loss": 0.03274321186056893,
        "train_loss": 0.0028944933368961756
      },
      {
        "epoch": 2698,
        "reward": 0.5301982760429382,
        "val_loss": 0.02012320844836982,
        "train_loss": 0.014720354017386993
      },
      {
        "epoch": 2699,
        "reward": 0.44829830527305603,
        "val_loss": 0.03881676231633589,
        "train_loss": 0.003684415510301383
      },
      {
        "epoch": 2700,
        "reward": 0.5718799829483032,
        "val_loss": 0.0143636954593863,
        "train_loss": 0.009831571737178225
      },
      {
        "epoch": 2701,
        "reward": 0.5725197196006775,
        "val_loss": 0.014288813487447831,
        "train_loss": 0.0005992794717538066
      },
      {
        "epoch": 2702,
        "reward": 0.5413537621498108,
        "val_loss": 0.018396622859914454,
        "train_loss": 0.002589245880528779
      },
      {
        "epoch": 2703,
        "reward": 0.5180975794792175,
        "val_loss": 0.022173794466652907,
        "train_loss": 0.049473259077280604
      },
      {
        "epoch": 2704,
        "reward": 0.46635374426841736,
        "val_loss": 0.03355991599840179,
        "train_loss": 346.1072696033976
      },
      {
        "epoch": 2705,
        "reward": 0.6132024526596069,
        "val_loss": 0.010197756758446173,
        "train_loss": 0.0015517185665972788
      },
      {
        "epoch": 2706,
        "reward": 0.4707087576389313,
        "val_loss": 0.032406310270224434,
        "train_loss": 0.0010970522362185875
      },
      {
        "epoch": 2707,
        "reward": 0.5871497988700867,
        "val_loss": 0.012671618581537456,
        "train_loss": 0.005348790532710705
      },
      {
        "epoch": 2708,
        "reward": 0.5941407084465027,
        "val_loss": 0.011959620643860294,
        "train_loss": 0.010010576976354785
      },
      {
        "epoch": 2709,
        "reward": 0.32697340846061707,
        "val_loss": 0.10858866938672561,
        "train_loss": 0.005789077381590547
      },
      {
        "epoch": 2710,
        "reward": 0.4175775945186615,
        "val_loss": 0.04985935407083681,
        "train_loss": 0.0051076878533667
      },
      {
        "epoch": 2711,
        "reward": 0.4611984193325043,
        "val_loss": 0.03498057054405633,
        "train_loss": 0.12300823871849459
      },
      {
        "epoch": 2712,
        "reward": 0.41967183351516724,
        "val_loss": 0.04900862497119566,
        "train_loss": 0.003561885590583048
      },
      {
        "epoch": 2713,
        "reward": 0.4478914439678192,
        "val_loss": 0.03894469561678956,
        "train_loss": 0.008148413337179451
      },
      {
        "epoch": 2714,
        "reward": 0.4374386966228485,
        "val_loss": 0.0423887140246474,
        "train_loss": 0.11750194584182011
      },
      {
        "epoch": 2715,
        "reward": 0.5098146200180054,
        "val_loss": 0.0236941409893916,
        "train_loss": 0.006197382401497775
      },
      {
        "epoch": 2716,
        "reward": 0.3973153531551361,
        "val_loss": 0.05897317166090943,
        "train_loss": 0.004330440920529537
      },
      {
        "epoch": 2717,
        "reward": 0.48934251070022583,
        "val_loss": 0.027911183891514417,
        "train_loss": 0.0069756071333568585
      },
      {
        "epoch": 2718,
        "reward": 0.39480650424957275,
        "val_loss": 0.060223315595067106,
        "train_loss": 0.38609358023719903
      },
      {
        "epoch": 2719,
        "reward": 0.4302431046962738,
        "val_loss": 0.04494654088297726,
        "train_loss": 0.6462621415702625
      },
      {
        "epoch": 2720,
        "reward": 0.42344579100608826,
        "val_loss": 0.04751487417005202,
        "train_loss": 575.9861125213176
      },
      {
        "epoch": 2721,
        "reward": 0.5333341360092163,
        "val_loss": 0.019622674051788636,
        "train_loss": 0.16940484698464459
      },
      {
        "epoch": 2722,
        "reward": 0.4403517246246338,
        "val_loss": 0.04139764431056392,
        "train_loss": 0.004868595610297724
      },
      {
        "epoch": 2723,
        "reward": 0.5503863096237183,
        "val_loss": 0.017103647120425843,
        "train_loss": 0.003593784018851063
      },
      {
        "epoch": 2724,
        "reward": 0.40294647216796875,
        "val_loss": 0.056269978205299206,
        "train_loss": 0.013110434089869526
      },
      {
        "epoch": 2725,
        "reward": 0.6141058802604675,
        "val_loss": 0.010120333164585256,
        "train_loss": 0.0023582742215134764
      },
      {
        "epoch": 2726,
        "reward": 0.5340508818626404,
        "val_loss": 0.01950997283711331,
        "train_loss": 0.01746803606713981
      },
      {
        "epoch": 2727,
        "reward": 0.31221529841423035,
        "val_loss": 0.12437744397279207,
        "train_loss": 0.007379270538701978
      },
      {
        "epoch": 2728,
        "reward": 0.5514290928840637,
        "val_loss": 0.016960076064736183,
        "train_loss": 0.20756722940614752
      },
      {
        "epoch": 2729,
        "reward": 0.4447281062602997,
        "val_loss": 0.03995463100000052,
        "train_loss": 0.002300501148266785
      },
      {
        "epoch": 2730,
        "reward": 0.5451430678367615,
        "val_loss": 0.01784323878538479,
        "train_loss": 0.004477431413411418
      },
      {
        "epoch": 2731,
        "reward": 0.5138962268829346,
        "val_loss": 0.022932538204518745,
        "train_loss": 0.05445278441419969
      },
      {
        "epoch": 2732,
        "reward": 0.5391504168510437,
        "val_loss": 0.018725924954716384,
        "train_loss": 0.4618300516392209
      },
      {
        "epoch": 2733,
        "reward": 0.5953947901725769,
        "val_loss": 0.011835805505272998,
        "train_loss": 0.001431005399712586
      },
      {
        "epoch": 2734,
        "reward": 0.4555611312389374,
        "val_loss": 0.03660579969800892,
        "train_loss": 0.0020916999643969367
      },
      {
        "epoch": 2735,
        "reward": 0.5457004904747009,
        "val_loss": 0.01776318358159707,
        "train_loss": 0.0017676170092314053
      },
      {
        "epoch": 2736,
        "reward": 0.5349858999252319,
        "val_loss": 0.019363879640358,
        "train_loss": 0.0007373126695098947
      },
      {
        "epoch": 2737,
        "reward": 0.4803943634033203,
        "val_loss": 0.029984502576033783,
        "train_loss": 0.005198171002671888
      },
      {
        "epoch": 2738,
        "reward": 0.6055353283882141,
        "val_loss": 0.010876324407685647,
        "train_loss": 0.007104735759478094
      },
      {
        "epoch": 2739,
        "reward": 0.49755629897117615,
        "val_loss": 0.026135758624150185,
        "train_loss": 0.0200228006537901
      },
      {
        "epoch": 2740,
        "reward": 0.5900154709815979,
        "val_loss": 0.012375223613032307,
        "train_loss": 0.009715938860696181
      },
      {
        "epoch": 2741,
        "reward": 0.49239492416381836,
        "val_loss": 0.027237652347789014,
        "train_loss": 0.007817265891879708
      },
      {
        "epoch": 2742,
        "reward": 0.5643497705459595,
        "val_loss": 0.015272992377244268,
        "train_loss": 0.002853866159706688
      },
      {
        "epoch": 2743,
        "reward": 0.39830097556114197,
        "val_loss": 0.05848987469237597,
        "train_loss": 0.009037533291190742
      },
      {
        "epoch": 2744,
        "reward": 0.3771447539329529,
        "val_loss": 0.06990414089419314,
        "train_loss": 0.042903222876790235
      },
      {
        "epoch": 2745,
        "reward": 0.5225422382354736,
        "val_loss": 0.02139794514784756,
        "train_loss": 0.0018593755372648957
      },
      {
        "epoch": 2746,
        "reward": 0.4389088749885559,
        "val_loss": 0.04188544218231982,
        "train_loss": 0.004246646035618631
      },
      {
        "epoch": 2747,
        "reward": 0.519804060459137,
        "val_loss": 0.021872709613879642,
        "train_loss": 0.0009273127102285519
      },
      {
        "epoch": 2748,
        "reward": 0.5642924904823303,
        "val_loss": 0.015280112706282776,
        "train_loss": 0.003691106467053592
      },
      {
        "epoch": 2749,
        "reward": 0.5932456254959106,
        "val_loss": 0.012048700767731393,
        "train_loss": 0.007828314145806066
      },
      {
        "epoch": 2750,
        "reward": 0.465193510055542,
        "val_loss": 0.03387435213101396,
        "train_loss": 0.003217116479598522
      },
      {
        "epoch": 2751,
        "reward": 0.5483161807060242,
        "val_loss": 0.01739209099884777,
        "train_loss": 0.0006213862570649991
      },
      {
        "epoch": 2752,
        "reward": 0.5714187026023865,
        "val_loss": 0.014417912424375703,
        "train_loss": 0.0021594097033987335
      },
      {
        "epoch": 2753,
        "reward": 0.5070725679397583,
        "val_loss": 0.024219811099880775,
        "train_loss": 0.0007745028591924752
      },
      {
        "epoch": 2754,
        "reward": 0.5529119968414307,
        "val_loss": 0.016757875363379884,
        "train_loss": 0.0015126736915991484
      },
      {
        "epoch": 2755,
        "reward": 0.42616358399391174,
        "val_loss": 0.04646955197365189,
        "train_loss": 0.005987116758240938
      },
      {
        "epoch": 2756,
        "reward": 0.4795988202095032,
        "val_loss": 0.03017623754983236,
        "train_loss": 0.445293637076373
      },
      {
        "epoch": 2757,
        "reward": 0.53377765417099,
        "val_loss": 0.019552853892361912,
        "train_loss": 0.008173399030021336
      },
      {
        "epoch": 2758,
        "reward": 0.5689159631729126,
        "val_loss": 0.014715416062244913,
        "train_loss": 0.00029945235987637573
      },
      {
        "epoch": 2759,
        "reward": 0.5416212677955627,
        "val_loss": 0.01835703701259003,
        "train_loss": 1.0741042444871662
      },
      {
        "epoch": 2760,
        "reward": 0.5288482308387756,
        "val_loss": 0.020342505924678074,
        "train_loss": 0.0013579216565543762
      },
      {
        "epoch": 2761,
        "reward": 0.5717521905899048,
        "val_loss": 0.014378692986481059,
        "train_loss": 0.00047774213508561687
      },
      {
        "epoch": 2762,
        "reward": 0.4201643168926239,
        "val_loss": 0.04881086220224721,
        "train_loss": 0.2956372836915499
      },
      {
        "epoch": 2763,
        "reward": 0.6166990995407104,
        "val_loss": 0.00990097577128576,
        "train_loss": 0.009482189260919628
      },
      {
        "epoch": 2764,
        "reward": 0.4724048674106598,
        "val_loss": 0.03196816348853255,
        "train_loss": 0.053686427886910554
      },
      {
        "epoch": 2765,
        "reward": 0.6082887053489685,
        "val_loss": 0.010628151601330111,
        "train_loss": 0.019201701350314036
      },
      {
        "epoch": 2766,
        "reward": 0.480459064245224,
        "val_loss": 0.029968955937614998,
        "train_loss": 0.0008479216684935847
      },
      {
        "epoch": 2767,
        "reward": 0.5213962197303772,
        "val_loss": 0.02159540206516145,
        "train_loss": 0.36523802755199053
      },
      {
        "epoch": 2768,
        "reward": 0.47683030366897583,
        "val_loss": 0.030853365383726277,
        "train_loss": 0.007938941844066414
      },
      {
        "epoch": 2769,
        "reward": 0.479734867811203,
        "val_loss": 0.03014336008605564,
        "train_loss": 0.07380373073186337
      },
      {
        "epoch": 2770,
        "reward": 0.5894713401794434,
        "val_loss": 0.012431010372113502,
        "train_loss": 0.008605650490450829
      },
      {
        "epoch": 2771,
        "reward": 0.497669517993927,
        "val_loss": 0.02611210376926465,
        "train_loss": 0.0006338898670649612
      },
      {
        "epoch": 2772,
        "reward": 0.5726373791694641,
        "val_loss": 0.014275082461348834,
        "train_loss": 0.03139673255396284
      },
      {
        "epoch": 2773,
        "reward": 0.5319790244102478,
        "val_loss": 0.019837472060836654,
        "train_loss": 0.009722559738852747
      },
      {
        "epoch": 2774,
        "reward": 0.38455986976623535,
        "val_loss": 0.06564302642280902,
        "train_loss": 0.0034298879918424063
      },
      {
        "epoch": 2775,
        "reward": 0.444195955991745,
        "val_loss": 0.04012722791490627,
        "train_loss": 0.0023997850445749255
      },
      {
        "epoch": 2776,
        "reward": 0.4557874798774719,
        "val_loss": 0.03653905034298077,
        "train_loss": 0.0014227793818340966
      },
      {
        "epoch": 2777,
        "reward": 0.6083694100379944,
        "val_loss": 0.010620952373886081,
        "train_loss": 0.004004108074905861
      },
      {
        "epoch": 2778,
        "reward": 0.43949589133262634,
        "val_loss": 0.0416862338939349,
        "train_loss": 0.025472629211963003
      },
      {
        "epoch": 2779,
        "reward": 0.5054764151573181,
        "val_loss": 0.02453110309735556,
        "train_loss": 0.017858293765649205
      },
      {
        "epoch": 2780,
        "reward": 0.5610761046409607,
        "val_loss": 0.01568482998482068,
        "train_loss": 0.09966344110748301
      },
      {
        "epoch": 2781,
        "reward": 0.4435889422893524,
        "val_loss": 0.04032506059385404,
        "train_loss": 0.017043969135416913
      },
      {
        "epoch": 2782,
        "reward": 0.5751903057098389,
        "val_loss": 0.013980107411043718,
        "train_loss": 0.003593776340883673
      },
      {
        "epoch": 2783,
        "reward": 0.4643442630767822,
        "val_loss": 0.034106428422091994,
        "train_loss": 0.004200634834566367
      },
      {
        "epoch": 2784,
        "reward": 0.5477493405342102,
        "val_loss": 0.017471877964063815,
        "train_loss": 0.09190938845853716
      },
      {
        "epoch": 2785,
        "reward": 0.3942319452762604,
        "val_loss": 0.0605137388806075,
        "train_loss": 0.001996171555875802
      },
      {
        "epoch": 2786,
        "reward": 0.5519610047340393,
        "val_loss": 0.016887278451447076,
        "train_loss": 13.693407310858191
      },
      {
        "epoch": 2787,
        "reward": 0.5374045372009277,
        "val_loss": 0.01899087589845294,
        "train_loss": 0.0007891736146348194
      },
      {
        "epoch": 2788,
        "reward": 0.49223288893699646,
        "val_loss": 0.027272988924128834,
        "train_loss": 0.009733483822751273
      },
      {
        "epoch": 2789,
        "reward": 0.4171466529369354,
        "val_loss": 0.05003639215491213,
        "train_loss": 0.009475615441042114
      },
      {
        "epoch": 2790,
        "reward": 0.5506250858306885,
        "val_loss": 0.017070673384296242,
        "train_loss": 0.00035154415791811724
      },
      {
        "epoch": 2791,
        "reward": 0.42353111505508423,
        "val_loss": 0.04748167634534184,
        "train_loss": 0.0010061717184026537
      },
      {
        "epoch": 2792,
        "reward": 0.4994795024394989,
        "val_loss": 0.02573672562097532,
        "train_loss": 0.008702116030113198
      },
      {
        "epoch": 2793,
        "reward": 0.3984985649585724,
        "val_loss": 0.05839352366872065,
        "train_loss": 0.0006903588998039385
      },
      {
        "epoch": 2794,
        "reward": 0.371749609708786,
        "val_loss": 0.0731997025057873,
        "train_loss": 0.0023674826095276993
      },
      {
        "epoch": 2795,
        "reward": 0.5167792439460754,
        "val_loss": 0.022409174265443914,
        "train_loss": 0.0023391115584252896
      },
      {
        "epoch": 2796,
        "reward": 0.3182991147041321,
        "val_loss": 0.11756061608113148,
        "train_loss": 0.001160881152215482
      },
      {
        "epoch": 2797,
        "reward": 0.5639860033988953,
        "val_loss": 0.01531824272855634,
        "train_loss": 0.03472466347971284
      },
      {
        "epoch": 2798,
        "reward": 0.5124492049217224,
        "val_loss": 0.0231997330618989,
        "train_loss": 0.3095138481390205
      },
      {
        "epoch": 2799,
        "reward": 0.46035638451576233,
        "val_loss": 0.03521847592492122,
        "train_loss": 0.6705047162538897
      },
      {
        "epoch": 2800,
        "reward": 0.5409048795700073,
        "val_loss": 0.018463263940897638,
        "train_loss": 0.0022630050373864973
      },
      {
        "epoch": 2801,
        "reward": 0.5734542012214661,
        "val_loss": 0.014180086516716983,
        "train_loss": 0.021702999002583895
      },
      {
        "epoch": 2802,
        "reward": 0.3854347765445709,
        "val_loss": 0.0651597041360219,
        "train_loss": 0.011869452420726772
      },
      {
        "epoch": 2803,
        "reward": 0.5656103491783142,
        "val_loss": 0.015117120155212303,
        "train_loss": 0.0026377793646365543
      },
      {
        "epoch": 2804,
        "reward": 0.47704458236694336,
        "val_loss": 0.030800394850042982,
        "train_loss": 0.002580103789442708
      },
      {
        "epoch": 2805,
        "reward": 0.5442363619804382,
        "val_loss": 0.017974178967831125,
        "train_loss": 0.04980400887542986
      },
      {
        "epoch": 2806,
        "reward": 0.46247774362564087,
        "val_loss": 0.034622315929612214,
        "train_loss": 0.002082951017406196
      },
      {
        "epoch": 2807,
        "reward": 0.45735761523246765,
        "val_loss": 0.03607950052017778,
        "train_loss": 0.7009993899143515
      },
      {
        "epoch": 2808,
        "reward": 0.6034603118896484,
        "val_loss": 0.011066770329177546,
        "train_loss": 0.006369788285706608
      },
      {
        "epoch": 2809,
        "reward": 0.5436832308769226,
        "val_loss": 0.018054521215422677,
        "train_loss": 0.012183461857192084
      },
      {
        "epoch": 2810,
        "reward": 0.37883123755455017,
        "val_loss": 0.0689084513349891,
        "train_loss": 0.00696150940141776
      },
      {
        "epoch": 2811,
        "reward": 0.4109835624694824,
        "val_loss": 0.052644231076036316,
        "train_loss": 0.04571799115716912
      },
      {
        "epoch": 2812,
        "reward": 0.600441575050354,
        "val_loss": 0.011349166323530622,
        "train_loss": 0.007230342167470274
      },
      {
        "epoch": 2813,
        "reward": 0.4710506498813629,
        "val_loss": 0.03231750613589871,
        "train_loss": 0.0017718532115902864
      },
      {
        "epoch": 2814,
        "reward": 0.5805891156196594,
        "val_loss": 0.01337478127191259,
        "train_loss": 0.00029929945017451805
      },
      {
        "epoch": 2815,
        "reward": 0.4448466897010803,
        "val_loss": 0.03991627659083211,
        "train_loss": 0.014910093323045168
      },
      {
        "epoch": 2816,
        "reward": 0.5749837756156921,
        "val_loss": 0.014003756355772825,
        "train_loss": 0.021428063000380113
      },
      {
        "epoch": 2817,
        "reward": 0.4860566556453705,
        "val_loss": 0.028655071025631123,
        "train_loss": 0.003516978808350429
      },
      {
        "epoch": 2818,
        "reward": 0.5534929633140564,
        "val_loss": 0.016679285470412912,
        "train_loss": 0.007163705172504164
      },
      {
        "epoch": 2819,
        "reward": 0.49207398295402527,
        "val_loss": 0.02730769666231936,
        "train_loss": 0.08136822281518946
      },
      {
        "epoch": 2820,
        "reward": 0.42385149002075195,
        "val_loss": 0.047357223751272874,
        "train_loss": 0.029949349306766983
      },
      {
        "epoch": 2821,
        "reward": 0.5425999760627747,
        "val_loss": 0.018212836934773286,
        "train_loss": 0.0015915031167511328
      },
      {
        "epoch": 2822,
        "reward": 0.5714735388755798,
        "val_loss": 0.01441146341624387,
        "train_loss": 0.030582569086025576
      },
      {
        "epoch": 2823,
        "reward": 0.5721973776817322,
        "val_loss": 0.014326493561644124,
        "train_loss": 0.003347614076950287
      },
      {
        "epoch": 2824,
        "reward": 0.5747076869010925,
        "val_loss": 0.01403543666830436,
        "train_loss": 0.00054442635840902
      },
      {
        "epoch": 2825,
        "reward": 0.4972391128540039,
        "val_loss": 0.026202160476324416,
        "train_loss": 0.005628925940142766
      },
      {
        "epoch": 2826,
        "reward": 0.5564091801643372,
        "val_loss": 0.01629001525829413,
        "train_loss": 0.0023739419422187124
      },
      {
        "epoch": 2827,
        "reward": 0.5729765295982361,
        "val_loss": 0.014235569637094159,
        "train_loss": 0.0020870543051107514
      },
      {
        "epoch": 2828,
        "reward": 0.30058860778808594,
        "val_loss": 0.13876027837977745,
        "train_loss": 4.8545239821883985
      },
      {
        "epoch": 2829,
        "reward": 0.4106532633304596,
        "val_loss": 0.052788110716002326,
        "train_loss": 0.007703226669578866
      },
      {
        "epoch": 2830,
        "reward": 0.3785174489021301,
        "val_loss": 0.06909250949268296,
        "train_loss": 0.1367685458004906
      },
      {
        "epoch": 2831,
        "reward": 0.3678949177265167,
        "val_loss": 0.0756616512194991,
        "train_loss": 0.0007682727230229165
      },
      {
        "epoch": 2832,
        "reward": 0.4122411906719208,
        "val_loss": 0.05210033577532158,
        "train_loss": 0.0036727880762608303
      },
      {
        "epoch": 2833,
        "reward": 0.5294140577316284,
        "val_loss": 0.020250319200256075,
        "train_loss": 0.014405967229447033
      },
      {
        "epoch": 2834,
        "reward": 0.5693580508232117,
        "val_loss": 0.014662453185467581,
        "train_loss": 0.04946173656185456
      },
      {
        "epoch": 2835,
        "reward": 0.5160250067710876,
        "val_loss": 0.02254495437123946,
        "train_loss": 0.0012681377014674721
      },
      {
        "epoch": 2836,
        "reward": 0.5090558528900146,
        "val_loss": 0.02383845989866781,
        "train_loss": 0.0008094126596937748
      },
      {
        "epoch": 2837,
        "reward": 0.48261508345603943,
        "val_loss": 0.029455784905232058,
        "train_loss": 0.003567859604817596
      },
      {
        "epoch": 2838,
        "reward": 0.44062572717666626,
        "val_loss": 0.04130572026250385,
        "train_loss": 162.79518503077438
      },
      {
        "epoch": 2839,
        "reward": 0.4953182339668274,
        "val_loss": 0.02660794996232393,
        "train_loss": 0.0018741411444212785
      },
      {
        "epoch": 2840,
        "reward": 0.40821853280067444,
        "val_loss": 0.053861966836848296,
        "train_loss": 0.0024039073850544287
      },
      {
        "epoch": 2841,
        "reward": 0.5290510058403015,
        "val_loss": 0.02030942691219804,
        "train_loss": 0.04171819215661379
      },
      {
        "epoch": 2842,
        "reward": 0.48585349321365356,
        "val_loss": 0.0287017162086808,
        "train_loss": 0.007723621186659539
      },
      {
        "epoch": 2843,
        "reward": 0.6181958913803101,
        "val_loss": 0.009776286327905837,
        "train_loss": 0.0025238548527703676
      },
      {
        "epoch": 2844,
        "reward": 0.4584260582923889,
        "val_loss": 0.03577022935028903,
        "train_loss": 0.037825629775205434
      },
      {
        "epoch": 2845,
        "reward": 0.32995641231536865,
        "val_loss": 0.10569095952087082,
        "train_loss": 0.013310380126558111
      },
      {
        "epoch": 2846,
        "reward": 0.585279643535614,
        "val_loss": 0.012868527976284636,
        "train_loss": 0.021324405150581836
      },
      {
        "epoch": 2847,
        "reward": 0.4286586344242096,
        "val_loss": 0.04553162430290415,
        "train_loss": 0.027980290318037778
      },
      {
        "epoch": 2848,
        "reward": 0.5761477947235107,
        "val_loss": 0.013870944693085871,
        "train_loss": 0.005985560158723484
      },
      {
        "epoch": 2849,
        "reward": 0.5357148051261902,
        "val_loss": 0.019250740067426313,
        "train_loss": 0.0041635637345332445
      },
      {
        "epoch": 2850,
        "reward": 0.5775520205497742,
        "val_loss": 0.013712260550424358,
        "train_loss": 0.0007915391638911947
      },
      {
        "epoch": 2851,
        "reward": 0.6163738965988159,
        "val_loss": 0.009928249257167667,
        "train_loss": 0.0011856012376938452
      },
      {
        "epoch": 2852,
        "reward": 0.4443809688091278,
        "val_loss": 0.04006713610579027,
        "train_loss": 0.003942910137101745
      },
      {
        "epoch": 2853,
        "reward": 0.6128308773040771,
        "val_loss": 0.010229755021490356,
        "train_loss": 0.00766718997433075
      },
      {
        "epoch": 2854,
        "reward": 0.4637737274169922,
        "val_loss": 0.03426325851666791,
        "train_loss": 0.0014120489096897542
      },
      {
        "epoch": 2855,
        "reward": 0.431250661611557,
        "val_loss": 0.04457868169837249,
        "train_loss": 0.010118931584971645
      },
      {
        "epoch": 2856,
        "reward": 0.5460658669471741,
        "val_loss": 0.017710894922077256,
        "train_loss": 0.10383493996893706
      },
      {
        "epoch": 2857,
        "reward": 0.3736550211906433,
        "val_loss": 0.07201624476874713,
        "train_loss": 0.0006850650786243653
      },
      {
        "epoch": 2858,
        "reward": 0.5213584303855896,
        "val_loss": 0.021601943533564087,
        "train_loss": 0.04036981088618701
      },
      {
        "epoch": 2859,
        "reward": 0.6073799729347229,
        "val_loss": 0.0107094955341641,
        "train_loss": 0.027617670288166734
      },
      {
        "epoch": 2860,
        "reward": 0.5766593813896179,
        "val_loss": 0.013812940394668008,
        "train_loss": 0.0015889849234047059
      },
      {
        "epoch": 2861,
        "reward": 0.5556475520133972,
        "val_loss": 0.01639084139969782,
        "train_loss": 0.0036927722998099785
      },
      {
        "epoch": 2862,
        "reward": 0.47102317214012146,
        "val_loss": 0.03232463072553011,
        "train_loss": 0.020581850619972916
      },
      {
        "epoch": 2863,
        "reward": 0.3970072865486145,
        "val_loss": 0.05912511776841711,
        "train_loss": 0.004331538367610987
      },
      {
        "epoch": 2864,
        "reward": 0.5966197848320007,
        "val_loss": 0.011715980505219445,
        "train_loss": 0.003018145252379047
      },
      {
        "epoch": 2865,
        "reward": 0.39677056670188904,
        "val_loss": 0.059242186336112876,
        "train_loss": 0.04903106093946427
      },
      {
        "epoch": 2866,
        "reward": 0.5922042727470398,
        "val_loss": 0.01215310058354849,
        "train_loss": 0.0012759724807726623
      },
      {
        "epoch": 2867,
        "reward": 0.4006091058254242,
        "val_loss": 0.057375100129450275,
        "train_loss": 0.013109327056974087
      },
      {
        "epoch": 2868,
        "reward": 0.5572426319122314,
        "val_loss": 0.01618034466914001,
        "train_loss": 0.0206160753981177
      },
      {
        "epoch": 2869,
        "reward": 0.4406430721282959,
        "val_loss": 0.041299897012192686,
        "train_loss": 0.002448219757158545
      },
      {
        "epoch": 2870,
        "reward": 0.5144584774971008,
        "val_loss": 0.02282953186970969,
        "train_loss": 0.13811905067076133
      },
      {
        "epoch": 2871,
        "reward": 0.47934532165527344,
        "val_loss": 0.03023760436917655,
        "train_loss": 0.001151856307790065
      },
      {
        "epoch": 2872,
        "reward": 0.5305719971656799,
        "val_loss": 0.020062924072200467,
        "train_loss": 0.11492357895915663
      },
      {
        "epoch": 2873,
        "reward": 0.4692845046520233,
        "val_loss": 0.032779022202053705,
        "train_loss": 0.0008627689048810685
      },
      {
        "epoch": 2874,
        "reward": 0.5965980887413025,
        "val_loss": 0.011718096150226691,
        "train_loss": 0.8123624738256822
      },
      {
        "epoch": 2875,
        "reward": 0.433625191450119,
        "val_loss": 0.043724395217265864,
        "train_loss": 0.020499160071862067
      },
      {
        "epoch": 2876,
        "reward": 0.5264946222305298,
        "val_loss": 0.020730363535611623,
        "train_loss": 0.007414597320859046
      },
      {
        "epoch": 2877,
        "reward": 0.5214516520500183,
        "val_loss": 0.02158580966663846,
        "train_loss": 0.0005680223127036208
      },
      {
        "epoch": 2878,
        "reward": 0.6089494824409485,
        "val_loss": 0.010569346195552498,
        "train_loss": 0.004239379585398568
      },
      {
        "epoch": 2879,
        "reward": 0.5597472190856934,
        "val_loss": 0.015854959440600527,
        "train_loss": 0.0015761423200484177
      },
      {
        "epoch": 2880,
        "reward": 0.5739376544952393,
        "val_loss": 0.014124130449740082,
        "train_loss": 0.0006067844720274269
      },
      {
        "epoch": 2881,
        "reward": 0.5624221563339233,
        "val_loss": 0.01551424213487605,
        "train_loss": 0.0005842278000307907
      },
      {
        "epoch": 2882,
        "reward": 0.4546385407447815,
        "val_loss": 0.03687917803212518,
        "train_loss": 0.7503859466093723
      },
      {
        "epoch": 2883,
        "reward": 0.5950292944908142,
        "val_loss": 0.011871767798376303,
        "train_loss": 0.017952058350448833
      },
      {
        "epoch": 2884,
        "reward": 0.48840567469596863,
        "val_loss": 0.028121272099919485,
        "train_loss": 0.0026522898927772496
      },
      {
        "epoch": 2885,
        "reward": 0.45275989174842834,
        "val_loss": 0.03744250600617046,
        "train_loss": 0.002774573192648579
      },
      {
        "epoch": 2886,
        "reward": 0.5089647173881531,
        "val_loss": 0.023855849139051446,
        "train_loss": 3.0972227703238238
      },
      {
        "epoch": 2887,
        "reward": 0.5000469088554382,
        "val_loss": 0.02562016000384964,
        "train_loss": 0.00027426149220078657
      },
      {
        "epoch": 2888,
        "reward": 0.3882370889186859,
        "val_loss": 0.06363806578052131,
        "train_loss": 0.08206968106924825
      },
      {
        "epoch": 2889,
        "reward": 0.30697208642959595,
        "val_loss": 0.13063171580974345,
        "train_loss": 0.0020914332697849693
      },
      {
        "epoch": 2890,
        "reward": 0.438233345746994,
        "val_loss": 0.042115889938681254,
        "train_loss": 0.007919367193135959
      },
      {
        "epoch": 2891,
        "reward": 0.5982376933097839,
        "val_loss": 0.011559414790099254,
        "train_loss": 0.002451531481920728
      },
      {
        "epoch": 2892,
        "reward": 0.5702052712440491,
        "val_loss": 0.014561450677449881,
        "train_loss": 0.06796555079892222
      },
      {
        "epoch": 2893,
        "reward": 0.4472113251686096,
        "val_loss": 0.039159541117052346,
        "train_loss": 0.37820994713380157
      },
      {
        "epoch": 2894,
        "reward": 0.5569623708724976,
        "val_loss": 0.016217152453464223,
        "train_loss": 0.002632089411515783
      },
      {
        "epoch": 2895,
        "reward": 0.38753411173820496,
        "val_loss": 0.0640160430567838,
        "train_loss": 0.002371573714657853
      },
      {
        "epoch": 2896,
        "reward": 0.5724087357521057,
        "val_loss": 0.014301780367532047,
        "train_loss": 0.002355201610589356
      },
      {
        "epoch": 2897,
        "reward": 0.5230550169944763,
        "val_loss": 0.021310164289648777,
        "train_loss": 0.038553922030517315
      },
      {
        "epoch": 2898,
        "reward": 0.5047455430030823,
        "val_loss": 0.024674979962583166,
        "train_loss": 0.0008260103558523741
      },
      {
        "epoch": 2899,
        "reward": 0.477309912443161,
        "val_loss": 0.030734950826237246,
        "train_loss": 0.0919387297159718
      },
      {
        "epoch": 2900,
        "reward": 0.4169006943702698,
        "val_loss": 0.05013773201998057,
        "train_loss": 0.004602487771520076
      },
      {
        "epoch": 2901,
        "reward": 0.3082311749458313,
        "val_loss": 0.1290962878764341,
        "train_loss": 0.0021464632417204344
      },
      {
        "epoch": 2902,
        "reward": 0.4935493469238281,
        "val_loss": 0.02698721161868889,
        "train_loss": 1.1224640311859735
      },
      {
        "epoch": 2903,
        "reward": 0.3314104974269867,
        "val_loss": 0.10431133380812493,
        "train_loss": 0.01731071921794908
      },
      {
        "epoch": 2904,
        "reward": 0.4222831428050995,
        "val_loss": 0.04796974208303644,
        "train_loss": 0.00687278559952303
      },
      {
        "epoch": 2905,
        "reward": 0.4199984669685364,
        "val_loss": 0.04887736994403115,
        "train_loss": 0.027431323837276977
      },
      {
        "epoch": 2906,
        "reward": 0.5257970690727234,
        "val_loss": 0.020846683319437682,
        "train_loss": 0.0011826985579371186
      },
      {
        "epoch": 2907,
        "reward": 0.5426655411720276,
        "val_loss": 0.01820321907507605,
        "train_loss": 0.01744814358406844
      },
      {
        "epoch": 2908,
        "reward": 0.4502262771129608,
        "val_loss": 0.03821652552661752,
        "train_loss": 0.0075374995181636435
      },
      {
        "epoch": 2909,
        "reward": 0.5896589756011963,
        "val_loss": 0.012411745941270575,
        "train_loss": 0.0019943960683952776
      },
      {
        "epoch": 2910,
        "reward": 0.5240169167518616,
        "val_loss": 0.021146446074583634,
        "train_loss": 0.6329077979076444
      },
      {
        "epoch": 2911,
        "reward": 0.4919692575931549,
        "val_loss": 0.027330586546408346,
        "train_loss": 0.0013774472065418964
      },
      {
        "epoch": 2912,
        "reward": 0.5599950551986694,
        "val_loss": 0.01582310708649207,
        "train_loss": 0.020985590735825517
      },
      {
        "epoch": 2913,
        "reward": 0.5099894404411316,
        "val_loss": 0.023661016894038767,
        "train_loss": 0.23170708637425064
      },
      {
        "epoch": 2914,
        "reward": 0.5852882862091064,
        "val_loss": 0.012867602617916418,
        "train_loss": 0.0014925361644509887
      },
      {
        "epoch": 2915,
        "reward": 0.4936436116695404,
        "val_loss": 0.026966858355860625,
        "train_loss": 0.003225079904609629
      },
      {
        "epoch": 2916,
        "reward": 0.4672468304634094,
        "val_loss": 0.03331995389869137,
        "train_loss": 0.00922516828066259
      },
      {
        "epoch": 2917,
        "reward": 0.6215460300445557,
        "val_loss": 0.009502207343237907,
        "train_loss": 0.002773664682256192
      },
      {
        "epoch": 2918,
        "reward": 0.49433979392051697,
        "val_loss": 0.026817070291144773,
        "train_loss": 0.6925417315916758
      },
      {
        "epoch": 2919,
        "reward": 0.6005302667617798,
        "val_loss": 0.011340778014398114,
        "train_loss": 0.003234359674094706
      },
      {
        "epoch": 2920,
        "reward": 0.4912145137786865,
        "val_loss": 0.027496151555429345,
        "train_loss": 0.8582998813758029
      },
      {
        "epoch": 2921,
        "reward": 0.36281725764274597,
        "val_loss": 0.07904912801002086,
        "train_loss": 0.007697777103024132
      },
      {
        "epoch": 2922,
        "reward": 0.540641725063324,
        "val_loss": 0.018502430649927452,
        "train_loss": 0.03026385186484941
      },
      {
        "epoch": 2923,
        "reward": 0.602074384689331,
        "val_loss": 0.011195627051555286,
        "train_loss": 0.002541067970888924
      },
      {
        "epoch": 2924,
        "reward": 0.5304189920425415,
        "val_loss": 0.020087587971439853,
        "train_loss": 0.0013588770650847857
      },
      {
        "epoch": 2925,
        "reward": 0.4259413182735443,
        "val_loss": 0.04655409440186174,
        "train_loss": 0.027815204347811793
      },
      {
        "epoch": 2926,
        "reward": 0.49398669600486755,
        "val_loss": 0.026892930435548936,
        "train_loss": 0.0024555270259656826
      },
      {
        "epoch": 2927,
        "reward": 0.4989181160926819,
        "val_loss": 0.025852570819552056,
        "train_loss": 0.0285027023242212
      },
      {
        "epoch": 2928,
        "reward": 0.4415616989135742,
        "val_loss": 0.04099325940062824,
        "train_loss": 0.10288186803574298
      },
      {
        "epoch": 2929,
        "reward": 0.5980933904647827,
        "val_loss": 0.011573297477817894,
        "train_loss": 0.0010116064354952835
      },
      {
        "epoch": 2930,
        "reward": 0.5020245909690857,
        "val_loss": 0.025217999647533622,
        "train_loss": 0.016911832738042695
      },
      {
        "epoch": 2931,
        "reward": 0.47080180048942566,
        "val_loss": 0.032382128410972655,
        "train_loss": 0.0016129850211322823
      },
      {
        "epoch": 2932,
        "reward": 0.5860071182250977,
        "val_loss": 0.012791597405989055,
        "train_loss": 0.01385587261450802
      },
      {
        "epoch": 2933,
        "reward": 0.5031063556671143,
        "val_loss": 0.025000693112815497,
        "train_loss": 0.0021651414993077477
      },
      {
        "epoch": 2934,
        "reward": 0.5474068522453308,
        "val_loss": 0.01752024764417521,
        "train_loss": 0.0018624359112427906
      },
      {
        "epoch": 2935,
        "reward": 0.5714174509048462,
        "val_loss": 0.014418065498050834,
        "train_loss": 0.007257731818480824
      },
      {
        "epoch": 2936,
        "reward": 0.5741162896156311,
        "val_loss": 0.01410351130367157,
        "train_loss": 0.0019448298791535134
      },
      {
        "epoch": 2937,
        "reward": 0.5119226574897766,
        "val_loss": 0.023297721675979637,
        "train_loss": 0.0007846302712747589
      },
      {
        "epoch": 2938,
        "reward": 0.5017396807670593,
        "val_loss": 0.025275557614544857,
        "train_loss": 0.0007216364935390429
      },
      {
        "epoch": 2939,
        "reward": 0.2977296710014343,
        "val_loss": 0.14259667300835385,
        "train_loss": 0.0027869038458972614
      },
      {
        "epoch": 2940,
        "reward": 0.6014819145202637,
        "val_loss": 0.011251122247943255,
        "train_loss": 0.0021481639405115296
      },
      {
        "epoch": 2941,
        "reward": 0.5164456367492676,
        "val_loss": 0.02246912650194385,
        "train_loss": 0.012933203704715898
      },
      {
        "epoch": 2942,
        "reward": 0.5192736983299255,
        "val_loss": 0.0219658501072055,
        "train_loss": 0.0009307665448507516
      },
      {
        "epoch": 2943,
        "reward": 0.5668870806694031,
        "val_loss": 0.014960776679280181,
        "train_loss": 0.004520474237604224
      },
      {
        "epoch": 2944,
        "reward": 0.36745238304138184,
        "val_loss": 0.07595024022365189,
        "train_loss": 0.0026079102191523327
      },
      {
        "epoch": 2945,
        "reward": 0.5421905517578125,
        "val_loss": 0.018273028256122155,
        "train_loss": 0.0029432683453216248
      },
      {
        "epoch": 2946,
        "reward": 0.5740935206413269,
        "val_loss": 0.014106144304345694,
        "train_loss": 0.02322846624192957
      },
      {
        "epoch": 2947,
        "reward": 0.3051069676876068,
        "val_loss": 0.1329463677372717,
        "train_loss": 0.006443306577691688
      },
      {
        "epoch": 2948,
        "reward": 0.4461912214756012,
        "val_loss": 0.039484125878776206,
        "train_loss": 0.015033470740001156
      },
      {
        "epoch": 2949,
        "reward": 0.4455323815345764,
        "val_loss": 0.039695275800893014,
        "train_loss": 0.019922727490744856
      },
      {
        "epoch": 2950,
        "reward": 0.5218134522438049,
        "val_loss": 0.021523302271296934,
        "train_loss": 0.0012191880338587697
      },
      {
        "epoch": 2951,
        "reward": 0.5216131806373596,
        "val_loss": 0.021557886546880973,
        "train_loss": 0.0006728893349645659
      },
      {
        "epoch": 2952,
        "reward": 0.516481339931488,
        "val_loss": 0.02246271839300919,
        "train_loss": 0.011464107227853813
      },
      {
        "epoch": 2953,
        "reward": 0.4084770679473877,
        "val_loss": 0.05374680179686818,
        "train_loss": 0.00859333141110815
      },
      {
        "epoch": 2954,
        "reward": 0.6068955063819885,
        "val_loss": 0.010753085784277314,
        "train_loss": 0.00887806799363926
      },
      {
        "epoch": 2955,
        "reward": 0.5461810231208801,
        "val_loss": 0.01769444414042352,
        "train_loss": 0.03234972556920358
      },
      {
        "epoch": 2956,
        "reward": 0.335666686296463,
        "val_loss": 0.10039232756597423,
        "train_loss": 0.007985123629273753
      },
      {
        "epoch": 2957,
        "reward": 0.5207080245018005,
        "val_loss": 0.021714829868869856,
        "train_loss": 0.002267751586261878
      },
      {
        "epoch": 2958,
        "reward": 0.4059264659881592,
        "val_loss": 0.054894726482286514,
        "train_loss": 0.007543223412942377
      },
      {
        "epoch": 2959,
        "reward": 0.4418807029724121,
        "val_loss": 0.040887345297960564,
        "train_loss": 0.0339455048264986
      },
      {
        "epoch": 2960,
        "reward": 0.4709912836551666,
        "val_loss": 0.03233290436868889,
        "train_loss": 0.01172211609851869
      },
      {
        "epoch": 2961,
        "reward": 0.40127697587013245,
        "val_loss": 0.0570569005046439,
        "train_loss": 0.0199260915974614
      },
      {
        "epoch": 2962,
        "reward": 0.5681676268577576,
        "val_loss": 0.01480547452826743,
        "train_loss": 0.01416138202320055
      },
      {
        "epoch": 2963,
        "reward": 0.5499539375305176,
        "val_loss": 0.0171635095336699,
        "train_loss": 0.004132991396414372
      },
      {
        "epoch": 2964,
        "reward": 0.6036010384559631,
        "val_loss": 0.011053756363253342,
        "train_loss": 0.23333594551957923
      },
      {
        "epoch": 2965,
        "reward": 0.6062037348747253,
        "val_loss": 0.010815607662932183,
        "train_loss": 0.0005504262022668627
      },
      {
        "epoch": 2966,
        "reward": 0.6361610293388367,
        "val_loss": 0.008383572382237097,
        "train_loss": 0.03676541727306288
      },
      {
        "epoch": 2967,
        "reward": 0.3654080629348755,
        "val_loss": 0.07729967612872965,
        "train_loss": 0.006669136778572675
      },
      {
        "epoch": 2968,
        "reward": 0.5129358172416687,
        "val_loss": 0.023109539810580566,
        "train_loss": 0.001707663811718983
      },
      {
        "epoch": 2969,
        "reward": 0.5635990500450134,
        "val_loss": 0.015366521561840532,
        "train_loss": 0.013888404378812643
      },
      {
        "epoch": 2970,
        "reward": 0.5135952234268188,
        "val_loss": 0.02298787039970713,
        "train_loss": 0.005826478730385203
      },
      {
        "epoch": 2971,
        "reward": 0.54559725522995,
        "val_loss": 0.01777798351031379,
        "train_loss": 0.002501755480816078
      },
      {
        "epoch": 2972,
        "reward": 0.48671814799308777,
        "val_loss": 0.028503724603069713,
        "train_loss": 0.053241540479663084
      },
      {
        "epoch": 2973,
        "reward": 0.5285772681236267,
        "val_loss": 0.020386796175444033,
        "train_loss": 0.9692118408358397
      },
      {
        "epoch": 2974,
        "reward": 0.5163969397544861,
        "val_loss": 0.02247789006547204,
        "train_loss": 0.0009523989802941147
      },
      {
        "epoch": 2975,
        "reward": 0.5005144476890564,
        "val_loss": 0.025524512113146818,
        "train_loss": 0.0007877978550041576
      },
      {
        "epoch": 2976,
        "reward": 0.5968307256698608,
        "val_loss": 0.011695458216438834,
        "train_loss": 0.001816670302271352
      },
      {
        "epoch": 2977,
        "reward": 0.5294195413589478,
        "val_loss": 0.020249427466166838,
        "train_loss": 0.0026901704973388754
      },
      {
        "epoch": 2978,
        "reward": 0.4702375829219818,
        "val_loss": 0.032529133881325833,
        "train_loss": 0.0073290355925774535
      },
      {
        "epoch": 2979,
        "reward": 0.4058780372142792,
        "val_loss": 0.05491677801910555,
        "train_loss": 0.28695384999323015
      },
      {
        "epoch": 2980,
        "reward": 0.3666827380657196,
        "val_loss": 0.07645512916496955,
        "train_loss": 0.034846465171557824
      },
      {
        "epoch": 2981,
        "reward": 0.611457884311676,
        "val_loss": 0.010348754931068729,
        "train_loss": 0.9809954648780184
      },
      {
        "epoch": 2982,
        "reward": 0.5755370259284973,
        "val_loss": 0.013940487042938392,
        "train_loss": 0.0014095709827957902
      },
      {
        "epoch": 2983,
        "reward": 0.604564368724823,
        "val_loss": 0.010965070265748571,
        "train_loss": 0.0009988491890803393
      },
      {
        "epoch": 2984,
        "reward": 0.436619371175766,
        "val_loss": 0.04267195282279447,
        "train_loss": 0.003965182798313986
      },
      {
        "epoch": 2985,
        "reward": 0.37238869071006775,
        "val_loss": 0.07280033748975256,
        "train_loss": 64.0591978714912
      },
      {
        "epoch": 2986,
        "reward": 0.5751007795333862,
        "val_loss": 0.013990358667797409,
        "train_loss": 1.5028195932937518
      },
      {
        "epoch": 2987,
        "reward": 0.6058921217918396,
        "val_loss": 0.010843875658922895,
        "train_loss": 0.0009710898626298541
      },
      {
        "epoch": 2988,
        "reward": 0.549748957157135,
        "val_loss": 0.017191965273273775,
        "train_loss": 0.00028005396501384894
      },
      {
        "epoch": 2989,
        "reward": 0.635200023651123,
        "val_loss": 0.008453439992341114,
        "train_loss": 0.06637215613446082
      },
      {
        "epoch": 2990,
        "reward": 0.46124839782714844,
        "val_loss": 0.03496649785665795,
        "train_loss": 0.16796328742717692
      },
      {
        "epoch": 2991,
        "reward": 0.525249183177948,
        "val_loss": 0.0209385042113094,
        "train_loss": 0.013401108459216441
      },
      {
        "epoch": 2992,
        "reward": 0.5753940939903259,
        "val_loss": 0.013956811018163404,
        "train_loss": 1.8560510987192147
      },
      {
        "epoch": 2993,
        "reward": 0.4630683958530426,
        "val_loss": 0.034458195184665134,
        "train_loss": 0.0008012626253473671
      },
      {
        "epoch": 2994,
        "reward": 0.587657630443573,
        "val_loss": 0.012618624522604347,
        "train_loss": 0.00669066786085619
      },
      {
        "epoch": 2995,
        "reward": 0.6274033188819885,
        "val_loss": 0.009039182709135016,
        "train_loss": 0.0007186818421762207
      },
      {
        "epoch": 2996,
        "reward": 0.5430545210838318,
        "val_loss": 0.018146247373286833,
        "train_loss": 0.005510469058120949
      },
      {
        "epoch": 2997,
        "reward": 0.46543022990226746,
        "val_loss": 0.033809947562466344,
        "train_loss": 0.0031784200868707137
      },
      {
        "epoch": 2998,
        "reward": 0.6180212497711182,
        "val_loss": 0.009790763694452056,
        "train_loss": 0.049657934250879304
      },
      {
        "epoch": 2999,
        "reward": 0.5984107851982117,
        "val_loss": 0.011542773093554257,
        "train_loss": 0.0005311482522315075
      }
    ]
  }
}