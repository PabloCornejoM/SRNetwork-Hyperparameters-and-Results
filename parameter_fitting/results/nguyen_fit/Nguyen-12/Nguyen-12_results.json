{
  "experiment_info": {
    "experiment_name": "Nguyen-12",
    "dataset_name": "Nguyen-12",
    "timestamp": "2025-08-30T22:54:30.943634",
    "random_seed": 42
  },
  "model_config": {
    "input_size": 2,
    "output_size": 1,
    "num_layers": 2,
    "nonlinear_info": [
      [
        4,
        0
      ],
      [
        0,
        0
      ],
      [
        0,
        0
      ]
    ],
    "function_set": [
      "SafeIdentityFunction",
      "SafeExp",
      "SafeLog",
      "SafeSin",
      "SafePower",
      "SafeCos",
      "ExpSwitchActivation",
      "SafeElementwisePower_0",
      "SafeElementwisePower_1"
    ]
  },
  "training_config": {
    "num_epochs": 3000,
    "batch_size": 32,
    "learning_rate": 2,
    "reg_strength": 0.0,
    "scheduler": "cosine"
  },
  "final_equation": {
    "equation_string": "Matrix([[3.08799*x1**3.57034 - 1.08293*x1**3.60101 - 9.7779*x2**1.03864 + 9.24932*x2**1.0691]])",
    "equation_latex": "Matrix([[3.08799*x1**3.57034 - 1.08293*x1**3.60101 - 9.7779*x2**1.03864 + 9.24932*x2**1.0691]])"
  },
  "evaluation_metrics": {
    "mse": "0.00022749994",
    "rmse": "0.015083102",
    "mae": "0.012320722"
  },
  "data_info": {
    "train_ratio": 0.8,
    "uncertainty_value": 0.0,
    "path_to_data": "/Users/pablocornejo/Documents/Tesis/SRNetwork/data/raw/nguyen.txt"
  },
  "lbfgs_optimization": {
    "enabled": true,
    "success": true,
    "message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
    "function_evaluations": 7,
    "gradient_evaluations": 7,
    "final_loss": 0.027636517271790166,
    "max_iterations": 1000,
    "tolerance": "1e-8",
    "criterion": "nrmse"
  },
  "lbfgs_topk_optimization": {
    "enabled": true,
    "num_models_optimized": 4,
    "optimization_summary": [
      {
        "rank": 1,
        "original_epoch": 2991,
        "original_val_loss": 0.00024387388423617397,
        "optimized_val_loss": "0.00022749994",
        "improvement_percent": "6.714104",
        "original_equation": "Matrix([[3.08799*x1**3.57034 - 1.08293*x1**3.60101 - 9.7779*x2**1.03864 + 9.24932*x2**1.0691]])",
        "optimized_equation": "Matrix([[3.08799*x1**3.57034 - 1.08293*x1**3.60101 - 9.7779*x2**1.03864 + 9.24932*x2**1.0691]])",
        "optimization_success": true,
        "function_evaluations": 7,
        "final_loss": 0.027636517271790166
      },
      {
        "rank": 2,
        "original_epoch": 2992,
        "original_val_loss": 0.0002438104898569041,
        "optimized_val_loss": "0.0002277238",
        "improvement_percent": "6.5980306",
        "original_equation": "Matrix([[3.08808*x1**3.57034 - 1.08285*x1**3.60101 - 9.77782*x2**1.03864 + 9.2494*x2**1.0691]])",
        "optimized_equation": "Matrix([[3.08808*x1**3.57034 - 1.08285*x1**3.60101 - 9.77782*x2**1.03865 + 9.2494*x2**1.0691]])",
        "optimization_success": true,
        "function_evaluations": 8,
        "final_loss": 0.027971740184205302
      },
      {
        "rank": 3,
        "original_epoch": 2964,
        "original_val_loss": 0.0002437883023438709,
        "optimized_val_loss": "0.00022781236",
        "improvement_percent": "6.5532064",
        "original_equation": "Matrix([[3.0877*x1**3.57034 - 1.08232*x1**3.60101 - 9.77738*x2**1.03864 + 9.24895*x2**1.0691]])",
        "optimized_equation": "Matrix([[3.0877*x1**3.57034 - 1.08232*x1**3.60101 - 9.77738*x2**1.03864 + 9.24895*x2**1.0691]])",
        "optimization_success": true,
        "function_evaluations": 8,
        "final_loss": 0.028595230329349245
      },
      {
        "rank": 4,
        "original_epoch": 2955,
        "original_val_loss": 0.00024370310919558897,
        "optimized_val_loss": "0.0002279068",
        "improvement_percent": "6.481784",
        "original_equation": "Matrix([[3.08744*x1**3.57034 - 1.08175*x1**3.60101 - 9.77707*x2**1.03864 + 9.24829*x2**1.0691]])",
        "optimized_equation": "Matrix([[3.08744*x1**3.57034 - 1.08175*x1**3.60101 - 9.77707*x2**1.03864 + 9.24829*x2**1.0691]])",
        "optimization_success": true,
        "function_evaluations": 12,
        "final_loss": 0.027890236618069376
      }
    ],
    "best_model": {
      "original_val_loss": 0.00024387388423617397,
      "optimized_val_loss": "0.00022749994",
      "improvement_percent": "6.714104",
      "equation": "Matrix([[3.08799*x1**3.57034 - 1.08293*x1**3.60101 - 9.7779*x2**1.03864 + 9.24932*x2**1.0691]])",
      "optimization_iterations": 1
    }
  },
  "reward_tracking": {
    "reward_type": "nrmse",
    "reward_interval": 1,
    "num_measurements": 3000,
    "initial_reward": 0.23971951007843018,
    "final_reward": 0.7749187350273132,
    "best_reward": 0.7750530242919922,
    "worst_reward": 0.03640196844935417,
    "average_reward": 0.4884514199929933,
    "reward_history": [
      {
        "epoch": 0,
        "reward": 0.23971951007843018,
        "val_loss": 0.02910077971007143,
        "train_loss": 0.6072958485545734
      },
      {
        "epoch": 1,
        "reward": 0.13587793707847595,
        "val_loss": 0.11700813046523503,
        "train_loss": 0.031275245817736365
      },
      {
        "epoch": 2,
        "reward": 0.28276607394218445,
        "val_loss": 0.018613611481019428,
        "train_loss": 0.039097558975649566
      },
      {
        "epoch": 3,
        "reward": 0.18042224645614624,
        "val_loss": 0.059698552425418584,
        "train_loss": 0.015221969170782428
      },
      {
        "epoch": 4,
        "reward": 0.27663514018058777,
        "val_loss": 0.019781706189470633,
        "train_loss": 0.07746473170566158
      },
      {
        "epoch": 5,
        "reward": 0.15882396697998047,
        "val_loss": 0.08115315011569432,
        "train_loss": 0.012929478534855522
      },
      {
        "epoch": 6,
        "reward": 0.38855743408203125,
        "val_loss": 0.007164148680333581,
        "train_loss": 0.02160191229240109
      },
      {
        "epoch": 7,
        "reward": 0.29990172386169434,
        "val_loss": 0.015766083129814694,
        "train_loss": 0.006439605906892281
      },
      {
        "epoch": 8,
        "reward": 0.3698933720588684,
        "val_loss": 0.008395347345088209,
        "train_loss": 0.01131813417081363
      },
      {
        "epoch": 9,
        "reward": 0.2053019106388092,
        "val_loss": 0.04334929585456848,
        "train_loss": 0.005968276599350457
      },
      {
        "epoch": 10,
        "reward": 0.05376696586608887,
        "val_loss": 0.8960428748811994,
        "train_loss": 0.13344664993480995
      },
      {
        "epoch": 11,
        "reward": 0.16267915070056915,
        "val_loss": 0.07664497728858675,
        "train_loss": 0.19904295220756188
      },
      {
        "epoch": 12,
        "reward": 0.23080280423164368,
        "val_loss": 0.03213341480919293,
        "train_loss": 0.027245574039765276
      },
      {
        "epoch": 13,
        "reward": 0.0821431577205658,
        "val_loss": 0.36121917409556253,
        "train_loss": 0.030674462887243584
      },
      {
        "epoch": 14,
        "reward": 0.15909184515476227,
        "val_loss": 0.08082858526280948,
        "train_loss": 0.29370413670459616
      },
      {
        "epoch": 15,
        "reward": 0.13874749839305878,
        "val_loss": 0.1114742143877915,
        "train_loss": 0.04666091087990655
      },
      {
        "epoch": 16,
        "reward": 0.22502122819423676,
        "val_loss": 0.034315976447292736,
        "train_loss": 0.01857524653090737
      },
      {
        "epoch": 17,
        "reward": 0.4886241555213928,
        "val_loss": 0.0031687947256224497,
        "train_loss": 0.011020137816488456
      },
      {
        "epoch": 18,
        "reward": 0.45523664355278015,
        "val_loss": 0.004142905552206295,
        "train_loss": 0.0037270300896265185
      },
      {
        "epoch": 19,
        "reward": 0.46270737051963806,
        "val_loss": 0.0039009699331862585,
        "train_loss": 0.004583863877297307
      },
      {
        "epoch": 20,
        "reward": 0.26732879877090454,
        "val_loss": 0.0217315424233675,
        "train_loss": 0.005035987571598246
      },
      {
        "epoch": 21,
        "reward": 0.4945813715457916,
        "val_loss": 0.0030212784186005592,
        "train_loss": 0.008122218513073256
      },
      {
        "epoch": 22,
        "reward": 0.3606054484844208,
        "val_loss": 0.009095716423221998,
        "train_loss": 0.008018345419818966
      },
      {
        "epoch": 23,
        "reward": 0.2872045934200287,
        "val_loss": 0.017820119059511592,
        "train_loss": 0.014314345091966411
      },
      {
        "epoch": 24,
        "reward": 0.2503950893878937,
        "val_loss": 0.025928476825356483,
        "train_loss": 0.011523536053853324
      },
      {
        "epoch": 25,
        "reward": 0.3831937313079834,
        "val_loss": 0.007495911958228264,
        "train_loss": 0.009866148853829006
      },
      {
        "epoch": 26,
        "reward": 0.25746864080429077,
        "val_loss": 0.02406271786562034,
        "train_loss": 0.005949882691941009
      },
      {
        "epoch": 27,
        "reward": 0.3439415991306305,
        "val_loss": 0.010526386023099934,
        "train_loss": 0.008255152697809255
      },
      {
        "epoch": 28,
        "reward": 0.26158803701400757,
        "val_loss": 0.023052891716361046,
        "train_loss": 0.006139296057741516
      },
      {
        "epoch": 29,
        "reward": 0.44709500670433044,
        "val_loss": 0.004424507131001779,
        "train_loss": 0.010330077923404483
      },
      {
        "epoch": 30,
        "reward": 0.4156336486339569,
        "val_loss": 0.0057189032169325015,
        "train_loss": 0.009826608333521737
      },
      {
        "epoch": 31,
        "reward": 0.46528854966163635,
        "val_loss": 0.003820831388501184,
        "train_loss": 0.0063680474682209585
      },
      {
        "epoch": 32,
        "reward": 0.1936997026205063,
        "val_loss": 0.05013018686856542,
        "train_loss": 0.004026657288285116
      },
      {
        "epoch": 33,
        "reward": 0.1684674620628357,
        "val_loss": 0.07048392934458596,
        "train_loss": 0.009709324293698255
      },
      {
        "epoch": 34,
        "reward": 0.10462218523025513,
        "val_loss": 0.21189890589032853,
        "train_loss": 0.10040269670291589
      },
      {
        "epoch": 35,
        "reward": 0.08442337810993195,
        "val_loss": 0.3402730960931097,
        "train_loss": 0.20640419310746858
      },
      {
        "epoch": 36,
        "reward": 0.07144090533256531,
        "val_loss": 0.48875237362725393,
        "train_loss": 0.1154200146959808
      },
      {
        "epoch": 37,
        "reward": 0.09020095318555832,
        "val_loss": 0.29432860016822815,
        "train_loss": 0.22223491473040177
      },
      {
        "epoch": 38,
        "reward": 0.1544737070798874,
        "val_loss": 0.08667797914573125,
        "train_loss": 0.08968854211987211
      },
      {
        "epoch": 39,
        "reward": 0.2112993448972702,
        "val_loss": 0.040308049214737754,
        "train_loss": 0.02989064471778245
      },
      {
        "epoch": 40,
        "reward": 0.4735732078552246,
        "val_loss": 0.0035749124695679973,
        "train_loss": 0.011899126326450361
      },
      {
        "epoch": 41,
        "reward": 0.5265485644340515,
        "val_loss": 0.0023390400955187424,
        "train_loss": 0.004947140930758346
      },
      {
        "epoch": 42,
        "reward": 0.4645098149776459,
        "val_loss": 0.0038448270809437546,
        "train_loss": 0.0030552796312034703
      },
      {
        "epoch": 43,
        "reward": 0.5124598741531372,
        "val_loss": 0.0026185729407838415,
        "train_loss": 0.004913175026348864
      },
      {
        "epoch": 44,
        "reward": 0.5401912331581116,
        "val_loss": 0.002096153479734702,
        "train_loss": 0.0024625336730143598
      },
      {
        "epoch": 45,
        "reward": 0.3261905610561371,
        "val_loss": 0.012345114589801856,
        "train_loss": 0.0025769241754180537
      },
      {
        "epoch": 46,
        "reward": 0.22182264924049377,
        "val_loss": 0.03560484546635832,
        "train_loss": 0.009800847010830274
      },
      {
        "epoch": 47,
        "reward": 0.321572870016098,
        "val_loss": 0.012876901110368115,
        "train_loss": 0.013573001822805963
      },
      {
        "epoch": 48,
        "reward": 0.2553917169570923,
        "val_loss": 0.024592675268650055,
        "train_loss": 0.016788736415597107
      },
      {
        "epoch": 49,
        "reward": 0.2917329967021942,
        "val_loss": 0.017052444429802045,
        "train_loss": 0.018547684863173906
      },
      {
        "epoch": 50,
        "reward": 0.2022279053926468,
        "val_loss": 0.04502348841301033,
        "train_loss": 0.011648135962716948
      },
      {
        "epoch": 51,
        "reward": 0.5100879073143005,
        "val_loss": 0.002668762080637472,
        "train_loss": 0.011597029260323884
      },
      {
        "epoch": 52,
        "reward": 0.3166479170322418,
        "val_loss": 0.013474089226552419,
        "train_loss": 0.008743390199155189
      },
      {
        "epoch": 53,
        "reward": 0.13037173449993134,
        "val_loss": 0.12872537119047983,
        "train_loss": 0.016105195614867486
      },
      {
        "epoch": 54,
        "reward": 0.20835256576538086,
        "val_loss": 0.04176664565290723,
        "train_loss": 0.045451147257923506
      },
      {
        "epoch": 55,
        "reward": 0.47508320212364197,
        "val_loss": 0.003531874722934195,
        "train_loss": 0.024444375634909823
      },
      {
        "epoch": 56,
        "reward": 0.4145660102367401,
        "val_loss": 0.005769421812146902,
        "train_loss": 0.005990794772724957
      },
      {
        "epoch": 57,
        "reward": 0.3226005733013153,
        "val_loss": 0.012756252395255225,
        "train_loss": 0.0065063399737342615
      },
      {
        "epoch": 58,
        "reward": 0.48824286460876465,
        "val_loss": 0.0031784812454134226,
        "train_loss": 0.006204186329761377
      },
      {
        "epoch": 59,
        "reward": 0.5340213775634766,
        "val_loss": 0.0022028168064675163,
        "train_loss": 0.0033200314053549217
      },
      {
        "epoch": 60,
        "reward": 0.20222170650959015,
        "val_loss": 0.04502696277839797,
        "train_loss": 0.0026092866075891298
      },
      {
        "epoch": 61,
        "reward": 0.11094313859939575,
        "val_loss": 0.18578976605619704,
        "train_loss": 0.04134242469444871
      },
      {
        "epoch": 62,
        "reward": 0.11402237415313721,
        "val_loss": 0.17467431830508368,
        "train_loss": 0.31322167491397035
      },
      {
        "epoch": 63,
        "reward": 0.15993018448352814,
        "val_loss": 0.07982400565275125,
        "train_loss": 0.07086314557986603
      },
      {
        "epoch": 64,
        "reward": 0.346768856048584,
        "val_loss": 0.010266381715025221,
        "train_loss": 0.02523746472210265
      },
      {
        "epoch": 65,
        "reward": 0.2531305253505707,
        "val_loss": 0.025186285642640933,
        "train_loss": 0.009465661264794808
      },
      {
        "epoch": 66,
        "reward": 0.1067049503326416,
        "val_loss": 0.20276095185961043,
        "train_loss": 0.0405946028409884
      },
      {
        "epoch": 67,
        "reward": 0.10866271704435349,
        "val_loss": 0.1946645144905363,
        "train_loss": 0.1288951069044952
      },
      {
        "epoch": 68,
        "reward": 0.06481768935918808,
        "val_loss": 0.602239340543747,
        "train_loss": 0.21550947857590821
      },
      {
        "epoch": 69,
        "reward": 0.29788944125175476,
        "val_loss": 0.016071796683328494,
        "train_loss": 0.1664773438242264
      },
      {
        "epoch": 70,
        "reward": 0.4625379145145416,
        "val_loss": 0.003906292508223227,
        "train_loss": 0.008907854460770838
      },
      {
        "epoch": 71,
        "reward": 0.43094000220298767,
        "val_loss": 0.005044825408341629,
        "train_loss": 0.006834348175079168
      },
      {
        "epoch": 72,
        "reward": 0.3074626624584198,
        "val_loss": 0.014677947520145349,
        "train_loss": 0.0037322658597706603
      },
      {
        "epoch": 73,
        "reward": 0.39442357420921326,
        "val_loss": 0.006819867063313723,
        "train_loss": 0.00460201915120706
      },
      {
        "epoch": 74,
        "reward": 0.3586958944797516,
        "val_loss": 0.009247810945713095,
        "train_loss": 0.006467131897807121
      },
      {
        "epoch": 75,
        "reward": 0.2521599531173706,
        "val_loss": 0.025446553315435137,
        "train_loss": 0.00777330455961279
      },
      {
        "epoch": 76,
        "reward": 0.3788844048976898,
        "val_loss": 0.0077749029733240604,
        "train_loss": 0.01505890548707192
      },
      {
        "epoch": 77,
        "reward": 0.31980380415916443,
        "val_loss": 0.013087743161512273,
        "train_loss": 0.02274812425737484
      },
      {
        "epoch": 78,
        "reward": 0.08834313601255417,
        "val_loss": 0.30809226419244495,
        "train_loss": 0.011262167012318969
      },
      {
        "epoch": 79,
        "reward": 0.2015342265367508,
        "val_loss": 0.04541284218430519,
        "train_loss": 0.0792150934620832
      },
      {
        "epoch": 80,
        "reward": 0.06602830439805984,
        "val_loss": 0.5788563404764447,
        "train_loss": 0.0448044897415317
      },
      {
        "epoch": 81,
        "reward": 0.28038501739501953,
        "val_loss": 0.019056996862803186,
        "train_loss": 0.10522840587565532
      },
      {
        "epoch": 82,
        "reward": 0.4186283051967621,
        "val_loss": 0.005579743268234389,
        "train_loss": 0.006271764318136355
      },
      {
        "epoch": 83,
        "reward": 0.4056357443332672,
        "val_loss": 0.006211502411003623,
        "train_loss": 0.0044854855424581236
      },
      {
        "epoch": 84,
        "reward": 0.3153861463069916,
        "val_loss": 0.013632320798933506,
        "train_loss": 0.004945060505213825
      },
      {
        "epoch": 85,
        "reward": 0.38665771484375,
        "val_loss": 0.007279742775218827,
        "train_loss": 0.0060616777359078135
      },
      {
        "epoch": 86,
        "reward": 0.5662305355072021,
        "val_loss": 0.0016978331176298006,
        "train_loss": 0.005238419210609908
      },
      {
        "epoch": 87,
        "reward": 0.34652411937713623,
        "val_loss": 0.010288589234863008,
        "train_loss": 0.0031749006392111857
      },
      {
        "epoch": 88,
        "reward": 0.17934612929821014,
        "val_loss": 0.06057586787002427,
        "train_loss": 0.020237436052411795
      },
      {
        "epoch": 89,
        "reward": 0.27752843499183655,
        "val_loss": 0.019606059417128563,
        "train_loss": 0.07788823699901024
      },
      {
        "epoch": 90,
        "reward": 0.38679519295692444,
        "val_loss": 0.007271308717983109,
        "train_loss": 0.0078008784151349505
      },
      {
        "epoch": 91,
        "reward": 0.4064377248287201,
        "val_loss": 0.006170326644288642,
        "train_loss": 0.0035603025305765467
      },
      {
        "epoch": 92,
        "reward": 0.21400943398475647,
        "val_loss": 0.03902407203401838,
        "train_loss": 0.008247938316064672
      },
      {
        "epoch": 93,
        "reward": 0.11720643192529678,
        "val_loss": 0.16412665162767684,
        "train_loss": 0.024302089161490306
      },
      {
        "epoch": 94,
        "reward": 0.1802394837141037,
        "val_loss": 0.05984635651111603,
        "train_loss": 0.03895460662897676
      },
      {
        "epoch": 95,
        "reward": 0.4010480046272278,
        "val_loss": 0.006452900956251791,
        "train_loss": 0.01212755264266609
      },
      {
        "epoch": 96,
        "reward": 0.5687315464019775,
        "val_loss": 0.0016635827154719404,
        "train_loss": 0.0029893688619127856
      },
      {
        "epoch": 97,
        "reward": 0.5818721652030945,
        "val_loss": 0.0014939174455191409,
        "train_loss": 0.0018125723626536245
      },
      {
        "epoch": 98,
        "reward": 0.5715893507003784,
        "val_loss": 0.00162523436093969,
        "train_loss": 0.0019621679686959116
      },
      {
        "epoch": 99,
        "reward": 0.4902699589729309,
        "val_loss": 0.0031273300160786937,
        "train_loss": 0.0017635329092557256
      },
      {
        "epoch": 100,
        "reward": 0.31049466133117676,
        "val_loss": 0.014266933048410075,
        "train_loss": 0.003370261415301894
      },
      {
        "epoch": 101,
        "reward": 0.15578195452690125,
        "val_loss": 0.08496471494436264,
        "train_loss": 0.014056926373786364
      },
      {
        "epoch": 102,
        "reward": 0.20455312728881836,
        "val_loss": 0.04374956472643784,
        "train_loss": 0.01826088226516731
      },
      {
        "epoch": 103,
        "reward": 0.3480505645275116,
        "val_loss": 0.010150952996420009,
        "train_loss": 0.01782792736776173
      },
      {
        "epoch": 104,
        "reward": 0.26152193546295166,
        "val_loss": 0.023068674307848726,
        "train_loss": 0.03554972956100336
      },
      {
        "epoch": 105,
        "reward": 0.04809930548071861,
        "val_loss": 1.1331030556133814,
        "train_loss": 0.028532462337842353
      },
      {
        "epoch": 106,
        "reward": 0.15615828335285187,
        "val_loss": 0.08448032928364617,
        "train_loss": 0.36343644190436375
      },
      {
        "epoch": 107,
        "reward": 0.1985144466161728,
        "val_loss": 0.04715967816965921,
        "train_loss": 0.03239676643771908
      },
      {
        "epoch": 108,
        "reward": 0.29654785990715027,
        "val_loss": 0.01627958326467446,
        "train_loss": 0.05089530509072714
      },
      {
        "epoch": 109,
        "reward": 0.19828946888446808,
        "val_loss": 0.047293297946453094,
        "train_loss": 0.0431298916293879
      },
      {
        "epoch": 110,
        "reward": 0.11995164304971695,
        "val_loss": 0.15572716827903474,
        "train_loss": 0.04739451526144806
      },
      {
        "epoch": 111,
        "reward": 0.1910196989774704,
        "val_loss": 0.05188995014343943,
        "train_loss": 0.2365830666743792
      },
      {
        "epoch": 112,
        "reward": 0.31421783566474915,
        "val_loss": 0.013780801024820124,
        "train_loss": 0.04215210095907633
      },
      {
        "epoch": 113,
        "reward": 0.28715166449546814,
        "val_loss": 0.017829340217368945,
        "train_loss": 0.018367337350075383
      },
      {
        "epoch": 114,
        "reward": 0.38987913727760315,
        "val_loss": 0.007084927588169064,
        "train_loss": 0.008832680992782116
      },
      {
        "epoch": 115,
        "reward": 0.12587742507457733,
        "val_loss": 0.13951236754655838,
        "train_loss": 0.020720106603291173
      },
      {
        "epoch": 116,
        "reward": 0.09310152381658554,
        "val_loss": 0.2745158885206495,
        "train_loss": 0.10451250283334118
      },
      {
        "epoch": 117,
        "reward": 0.07415994256734848,
        "val_loss": 0.45091716732297626,
        "train_loss": 0.1240396206267178
      },
      {
        "epoch": 118,
        "reward": 0.09793881326913834,
        "val_loss": 0.245429094348635,
        "train_loss": 0.09947201704534774
      },
      {
        "epoch": 119,
        "reward": 0.06563127040863037,
        "val_loss": 0.5863792257649558,
        "train_loss": 0.23858546633989766
      },
      {
        "epoch": 120,
        "reward": 0.3068147897720337,
        "val_loss": 0.014767591841518879,
        "train_loss": 0.41412930856817043
      },
      {
        "epoch": 121,
        "reward": 0.1237834021449089,
        "val_loss": 0.14496452574219024,
        "train_loss": 0.13306016109597224
      },
      {
        "epoch": 122,
        "reward": 0.2726542353630066,
        "val_loss": 0.02058832879577364,
        "train_loss": 0.049491634055112414
      },
      {
        "epoch": 123,
        "reward": 0.38921231031417847,
        "val_loss": 0.007124776453045862,
        "train_loss": 0.007902462120490292
      },
      {
        "epoch": 124,
        "reward": 0.4881007671356201,
        "val_loss": 0.003182099899277091,
        "train_loss": 0.0033168143048757114
      },
      {
        "epoch": 125,
        "reward": 0.37624332308769226,
        "val_loss": 0.007951637330864156,
        "train_loss": 0.0030557028143308484
      },
      {
        "epoch": 126,
        "reward": 0.48208269476890564,
        "val_loss": 0.0033391929298107114,
        "train_loss": 0.006296267867303238
      },
      {
        "epoch": 127,
        "reward": 0.48323431611061096,
        "val_loss": 0.003308533990223493,
        "train_loss": 0.003928096673917025
      },
      {
        "epoch": 128,
        "reward": 0.4636755585670471,
        "val_loss": 0.0038707094666148934,
        "train_loss": 0.005118522395955201
      },
      {
        "epoch": 129,
        "reward": 0.36741283535957336,
        "val_loss": 0.008576217639659132,
        "train_loss": 0.0024420345703569744
      },
      {
        "epoch": 130,
        "reward": 0.5533883571624756,
        "val_loss": 0.0018843589849503978,
        "train_loss": 0.0028964425592466095
      },
      {
        "epoch": 131,
        "reward": 0.47759172320365906,
        "val_loss": 0.003461547528526613,
        "train_loss": 0.0014685999709539688
      },
      {
        "epoch": 132,
        "reward": 0.5689831376075745,
        "val_loss": 0.0016601725780804241,
        "train_loss": 0.0017499725592922634
      },
      {
        "epoch": 133,
        "reward": 0.535093367099762,
        "val_loss": 0.002183917161476399,
        "train_loss": 0.0016706376761878626
      },
      {
        "epoch": 134,
        "reward": 0.5111033916473389,
        "val_loss": 0.0026471607520111968,
        "train_loss": 0.0014101145184563042
      },
      {
        "epoch": 135,
        "reward": 0.33696720004081726,
        "val_loss": 0.011201042415840285,
        "train_loss": 0.003335208099227972
      },
      {
        "epoch": 136,
        "reward": 0.5013696551322937,
        "val_loss": 0.002861575023936374,
        "train_loss": 0.002791398151132923
      },
      {
        "epoch": 137,
        "reward": 0.41786715388298035,
        "val_loss": 0.005614760697686246,
        "train_loss": 0.0022742503161470476
      },
      {
        "epoch": 138,
        "reward": 0.34508416056632996,
        "val_loss": 0.010420405904629402,
        "train_loss": 0.008026143889695119
      },
      {
        "epoch": 139,
        "reward": 0.4551199972629547,
        "val_loss": 0.004146805199395333,
        "train_loss": 0.005121217329220739
      },
      {
        "epoch": 140,
        "reward": 0.3681464195251465,
        "val_loss": 0.008522271245185817,
        "train_loss": 0.0029304265559543497
      },
      {
        "epoch": 141,
        "reward": 0.43143120408058167,
        "val_loss": 0.005024660046079329,
        "train_loss": 0.002695873601344199
      },
      {
        "epoch": 142,
        "reward": 0.24508321285247803,
        "val_loss": 0.027449525626642362,
        "train_loss": 0.002513554681522342
      },
      {
        "epoch": 143,
        "reward": 0.33949509263038635,
        "val_loss": 0.010950871610215731,
        "train_loss": 0.005194914809320695
      },
      {
        "epoch": 144,
        "reward": 0.4160825312137604,
        "val_loss": 0.00569780423705067,
        "train_loss": 0.0153483823814895
      },
      {
        "epoch": 145,
        "reward": 0.2025410234928131,
        "val_loss": 0.044849175959825516,
        "train_loss": 0.006733949443934342
      },
      {
        "epoch": 146,
        "reward": 0.5112654566764832,
        "val_loss": 0.002643729410400348,
        "train_loss": 0.031162935824025996
      },
      {
        "epoch": 147,
        "reward": 0.6162043213844299,
        "val_loss": 0.0011223141503121173,
        "train_loss": 0.0025417844607782914
      },
      {
        "epoch": 148,
        "reward": 0.2004636973142624,
        "val_loss": 0.046022330543824604,
        "train_loss": 0.0020858740138534745
      },
      {
        "epoch": 149,
        "reward": 0.18341080844402313,
        "val_loss": 0.05734836310148239,
        "train_loss": 0.025874579943215046
      },
      {
        "epoch": 150,
        "reward": 0.2418861836194992,
        "val_loss": 0.028419104271701405,
        "train_loss": 0.025813124200213294
      },
      {
        "epoch": 151,
        "reward": 0.2908598482608795,
        "val_loss": 0.017197297886013985,
        "train_loss": 0.011395757601488955
      },
      {
        "epoch": 152,
        "reward": 0.062291450798511505,
        "val_loss": 0.6556054268564496,
        "train_loss": 0.09679716062069368
      },
      {
        "epoch": 153,
        "reward": 0.26820695400238037,
        "val_loss": 0.02153774776629039,
        "train_loss": 0.21144138706418183
      },
      {
        "epoch": 154,
        "reward": 0.1512557864189148,
        "val_loss": 0.0910947455891541,
        "train_loss": 0.07694857531728652
      },
      {
        "epoch": 155,
        "reward": 0.35969850420951843,
        "val_loss": 0.009167593504701341,
        "train_loss": 0.036077618455657594
      },
      {
        "epoch": 156,
        "reward": 0.5493776798248291,
        "val_loss": 0.0019464668418679918,
        "train_loss": 0.004267169471579389
      },
      {
        "epoch": 157,
        "reward": 0.5499317646026611,
        "val_loss": 0.0019377721972497447,
        "train_loss": 0.002170308510708985
      },
      {
        "epoch": 158,
        "reward": 0.2692013680934906,
        "val_loss": 0.021320860433791364,
        "train_loss": 0.0019026701360976754
      },
      {
        "epoch": 159,
        "reward": 0.2595519423484802,
        "val_loss": 0.02354530757293105,
        "train_loss": 0.008172805387720548
      },
      {
        "epoch": 160,
        "reward": 0.19152091443538666,
        "val_loss": 0.051554771938494275,
        "train_loss": 0.024703426886564836
      },
      {
        "epoch": 161,
        "reward": 0.3282088339328766,
        "val_loss": 0.012120811933917659,
        "train_loss": 0.031516258927205436
      },
      {
        "epoch": 162,
        "reward": 0.26007285714149475,
        "val_loss": 0.023418094696743146,
        "train_loss": 0.008332828700076789
      },
      {
        "epoch": 163,
        "reward": 0.22270651161670685,
        "val_loss": 0.0352425966411829,
        "train_loss": 0.022796407006143663
      },
      {
        "epoch": 164,
        "reward": 0.605988621711731,
        "val_loss": 0.0012230726507758455,
        "train_loss": 0.028040573437465355
      },
      {
        "epoch": 165,
        "reward": 0.15595440566539764,
        "val_loss": 0.08474227599799633,
        "train_loss": 0.004254921630490571
      },
      {
        "epoch": 166,
        "reward": 0.05243226885795593,
        "val_loss": 0.9449022199426379,
        "train_loss": 0.15906814321015889
      },
      {
        "epoch": 167,
        "reward": 0.2864510715007782,
        "val_loss": 0.017951890027948787,
        "train_loss": 0.3623469707448609
      },
      {
        "epoch": 168,
        "reward": 0.18945838510990143,
        "val_loss": 0.05295252640332494,
        "train_loss": 0.01076684679943495
      },
      {
        "epoch": 169,
        "reward": 0.3152931034564972,
        "val_loss": 0.013644074821578605,
        "train_loss": 0.02431789982186344
      },
      {
        "epoch": 170,
        "reward": 0.4587479531764984,
        "val_loss": 0.004027303873694369,
        "train_loss": 0.00786254291709226
      },
      {
        "epoch": 171,
        "reward": 0.608948290348053,
        "val_loss": 0.0011930849037266203,
        "train_loss": 0.00424397717982244
      },
      {
        "epoch": 172,
        "reward": 0.5647965669631958,
        "val_loss": 0.0017177673622167536,
        "train_loss": 0.0014785823631637658
      },
      {
        "epoch": 173,
        "reward": 0.6295231580734253,
        "val_loss": 0.0010019881384713309,
        "train_loss": 0.0015624866153722485
      },
      {
        "epoch": 174,
        "reward": 0.6132148504257202,
        "val_loss": 0.0011510071261519833,
        "train_loss": 0.0023238272159897652
      },
      {
        "epoch": 175,
        "reward": 0.3927779793739319,
        "val_loss": 0.006914557689534766,
        "train_loss": 0.00205625845074582
      },
      {
        "epoch": 176,
        "reward": 0.5105969309806824,
        "val_loss": 0.0026579117901357158,
        "train_loss": 0.0030040741884686914
      },
      {
        "epoch": 177,
        "reward": 0.3156694769859314,
        "val_loss": 0.01359659992158413,
        "train_loss": 0.011043881407553831
      },
      {
        "epoch": 178,
        "reward": 0.375314861536026,
        "val_loss": 0.008014832423733813,
        "train_loss": 0.0026195036659303764
      },
      {
        "epoch": 179,
        "reward": 0.3846987187862396,
        "val_loss": 0.007401128565626485,
        "train_loss": 0.007901518274313556
      },
      {
        "epoch": 180,
        "reward": 0.3804360032081604,
        "val_loss": 0.00767313369682857,
        "train_loss": 0.00596093365633211
      },
      {
        "epoch": 181,
        "reward": 0.10982365906238556,
        "val_loss": 0.19007454706089838,
        "train_loss": 0.011519061670137139
      },
      {
        "epoch": 182,
        "reward": 0.2571866810321808,
        "val_loss": 0.024133826472929547,
        "train_loss": 0.09748839141684584
      },
      {
        "epoch": 183,
        "reward": 0.4159190356731415,
        "val_loss": 0.00570548212687884,
        "train_loss": 0.050721214090187386
      },
      {
        "epoch": 184,
        "reward": 0.41973376274108887,
        "val_loss": 0.005529304700238364,
        "train_loss": 0.008478811736075351
      },
      {
        "epoch": 185,
        "reward": 0.15137456357479095,
        "val_loss": 0.0909263864159584,
        "train_loss": 0.017903625320033055
      },
      {
        "epoch": 186,
        "reward": 0.069378562271595,
        "val_loss": 0.5205461361578533,
        "train_loss": 0.04954825054245213
      },
      {
        "epoch": 187,
        "reward": 0.139649897813797,
        "val_loss": 0.10980771854519844,
        "train_loss": 0.18938359147152647
      },
      {
        "epoch": 188,
        "reward": 0.12910635769367218,
        "val_loss": 0.1316432644213949,
        "train_loss": 0.05095231162893189
      },
      {
        "epoch": 189,
        "reward": 0.3848864734172821,
        "val_loss": 0.007389396329277328,
        "train_loss": 0.026735428922200717
      },
      {
        "epoch": 190,
        "reward": 0.3850618898868561,
        "val_loss": 0.007378455517547471,
        "train_loss": 0.004461349570314828
      },
      {
        "epoch": 191,
        "reward": 0.43339505791664124,
        "val_loss": 0.004944889523488071,
        "train_loss": 0.004613348110489404
      },
      {
        "epoch": 192,
        "reward": 0.3017527759075165,
        "val_loss": 0.01549100543239287,
        "train_loss": 0.010426994764622157
      },
      {
        "epoch": 193,
        "reward": 0.5018313527107239,
        "val_loss": 0.0028510248022420065,
        "train_loss": 0.003403803268716169
      },
      {
        "epoch": 194,
        "reward": 0.42867666482925415,
        "val_loss": 0.0051388755174619815,
        "train_loss": 0.003012343766525961
      },
      {
        "epoch": 195,
        "reward": 0.30924323201179504,
        "val_loss": 0.014434895079050745,
        "train_loss": 0.006809335488539476
      },
      {
        "epoch": 196,
        "reward": 0.40774330496788025,
        "val_loss": 0.0061039346536355355,
        "train_loss": 0.01131260978917663
      },
      {
        "epoch": 197,
        "reward": 0.5248095393180847,
        "val_loss": 0.0023718958421211156,
        "train_loss": 0.002987599748079307
      },
      {
        "epoch": 198,
        "reward": 0.37489864230155945,
        "val_loss": 0.008043348822476608,
        "train_loss": 0.0034684559292285345
      },
      {
        "epoch": 199,
        "reward": 0.37621819972991943,
        "val_loss": 0.007953336429116982,
        "train_loss": 0.007753895738950143
      },
      {
        "epoch": 200,
        "reward": 0.09687547385692596,
        "val_loss": 0.2514382717864854,
        "train_loss": 0.018526658281469002
      },
      {
        "epoch": 201,
        "reward": 0.0977339819073677,
        "val_loss": 0.24657084686415537,
        "train_loss": 0.15888955233430563
      },
      {
        "epoch": 202,
        "reward": 0.06854364275932312,
        "val_loss": 0.5342620313167572,
        "train_loss": 0.18477191023815137
      },
      {
        "epoch": 203,
        "reward": 0.5201327800750732,
        "val_loss": 0.0024625062609889676,
        "train_loss": 0.07872366609740339
      },
      {
        "epoch": 204,
        "reward": 0.3262789845466614,
        "val_loss": 0.012335186757679497,
        "train_loss": 0.0027474310459533278
      },
      {
        "epoch": 205,
        "reward": 0.3099421560764313,
        "val_loss": 0.014340803426291262,
        "train_loss": 0.009986333669915508
      },
      {
        "epoch": 206,
        "reward": 0.17185835540294647,
        "val_loss": 0.06717870384454727,
        "train_loss": 0.007535447290417953
      },
      {
        "epoch": 207,
        "reward": 0.26818156242370605,
        "val_loss": 0.02154331687571747,
        "train_loss": 0.0513335070751894
      },
      {
        "epoch": 208,
        "reward": 0.09922748059034348,
        "val_loss": 0.23841299968106405,
        "train_loss": 0.03335916178408437
      },
      {
        "epoch": 209,
        "reward": 0.4243835508823395,
        "val_loss": 0.005322468533579793,
        "train_loss": 0.1533401287765278
      },
      {
        "epoch": 210,
        "reward": 0.25020167231559753,
        "val_loss": 0.025981975187148367,
        "train_loss": 0.013509829882353257
      },
      {
        "epoch": 211,
        "reward": 0.3646387457847595,
        "val_loss": 0.008783742519361632,
        "train_loss": 0.005510265609840504
      },
      {
        "epoch": 212,
        "reward": 0.0734785720705986,
        "val_loss": 0.4599951037338802,
        "train_loss": 0.016958214861985583
      },
      {
        "epoch": 213,
        "reward": 0.11592715233564377,
        "val_loss": 0.16825557393687113,
        "train_loss": 0.16071704438386056
      },
      {
        "epoch": 214,
        "reward": 0.14813080430030823,
        "val_loss": 0.0956794646169458,
        "train_loss": 0.20090160343366173
      },
      {
        "epoch": 215,
        "reward": 0.24265967309474945,
        "val_loss": 0.028180631143706187,
        "train_loss": 0.10133722710620183
      },
      {
        "epoch": 216,
        "reward": 0.27482378482818604,
        "val_loss": 0.020143833676619188,
        "train_loss": 0.014030666511434201
      },
      {
        "epoch": 217,
        "reward": 0.544658362865448,
        "val_loss": 0.002022040924722595,
        "train_loss": 0.00716281422557166
      },
      {
        "epoch": 218,
        "reward": 0.49983611702919006,
        "val_loss": 0.002896896912716329,
        "train_loss": 0.00383010937142759
      },
      {
        "epoch": 219,
        "reward": 0.5551543235778809,
        "val_loss": 0.0018576116334380849,
        "train_loss": 0.010502238133295368
      },
      {
        "epoch": 220,
        "reward": 0.4414757192134857,
        "val_loss": 0.004630567339648094,
        "train_loss": 0.0023856963984704074
      },
      {
        "epoch": 221,
        "reward": 0.3908834457397461,
        "val_loss": 0.007025380153208971,
        "train_loss": 0.0027372795152936866
      },
      {
        "epoch": 222,
        "reward": 0.4565456509590149,
        "val_loss": 0.004099410625972918,
        "train_loss": 0.0036911057317271256
      },
      {
        "epoch": 223,
        "reward": 0.3390350043773651,
        "val_loss": 0.010995918153119939,
        "train_loss": 0.007751858522309563
      },
      {
        "epoch": 224,
        "reward": 0.4775004982948303,
        "val_loss": 0.0034640790628535406,
        "train_loss": 0.0037953532435214864
      },
      {
        "epoch": 225,
        "reward": 0.5038004517555237,
        "val_loss": 0.002806462796538004,
        "train_loss": 0.0018332584273034276
      },
      {
        "epoch": 226,
        "reward": 0.45282745361328125,
        "val_loss": 0.004224223284316915,
        "train_loss": 0.0016902012100147728
      },
      {
        "epoch": 227,
        "reward": 0.5858762264251709,
        "val_loss": 0.0014454804726743273,
        "train_loss": 0.0023480076937140927
      },
      {
        "epoch": 228,
        "reward": 0.4568251073360443,
        "val_loss": 0.004090185310425503,
        "train_loss": 0.0020019941139253206
      },
      {
        "epoch": 229,
        "reward": 0.36890843510627747,
        "val_loss": 0.008466642216912337,
        "train_loss": 0.0014464930550625117
      },
      {
        "epoch": 230,
        "reward": 0.139923095703125,
        "val_loss": 0.10930988086121422,
        "train_loss": 0.007901919298232175
      },
      {
        "epoch": 231,
        "reward": 0.07460031658411026,
        "val_loss": 0.445185444184712,
        "train_loss": 0.11598253899361365
      },
      {
        "epoch": 232,
        "reward": 0.06694704294204712,
        "val_loss": 0.5619703871863229,
        "train_loss": 0.1904145998056405
      },
      {
        "epoch": 233,
        "reward": 0.21378043293952942,
        "val_loss": 0.03913050490830626,
        "train_loss": 0.16045112311929607
      },
      {
        "epoch": 234,
        "reward": 0.3273334205150604,
        "val_loss": 0.01221750962681004,
        "train_loss": 0.019240764272021458
      },
      {
        "epoch": 235,
        "reward": 0.418156236410141,
        "val_loss": 0.0056014355338577715,
        "train_loss": 0.008493679405476611
      },
      {
        "epoch": 236,
        "reward": 0.14199043810367584,
        "val_loss": 0.10564034645046506,
        "train_loss": 0.009063764699161626
      },
      {
        "epoch": 237,
        "reward": 0.3344838321208954,
        "val_loss": 0.011453297987048115,
        "train_loss": 0.05198367851643035
      },
      {
        "epoch": 238,
        "reward": 0.09967731684446335,
        "val_loss": 0.23603008261748723,
        "train_loss": 0.058306827066609494
      },
      {
        "epoch": 239,
        "reward": 0.20595259964466095,
        "val_loss": 0.043005297758749554,
        "train_loss": 0.06256142267599128
      },
      {
        "epoch": 240,
        "reward": 0.20541083812713623,
        "val_loss": 0.043291467907173295,
        "train_loss": 0.014495051835323326
      },
      {
        "epoch": 241,
        "reward": 0.536745011806488,
        "val_loss": 0.0021551018081871526,
        "train_loss": 0.014236737651607165
      },
      {
        "epoch": 242,
        "reward": 0.6362131237983704,
        "val_loss": 0.0009459159835906965,
        "train_loss": 0.0022807526710878915
      },
      {
        "epoch": 243,
        "reward": 0.5902252793312073,
        "val_loss": 0.001394499874939876,
        "train_loss": 0.001139188816663451
      },
      {
        "epoch": 244,
        "reward": 0.4919753968715668,
        "val_loss": 0.0030849372768508537,
        "train_loss": 0.0013313236990003274
      },
      {
        "epoch": 245,
        "reward": 0.5124889612197876,
        "val_loss": 0.0026179633402664748,
        "train_loss": 0.003173326634658644
      },
      {
        "epoch": 246,
        "reward": 0.5295565128326416,
        "val_loss": 0.002283252675884536,
        "train_loss": 0.0014373838169446501
      },
      {
        "epoch": 247,
        "reward": 0.17433960735797882,
        "val_loss": 0.064889504175101,
        "train_loss": 0.005035804277912785
      },
      {
        "epoch": 248,
        "reward": 0.14268939197063446,
        "val_loss": 0.10443755239248276,
        "train_loss": 0.046412951178633824
      },
      {
        "epoch": 249,
        "reward": 0.12941142916679382,
        "val_loss": 0.13093158496277674,
        "train_loss": 0.10422159502139458
      },
      {
        "epoch": 250,
        "reward": 0.4566674828529358,
        "val_loss": 0.004095387545281223,
        "train_loss": 0.02562403648950679
      },
      {
        "epoch": 251,
        "reward": 0.23386633396148682,
        "val_loss": 0.03104826861194202,
        "train_loss": 0.005461870954604819
      },
      {
        "epoch": 252,
        "reward": 0.39985543489456177,
        "val_loss": 0.006517325794058186,
        "train_loss": 0.010103902206397973
      },
      {
        "epoch": 253,
        "reward": 0.19131635129451752,
        "val_loss": 0.05169122187154634,
        "train_loss": 0.008318220533195787
      },
      {
        "epoch": 254,
        "reward": 0.1813574731349945,
        "val_loss": 0.05894967115351132,
        "train_loss": 0.029786216578661248
      },
      {
        "epoch": 255,
        "reward": 0.43572887778282166,
        "val_loss": 0.004851841434304204,
        "train_loss": 0.014520488605530072
      },
      {
        "epoch": 256,
        "reward": 0.4317656457424164,
        "val_loss": 0.0050109766556748325,
        "train_loss": 0.0019854142133576367
      },
      {
        "epoch": 257,
        "reward": 0.6144937872886658,
        "val_loss": 0.001138653448184154,
        "train_loss": 0.001815745846565383
      },
      {
        "epoch": 258,
        "reward": 0.5252497792243958,
        "val_loss": 0.0023635364237374495,
        "train_loss": 0.002830055120284669
      },
      {
        "epoch": 259,
        "reward": 0.5123727917671204,
        "val_loss": 0.002620398948368217,
        "train_loss": 0.002773646672721952
      },
      {
        "epoch": 260,
        "reward": 0.22944378852844238,
        "val_loss": 0.03263020382395813,
        "train_loss": 0.004475595075816203
      },
      {
        "epoch": 261,
        "reward": 0.3312850296497345,
        "val_loss": 0.011788055500281709,
        "train_loss": 0.011367604243927278
      },
      {
        "epoch": 262,
        "reward": 0.33124107122421265,
        "val_loss": 0.011792734797511781,
        "train_loss": 0.013112850457008999
      },
      {
        "epoch": 263,
        "reward": 0.1755470186471939,
        "val_loss": 0.0638129147035735,
        "train_loss": 0.01191037582555929
      },
      {
        "epoch": 264,
        "reward": 0.5450742244720459,
        "val_loss": 0.0020152703592819826,
        "train_loss": 0.050434526888868556
      },
      {
        "epoch": 265,
        "reward": 0.5064369440078735,
        "val_loss": 0.0027478831387790187,
        "train_loss": 0.007762338550282248
      },
      {
        "epoch": 266,
        "reward": 0.33834511041641235,
        "val_loss": 0.011063868312963418,
        "train_loss": 0.001439660924146525
      },
      {
        "epoch": 267,
        "reward": 0.3168533742427826,
        "val_loss": 0.013448532338121108,
        "train_loss": 0.06623692240100354
      },
      {
        "epoch": 268,
        "reward": 0.22295652329921722,
        "val_loss": 0.035140992275306156,
        "train_loss": 0.07957346180382256
      },
      {
        "epoch": 269,
        "reward": 0.23646147549152374,
        "val_loss": 0.030165100736277446,
        "train_loss": 0.011211897345044864
      },
      {
        "epoch": 270,
        "reward": 0.4410480558872223,
        "val_loss": 0.004646659529368792,
        "train_loss": 0.01639053888636856
      },
      {
        "epoch": 271,
        "reward": 0.32946673035621643,
        "val_loss": 0.011983432906812854,
        "train_loss": 0.007822189862526311
      },
      {
        "epoch": 272,
        "reward": 0.3872632086277008,
        "val_loss": 0.007242677167856267,
        "train_loss": 0.005860815464984626
      },
      {
        "epoch": 273,
        "reward": 0.07944589853286743,
        "val_loss": 0.3884358661515372,
        "train_loss": 0.024868889461056545
      },
      {
        "epoch": 274,
        "reward": 0.1088431254029274,
        "val_loss": 0.19394117700202124,
        "train_loss": 0.08306389342312916
      },
      {
        "epoch": 275,
        "reward": 0.4273833930492401,
        "val_loss": 0.005193453215594802,
        "train_loss": 0.028314608637279328
      },
      {
        "epoch": 276,
        "reward": 0.26758241653442383,
        "val_loss": 0.021675346685307368,
        "train_loss": 0.0019305438819663743
      },
      {
        "epoch": 277,
        "reward": 0.18861638009548187,
        "val_loss": 0.05353740496294839,
        "train_loss": 0.012293509151697015
      },
      {
        "epoch": 278,
        "reward": 0.24188320338726044,
        "val_loss": 0.028420031336801394,
        "train_loss": 0.011541629733983427
      },
      {
        "epoch": 279,
        "reward": 0.45371127128601074,
        "val_loss": 0.004194198442356927,
        "train_loss": 0.02281759663646181
      },
      {
        "epoch": 280,
        "reward": 0.4847380220890045,
        "val_loss": 0.003268931260598557,
        "train_loss": 0.0024194661169671095
      },
      {
        "epoch": 281,
        "reward": 0.3705404996871948,
        "val_loss": 0.008348874015999692,
        "train_loss": 0.0027245402359881155
      },
      {
        "epoch": 282,
        "reward": 0.38982442021369934,
        "val_loss": 0.0070881882150258336,
        "train_loss": 0.0032184710681366804
      },
      {
        "epoch": 283,
        "reward": 0.2823198437690735,
        "val_loss": 0.018695746548473835,
        "train_loss": 0.005675228610226231
      },
      {
        "epoch": 284,
        "reward": 0.44880738854408264,
        "val_loss": 0.004363656675975237,
        "train_loss": 0.011334502845644377
      },
      {
        "epoch": 285,
        "reward": 0.12117301672697067,
        "val_loss": 0.15218033960887364,
        "train_loss": 0.0039323593462960655
      },
      {
        "epoch": 286,
        "reward": 0.06180545687675476,
        "val_loss": 0.6666468637330192,
        "train_loss": 0.03766785778750021
      },
      {
        "epoch": 287,
        "reward": 0.134820818901062,
        "val_loss": 0.1191411656992776,
        "train_loss": 0.2238086246742079
      },
      {
        "epoch": 288,
        "reward": 0.07598637789487839,
        "val_loss": 0.4278080633708409,
        "train_loss": 0.1319713574081946
      },
      {
        "epoch": 289,
        "reward": 0.6485740542411804,
        "val_loss": 0.0008494001148002488,
        "train_loss": 0.3167602992974795
      },
      {
        "epoch": 290,
        "reward": 0.4041700065135956,
        "val_loss": 0.006287531494828207,
        "train_loss": 0.038460214828284316
      },
      {
        "epoch": 291,
        "reward": 0.16379638016223907,
        "val_loss": 0.0754013532506568,
        "train_loss": 0.02201942197727756
      },
      {
        "epoch": 292,
        "reward": 0.1427212804555893,
        "val_loss": 0.10438311419316701,
        "train_loss": 0.0356863675182327
      },
      {
        "epoch": 293,
        "reward": 0.10836656391620636,
        "val_loss": 0.19585999633584703,
        "train_loss": 0.062703070221827
      },
      {
        "epoch": 294,
        "reward": 0.33780428767204285,
        "val_loss": 0.011117475240358285,
        "train_loss": 0.026403387955164923
      },
      {
        "epoch": 295,
        "reward": 0.3568340241909027,
        "val_loss": 0.00939890429643648,
        "train_loss": 0.004223425353232484
      },
      {
        "epoch": 296,
        "reward": 0.1849486082792282,
        "val_loss": 0.056186430156230927,
        "train_loss": 0.008185431468658723
      },
      {
        "epoch": 297,
        "reward": 0.21604886651039124,
        "val_loss": 0.03809234978897231,
        "train_loss": 0.02016467035551054
      },
      {
        "epoch": 298,
        "reward": 0.21953105926513672,
        "val_loss": 0.03656646742352417,
        "train_loss": 0.014882375701115681
      },
      {
        "epoch": 299,
        "reward": 0.16000664234161377,
        "val_loss": 0.0797332227230072,
        "train_loss": 0.10330343622571
      },
      {
        "epoch": 300,
        "reward": 0.26034796237945557,
        "val_loss": 0.023351251546825682,
        "train_loss": 0.01878806954706446
      },
      {
        "epoch": 301,
        "reward": 0.5400621891021729,
        "val_loss": 0.002098332192482693,
        "train_loss": 0.008700076894316365
      },
      {
        "epoch": 302,
        "reward": 0.09108784049749374,
        "val_loss": 0.288062470299857,
        "train_loss": 0.00253038278942068
      },
      {
        "epoch": 303,
        "reward": 0.19699466228485107,
        "val_loss": 0.04807193524071148,
        "train_loss": 0.07825949574257371
      },
      {
        "epoch": 304,
        "reward": 0.12331338226795197,
        "val_loss": 0.14622848693813598,
        "train_loss": 0.012485606873479601
      },
      {
        "epoch": 305,
        "reward": 0.1269502490758896,
        "val_loss": 0.1368278722677912,
        "train_loss": 0.13508822006406263
      },
      {
        "epoch": 306,
        "reward": 0.10661939531564713,
        "val_loss": 0.2031254151037761,
        "train_loss": 0.16274208045349672
      },
      {
        "epoch": 307,
        "reward": 0.06627532094717026,
        "val_loss": 0.5742455635751996,
        "train_loss": 0.1413592896424234
      },
      {
        "epoch": 308,
        "reward": 0.14336948096752167,
        "val_loss": 0.10328499972820282,
        "train_loss": 0.3467198465950787
      },
      {
        "epoch": 309,
        "reward": 0.07779531925916672,
        "val_loss": 0.4065475570304053,
        "train_loss": 0.26775187314846194
      },
      {
        "epoch": 310,
        "reward": 0.13561443984508514,
        "val_loss": 0.11753490407552038,
        "train_loss": 0.1420477399459252
      },
      {
        "epoch": 311,
        "reward": 0.14876414835453033,
        "val_loss": 0.09472550238881793,
        "train_loss": 0.10213367809326603
      },
      {
        "epoch": 312,
        "reward": 0.6399171352386475,
        "val_loss": 0.0009160542727581092,
        "train_loss": 0.02655747075018903
      },
      {
        "epoch": 313,
        "reward": 0.6258410811424255,
        "val_loss": 0.0010340650000476412,
        "train_loss": 0.0009420057143030975
      },
      {
        "epoch": 314,
        "reward": 0.6282963156700134,
        "val_loss": 0.0010125775172907328,
        "train_loss": 0.001143106957897544
      },
      {
        "epoch": 315,
        "reward": 0.6606585383415222,
        "val_loss": 0.000763279344287834,
        "train_loss": 0.0009428806280573973
      },
      {
        "epoch": 316,
        "reward": 0.49692589044570923,
        "val_loss": 0.0029651346350354807,
        "train_loss": 0.0010324314050824167
      },
      {
        "epoch": 317,
        "reward": 0.6338743567466736,
        "val_loss": 0.0009652001982820886,
        "train_loss": 0.002946728851664095
      },
      {
        "epoch": 318,
        "reward": 0.6118740439414978,
        "val_loss": 0.0011640858720056713,
        "train_loss": 0.001022617710987106
      },
      {
        "epoch": 319,
        "reward": 0.14269225299358368,
        "val_loss": 0.10443264352423805,
        "train_loss": 0.002974608570534306
      },
      {
        "epoch": 320,
        "reward": 0.3950293958187103,
        "val_loss": 0.00678536734942879,
        "train_loss": 0.021320338645287287
      },
      {
        "epoch": 321,
        "reward": 0.5849470496177673,
        "val_loss": 0.0014565909181588463,
        "train_loss": 0.0031167763809207827
      },
      {
        "epoch": 322,
        "reward": 0.4759000241756439,
        "val_loss": 0.003508815175986716,
        "train_loss": 0.003319021383783995
      },
      {
        "epoch": 323,
        "reward": 0.48246651887893677,
        "val_loss": 0.0033289417291858365,
        "train_loss": 0.0010519416402810467
      },
      {
        "epoch": 324,
        "reward": 0.4807894825935364,
        "val_loss": 0.0033739659868712935,
        "train_loss": 0.0020957313122030776
      },
      {
        "epoch": 325,
        "reward": 0.5388756990432739,
        "val_loss": 0.0021184714777129038,
        "train_loss": 0.001927674111567075
      },
      {
        "epoch": 326,
        "reward": 0.47080346941947937,
        "val_loss": 0.003655259730294347,
        "train_loss": 0.0015627354284963356
      },
      {
        "epoch": 327,
        "reward": 0.46520882844924927,
        "val_loss": 0.003823281664933477,
        "train_loss": 0.0017447889101906465
      },
      {
        "epoch": 328,
        "reward": 0.5204824805259705,
        "val_loss": 0.0024556153719978674,
        "train_loss": 0.0015155167806929408
      },
      {
        "epoch": 329,
        "reward": 0.3798050880432129,
        "val_loss": 0.0077143338109765735,
        "train_loss": 0.0026326052141554942
      },
      {
        "epoch": 330,
        "reward": 0.2354860156774521,
        "val_loss": 0.030493293223636492,
        "train_loss": 0.007230646503068363
      },
      {
        "epoch": 331,
        "reward": 0.18899650871753693,
        "val_loss": 0.05327230638691357,
        "train_loss": 0.008361458644055976
      },
      {
        "epoch": 332,
        "reward": 0.4059545695781708,
        "val_loss": 0.006195099226066044,
        "train_loss": 0.01702293728102142
      },
      {
        "epoch": 333,
        "reward": 0.4956533908843994,
        "val_loss": 0.0029954748627330574,
        "train_loss": 0.004099312867485703
      },
      {
        "epoch": 334,
        "reward": 0.473126083612442,
        "val_loss": 0.003587759964700256,
        "train_loss": 0.001616945870829603
      },
      {
        "epoch": 335,
        "reward": 0.2823515236377716,
        "val_loss": 0.01868989611310618,
        "train_loss": 0.0017776543211836654
      },
      {
        "epoch": 336,
        "reward": 0.5319029688835144,
        "val_loss": 0.002240632993302175,
        "train_loss": 0.0036333203293347303
      },
      {
        "epoch": 337,
        "reward": 0.07568691670894623,
        "val_loss": 0.43147956899234224,
        "train_loss": 0.003862843123407891
      },
      {
        "epoch": 338,
        "reward": 0.10479207336902618,
        "val_loss": 0.2111323199101857,
        "train_loss": 0.27989509902321374
      },
      {
        "epoch": 339,
        "reward": 0.10001670569181442,
        "val_loss": 0.2342542495046343,
        "train_loss": 0.1685838428361771
      },
      {
        "epoch": 340,
        "reward": 0.19472141563892365,
        "val_loss": 0.04947987677795546,
        "train_loss": 0.03536005006977715
      },
      {
        "epoch": 341,
        "reward": 0.4534842073917389,
        "val_loss": 0.004201891399653894,
        "train_loss": 0.01030213084931557
      },
      {
        "epoch": 342,
        "reward": 0.16470572352409363,
        "val_loss": 0.07440897556287902,
        "train_loss": 0.005387892668995147
      },
      {
        "epoch": 343,
        "reward": 0.22877450287342072,
        "val_loss": 0.032878439341272624,
        "train_loss": 0.026698613344566323
      },
      {
        "epoch": 344,
        "reward": 0.3307214677333832,
        "val_loss": 0.011848208893622671,
        "train_loss": 0.010659784018711295
      },
      {
        "epoch": 345,
        "reward": 0.49826762080192566,
        "val_loss": 0.0029334765526333024,
        "train_loss": 0.003094607689350736
      },
      {
        "epoch": 346,
        "reward": 0.23694618046283722,
        "val_loss": 0.03000368443982942,
        "train_loss": 0.001596940014188966
      },
      {
        "epoch": 347,
        "reward": 0.4060915410518646,
        "val_loss": 0.006188063150537866,
        "train_loss": 0.011512431719053823
      },
      {
        "epoch": 348,
        "reward": 0.4779561161994934,
        "val_loss": 0.0034514499296035084,
        "train_loss": 0.008798197270012818
      },
      {
        "epoch": 349,
        "reward": 0.20010323822498322,
        "val_loss": 0.04622993405376162,
        "train_loss": 0.0026165610380793135
      },
      {
        "epoch": 350,
        "reward": 0.2038421630859375,
        "val_loss": 0.04413407428988388,
        "train_loss": 0.011312415728473123
      },
      {
        "epoch": 351,
        "reward": 0.05811430886387825,
        "val_loss": 0.7599656241280692,
        "train_loss": 0.05554088312559403
      },
      {
        "epoch": 352,
        "reward": 0.148949533700943,
        "val_loss": 0.09444870693343026,
        "train_loss": 0.18375153065874025
      },
      {
        "epoch": 353,
        "reward": 0.28274962306022644,
        "val_loss": 0.018616636017603532,
        "train_loss": 0.01878855223633134
      },
      {
        "epoch": 354,
        "reward": 0.6336832046508789,
        "val_loss": 0.000966791670569884,
        "train_loss": 0.021514187531115916
      },
      {
        "epoch": 355,
        "reward": 0.45968133211135864,
        "val_loss": 0.003997144621929952,
        "train_loss": 0.0019679183807546417
      },
      {
        "epoch": 356,
        "reward": 0.2625068128108978,
        "val_loss": 0.022834875487855504,
        "train_loss": 0.0036774205901355553
      },
      {
        "epoch": 357,
        "reward": 0.5203835964202881,
        "val_loss": 0.0024575625346707447,
        "train_loss": 0.00794949542838507
      },
      {
        "epoch": 358,
        "reward": 0.40629157423973083,
        "val_loss": 0.006177808756807021,
        "train_loss": 0.014077911516114209
      },
      {
        "epoch": 359,
        "reward": 0.4791313111782074,
        "val_loss": 0.0034190951846539974,
        "train_loss": 0.010292938585805062
      },
      {
        "epoch": 360,
        "reward": 0.41799408197402954,
        "val_loss": 0.005608905905059406,
        "train_loss": 0.00295402157980089
      },
      {
        "epoch": 361,
        "reward": 0.2940344512462616,
        "val_loss": 0.01667763026697295,
        "train_loss": 0.002185501082119747
      },
      {
        "epoch": 362,
        "reward": 0.3824353814125061,
        "val_loss": 0.007544185134715268,
        "train_loss": 0.005270149433412231
      },
      {
        "epoch": 363,
        "reward": 0.16083210706710815,
        "val_loss": 0.07876184263399669,
        "train_loss": 0.00628536855443739
      },
      {
        "epoch": 364,
        "reward": 0.07662827521562576,
        "val_loss": 0.42008655411856516,
        "train_loss": 0.052585816727234766
      },
      {
        "epoch": 365,
        "reward": 0.1798415184020996,
        "val_loss": 0.06016989424824715,
        "train_loss": 0.06620184350714016
      },
      {
        "epoch": 366,
        "reward": 0.27747857570648193,
        "val_loss": 0.019615813491067717,
        "train_loss": 0.048181683684770875
      },
      {
        "epoch": 367,
        "reward": 0.23020417988300323,
        "val_loss": 0.032351050791995864,
        "train_loss": 0.022128383118587617
      },
      {
        "epoch": 368,
        "reward": 0.07858040928840637,
        "val_loss": 0.39778650232723783,
        "train_loss": 0.04118625532450656
      },
      {
        "epoch": 369,
        "reward": 0.21475504338741302,
        "val_loss": 0.03868007633302893,
        "train_loss": 0.09907893297629645
      },
      {
        "epoch": 370,
        "reward": 0.40026503801345825,
        "val_loss": 0.006495120536003794,
        "train_loss": 0.007819925903347142
      },
      {
        "epoch": 371,
        "reward": 0.2923172116279602,
        "val_loss": 0.016956342650311335,
        "train_loss": 0.003100316257377227
      },
      {
        "epoch": 372,
        "reward": 0.36589315533638,
        "val_loss": 0.008689205228750194,
        "train_loss": 0.004861539207363071
      },
      {
        "epoch": 373,
        "reward": 0.45953845977783203,
        "val_loss": 0.004001746053940484,
        "train_loss": 0.004321761265880643
      },
      {
        "epoch": 374,
        "reward": 0.43636828660964966,
        "val_loss": 0.004826676798984408,
        "train_loss": 0.00945811802879549
      },
      {
        "epoch": 375,
        "reward": 0.5569089651107788,
        "val_loss": 0.0018313922753025378,
        "train_loss": 0.007770757195360672
      },
      {
        "epoch": 376,
        "reward": 0.4721132218837738,
        "val_loss": 0.0036170371542019503,
        "train_loss": 0.0026877568486200357
      },
      {
        "epoch": 377,
        "reward": 0.17140284180641174,
        "val_loss": 0.06761056770171438,
        "train_loss": 0.01467102908421881
      },
      {
        "epoch": 378,
        "reward": 0.18269608914852142,
        "val_loss": 0.057899169091667445,
        "train_loss": 0.026937711858548798
      },
      {
        "epoch": 379,
        "reward": 0.3162238895893097,
        "val_loss": 0.013527022142495428,
        "train_loss": 0.030851684879612897
      },
      {
        "epoch": 380,
        "reward": 0.2674614191055298,
        "val_loss": 0.021702131123415062,
        "train_loss": 0.008092299264927324
      },
      {
        "epoch": 381,
        "reward": 0.3353932201862335,
        "val_loss": 0.011360163667372294,
        "train_loss": 0.015293705030881729
      },
      {
        "epoch": 382,
        "reward": 0.4064039885997772,
        "val_loss": 0.006172054513756718,
        "train_loss": 0.01165940227936237
      },
      {
        "epoch": 383,
        "reward": 0.31631919741630554,
        "val_loss": 0.013515103874461991,
        "train_loss": 0.0045686929068044545
      },
      {
        "epoch": 384,
        "reward": 0.20194847881793976,
        "val_loss": 0.04517981569681849,
        "train_loss": 0.035640114112398945
      },
      {
        "epoch": 385,
        "reward": 0.29702407121658325,
        "val_loss": 0.016205456307423965,
        "train_loss": 0.10526151433945276
      },
      {
        "epoch": 386,
        "reward": 0.36755725741386414,
        "val_loss": 0.008565568764294897,
        "train_loss": 0.004827485383709875
      },
      {
        "epoch": 387,
        "reward": 0.515329897403717,
        "val_loss": 0.002559089251527829,
        "train_loss": 0.0031504861567205247
      },
      {
        "epoch": 388,
        "reward": 0.3126765787601471,
        "val_loss": 0.013979616242327861,
        "train_loss": 0.006908656128154269
      },
      {
        "epoch": 389,
        "reward": 0.3388229310512543,
        "val_loss": 0.011016756163111754,
        "train_loss": 0.004033221567694385
      },
      {
        "epoch": 390,
        "reward": 0.14913664758205414,
        "val_loss": 0.09417042455502919,
        "train_loss": 0.02020869982572129
      },
      {
        "epoch": 391,
        "reward": 0.13278484344482422,
        "val_loss": 0.12340146409613746,
        "train_loss": 0.09299948370943849
      },
      {
        "epoch": 392,
        "reward": 0.052861619740724564,
        "val_loss": 0.9287731902939933,
        "train_loss": 0.2777075864231357
      },
      {
        "epoch": 393,
        "reward": 0.0715518668293953,
        "val_loss": 0.48712120950222015,
        "train_loss": 0.2420619698241353
      },
      {
        "epoch": 394,
        "reward": 0.13779528439044952,
        "val_loss": 0.113270210900477,
        "train_loss": 0.11231609674779555
      },
      {
        "epoch": 395,
        "reward": 0.6019108891487122,
        "val_loss": 0.0012654931384271809,
        "train_loss": 0.055767431877589285
      },
      {
        "epoch": 396,
        "reward": 0.44985395669937134,
        "val_loss": 0.0043268961432789054,
        "train_loss": 0.01031707394017408
      },
      {
        "epoch": 397,
        "reward": 0.36743196845054626,
        "val_loss": 0.008574803825467825,
        "train_loss": 0.002984021441079676
      },
      {
        "epoch": 398,
        "reward": 0.5120629668235779,
        "val_loss": 0.0026269053508128437,
        "train_loss": 0.0039488223276293866
      },
      {
        "epoch": 399,
        "reward": 0.3942966163158417,
        "val_loss": 0.006827121201370444,
        "train_loss": 0.001814905168990103
      },
      {
        "epoch": 400,
        "reward": 0.6027012467384338,
        "val_loss": 0.0012571700333085442,
        "train_loss": 0.005158370475468333
      },
      {
        "epoch": 401,
        "reward": 0.5784781575202942,
        "val_loss": 0.0015361366760251777,
        "train_loss": 0.0014243949744223545
      },
      {
        "epoch": 402,
        "reward": 0.4953143298625946,
        "val_loss": 0.003003612227205719,
        "train_loss": 0.0019223115142757217
      },
      {
        "epoch": 403,
        "reward": 0.40493711829185486,
        "val_loss": 0.006247611649866615,
        "train_loss": 0.002012375321031029
      },
      {
        "epoch": 404,
        "reward": 0.427108496427536,
        "val_loss": 0.005205136723816395,
        "train_loss": 0.003306096634612634
      },
      {
        "epoch": 405,
        "reward": 0.3479470908641815,
        "val_loss": 0.01016021626336234,
        "train_loss": 0.0021515202556306925
      },
      {
        "epoch": 406,
        "reward": 0.40580400824546814,
        "val_loss": 0.006202836371293026,
        "train_loss": 0.004815439672361558
      },
      {
        "epoch": 407,
        "reward": 0.35981589555740356,
        "val_loss": 0.009158257261982985,
        "train_loss": 0.003059077110195246
      },
      {
        "epoch": 408,
        "reward": 0.5069403052330017,
        "val_loss": 0.00273683836816677,
        "train_loss": 0.002946980187866407
      },
      {
        "epoch": 409,
        "reward": 0.3826555907726288,
        "val_loss": 0.007530132042510169,
        "train_loss": 0.002182714524678886
      },
      {
        "epoch": 410,
        "reward": 0.30367907881736755,
        "val_loss": 0.01521082581686122,
        "train_loss": 0.0037563535073646703
      },
      {
        "epoch": 411,
        "reward": 0.46101728081703186,
        "val_loss": 0.003954384309638824,
        "train_loss": 0.004240756972509329
      },
      {
        "epoch": 412,
        "reward": 0.2226821482181549,
        "val_loss": 0.03525251748838595,
        "train_loss": 0.007327893556346401
      },
      {
        "epoch": 413,
        "reward": 0.17393702268600464,
        "val_loss": 0.06525381548064095,
        "train_loss": 0.06391487098657168
      },
      {
        "epoch": 414,
        "reward": 0.14278468489646912,
        "val_loss": 0.10427501371928624,
        "train_loss": 0.05669493623225627
      },
      {
        "epoch": 415,
        "reward": 0.1250171810388565,
        "val_loss": 0.14171746692487172,
        "train_loss": 0.18099933929848844
      },
      {
        "epoch": 416,
        "reward": 0.08725608885288239,
        "val_loss": 0.31657022131340845,
        "train_loss": 0.2108215787089788
      },
      {
        "epoch": 417,
        "reward": 0.10005604475736618,
        "val_loss": 0.23404961398669652,
        "train_loss": 0.19341901824093208
      },
      {
        "epoch": 418,
        "reward": 0.46651172637939453,
        "val_loss": 0.0037834526571844307,
        "train_loss": 0.15384888188698545
      },
      {
        "epoch": 419,
        "reward": 0.6206057071685791,
        "val_loss": 0.0010812187766922371,
        "train_loss": 0.010470810267948903
      },
      {
        "epoch": 420,
        "reward": 0.4173637330532074,
        "val_loss": 0.005638055403583816,
        "train_loss": 0.003497005974150642
      },
      {
        "epoch": 421,
        "reward": 0.4380905330181122,
        "val_loss": 0.0047595801297575235,
        "train_loss": 0.004125271554445275
      },
      {
        "epoch": 422,
        "reward": 0.41112685203552246,
        "val_loss": 0.005935475429786103,
        "train_loss": 0.003588072747404042
      },
      {
        "epoch": 423,
        "reward": 0.4068220555782318,
        "val_loss": 0.006150701349335057,
        "train_loss": 0.0013513927898692111
      },
      {
        "epoch": 424,
        "reward": 0.5255221128463745,
        "val_loss": 0.00235837945781116,
        "train_loss": 0.0026245053175863666
      },
      {
        "epoch": 425,
        "reward": 0.36005499958992004,
        "val_loss": 0.00913926646379488,
        "train_loss": 0.002285540129378205
      },
      {
        "epoch": 426,
        "reward": 0.5340456962585449,
        "val_loss": 0.002202386801530208,
        "train_loss": 0.007683122770126479
      },
      {
        "epoch": 427,
        "reward": 0.12796880304813385,
        "val_loss": 0.13434438300984247,
        "train_loss": 0.0040436375756354
      },
      {
        "epoch": 428,
        "reward": 0.2275269329547882,
        "val_loss": 0.033347622624465396,
        "train_loss": 0.05152311233373789
      },
      {
        "epoch": 429,
        "reward": 0.13444861769676208,
        "val_loss": 0.1199048204081399,
        "train_loss": 0.020546329700244732
      },
      {
        "epoch": 430,
        "reward": 0.07337310165166855,
        "val_loss": 0.46142347369875225,
        "train_loss": 0.07214889637767695
      },
      {
        "epoch": 431,
        "reward": 0.08138695359230042,
        "val_loss": 0.3685694294316428,
        "train_loss": 0.16486789388356834
      },
      {
        "epoch": 432,
        "reward": 0.19518153369426727,
        "val_loss": 0.04919059947133064,
        "train_loss": 0.2295489592316489
      },
      {
        "epoch": 433,
        "reward": 0.20470097661018372,
        "val_loss": 0.043670164687292914,
        "train_loss": 0.019093210162317027
      },
      {
        "epoch": 434,
        "reward": 0.11547157913446426,
        "val_loss": 0.1697606502899102,
        "train_loss": 0.01010373283105974
      },
      {
        "epoch": 435,
        "reward": 0.37504979968070984,
        "val_loss": 0.008032977148624403,
        "train_loss": 0.09134456470549314
      },
      {
        "epoch": 436,
        "reward": 0.47883662581443787,
        "val_loss": 0.003427178133279085,
        "train_loss": 0.002227384171699389
      },
      {
        "epoch": 437,
        "reward": 0.4337981641292572,
        "val_loss": 0.004928681400737592,
        "train_loss": 0.004306886004857146
      },
      {
        "epoch": 438,
        "reward": 0.5328326225280762,
        "val_loss": 0.002223960414994508,
        "train_loss": 0.002235983599033576
      },
      {
        "epoch": 439,
        "reward": 0.5656829476356506,
        "val_loss": 0.0017054193719689334,
        "train_loss": 0.0014507756725204391
      },
      {
        "epoch": 440,
        "reward": 0.5090214610099792,
        "val_loss": 0.0026916375915919033,
        "train_loss": 0.0017140657090259572
      },
      {
        "epoch": 441,
        "reward": 0.16514679789543152,
        "val_loss": 0.07393391004630498,
        "train_loss": 0.0019258449700338622
      },
      {
        "epoch": 442,
        "reward": 0.2400103062391281,
        "val_loss": 0.029008102204118456,
        "train_loss": 0.021306980463962715
      },
      {
        "epoch": 443,
        "reward": 0.16528624296188354,
        "val_loss": 0.07378455251455307,
        "train_loss": 0.05669649479051049
      },
      {
        "epoch": 444,
        "reward": 0.48150965571403503,
        "val_loss": 0.0033545565425551365,
        "train_loss": 0.013896720651805831
      },
      {
        "epoch": 445,
        "reward": 0.4350733757019043,
        "val_loss": 0.004877785686403513,
        "train_loss": 0.00200047321134032
      },
      {
        "epoch": 446,
        "reward": 0.5832703113555908,
        "val_loss": 0.0014768383199615137,
        "train_loss": 0.0041035468255778635
      },
      {
        "epoch": 447,
        "reward": 0.42649611830711365,
        "val_loss": 0.005231259823111551,
        "train_loss": 0.0026205317430699673
      },
      {
        "epoch": 448,
        "reward": 0.6564013957977295,
        "val_loss": 0.0007927341669398759,
        "train_loss": 0.0030509244489411893
      },
      {
        "epoch": 449,
        "reward": 0.6293529868125916,
        "val_loss": 0.0010034509551977472,
        "train_loss": 0.0015430608674740563
      },
      {
        "epoch": 450,
        "reward": 0.38258811831474304,
        "val_loss": 0.007534434619758811,
        "train_loss": 0.0013355324582125132
      },
      {
        "epoch": 451,
        "reward": 0.6066328287124634,
        "val_loss": 0.0012164888071960636,
        "train_loss": 0.0022435921530884048
      },
      {
        "epoch": 452,
        "reward": 0.537470817565918,
        "val_loss": 0.00214255549612322,
        "train_loss": 0.0013118528961338317
      },
      {
        "epoch": 453,
        "reward": 0.276762455701828,
        "val_loss": 0.01975655655509659,
        "train_loss": 0.0017200438843037074
      },
      {
        "epoch": 454,
        "reward": 0.595905065536499,
        "val_loss": 0.0013303821407524602,
        "train_loss": 0.007607333924030312
      },
      {
        "epoch": 455,
        "reward": 0.36855947971343994,
        "val_loss": 0.008492067722337586,
        "train_loss": 0.0019086559052364184
      },
      {
        "epoch": 456,
        "reward": 0.4294450879096985,
        "val_loss": 0.0051067357417196035,
        "train_loss": 0.01391012430954456
      },
      {
        "epoch": 457,
        "reward": 0.13721917569637299,
        "val_loss": 0.11437606279339109,
        "train_loss": 0.00508125935224458
      },
      {
        "epoch": 458,
        "reward": 0.09904669225215912,
        "val_loss": 0.2393802319254194,
        "train_loss": 0.039260427037683815
      },
      {
        "epoch": 459,
        "reward": 0.16899967193603516,
        "val_loss": 0.06995106754558426,
        "train_loss": 0.13578487646121246
      },
      {
        "epoch": 460,
        "reward": 0.18962140381336212,
        "val_loss": 0.0528402498790196,
        "train_loss": 0.031229536917705376
      },
      {
        "epoch": 461,
        "reward": 0.4442848265171051,
        "val_loss": 0.004526320844888687,
        "train_loss": 0.03498203124259957
      },
      {
        "epoch": 462,
        "reward": 0.5772809386253357,
        "val_loss": 0.0015512898098677397,
        "train_loss": 0.003804484315109081
      },
      {
        "epoch": 463,
        "reward": 0.5193747282028198,
        "val_loss": 0.0024775092024356127,
        "train_loss": 0.0019103122092649126
      },
      {
        "epoch": 464,
        "reward": 0.29231736063957214,
        "val_loss": 0.016956320697707788,
        "train_loss": 0.0027226682712073224
      },
      {
        "epoch": 465,
        "reward": 0.5972755551338196,
        "val_loss": 0.0013153165179703916,
        "train_loss": 0.003938996068777319
      },
      {
        "epoch": 466,
        "reward": 0.21380114555358887,
        "val_loss": 0.039120860397815704,
        "train_loss": 0.0057139932334673805
      },
      {
        "epoch": 467,
        "reward": 0.18244218826293945,
        "val_loss": 0.05809651740959713,
        "train_loss": 0.01383873333151524
      },
      {
        "epoch": 468,
        "reward": 0.5208575129508972,
        "val_loss": 0.00244824678104903,
        "train_loss": 0.010850300096745532
      },
      {
        "epoch": 469,
        "reward": 0.4741843640804291,
        "val_loss": 0.003557429582412754,
        "train_loss": 0.001550306970312494
      },
      {
        "epoch": 470,
        "reward": 0.2220660001039505,
        "val_loss": 0.0355046314320394,
        "train_loss": 0.0038175019639871046
      },
      {
        "epoch": 471,
        "reward": 0.516157329082489,
        "val_loss": 0.0025421887735969256,
        "train_loss": 0.008610051448018706
      },
      {
        "epoch": 472,
        "reward": 0.35573872923851013,
        "val_loss": 0.00948910867529256,
        "train_loss": 0.0033977318201393178
      },
      {
        "epoch": 473,
        "reward": 0.11902224272489548,
        "val_loss": 0.15850295765059336,
        "train_loss": 0.0681640311892037
      },
      {
        "epoch": 474,
        "reward": 0.13442158699035645,
        "val_loss": 0.11996053478547505,
        "train_loss": 0.1119844783276606
      },
      {
        "epoch": 475,
        "reward": 0.06628940254449844,
        "val_loss": 0.5739844185965401,
        "train_loss": 0.07547959798158935
      },
      {
        "epoch": 476,
        "reward": 0.03640196844935417,
        "val_loss": 2.0272426094327654,
        "train_loss": 0.39805638404448895
      },
      {
        "epoch": 477,
        "reward": 0.12419389933347702,
        "val_loss": 0.14387295288699015,
        "train_loss": 0.4652633319895428
      },
      {
        "epoch": 478,
        "reward": 0.16037152707576752,
        "val_loss": 0.07930186284439904,
        "train_loss": 0.0680546084499488
      },
      {
        "epoch": 479,
        "reward": 0.24742232263088226,
        "val_loss": 0.02676632029137441,
        "train_loss": 0.055337262384665124
      },
      {
        "epoch": 480,
        "reward": 0.18486563861370087,
        "val_loss": 0.05624833703041077,
        "train_loss": 0.027370402119301546
      },
      {
        "epoch": 481,
        "reward": 0.12500964105129242,
        "val_loss": 0.14173698957477296,
        "train_loss": 0.012976703352670973
      },
      {
        "epoch": 482,
        "reward": 0.22139616310596466,
        "val_loss": 0.035781342536211014,
        "train_loss": 0.08986033301397793
      },
      {
        "epoch": 483,
        "reward": 0.5532997846603394,
        "val_loss": 0.0018857107996674521,
        "train_loss": 0.014815471629844978
      },
      {
        "epoch": 484,
        "reward": 0.12164033949375153,
        "val_loss": 0.15085273342473166,
        "train_loss": 0.005302151700911613
      },
      {
        "epoch": 485,
        "reward": 0.171987846493721,
        "val_loss": 0.0670566154377801,
        "train_loss": 0.09451223376135413
      },
      {
        "epoch": 486,
        "reward": 0.16394974291324615,
        "val_loss": 0.07523276497210775,
        "train_loss": 0.10825206912480868
      },
      {
        "epoch": 487,
        "reward": 0.3402644097805023,
        "val_loss": 0.010876030727688755,
        "train_loss": 0.03190504136280371
      },
      {
        "epoch": 488,
        "reward": 0.6368317008018494,
        "val_loss": 0.0009408714332883912,
        "train_loss": 0.008445532070114635
      },
      {
        "epoch": 489,
        "reward": 0.32410088181495667,
        "val_loss": 0.012582502793520689,
        "train_loss": 0.0010868717934219884
      },
      {
        "epoch": 490,
        "reward": 0.4949842393398285,
        "val_loss": 0.0030115545128605197,
        "train_loss": 0.004403854491941344
      },
      {
        "epoch": 491,
        "reward": 0.5654171705245972,
        "val_loss": 0.0017091133964381047,
        "train_loss": 0.002998572075739503
      },
      {
        "epoch": 492,
        "reward": 0.4384334087371826,
        "val_loss": 0.004746340215206146,
        "train_loss": 0.003829360632852723
      },
      {
        "epoch": 493,
        "reward": 0.30252838134765625,
        "val_loss": 0.015377460047602654,
        "train_loss": 0.004654273308915435
      },
      {
        "epoch": 494,
        "reward": 0.32631921768188477,
        "val_loss": 0.012330670175807816,
        "train_loss": 0.01198531308462127
      },
      {
        "epoch": 495,
        "reward": 0.285564124584198,
        "val_loss": 0.018108518794178963,
        "train_loss": 0.01620740552805973
      },
      {
        "epoch": 496,
        "reward": 0.2396698296070099,
        "val_loss": 0.02911665476858616,
        "train_loss": 0.013159984812283745
      },
      {
        "epoch": 497,
        "reward": 0.5539062023162842,
        "val_loss": 0.0018764787070852304,
        "train_loss": 0.008094164974933777
      },
      {
        "epoch": 498,
        "reward": 0.39713791012763977,
        "val_loss": 0.006666792224028281,
        "train_loss": 0.002516449816399612
      },
      {
        "epoch": 499,
        "reward": 0.47275710105895996,
        "val_loss": 0.0035983965333018985,
        "train_loss": 0.002324365461810465
      },
      {
        "epoch": 500,
        "reward": 0.5003225207328796,
        "val_loss": 0.002885647849845035,
        "train_loss": 0.00272585385111877
      },
      {
        "epoch": 501,
        "reward": 0.47224465012550354,
        "val_loss": 0.003613224485889077,
        "train_loss": 0.001526442114621974
      },
      {
        "epoch": 502,
        "reward": 0.4072240889072418,
        "val_loss": 0.0061302456139986005,
        "train_loss": 0.0030619739913023435
      },
      {
        "epoch": 503,
        "reward": 0.2786484360694885,
        "val_loss": 0.019388511510831968,
        "train_loss": 0.0035392318185096462
      },
      {
        "epoch": 504,
        "reward": 0.05820269137620926,
        "val_loss": 0.7575170993804932,
        "train_loss": 0.005615593569997985
      },
      {
        "epoch": 505,
        "reward": 0.09934177249670029,
        "val_loss": 0.2378043872969491,
        "train_loss": 0.2881681708833919
      },
      {
        "epoch": 506,
        "reward": 0.12468244135379791,
        "val_loss": 0.1425884355391775,
        "train_loss": 0.22930847778199956
      },
      {
        "epoch": 507,
        "reward": 0.20889544486999512,
        "val_loss": 0.041492873270596774,
        "train_loss": 0.037547967701147385
      },
      {
        "epoch": 508,
        "reward": 0.47832342982292175,
        "val_loss": 0.003441304766706058,
        "train_loss": 0.00691853895654486
      },
      {
        "epoch": 509,
        "reward": 0.19485121965408325,
        "val_loss": 0.04939803747194154,
        "train_loss": 0.006197855154124017
      },
      {
        "epoch": 510,
        "reward": 0.3553483486175537,
        "val_loss": 0.009521497280469962,
        "train_loss": 0.021019785729899574
      },
      {
        "epoch": 511,
        "reward": 0.44180068373680115,
        "val_loss": 0.004618378721975854,
        "train_loss": 0.008791156457916189
      },
      {
        "epoch": 512,
        "reward": 0.3624686896800995,
        "val_loss": 0.008950056042522192,
        "train_loss": 0.0025514918172663014
      },
      {
        "epoch": 513,
        "reward": 0.2927076518535614,
        "val_loss": 0.016892479865678718,
        "train_loss": 0.0043519368605652396
      },
      {
        "epoch": 514,
        "reward": 0.41429492831230164,
        "val_loss": 0.0057823247209723505,
        "train_loss": 0.011104301193112266
      },
      {
        "epoch": 515,
        "reward": 0.43686363101005554,
        "val_loss": 0.004807276351909552,
        "train_loss": 0.004156481385087738
      },
      {
        "epoch": 516,
        "reward": 0.6038402915000916,
        "val_loss": 0.0012452601222321391,
        "train_loss": 0.0028699885588139296
      },
      {
        "epoch": 517,
        "reward": 0.3800729215145111,
        "val_loss": 0.007696816830762795,
        "train_loss": 0.0012247242803613727
      },
      {
        "epoch": 518,
        "reward": 0.645095705986023,
        "val_loss": 0.0008756650162727705,
        "train_loss": 0.002170392884671366
      },
      {
        "epoch": 519,
        "reward": 0.5108689665794373,
        "val_loss": 0.0026521315199456046,
        "train_loss": 0.0010959692859055044
      },
      {
        "epoch": 520,
        "reward": 0.41609644889831543,
        "val_loss": 0.005697153309094054,
        "train_loss": 0.001876189469700106
      },
      {
        "epoch": 521,
        "reward": 0.38991615176200867,
        "val_loss": 0.007082723413727113,
        "train_loss": 0.005160716428340843
      },
      {
        "epoch": 522,
        "reward": 0.18784694373607635,
        "val_loss": 0.054079320813928335,
        "train_loss": 0.008703325673615417
      },
      {
        "epoch": 523,
        "reward": 0.2402341216802597,
        "val_loss": 0.028937034042818204,
        "train_loss": 0.01775356768988646
      },
      {
        "epoch": 524,
        "reward": 0.1338009089231491,
        "val_loss": 0.1212497768657548,
        "train_loss": 0.014831734834632907
      },
      {
        "epoch": 525,
        "reward": 0.1469818651676178,
        "val_loss": 0.09744346780436379,
        "train_loss": 0.04503860641629077
      },
      {
        "epoch": 526,
        "reward": 0.09176802635192871,
        "val_loss": 0.2833834375653948,
        "train_loss": 0.1718432684070789
      },
      {
        "epoch": 527,
        "reward": 0.2242925465106964,
        "val_loss": 0.03460429622126477,
        "train_loss": 0.08417557903493826
      },
      {
        "epoch": 528,
        "reward": 0.6064714789390564,
        "val_loss": 0.0012181346454391523,
        "train_loss": 0.042349269559893474
      },
      {
        "epoch": 529,
        "reward": 0.3770371377468109,
        "val_loss": 0.007898045969860894,
        "train_loss": 0.0066961933178110765
      },
      {
        "epoch": 530,
        "reward": 0.49617552757263184,
        "val_loss": 0.002982986791591559,
        "train_loss": 0.004706706940641407
      },
      {
        "epoch": 531,
        "reward": 0.11166087538003922,
        "val_loss": 0.18311301618814468,
        "train_loss": 0.006381427130411164
      },
      {
        "epoch": 532,
        "reward": 0.1522693783044815,
        "val_loss": 0.0896714734179633,
        "train_loss": 0.17942335381387517
      },
      {
        "epoch": 533,
        "reward": 0.10503324121236801,
        "val_loss": 0.2100505850144795,
        "train_loss": 0.11182063914692172
      },
      {
        "epoch": 534,
        "reward": 0.12945929169654846,
        "val_loss": 0.13082036908183778,
        "train_loss": 0.04840774770295516
      },
      {
        "epoch": 535,
        "reward": 0.37700721621513367,
        "val_loss": 0.007900061551481485,
        "train_loss": 0.02164082291150967
      },
      {
        "epoch": 536,
        "reward": 0.5355802774429321,
        "val_loss": 0.0021753838851249646,
        "train_loss": 0.002327746953627551
      },
      {
        "epoch": 537,
        "reward": 0.5240007042884827,
        "val_loss": 0.002387330717673259,
        "train_loss": 0.007467796540228077
      },
      {
        "epoch": 538,
        "reward": 0.526624858379364,
        "val_loss": 0.0023376089853367637,
        "train_loss": 0.004515030806942377
      },
      {
        "epoch": 539,
        "reward": 0.3361046016216278,
        "val_loss": 0.011287926829286985,
        "train_loss": 0.0023629448005522136
      },
      {
        "epoch": 540,
        "reward": 0.44289156794548035,
        "val_loss": 0.0045777116902172565,
        "train_loss": 0.009743995431703158
      },
      {
        "epoch": 541,
        "reward": 0.2661556303501129,
        "val_loss": 0.021993803658655713,
        "train_loss": 0.009227816857254276
      },
      {
        "epoch": 542,
        "reward": 0.6219034194946289,
        "val_loss": 0.0010693585999043925,
        "train_loss": 0.004795966213210844
      },
      {
        "epoch": 543,
        "reward": 0.35555902123451233,
        "val_loss": 0.009504002718521016,
        "train_loss": 0.00165304591288217
      },
      {
        "epoch": 544,
        "reward": 0.21295849978923798,
        "val_loss": 0.03951564537627356,
        "train_loss": 0.002432691410201817
      },
      {
        "epoch": 545,
        "reward": 0.3317708969116211,
        "val_loss": 0.011736480120037283,
        "train_loss": 0.009037890624872839
      },
      {
        "epoch": 546,
        "reward": 0.3821084797382355,
        "val_loss": 0.0075651036375867465,
        "train_loss": 0.005632472945413051
      },
      {
        "epoch": 547,
        "reward": 0.34996291995048523,
        "val_loss": 0.009981503876458322,
        "train_loss": 0.0037524927174672484
      },
      {
        "epoch": 548,
        "reward": 0.22219863533973694,
        "val_loss": 0.03545016688959939,
        "train_loss": 0.008005545859654935
      },
      {
        "epoch": 549,
        "reward": 0.08794835209846497,
        "val_loss": 0.31113375084740774,
        "train_loss": 0.09997063889526404
      },
      {
        "epoch": 550,
        "reward": 0.09006749838590622,
        "val_loss": 0.29528799865927013,
        "train_loss": 0.07084594186968528
      },
      {
        "epoch": 551,
        "reward": 0.07632345706224442,
        "val_loss": 0.4237282659326281,
        "train_loss": 0.26078937464178753
      },
      {
        "epoch": 552,
        "reward": 0.13013555109500885,
        "val_loss": 0.1292632200888225,
        "train_loss": 0.09595115565641138
      },
      {
        "epoch": 553,
        "reward": 0.31660374999046326,
        "val_loss": 0.013479593808629684,
        "train_loss": 0.0782910140338712
      },
      {
        "epoch": 554,
        "reward": 0.06441786885261536,
        "val_loss": 0.6102598522390638,
        "train_loss": 0.03089624914663056
      },
      {
        "epoch": 555,
        "reward": 0.10935039818286896,
        "val_loss": 0.19192728027701378,
        "train_loss": 0.230117694224016
      },
      {
        "epoch": 556,
        "reward": 0.4446551501750946,
        "val_loss": 0.004512763482385448,
        "train_loss": 0.14712063649382728
      },
      {
        "epoch": 557,
        "reward": 0.1605982631444931,
        "val_loss": 0.07903541997075081,
        "train_loss": 0.029835244139226582
      },
      {
        "epoch": 558,
        "reward": 0.44663068652153015,
        "val_loss": 0.004441163602418133,
        "train_loss": 0.02016341217677109
      },
      {
        "epoch": 559,
        "reward": 0.5492092370986938,
        "val_loss": 0.0019491177517920732,
        "train_loss": 0.0017499961473871595
      },
      {
        "epoch": 560,
        "reward": 0.5157768130302429,
        "val_loss": 0.0025499474556584445,
        "train_loss": 0.0017065878133647717
      },
      {
        "epoch": 561,
        "reward": 0.6553256511688232,
        "val_loss": 0.0008003268241217094,
        "train_loss": 0.001150331486804554
      },
      {
        "epoch": 562,
        "reward": 0.48268768191337585,
        "val_loss": 0.0033230516460857223,
        "train_loss": 0.001141701840074697
      },
      {
        "epoch": 563,
        "reward": 0.2921055555343628,
        "val_loss": 0.016991081381482736,
        "train_loss": 0.002849577084326973
      },
      {
        "epoch": 564,
        "reward": 0.27493229508399963,
        "val_loss": 0.02012191792683942,
        "train_loss": 0.006154686467757879
      },
      {
        "epoch": 565,
        "reward": 0.5628523230552673,
        "val_loss": 0.001745142973959446,
        "train_loss": 0.017388857447748214
      },
      {
        "epoch": 566,
        "reward": 0.4070497453212738,
        "val_loss": 0.006139107314603669,
        "train_loss": 0.0012575118766667752
      },
      {
        "epoch": 567,
        "reward": 0.4857514500617981,
        "val_loss": 0.0032425119674631526,
        "train_loss": 0.004776764948753855
      },
      {
        "epoch": 568,
        "reward": 0.33484721183776855,
        "val_loss": 0.011415977829269,
        "train_loss": 0.0020237890085599455
      },
      {
        "epoch": 569,
        "reward": 0.3451882004737854,
        "val_loss": 0.010410817473062448,
        "train_loss": 0.0031105056613551616
      },
      {
        "epoch": 570,
        "reward": 0.5488143563270569,
        "val_loss": 0.001955344192018466,
        "train_loss": 0.0057842933971327375
      },
      {
        "epoch": 571,
        "reward": 0.5310227870941162,
        "val_loss": 0.002256528108513781,
        "train_loss": 0.0027659829737296184
      },
      {
        "epoch": 572,
        "reward": 0.6575611233711243,
        "val_loss": 0.0007846169340025101,
        "train_loss": 0.0026259815335484184
      },
      {
        "epoch": 573,
        "reward": 0.5780693292617798,
        "val_loss": 0.0015412963028731091,
        "train_loss": 0.0015815905611326832
      },
      {
        "epoch": 574,
        "reward": 0.3806135654449463,
        "val_loss": 0.007661582502935614,
        "train_loss": 0.0011515887431764545
      },
      {
        "epoch": 575,
        "reward": 0.3637220561504364,
        "val_loss": 0.008853563107550144,
        "train_loss": 0.011204380139063757
      },
      {
        "epoch": 576,
        "reward": 0.3121844530105591,
        "val_loss": 0.014043814901794707,
        "train_loss": 0.003494534695234436
      },
      {
        "epoch": 577,
        "reward": 0.5880187153816223,
        "val_loss": 0.001420156772448016,
        "train_loss": 0.008378322603395926
      },
      {
        "epoch": 578,
        "reward": 0.3510068356990814,
        "val_loss": 0.009890374461455005,
        "train_loss": 0.0012637666010190374
      },
      {
        "epoch": 579,
        "reward": 0.5467205047607422,
        "val_loss": 0.00198868104988443,
        "train_loss": 0.0043075448803182766
      },
      {
        "epoch": 580,
        "reward": 0.3630652129650116,
        "val_loss": 0.00890398318214076,
        "train_loss": 0.0025681296650033733
      },
      {
        "epoch": 581,
        "reward": 0.5970731973648071,
        "val_loss": 0.0013175306376069784,
        "train_loss": 0.0033492960803694306
      },
      {
        "epoch": 582,
        "reward": 0.561982274055481,
        "val_loss": 0.0017575264708804233,
        "train_loss": 0.0019260848901187554
      },
      {
        "epoch": 583,
        "reward": 0.3925275206565857,
        "val_loss": 0.0069290995597839355,
        "train_loss": 0.00226392301892002
      },
      {
        "epoch": 584,
        "reward": 0.26652607321739197,
        "val_loss": 0.02191057282366923,
        "train_loss": 0.0031752563999571768
      },
      {
        "epoch": 585,
        "reward": 0.6083874106407166,
        "val_loss": 0.0011987170603658473,
        "train_loss": 0.009728986281865777
      },
      {
        "epoch": 586,
        "reward": 0.47952863574028015,
        "val_loss": 0.003408225652362619,
        "train_loss": 0.0015915615234776991
      },
      {
        "epoch": 587,
        "reward": 0.2712400555610657,
        "val_loss": 0.02088454897914614,
        "train_loss": 0.0035521512707838644
      },
      {
        "epoch": 588,
        "reward": 0.3455996811389923,
        "val_loss": 0.010372991407556193,
        "train_loss": 0.006190186337335035
      },
      {
        "epoch": 589,
        "reward": 0.572317898273468,
        "val_loss": 0.0016155896841415337,
        "train_loss": 0.004629922578505312
      },
      {
        "epoch": 590,
        "reward": 0.5379292368888855,
        "val_loss": 0.0021346675431621926,
        "train_loss": 0.0015722263341068844
      },
      {
        "epoch": 591,
        "reward": 0.36922162771224976,
        "val_loss": 0.008443898255271571,
        "train_loss": 0.005769586070528021
      },
      {
        "epoch": 592,
        "reward": 0.42795130610466003,
        "val_loss": 0.005169411422684789,
        "train_loss": 0.003172004690546041
      },
      {
        "epoch": 593,
        "reward": 0.4975700080394745,
        "val_loss": 0.0029498946719935964,
        "train_loss": 0.0017281962903395582
      },
      {
        "epoch": 594,
        "reward": 0.6128057837486267,
        "val_loss": 0.0011549834411458246,
        "train_loss": 0.0021883225954997423
      },
      {
        "epoch": 595,
        "reward": 0.6125852465629578,
        "val_loss": 0.001157131786125579,
        "train_loss": 0.0014645352583521833
      },
      {
        "epoch": 596,
        "reward": 0.40673351287841797,
        "val_loss": 0.006155217265976327,
        "train_loss": 0.0018215499910114047
      },
      {
        "epoch": 597,
        "reward": 0.5094265341758728,
        "val_loss": 0.0026829261665365528,
        "train_loss": 0.0028785507736476855
      },
      {
        "epoch": 598,
        "reward": 0.6229779124259949,
        "val_loss": 0.0010596248820157988,
        "train_loss": 0.0017767791566886725
      },
      {
        "epoch": 599,
        "reward": 0.1216864138841629,
        "val_loss": 0.15072268779788697,
        "train_loss": 0.009651291922916872
      },
      {
        "epoch": 600,
        "reward": 0.12113819271326065,
        "val_loss": 0.15227994748524257,
        "train_loss": 0.14685190958194794
      },
      {
        "epoch": 601,
        "reward": 0.10338069498538971,
        "val_loss": 0.21762109441416605,
        "train_loss": 0.05994829267281322
      },
      {
        "epoch": 602,
        "reward": 0.08413820713758469,
        "val_loss": 0.3427970749991281,
        "train_loss": 0.10232187309324778
      },
      {
        "epoch": 603,
        "reward": 0.12343575060367584,
        "val_loss": 0.14589796321732657,
        "train_loss": 0.10928612684717966
      },
      {
        "epoch": 604,
        "reward": 0.13606072962284088,
        "val_loss": 0.11664454958268575,
        "train_loss": 0.06880546742244266
      },
      {
        "epoch": 605,
        "reward": 0.1262281984090805,
        "val_loss": 0.13862672661031997,
        "train_loss": 0.18716261153503394
      },
      {
        "epoch": 606,
        "reward": 0.09842362254858017,
        "val_loss": 0.24275600271565573,
        "train_loss": 0.3229866178992849
      },
      {
        "epoch": 607,
        "reward": 0.2791227400302887,
        "val_loss": 0.01929727555917842,
        "train_loss": 0.08905144653712901
      },
      {
        "epoch": 608,
        "reward": 0.25970372557640076,
        "val_loss": 0.023508145873035704,
        "train_loss": 0.020343682849600624
      },
      {
        "epoch": 609,
        "reward": 0.3827374279499054,
        "val_loss": 0.007524918964398759,
        "train_loss": 0.008535896718967706
      },
      {
        "epoch": 610,
        "reward": 0.2726437747478485,
        "val_loss": 0.02059049585035869,
        "train_loss": 0.013835764409472736
      },
      {
        "epoch": 611,
        "reward": 0.5038836598396301,
        "val_loss": 0.0028045954615143792,
        "train_loss": 0.010816782156605488
      },
      {
        "epoch": 612,
        "reward": 0.44202089309692383,
        "val_loss": 0.004610138812235424,
        "train_loss": 0.0034229365102454233
      },
      {
        "epoch": 613,
        "reward": 0.6293814182281494,
        "val_loss": 0.0010032062834527875,
        "train_loss": 0.001681403109194854
      },
      {
        "epoch": 614,
        "reward": 0.6329441666603088,
        "val_loss": 0.0009729648008942604,
        "train_loss": 0.001478639240443814
      },
      {
        "epoch": 615,
        "reward": 0.1700771450996399,
        "val_loss": 0.0688885652593204,
        "train_loss": 0.0019303914159536362
      },
      {
        "epoch": 616,
        "reward": 0.49180006980895996,
        "val_loss": 0.0030892681263919386,
        "train_loss": 0.017997170176805903
      },
      {
        "epoch": 617,
        "reward": 0.32730793952941895,
        "val_loss": 0.012220336922577449,
        "train_loss": 0.003717749148983365
      },
      {
        "epoch": 618,
        "reward": 0.3527994751930237,
        "val_loss": 0.009736114580716406,
        "train_loss": 0.010473260856367862
      },
      {
        "epoch": 619,
        "reward": 0.493967205286026,
        "val_loss": 0.0030361599222357783,
        "train_loss": 0.00359374714585451
      },
      {
        "epoch": 620,
        "reward": 0.5763487815856934,
        "val_loss": 0.0015631830153454626,
        "train_loss": 0.0011443655866269881
      },
      {
        "epoch": 621,
        "reward": 0.5091640949249268,
        "val_loss": 0.002688567104217197,
        "train_loss": 0.0009008798425873885
      },
      {
        "epoch": 622,
        "reward": 0.447609007358551,
        "val_loss": 0.004406150463702423,
        "train_loss": 0.0013932286775133645
      },
      {
        "epoch": 623,
        "reward": 0.37584230303764343,
        "val_loss": 0.007978865344609534,
        "train_loss": 0.0055978578300430225
      },
      {
        "epoch": 624,
        "reward": 0.5578281283378601,
        "val_loss": 0.0018177950654977135,
        "train_loss": 0.0057178000256849024
      },
      {
        "epoch": 625,
        "reward": 0.3095705509185791,
        "val_loss": 0.014390736618744475,
        "train_loss": 0.010903728301995076
      },
      {
        "epoch": 626,
        "reward": 0.22878141701221466,
        "val_loss": 0.032875865431768556,
        "train_loss": 0.014462388604162978
      },
      {
        "epoch": 627,
        "reward": 0.24772481620311737,
        "val_loss": 0.02667952887713909,
        "train_loss": 0.027358530554920435
      },
      {
        "epoch": 628,
        "reward": 0.2688029408454895,
        "val_loss": 0.021407437909926687,
        "train_loss": 0.012468005158902647
      },
      {
        "epoch": 629,
        "reward": 0.6031160354614258,
        "val_loss": 0.001252820690362049,
        "train_loss": 0.03168511234868605
      },
      {
        "epoch": 630,
        "reward": 0.6171692609786987,
        "val_loss": 0.001113189018464514,
        "train_loss": 0.002342859086079093
      },
      {
        "epoch": 631,
        "reward": 0.25469669699668884,
        "val_loss": 0.024773264436849525,
        "train_loss": 0.003925123254213339
      },
      {
        "epoch": 632,
        "reward": 0.34534427523612976,
        "val_loss": 0.010396452753671579,
        "train_loss": 0.01531087743765406
      },
      {
        "epoch": 633,
        "reward": 0.6424030065536499,
        "val_loss": 0.000896471444450851,
        "train_loss": 0.004169635926910604
      },
      {
        "epoch": 634,
        "reward": 0.1950695514678955,
        "val_loss": 0.04926079085894993,
        "train_loss": 0.0018315891435262389
      },
      {
        "epoch": 635,
        "reward": 0.12435759603977203,
        "val_loss": 0.1434407617364611,
        "train_loss": 0.04452084179949732
      },
      {
        "epoch": 636,
        "reward": 0.22413210570812225,
        "val_loss": 0.03466817843062537,
        "train_loss": 0.07182872692982738
      },
      {
        "epoch": 637,
        "reward": 0.08227550983428955,
        "val_loss": 0.35995408254010336,
        "train_loss": 0.019524917910950117
      },
      {
        "epoch": 638,
        "reward": 0.0762079581618309,
        "val_loss": 0.4251199258225305,
        "train_loss": 0.279975917082853
      },
      {
        "epoch": 639,
        "reward": 0.3614160716533661,
        "val_loss": 0.0090320165535169,
        "train_loss": 0.2727185720577836
      },
      {
        "epoch": 640,
        "reward": 0.1835355907678604,
        "val_loss": 0.057252908391611915,
        "train_loss": 0.021302453278062437
      },
      {
        "epoch": 641,
        "reward": 0.089678093791008,
        "val_loss": 0.29811298847198486,
        "train_loss": 0.031583071946023174
      },
      {
        "epoch": 642,
        "reward": 0.21632492542266846,
        "val_loss": 0.03796842774110181,
        "train_loss": 0.07348661106796218
      },
      {
        "epoch": 643,
        "reward": 0.15580645203590393,
        "val_loss": 0.08493308244006974,
        "train_loss": 0.029277334150929864
      },
      {
        "epoch": 644,
        "reward": 0.35703280568122864,
        "val_loss": 0.009382638481578656,
        "train_loss": 0.03630606525649245
      },
      {
        "epoch": 645,
        "reward": 0.5063947439193726,
        "val_loss": 0.002748811318139945,
        "train_loss": 0.0029941216388788936
      },
      {
        "epoch": 646,
        "reward": 0.6025441884994507,
        "val_loss": 0.0012588199876647974,
        "train_loss": 0.003155580753802776
      },
      {
        "epoch": 647,
        "reward": 0.3532737195491791,
        "val_loss": 0.00969576503017119,
        "train_loss": 0.0011152592957772028
      },
      {
        "epoch": 648,
        "reward": 0.5477997660636902,
        "val_loss": 0.0019714313841957066,
        "train_loss": 0.004214064896447011
      },
      {
        "epoch": 649,
        "reward": 0.6292309165000916,
        "val_loss": 0.0010045015619003347,
        "train_loss": 0.001809377185194395
      },
      {
        "epoch": 650,
        "reward": 0.4509457051753998,
        "val_loss": 0.004288897749834827,
        "train_loss": 0.001064451545691834
      },
      {
        "epoch": 651,
        "reward": 0.12016323953866959,
        "val_loss": 0.15510459297469684,
        "train_loss": 0.007512004777359275
      },
      {
        "epoch": 652,
        "reward": 0.08201636373996735,
        "val_loss": 0.3624370428068297,
        "train_loss": 0.2539393342796337
      },
      {
        "epoch": 653,
        "reward": 0.2823637127876282,
        "val_loss": 0.01868764903130276,
        "train_loss": 0.13512881075999197
      },
      {
        "epoch": 654,
        "reward": 0.4257662296295166,
        "val_loss": 0.005262578671265926,
        "train_loss": 0.015524797978846787
      },
      {
        "epoch": 655,
        "reward": 0.6320714354515076,
        "val_loss": 0.000980298433985029,
        "train_loss": 0.006091144271732236
      },
      {
        "epoch": 656,
        "reward": 0.21107612550258636,
        "val_loss": 0.040416227387530465,
        "train_loss": 0.0015170420385682238
      },
      {
        "epoch": 657,
        "reward": 0.4669000804424286,
        "val_loss": 0.0037716651069266455,
        "train_loss": 0.008757785508910624
      },
      {
        "epoch": 658,
        "reward": 0.31903061270713806,
        "val_loss": 0.013181175637458051,
        "train_loss": 0.004417207356919579
      },
      {
        "epoch": 659,
        "reward": 0.5011895895004272,
        "val_loss": 0.002865699918142387,
        "train_loss": 0.005710454372232421
      },
      {
        "epoch": 660,
        "reward": 0.6091210246086121,
        "val_loss": 0.0011913541155601187,
        "train_loss": 0.002534098702041704
      },
      {
        "epoch": 661,
        "reward": 0.3694266974925995,
        "val_loss": 0.00842904266236084,
        "train_loss": 0.0027912328368984163
      },
      {
        "epoch": 662,
        "reward": 0.37938186526298523,
        "val_loss": 0.007742112901593957,
        "train_loss": 0.004529674624791369
      },
      {
        "epoch": 663,
        "reward": 0.6687204241752625,
        "val_loss": 0.0007100092895728137,
        "train_loss": 0.0059384854262484275
      },
      {
        "epoch": 664,
        "reward": 0.6596031188964844,
        "val_loss": 0.0007704946495193456,
        "train_loss": 0.0011192051852748801
      },
      {
        "epoch": 665,
        "reward": 0.5133209824562073,
        "val_loss": 0.0026005838964400546,
        "train_loss": 0.0010107356009449666
      },
      {
        "epoch": 666,
        "reward": 0.6103845834732056,
        "val_loss": 0.0011787697356859489,
        "train_loss": 0.0025422478110368294
      },
      {
        "epoch": 667,
        "reward": 0.3039616644382477,
        "val_loss": 0.015170234787677015,
        "train_loss": 0.001789592882582488
      },
      {
        "epoch": 668,
        "reward": 0.18177685141563416,
        "val_loss": 0.058617881898369105,
        "train_loss": 0.01835823599070024
      },
      {
        "epoch": 669,
        "reward": 0.1538708209991455,
        "val_loss": 0.08748315434370722,
        "train_loss": 0.06335810997272627
      },
      {
        "epoch": 670,
        "reward": 0.07694435119628906,
        "val_loss": 0.4163570361477988,
        "train_loss": 0.05722961228233404
      },
      {
        "epoch": 671,
        "reward": 0.3042363226413727,
        "val_loss": 0.01513091049024037,
        "train_loss": 0.07615469702376196
      },
      {
        "epoch": 672,
        "reward": 0.11563128232955933,
        "val_loss": 0.1692309273140771,
        "train_loss": 0.034213779404616125
      },
      {
        "epoch": 673,
        "reward": 0.09442552924156189,
        "val_loss": 0.266092911362648,
        "train_loss": 0.12205473054200411
      },
      {
        "epoch": 674,
        "reward": 0.1908217966556549,
        "val_loss": 0.052023086696863174,
        "train_loss": 0.06127829732409177
      },
      {
        "epoch": 675,
        "reward": 0.10758542269468307,
        "val_loss": 0.19906280083315714,
        "train_loss": 0.021881042119975273
      },
      {
        "epoch": 676,
        "reward": 0.15703406929969788,
        "val_loss": 0.08336735064429897,
        "train_loss": 0.05784322151269477
      },
      {
        "epoch": 677,
        "reward": 0.17014960944652557,
        "val_loss": 0.06881788053682872,
        "train_loss": 0.14266132413803673
      },
      {
        "epoch": 678,
        "reward": 0.2880884110927582,
        "val_loss": 0.01766705433172839,
        "train_loss": 0.04607301608624626
      },
      {
        "epoch": 679,
        "reward": 0.3811582028865814,
        "val_loss": 0.007626275664993695,
        "train_loss": 0.007805874239868269
      },
      {
        "epoch": 680,
        "reward": 0.5041967034339905,
        "val_loss": 0.002797580324113369,
        "train_loss": 0.003907900650609428
      },
      {
        "epoch": 681,
        "reward": 0.30963394045829773,
        "val_loss": 0.014382202311285905,
        "train_loss": 0.0015843933081039442
      },
      {
        "epoch": 682,
        "reward": 0.6289416551589966,
        "val_loss": 0.0010069951448323472,
        "train_loss": 0.004822588514518709
      },
      {
        "epoch": 683,
        "reward": 0.3623995780944824,
        "val_loss": 0.008955411746033601,
        "train_loss": 0.0017480032609175676
      },
      {
        "epoch": 684,
        "reward": 0.28383147716522217,
        "val_loss": 0.01841929435197796,
        "train_loss": 0.005257047001997797
      },
      {
        "epoch": 685,
        "reward": 0.503292977809906,
        "val_loss": 0.0028178804287953036,
        "train_loss": 0.0047362479358875696
      },
      {
        "epoch": 686,
        "reward": 0.5081759691238403,
        "val_loss": 0.0027099100407212973,
        "train_loss": 0.002676442096484467
      },
      {
        "epoch": 687,
        "reward": 0.4177274703979492,
        "val_loss": 0.005621214430513126,
        "train_loss": 0.0011676403944595503
      },
      {
        "epoch": 688,
        "reward": 0.20390860736370087,
        "val_loss": 0.04409794136881828,
        "train_loss": 0.003693687017613019
      },
      {
        "epoch": 689,
        "reward": 0.5136613845825195,
        "val_loss": 0.0025935068427185926,
        "train_loss": 0.009746203340070609
      },
      {
        "epoch": 690,
        "reward": 0.4659467339515686,
        "val_loss": 0.003800671996681818,
        "train_loss": 0.0027103679133758237
      },
      {
        "epoch": 691,
        "reward": 0.5320133566856384,
        "val_loss": 0.0022386468980195267,
        "train_loss": 0.0016604943800932514
      },
      {
        "epoch": 692,
        "reward": 0.5136123299598694,
        "val_loss": 0.002594525061015572,
        "train_loss": 0.001751400848241666
      },
      {
        "epoch": 693,
        "reward": 0.4569275975227356,
        "val_loss": 0.00408680979827685,
        "train_loss": 0.0019181882761096438
      },
      {
        "epoch": 694,
        "reward": 0.5533937215805054,
        "val_loss": 0.0018842780264094472,
        "train_loss": 0.004667824214825837
      },
      {
        "epoch": 695,
        "reward": 0.42196112871170044,
        "val_loss": 0.005429164173879794,
        "train_loss": 0.002120679734686676
      },
      {
        "epoch": 696,
        "reward": 0.6505100131034851,
        "val_loss": 0.0008350743945421917,
        "train_loss": 0.001929306579628386
      },
      {
        "epoch": 697,
        "reward": 0.48225027322769165,
        "val_loss": 0.00333471320170377,
        "train_loss": 0.0013471132999536796
      },
      {
        "epoch": 698,
        "reward": 0.6545132398605347,
        "val_loss": 0.0008061014315379518,
        "train_loss": 0.005923710320180712
      },
      {
        "epoch": 699,
        "reward": 0.2541496455669403,
        "val_loss": 0.024916561586516246,
        "train_loss": 0.008319782514053468
      },
      {
        "epoch": 700,
        "reward": 0.5569543242454529,
        "val_loss": 0.0018307181474353587,
        "train_loss": 0.01282299216165064
      },
      {
        "epoch": 701,
        "reward": 0.3746670186519623,
        "val_loss": 0.008059263561985322,
        "train_loss": 0.0014741722096075066
      },
      {
        "epoch": 702,
        "reward": 0.5372236371040344,
        "val_loss": 0.0021468208537303974,
        "train_loss": 0.0031644505098274048
      },
      {
        "epoch": 703,
        "reward": 0.33349475264549255,
        "val_loss": 0.011555609559374196,
        "train_loss": 0.0016103162824247892
      },
      {
        "epoch": 704,
        "reward": 0.2254592627286911,
        "val_loss": 0.034144126410995214,
        "train_loss": 0.006118612088567506
      },
      {
        "epoch": 705,
        "reward": 0.510374128818512,
        "val_loss": 0.002662656396361334,
        "train_loss": 0.009536275335694181
      },
      {
        "epoch": 706,
        "reward": 0.6234318614006042,
        "val_loss": 0.0010555354778521828,
        "train_loss": 0.0012839885379295223
      },
      {
        "epoch": 707,
        "reward": 0.3041529059410095,
        "val_loss": 0.015142845389034067,
        "train_loss": 0.0014299946499075024
      },
      {
        "epoch": 708,
        "reward": 0.08787087351083755,
        "val_loss": 0.31173556191580637,
        "train_loss": 0.019540656940080225
      },
      {
        "epoch": 709,
        "reward": 0.24126151204109192,
        "val_loss": 0.02861355697470052,
        "train_loss": 0.09645450350721009
      },
      {
        "epoch": 710,
        "reward": 0.1930311620235443,
        "val_loss": 0.050561786496213505,
        "train_loss": 0.04170626882786074
      },
      {
        "epoch": 711,
        "reward": 0.38248199224472046,
        "val_loss": 0.0075412112886884385,
        "train_loss": 0.020198378503734533
      },
      {
        "epoch": 712,
        "reward": 0.1219840869307518,
        "val_loss": 0.14988633351666586,
        "train_loss": 0.005049926663139978
      },
      {
        "epoch": 713,
        "reward": 0.09402745962142944,
        "val_loss": 0.26858664623328615,
        "train_loss": 0.08466307870660855
      },
      {
        "epoch": 714,
        "reward": 0.11514153331518173,
        "val_loss": 0.17086268216371536,
        "train_loss": 0.08299589333070728
      },
      {
        "epoch": 715,
        "reward": 0.18257088959217072,
        "val_loss": 0.05799638054200581,
        "train_loss": 0.03841301640316557
      },
      {
        "epoch": 716,
        "reward": 0.4814719259738922,
        "val_loss": 0.003355569505531873,
        "train_loss": 0.014489270889988312
      },
      {
        "epoch": 717,
        "reward": 0.6632554531097412,
        "val_loss": 0.0007457669957407884,
        "train_loss": 0.0026743976779926015
      },
      {
        "epoch": 718,
        "reward": 0.6311677694320679,
        "val_loss": 0.000987943253546421,
        "train_loss": 0.0008390573336957739
      },
      {
        "epoch": 719,
        "reward": 0.4016275107860565,
        "val_loss": 0.006421846936323813,
        "train_loss": 0.0009018860773022214
      },
      {
        "epoch": 720,
        "reward": 0.6090126037597656,
        "val_loss": 0.0011924404950280274,
        "train_loss": 0.0014076929778988974
      },
      {
        "epoch": 721,
        "reward": 0.3526463210582733,
        "val_loss": 0.009749181502099549,
        "train_loss": 0.002535484207328409
      },
      {
        "epoch": 722,
        "reward": 0.3501616418361664,
        "val_loss": 0.009964078664779663,
        "train_loss": 0.010236217994063806
      },
      {
        "epoch": 723,
        "reward": 0.36267730593681335,
        "val_loss": 0.008933911831783397,
        "train_loss": 0.009941633404545987
      },
      {
        "epoch": 724,
        "reward": 0.37796661257743835,
        "val_loss": 0.00783581386453339,
        "train_loss": 0.009690892022962753
      },
      {
        "epoch": 725,
        "reward": 0.1699025183916092,
        "val_loss": 0.06905929797462054,
        "train_loss": 0.018034763822260384
      },
      {
        "epoch": 726,
        "reward": 0.12934310734272003,
        "val_loss": 0.1310904696583748,
        "train_loss": 0.07643002981337933
      },
      {
        "epoch": 727,
        "reward": 0.1495426744222641,
        "val_loss": 0.09357035639030593,
        "train_loss": 0.03342576573889416
      },
      {
        "epoch": 728,
        "reward": 0.2507311701774597,
        "val_loss": 0.025835835374891758,
        "train_loss": 0.030987026881820593
      },
      {
        "epoch": 729,
        "reward": 0.2647629678249359,
        "val_loss": 0.022310230348791395,
        "train_loss": 0.023785319217075503
      },
      {
        "epoch": 730,
        "reward": 0.3219568133354187,
        "val_loss": 0.012831667837287699,
        "train_loss": 0.011588439014023887
      },
      {
        "epoch": 731,
        "reward": 0.3059016466140747,
        "val_loss": 0.014895053314311164,
        "train_loss": 0.01906301833402652
      },
      {
        "epoch": 732,
        "reward": 0.40398263931274414,
        "val_loss": 0.006297324518007892,
        "train_loss": 0.013503824134554284
      },
      {
        "epoch": 733,
        "reward": 0.5590700507164001,
        "val_loss": 0.0017995775644002216,
        "train_loss": 0.0024886378288591425
      },
      {
        "epoch": 734,
        "reward": 0.5003342032432556,
        "val_loss": 0.002885376336053014,
        "train_loss": 0.002476711435100207
      },
      {
        "epoch": 735,
        "reward": 0.3047439157962799,
        "val_loss": 0.01505855065105217,
        "train_loss": 0.0033529487599690375
      },
      {
        "epoch": 736,
        "reward": 0.33114856481552124,
        "val_loss": 0.01180258925471987,
        "train_loss": 0.011767069084061613
      },
      {
        "epoch": 737,
        "reward": 0.47314387559890747,
        "val_loss": 0.0035872481197917034,
        "train_loss": 0.0076657193489014525
      },
      {
        "epoch": 738,
        "reward": 0.16804568469524384,
        "val_loss": 0.07091007621160575,
        "train_loss": 0.034879412434887715
      },
      {
        "epoch": 739,
        "reward": 0.21066848933696747,
        "val_loss": 0.04061471697475229,
        "train_loss": 0.055460225571340956
      },
      {
        "epoch": 740,
        "reward": 0.4110932946205139,
        "val_loss": 0.0059371197463146275,
        "train_loss": 0.014061208068456975
      },
      {
        "epoch": 741,
        "reward": 0.456221342086792,
        "val_loss": 0.004110142056431089,
        "train_loss": 0.003192142552087227
      },
      {
        "epoch": 742,
        "reward": 0.22417111694812775,
        "val_loss": 0.034652636519500186,
        "train_loss": 0.007803242339762689
      },
      {
        "epoch": 743,
        "reward": 0.1290103793144226,
        "val_loss": 0.13186826344047273,
        "train_loss": 0.014066240284591913
      },
      {
        "epoch": 744,
        "reward": 0.2713647186756134,
        "val_loss": 0.020858222086514746,
        "train_loss": 0.06434480917120639
      },
      {
        "epoch": 745,
        "reward": 0.24967411160469055,
        "val_loss": 0.02612862443285329,
        "train_loss": 0.010859913922523936
      },
      {
        "epoch": 746,
        "reward": 0.5101850628852844,
        "val_loss": 0.00266668844103281,
        "train_loss": 0.010336900987357903
      },
      {
        "epoch": 747,
        "reward": 0.6189347505569458,
        "val_loss": 0.0010966619343629905,
        "train_loss": 0.0037824187714319965
      },
      {
        "epoch": 748,
        "reward": 0.4689579904079437,
        "val_loss": 0.003709825121664575,
        "train_loss": 0.0011647695265799905
      },
      {
        "epoch": 749,
        "reward": 0.520026445388794,
        "val_loss": 0.0024646049132570624,
        "train_loss": 0.005102755856429352
      },
      {
        "epoch": 750,
        "reward": 0.2313658446073532,
        "val_loss": 0.031930411500590186,
        "train_loss": 0.009202779510815162
      },
      {
        "epoch": 751,
        "reward": 0.17712675034999847,
        "val_loss": 0.06243975992713656,
        "train_loss": 0.015337913538902424
      },
      {
        "epoch": 752,
        "reward": 0.6707284450531006,
        "val_loss": 0.0006972341839822807,
        "train_loss": 0.009628013553797114
      },
      {
        "epoch": 753,
        "reward": 0.551197350025177,
        "val_loss": 0.0019180516745629056,
        "train_loss": 0.0014123467329996997
      },
      {
        "epoch": 754,
        "reward": 0.4049321115016937,
        "val_loss": 0.006247874016740492,
        "train_loss": 0.007922952829214744
      },
      {
        "epoch": 755,
        "reward": 0.6115450859069824,
        "val_loss": 0.0011673149669409863,
        "train_loss": 0.00358249496247691
      },
      {
        "epoch": 756,
        "reward": 0.48131486773490906,
        "val_loss": 0.003359794250822493,
        "train_loss": 0.0016950705567768847
      },
      {
        "epoch": 757,
        "reward": 0.491879940032959,
        "val_loss": 0.003087294820163931,
        "train_loss": 0.006339720183929715
      },
      {
        "epoch": 758,
        "reward": 0.1754167377948761,
        "val_loss": 0.06392793783119746,
        "train_loss": 0.0019626277409350644
      },
      {
        "epoch": 759,
        "reward": 0.1997418850660324,
        "val_loss": 0.04643929377198219,
        "train_loss": 0.26631273114113496
      },
      {
        "epoch": 760,
        "reward": 0.5677483677864075,
        "val_loss": 0.0016769699286669493,
        "train_loss": 0.022190198003395032
      },
      {
        "epoch": 761,
        "reward": 0.5885404348373413,
        "val_loss": 0.0014140520610713533,
        "train_loss": 0.0027481757441329626
      },
      {
        "epoch": 762,
        "reward": 0.2635928988456726,
        "val_loss": 0.02258043350385768,
        "train_loss": 0.002658797719050199
      },
      {
        "epoch": 763,
        "reward": 0.25160443782806396,
        "val_loss": 0.0255970231124333,
        "train_loss": 0.006503184133460029
      },
      {
        "epoch": 764,
        "reward": 0.6759584546089172,
        "val_loss": 0.0006648521105359707,
        "train_loss": 0.01651548559535653
      },
      {
        "epoch": 765,
        "reward": 0.40284034609794617,
        "val_loss": 0.006357388703950814,
        "train_loss": 0.002156945164852704
      },
      {
        "epoch": 766,
        "reward": 0.6292913556098938,
        "val_loss": 0.0010039812020425285,
        "train_loss": 0.0016820319156417658
      },
      {
        "epoch": 767,
        "reward": 0.6708149909973145,
        "val_loss": 0.0006966876514655139,
        "train_loss": 0.0007750854442397562
      },
      {
        "epoch": 768,
        "reward": 0.562667727470398,
        "val_loss": 0.0017477640150380985,
        "train_loss": 0.0008949651293313274
      },
      {
        "epoch": 769,
        "reward": 0.2715030610561371,
        "val_loss": 0.02082905638962984,
        "train_loss": 0.002559473931726713
      },
      {
        "epoch": 770,
        "reward": 0.07975141704082489,
        "val_loss": 0.38520966257367817,
        "train_loss": 0.19681973652376866
      },
      {
        "epoch": 771,
        "reward": 0.2526697814464569,
        "val_loss": 0.025309423516903604,
        "train_loss": 0.09342806206684774
      },
      {
        "epoch": 772,
        "reward": 0.14248889684677124,
        "val_loss": 0.10478064577494349,
        "train_loss": 0.05418433915250576
      },
      {
        "epoch": 773,
        "reward": 0.13704223930835724,
        "val_loss": 0.1147186245237078,
        "train_loss": 0.04725816978428226
      },
      {
        "epoch": 774,
        "reward": 0.4136979579925537,
        "val_loss": 0.005810851264478905,
        "train_loss": 0.029575574803647423
      },
      {
        "epoch": 775,
        "reward": 0.13416671752929688,
        "val_loss": 0.12048766283052308,
        "train_loss": 0.0029238027233916978
      },
      {
        "epoch": 776,
        "reward": 0.13784073293209076,
        "val_loss": 0.11318359417574746,
        "train_loss": 0.0755617227853061
      },
      {
        "epoch": 777,
        "reward": 0.4442380964756012,
        "val_loss": 0.0045280323496886665,
        "train_loss": 0.017470536498317066
      },
      {
        "epoch": 778,
        "reward": 0.26817697286605835,
        "val_loss": 0.021544329822063446,
        "train_loss": 0.018634849048864383
      },
      {
        "epoch": 779,
        "reward": 0.17913438379764557,
        "val_loss": 0.060750500432082584,
        "train_loss": 0.08923507288384896
      },
      {
        "epoch": 780,
        "reward": 0.1605795919895172,
        "val_loss": 0.07905729966504234,
        "train_loss": 0.04205058918047983
      },
      {
        "epoch": 781,
        "reward": 0.46437153220176697,
        "val_loss": 0.003849106208820428,
        "train_loss": 0.018029368807149764
      },
      {
        "epoch": 782,
        "reward": 0.42145633697509766,
        "val_loss": 0.005451685865409672,
        "train_loss": 0.003271375155936067
      },
      {
        "epoch": 783,
        "reward": 0.39870399236679077,
        "val_loss": 0.006580203172883817,
        "train_loss": 0.0033136572433599774
      },
      {
        "epoch": 784,
        "reward": 0.1529737263917923,
        "val_loss": 0.08870001137256622,
        "train_loss": 0.013928086779882366
      },
      {
        "epoch": 785,
        "reward": 0.25463494658470154,
        "val_loss": 0.024789389755044664,
        "train_loss": 0.036346290923225194
      },
      {
        "epoch": 786,
        "reward": 0.6205718517303467,
        "val_loss": 0.0010815302625165454,
        "train_loss": 0.010724289844242426
      },
      {
        "epoch": 787,
        "reward": 0.15673789381980896,
        "val_loss": 0.0837415222610746,
        "train_loss": 0.02232111045025074
      },
      {
        "epoch": 788,
        "reward": 0.24900467693805695,
        "val_loss": 0.02631619599248682,
        "train_loss": 0.06681966536248532
      },
      {
        "epoch": 789,
        "reward": 0.22397182881832123,
        "val_loss": 0.03473217040300369,
        "train_loss": 0.01939878203288222
      },
      {
        "epoch": 790,
        "reward": 0.13682477176189423,
        "val_loss": 0.11514156152095113,
        "train_loss": 0.04399745917180553
      },
      {
        "epoch": 791,
        "reward": 0.11835408210754395,
        "val_loss": 0.16054086174283708,
        "train_loss": 0.0956229197864349
      },
      {
        "epoch": 792,
        "reward": 0.34104403853416443,
        "val_loss": 0.010800790041685104,
        "train_loss": 0.03410567610990256
      },
      {
        "epoch": 793,
        "reward": 0.2898612916469574,
        "val_loss": 0.01736479438841343,
        "train_loss": 0.010266632699103165
      },
      {
        "epoch": 794,
        "reward": 0.2828740179538727,
        "val_loss": 0.018593817949295044,
        "train_loss": 0.004607269524757822
      },
      {
        "epoch": 795,
        "reward": 0.494610995054245,
        "val_loss": 0.0030205626639404465,
        "train_loss": 0.010765265395793203
      },
      {
        "epoch": 796,
        "reward": 0.20101825892925262,
        "val_loss": 0.045705274279628484,
        "train_loss": 0.0024175141835047933
      },
      {
        "epoch": 797,
        "reward": 0.3329254388809204,
        "val_loss": 0.011614983202889562,
        "train_loss": 0.026196004826348283
      },
      {
        "epoch": 798,
        "reward": 0.4611203372478485,
        "val_loss": 0.003951106569729745,
        "train_loss": 0.007932423699038247
      },
      {
        "epoch": 799,
        "reward": 0.32567641139030457,
        "val_loss": 0.012403028684535198,
        "train_loss": 0.003109175030728623
      },
      {
        "epoch": 800,
        "reward": 0.22958090901374817,
        "val_loss": 0.03257963513689382,
        "train_loss": 0.01702590924777234
      },
      {
        "epoch": 801,
        "reward": 0.09700081497430801,
        "val_loss": 0.2507192556347166,
        "train_loss": 0.027306381355559167
      },
      {
        "epoch": 802,
        "reward": 0.39445266127586365,
        "val_loss": 0.0068182034551032954,
        "train_loss": 0.1287913379044487
      },
      {
        "epoch": 803,
        "reward": 0.29826727509498596,
        "val_loss": 0.016013859372053827,
        "train_loss": 0.027839104510628834
      },
      {
        "epoch": 804,
        "reward": 0.46653077006340027,
        "val_loss": 0.003782873341281499,
        "train_loss": 0.014907551576750567
      },
      {
        "epoch": 805,
        "reward": 0.5320081114768982,
        "val_loss": 0.002238741152853306,
        "train_loss": 0.0027735941056072568
      },
      {
        "epoch": 806,
        "reward": 0.48358240723609924,
        "val_loss": 0.0032993223617917727,
        "train_loss": 0.0020346000875668744
      },
      {
        "epoch": 807,
        "reward": 0.4062678813934326,
        "val_loss": 0.006179022868829114,
        "train_loss": 0.0027521883379309797
      },
      {
        "epoch": 808,
        "reward": 0.23801426589488983,
        "val_loss": 0.029651814539517676,
        "train_loss": 0.006387949715225169
      },
      {
        "epoch": 809,
        "reward": 0.17982399463653564,
        "val_loss": 0.060184204684836526,
        "train_loss": 0.025792855536565185
      },
      {
        "epoch": 810,
        "reward": 0.37133467197418213,
        "val_loss": 0.008292234968394041,
        "train_loss": 0.024769941792048764
      },
      {
        "epoch": 811,
        "reward": 0.492727130651474,
        "val_loss": 0.00306643675347524,
        "train_loss": 0.0023241459644990615
      },
      {
        "epoch": 812,
        "reward": 0.49993380904197693,
        "val_loss": 0.002894634347675102,
        "train_loss": 0.003570786844569249
      },
      {
        "epoch": 813,
        "reward": 0.6326282620429993,
        "val_loss": 0.0009756136569194496,
        "train_loss": 0.001086673041125043
      },
      {
        "epoch": 814,
        "reward": 0.5756492018699646,
        "val_loss": 0.0015721644574244107,
        "train_loss": 0.0013723719032266391
      },
      {
        "epoch": 815,
        "reward": 0.30350807309150696,
        "val_loss": 0.015235452779701777,
        "train_loss": 0.0022120603154270123
      },
      {
        "epoch": 816,
        "reward": 0.20884285867214203,
        "val_loss": 0.04151929861732891,
        "train_loss": 0.008752103872561397
      },
      {
        "epoch": 817,
        "reward": 0.15263649821281433,
        "val_loss": 0.08916333104882922,
        "train_loss": 0.06157158134737983
      },
      {
        "epoch": 818,
        "reward": 0.05669912323355675,
        "val_loss": 0.8007766945021493,
        "train_loss": 0.041254330229444
      },
      {
        "epoch": 819,
        "reward": 0.3212953507900238,
        "val_loss": 0.012909710274210997,
        "train_loss": 0.1883373567207645
      },
      {
        "epoch": 820,
        "reward": 0.4789259433746338,
        "val_loss": 0.0034247260108324034,
        "train_loss": 0.006890207083555511
      },
      {
        "epoch": 821,
        "reward": 0.595453679561615,
        "val_loss": 0.0013353780543963825,
        "train_loss": 0.002364829802760281
      },
      {
        "epoch": 822,
        "reward": 0.6051373481750488,
        "val_loss": 0.001231821985649211,
        "train_loss": 0.0017117546717949712
      },
      {
        "epoch": 823,
        "reward": 0.23401521146297455,
        "val_loss": 0.030996733478137424,
        "train_loss": 0.0059339780575380875
      },
      {
        "epoch": 824,
        "reward": 0.25915318727493286,
        "val_loss": 0.023643264680036476,
        "train_loss": 0.023759450432128057
      },
      {
        "epoch": 825,
        "reward": 0.4002366065979004,
        "val_loss": 0.006496656087360212,
        "train_loss": 0.007514205671143897
      },
      {
        "epoch": 826,
        "reward": 0.4101882874965668,
        "val_loss": 0.0059816913147057805,
        "train_loss": 0.001745644152693925
      },
      {
        "epoch": 827,
        "reward": 0.6297304034233093,
        "val_loss": 0.0010002086970156857,
        "train_loss": 0.0047553430866593355
      },
      {
        "epoch": 828,
        "reward": 0.2317822277545929,
        "val_loss": 0.03178133815526962,
        "train_loss": 0.0013913039091186454
      },
      {
        "epoch": 829,
        "reward": 0.1536230593919754,
        "val_loss": 0.08781696802803449,
        "train_loss": 0.00783883273610487
      },
      {
        "epoch": 830,
        "reward": 0.3404170870780945,
        "val_loss": 0.010861247910984926,
        "train_loss": 0.03221816627606481
      },
      {
        "epoch": 831,
        "reward": 0.13443660736083984,
        "val_loss": 0.11992959039551872,
        "train_loss": 0.004769703950912047
      },
      {
        "epoch": 832,
        "reward": 0.21171057224273682,
        "val_loss": 0.040109752411288876,
        "train_loss": 0.0648975648006084
      },
      {
        "epoch": 833,
        "reward": 0.17829769849777222,
        "val_loss": 0.06144707703164646,
        "train_loss": 0.02283011195070755
      },
      {
        "epoch": 834,
        "reward": 0.2014281302690506,
        "val_loss": 0.04547278157302311,
        "train_loss": 0.03565048666468311
      },
      {
        "epoch": 835,
        "reward": 0.38204678893089294,
        "val_loss": 0.007569056004285812,
        "train_loss": 0.009908994776196778
      },
      {
        "epoch": 836,
        "reward": 0.4569430351257324,
        "val_loss": 0.004086300165259412,
        "train_loss": 0.005135003207692206
      },
      {
        "epoch": 837,
        "reward": 0.31442174315452576,
        "val_loss": 0.013754746011857475,
        "train_loss": 0.004308512321306177
      },
      {
        "epoch": 838,
        "reward": 0.6389988660812378,
        "val_loss": 0.0009233808544065271,
        "train_loss": 0.004808168080881632
      },
      {
        "epoch": 839,
        "reward": 0.6040323972702026,
        "val_loss": 0.0012432620860636234,
        "train_loss": 0.00104096790458313
      },
      {
        "epoch": 840,
        "reward": 0.5496649146080017,
        "val_loss": 0.0019419552824859107,
        "train_loss": 0.0010599732945243327
      },
      {
        "epoch": 841,
        "reward": 0.5430105924606323,
        "val_loss": 0.0020490824577531646,
        "train_loss": 0.0007817529969123335
      },
      {
        "epoch": 842,
        "reward": 0.5559344291687012,
        "val_loss": 0.0018459106629182185,
        "train_loss": 0.0019414397288178757
      },
      {
        "epoch": 843,
        "reward": 0.35376301407814026,
        "val_loss": 0.009654338138976268,
        "train_loss": 0.0022289166652346747
      },
      {
        "epoch": 844,
        "reward": 0.5178219676017761,
        "val_loss": 0.002508520514571241,
        "train_loss": 0.0043418011594509994
      },
      {
        "epoch": 845,
        "reward": 0.3127787709236145,
        "val_loss": 0.01396633218973875,
        "train_loss": 0.0017366899517478136
      },
      {
        "epoch": 846,
        "reward": 0.26647159457206726,
        "val_loss": 0.021922779934746877,
        "train_loss": 0.002111321843515795
      },
      {
        "epoch": 847,
        "reward": 0.5713500380516052,
        "val_loss": 0.001628414262086153,
        "train_loss": 0.0040423626845809985
      },
      {
        "epoch": 848,
        "reward": 0.3588259220123291,
        "val_loss": 0.009237362271440881,
        "train_loss": 0.0022729066381893624
      },
      {
        "epoch": 849,
        "reward": 0.29073259234428406,
        "val_loss": 0.017218538027788912,
        "train_loss": 0.003812807992709657
      },
      {
        "epoch": 850,
        "reward": 0.3608453571796417,
        "val_loss": 0.009076811905418123,
        "train_loss": 0.01236124897751814
      },
      {
        "epoch": 851,
        "reward": 0.265688419342041,
        "val_loss": 0.022099333815276623,
        "train_loss": 0.007017792000344623
      },
      {
        "epoch": 852,
        "reward": 0.4289720952510834,
        "val_loss": 0.005126491887494922,
        "train_loss": 0.004788760148725347
      },
      {
        "epoch": 853,
        "reward": 0.32800692319869995,
        "val_loss": 0.012143035286239215,
        "train_loss": 0.0016151512480484177
      },
      {
        "epoch": 854,
        "reward": 0.28178855776786804,
        "val_loss": 0.01879410379167114,
        "train_loss": 0.009566850863988154
      },
      {
        "epoch": 855,
        "reward": 0.4423997104167938,
        "val_loss": 0.004596001335552761,
        "train_loss": 0.005724701246855637
      },
      {
        "epoch": 856,
        "reward": 0.3301270306110382,
        "val_loss": 0.011912045601223196,
        "train_loss": 0.0026925222258656644
      },
      {
        "epoch": 857,
        "reward": 0.2833978831768036,
        "val_loss": 0.018498087035758153,
        "train_loss": 0.008167683064059999
      },
      {
        "epoch": 858,
        "reward": 0.23322705924510956,
        "val_loss": 0.03127082543713706,
        "train_loss": 0.015578488702885807
      },
      {
        "epoch": 859,
        "reward": 0.5984646677970886,
        "val_loss": 0.0013023693630072688,
        "train_loss": 0.01357268485858535
      },
      {
        "epoch": 860,
        "reward": 0.6447992324829102,
        "val_loss": 0.0008779353811405599,
        "train_loss": 0.0015500310020378004
      },
      {
        "epoch": 861,
        "reward": 0.591052770614624,
        "val_loss": 0.0013849866476708225,
        "train_loss": 0.0012765334563132806
      },
      {
        "epoch": 862,
        "reward": 0.47617706656455994,
        "val_loss": 0.0035010292860014097,
        "train_loss": 0.00145894889171289
      },
      {
        "epoch": 863,
        "reward": 0.3098883628845215,
        "val_loss": 0.014348016519631659,
        "train_loss": 0.006501623089067065
      },
      {
        "epoch": 864,
        "reward": 0.20738540589809418,
        "val_loss": 0.04226018914154598,
        "train_loss": 0.011654606003022448
      },
      {
        "epoch": 865,
        "reward": 0.14810322225093842,
        "val_loss": 0.09572129749826022,
        "train_loss": 0.020388209623678658
      },
      {
        "epoch": 866,
        "reward": 0.28169989585876465,
        "val_loss": 0.018810579287154332,
        "train_loss": 0.0743010639741372
      },
      {
        "epoch": 867,
        "reward": 0.27448761463165283,
        "val_loss": 0.02021193171718291,
        "train_loss": 0.055791632254393056
      },
      {
        "epoch": 868,
        "reward": 0.06043308973312378,
        "val_loss": 0.6993095832211631,
        "train_loss": 0.10375096022527522
      },
      {
        "epoch": 869,
        "reward": 0.053422655910253525,
        "val_loss": 0.9082908289773124,
        "train_loss": 0.7048912896917989
      },
      {
        "epoch": 870,
        "reward": 0.1663726419210434,
        "val_loss": 0.07263462139027459,
        "train_loss": 0.3052805612499539
      },
      {
        "epoch": 871,
        "reward": 0.40893909335136414,
        "val_loss": 0.006043812060462577,
        "train_loss": 0.02578457539199847
      },
      {
        "epoch": 872,
        "reward": 0.42320796847343445,
        "val_loss": 0.005373961558299405,
        "train_loss": 0.004283908528472798
      },
      {
        "epoch": 873,
        "reward": 0.3976493179798126,
        "val_loss": 0.006638378304030214,
        "train_loss": 0.0034481346575865666
      },
      {
        "epoch": 874,
        "reward": 0.3760177493095398,
        "val_loss": 0.007966938295534678,
        "train_loss": 0.0029972009383177813
      },
      {
        "epoch": 875,
        "reward": 0.501678466796875,
        "val_loss": 0.0028545140022678034,
        "train_loss": 0.0018409705132416303
      },
      {
        "epoch": 876,
        "reward": 0.4948500096797943,
        "val_loss": 0.003014790526192103,
        "train_loss": 0.0018899544341435942
      },
      {
        "epoch": 877,
        "reward": 0.5836567282676697,
        "val_loss": 0.0014721486368216574,
        "train_loss": 0.001397768355673179
      },
      {
        "epoch": 878,
        "reward": 0.5583484172821045,
        "val_loss": 0.001810141755933208,
        "train_loss": 0.0012041968606913893
      },
      {
        "epoch": 879,
        "reward": 0.6776242852210999,
        "val_loss": 0.0006548026659792024,
        "train_loss": 0.0020588358546284814
      },
      {
        "epoch": 880,
        "reward": 0.5120572447776794,
        "val_loss": 0.0026270259570862564,
        "train_loss": 0.0015118679663058943
      },
      {
        "epoch": 881,
        "reward": 0.285763144493103,
        "val_loss": 0.018073230316596373,
        "train_loss": 0.0021123574764575236
      },
      {
        "epoch": 882,
        "reward": 0.4091702103614807,
        "val_loss": 0.006032265390136412,
        "train_loss": 0.013763329582826164
      },
      {
        "epoch": 883,
        "reward": 0.22123722732067108,
        "val_loss": 0.035847394594124386,
        "train_loss": 0.0030077562685339497
      },
      {
        "epoch": 884,
        "reward": 0.20034773647785187,
        "val_loss": 0.04608898130910737,
        "train_loss": 0.017447413787522237
      },
      {
        "epoch": 885,
        "reward": 0.48392969369888306,
        "val_loss": 0.003290158064503755,
        "train_loss": 0.012041452063455766
      },
      {
        "epoch": 886,
        "reward": 0.4252532124519348,
        "val_loss": 0.0052847164084336585,
        "train_loss": 0.001986734116594737
      },
      {
        "epoch": 887,
        "reward": 0.5363610982894897,
        "val_loss": 0.0021617679823456065,
        "train_loss": 0.0023681637551887366
      },
      {
        "epoch": 888,
        "reward": 0.5812893509864807,
        "val_loss": 0.0015010907580809934,
        "train_loss": 0.0019781479853778505
      },
      {
        "epoch": 889,
        "reward": 0.4100641906261444,
        "val_loss": 0.005987832522285836,
        "train_loss": 0.001624150343839294
      },
      {
        "epoch": 890,
        "reward": 0.30357035994529724,
        "val_loss": 0.015226479486695357,
        "train_loss": 0.022592321709873013
      },
      {
        "epoch": 891,
        "reward": 0.509232223033905,
        "val_loss": 0.0026871011525924715,
        "train_loss": 0.004895668080560147
      },
      {
        "epoch": 892,
        "reward": 0.22767527401447296,
        "val_loss": 0.03329138218292168,
        "train_loss": 0.007429231016431004
      },
      {
        "epoch": 893,
        "reward": 0.4551528990268707,
        "val_loss": 0.004145705207650151,
        "train_loss": 0.017275135496255152
      },
      {
        "epoch": 894,
        "reward": 0.3681977093219757,
        "val_loss": 0.008518514489488942,
        "train_loss": 0.0023278311978524122
      },
      {
        "epoch": 895,
        "reward": 0.25506994128227234,
        "val_loss": 0.02467607693480594,
        "train_loss": 0.016193491122416723
      },
      {
        "epoch": 896,
        "reward": 0.1328875869512558,
        "val_loss": 0.1231815330684185,
        "train_loss": 0.03404722726330734
      },
      {
        "epoch": 897,
        "reward": 0.09725628048181534,
        "val_loss": 0.24926272460392543,
        "train_loss": 0.06929128155063242
      },
      {
        "epoch": 898,
        "reward": 0.25332003831863403,
        "val_loss": 0.02513585239648819,
        "train_loss": 0.045069999527186155
      },
      {
        "epoch": 899,
        "reward": 0.43052130937576294,
        "val_loss": 0.005062085775924581,
        "train_loss": 0.006372047373308585
      },
      {
        "epoch": 900,
        "reward": 0.18466375768184662,
        "val_loss": 0.05639930495194027,
        "train_loss": 0.006637783447961108
      },
      {
        "epoch": 901,
        "reward": 0.16020002961158752,
        "val_loss": 0.07950422806399209,
        "train_loss": 0.06298668151990008
      },
      {
        "epoch": 902,
        "reward": 0.1265110969543457,
        "val_loss": 0.13791808592421667,
        "train_loss": 0.1425351186727102
      },
      {
        "epoch": 903,
        "reward": 0.19466036558151245,
        "val_loss": 0.04951842315495014,
        "train_loss": 0.031619893407108836
      },
      {
        "epoch": 904,
        "reward": 0.2247426062822342,
        "val_loss": 0.03442585175590856,
        "train_loss": 0.03491523860094066
      },
      {
        "epoch": 905,
        "reward": 0.29983848333358765,
        "val_loss": 0.01577558381749051,
        "train_loss": 0.008719517022165326
      },
      {
        "epoch": 906,
        "reward": 0.6636778712272644,
        "val_loss": 0.0007429503187138055,
        "train_loss": 0.004152090111277245
      },
      {
        "epoch": 907,
        "reward": 0.6430942416191101,
        "val_loss": 0.0008910899299995176,
        "train_loss": 0.0014765856172184262
      },
      {
        "epoch": 908,
        "reward": 0.629999577999115,
        "val_loss": 0.0009979015199600586,
        "train_loss": 0.0009541569183616397
      },
      {
        "epoch": 909,
        "reward": 0.5566619038581848,
        "val_loss": 0.0018350623847384537,
        "train_loss": 0.0015012478979770094
      },
      {
        "epoch": 910,
        "reward": 0.3606949746608734,
        "val_loss": 0.009088658128998109,
        "train_loss": 0.0020101701705313576
      },
      {
        "epoch": 911,
        "reward": 0.5776140093803406,
        "val_loss": 0.0015470606324795102,
        "train_loss": 0.002089159639126592
      },
      {
        "epoch": 912,
        "reward": 0.4743689000606537,
        "val_loss": 0.003552166046574712,
        "train_loss": 0.002824634065081437
      },
      {
        "epoch": 913,
        "reward": 0.6643913388252258,
        "val_loss": 0.0007382139696606568,
        "train_loss": 0.002066005616842841
      },
      {
        "epoch": 914,
        "reward": 0.25789332389831543,
        "val_loss": 0.023956101121647016,
        "train_loss": 0.0024561189191165166
      },
      {
        "epoch": 915,
        "reward": 0.30652663111686707,
        "val_loss": 0.014807670643287045,
        "train_loss": 0.02640434147682614
      },
      {
        "epoch": 916,
        "reward": 0.24036720395088196,
        "val_loss": 0.02889486708279167,
        "train_loss": 0.0068062055126154935
      },
      {
        "epoch": 917,
        "reward": 0.0835811048746109,
        "val_loss": 0.34780477413109373,
        "train_loss": 0.04565602430375293
      },
      {
        "epoch": 918,
        "reward": 0.2427148073911667,
        "val_loss": 0.028163723913686618,
        "train_loss": 0.14646196977880138
      },
      {
        "epoch": 919,
        "reward": 0.3354131579399109,
        "val_loss": 0.011358136311173439,
        "train_loss": 0.02207116276706354
      },
      {
        "epoch": 920,
        "reward": 0.6511476635932922,
        "val_loss": 0.0008304014419471579,
        "train_loss": 0.005692917584943084
      },
      {
        "epoch": 921,
        "reward": 0.44565725326538086,
        "val_loss": 0.004476292956886547,
        "train_loss": 0.00253212850797214
      },
      {
        "epoch": 922,
        "reward": 0.49933162331581116,
        "val_loss": 0.002908612701243588,
        "train_loss": 0.0019791387950975218
      },
      {
        "epoch": 923,
        "reward": 0.5066681504249573,
        "val_loss": 0.0027428038052416275,
        "train_loss": 0.0012334932367733787
      },
      {
        "epoch": 924,
        "reward": 0.6353694796562195,
        "val_loss": 0.0009528333986444133,
        "train_loss": 0.0010708977743678798
      },
      {
        "epoch": 925,
        "reward": 0.5073623061180115,
        "val_loss": 0.0027276117886815754,
        "train_loss": 0.001976465757112377
      },
      {
        "epoch": 926,
        "reward": 0.13598094880580902,
        "val_loss": 0.11680302609290395,
        "train_loss": 0.002919079158276033
      },
      {
        "epoch": 927,
        "reward": 0.17519055306911469,
        "val_loss": 0.06412827436413084,
        "train_loss": 0.22171649838296267
      },
      {
        "epoch": 928,
        "reward": 0.5890966653823853,
        "val_loss": 0.0014075702970980533,
        "train_loss": 0.012045761300844159
      },
      {
        "epoch": 929,
        "reward": 0.44381484389305115,
        "val_loss": 0.004543586600837963,
        "train_loss": 0.0014535983881125082
      },
      {
        "epoch": 930,
        "reward": 0.254678338766098,
        "val_loss": 0.02477805076965264,
        "train_loss": 0.004912401775632484
      },
      {
        "epoch": 931,
        "reward": 0.22754192352294922,
        "val_loss": 0.033341929715658934,
        "train_loss": 0.014340231571203241
      },
      {
        "epoch": 932,
        "reward": 0.3842996060848236,
        "val_loss": 0.00742613135038742,
        "train_loss": 0.02201175746089435
      },
      {
        "epoch": 933,
        "reward": 0.23989401757717133,
        "val_loss": 0.02904511775289263,
        "train_loss": 0.0034124573173287967
      },
      {
        "epoch": 934,
        "reward": 0.18991126120090485,
        "val_loss": 0.05264140692140375,
        "train_loss": 0.021159525002496175
      },
      {
        "epoch": 935,
        "reward": 0.16897150874137878,
        "val_loss": 0.06997913388269288,
        "train_loss": 0.058791743589189045
      },
      {
        "epoch": 936,
        "reward": 0.21137790381908417,
        "val_loss": 0.040270064026117325,
        "train_loss": 0.034716057836004226
      },
      {
        "epoch": 937,
        "reward": 0.2562102973461151,
        "val_loss": 0.024382081015833786,
        "train_loss": 0.023643361887199996
      },
      {
        "epoch": 938,
        "reward": 0.36312320828437805,
        "val_loss": 0.008899519619132792,
        "train_loss": 0.01218782956353747
      },
      {
        "epoch": 939,
        "reward": 0.20133402943611145,
        "val_loss": 0.04552601969667843,
        "train_loss": 0.013745268690399826
      },
      {
        "epoch": 940,
        "reward": 0.23482809960842133,
        "val_loss": 0.03071719647518226,
        "train_loss": 0.06367644872695494
      },
      {
        "epoch": 941,
        "reward": 0.26254311203956604,
        "val_loss": 0.022826308384537697,
        "train_loss": 0.018620236428642575
      },
      {
        "epoch": 942,
        "reward": 0.35583582520484924,
        "val_loss": 0.009481072824980532,
        "train_loss": 0.005922299635130912
      },
      {
        "epoch": 943,
        "reward": 0.1827581375837326,
        "val_loss": 0.05785107373126915,
        "train_loss": 0.010210283321682185
      },
      {
        "epoch": 944,
        "reward": 0.4140119254589081,
        "val_loss": 0.0057958286821043915,
        "train_loss": 0.02531540219206363
      },
      {
        "epoch": 945,
        "reward": 0.3944607973098755,
        "val_loss": 0.006817742450428861,
        "train_loss": 0.002729206340251704
      },
      {
        "epoch": 946,
        "reward": 0.4756719768047333,
        "val_loss": 0.0035152381751686335,
        "train_loss": 0.0036834646505387635
      },
      {
        "epoch": 947,
        "reward": 0.5513402223587036,
        "val_loss": 0.00191583698948047,
        "train_loss": 0.0016794602829927148
      },
      {
        "epoch": 948,
        "reward": 0.5446410775184631,
        "val_loss": 0.0020223238721622954,
        "train_loss": 0.0024216741597998547
      },
      {
        "epoch": 949,
        "reward": 0.44595852494239807,
        "val_loss": 0.004465388766090784,
        "train_loss": 0.002107636180321256
      },
      {
        "epoch": 950,
        "reward": 0.21990683674812317,
        "val_loss": 0.03640652687421867,
        "train_loss": 0.0035026270376804928
      },
      {
        "epoch": 951,
        "reward": 0.6168970465660095,
        "val_loss": 0.0011157563837644244,
        "train_loss": 0.01797968280600169
      },
      {
        "epoch": 952,
        "reward": 0.5400036573410034,
        "val_loss": 0.002099321905656585,
        "train_loss": 0.0028495516722054724
      },
      {
        "epoch": 953,
        "reward": 0.33670732378959656,
        "val_loss": 0.011227137143058437,
        "train_loss": 0.0035332979325455828
      },
      {
        "epoch": 954,
        "reward": 0.4284310042858124,
        "val_loss": 0.0051491945050656796,
        "train_loss": 0.01062988487963314
      },
      {
        "epoch": 955,
        "reward": 0.3785494267940521,
        "val_loss": 0.007797074637242726,
        "train_loss": 0.006881825209487802
      },
      {
        "epoch": 956,
        "reward": 0.5201463103294373,
        "val_loss": 0.002462240933839764,
        "train_loss": 0.01852360094422833
      },
      {
        "epoch": 957,
        "reward": 0.216495543718338,
        "val_loss": 0.03789210931531021,
        "train_loss": 0.002400366134959488
      },
      {
        "epoch": 958,
        "reward": 0.3999268412590027,
        "val_loss": 0.006513449962117842,
        "train_loss": 0.011764753632842958
      },
      {
        "epoch": 959,
        "reward": 0.44555360078811646,
        "val_loss": 0.004480050344552312,
        "train_loss": 0.0028672160047930307
      },
      {
        "epoch": 960,
        "reward": 0.6777747869491577,
        "val_loss": 0.0006539009128963309,
        "train_loss": 0.001280079835851211
      },
      {
        "epoch": 961,
        "reward": 0.2867729961872101,
        "val_loss": 0.017895457201770375,
        "train_loss": 0.00532855381607078
      },
      {
        "epoch": 962,
        "reward": 0.34907108545303345,
        "val_loss": 0.01006011977525694,
        "train_loss": 0.011163090836502167
      },
      {
        "epoch": 963,
        "reward": 0.3017460107803345,
        "val_loss": 0.015491997956165246,
        "train_loss": 0.008596528684183095
      },
      {
        "epoch": 964,
        "reward": 0.19413742423057556,
        "val_loss": 0.049850228907806535,
        "train_loss": 0.004426549844748269
      },
      {
        "epoch": 965,
        "reward": 0.3811749815940857,
        "val_loss": 0.0076251910733325145,
        "train_loss": 0.02242108747081007
      },
      {
        "epoch": 966,
        "reward": 0.21985915303230286,
        "val_loss": 0.036426774359175136,
        "train_loss": 0.004788661688508
      },
      {
        "epoch": 967,
        "reward": 0.1731242686510086,
        "val_loss": 0.0659976207784244,
        "train_loss": 0.011751377993137933
      },
      {
        "epoch": 968,
        "reward": 0.130912646651268,
        "val_loss": 0.12750501398529326,
        "train_loss": 0.09876359669634929
      },
      {
        "epoch": 969,
        "reward": 0.12149399518966675,
        "val_loss": 0.15126676431724004,
        "train_loss": 0.18100828842188305
      },
      {
        "epoch": 970,
        "reward": 0.18792541325092316,
        "val_loss": 0.05402372085622379,
        "train_loss": 0.11756984070122528
      },
      {
        "epoch": 971,
        "reward": 0.16538971662521362,
        "val_loss": 0.07367395662835666,
        "train_loss": 0.017974936013790563
      },
      {
        "epoch": 972,
        "reward": 0.1837230771780014,
        "val_loss": 0.057109891303947995,
        "train_loss": 0.0497559062563456
      },
      {
        "epoch": 973,
        "reward": 0.23110322654247284,
        "val_loss": 0.032024898433259556,
        "train_loss": 0.03132641953057968
      },
      {
        "epoch": 974,
        "reward": 0.23657982051372528,
        "val_loss": 0.030125584985528673,
        "train_loss": 0.021420513371030944
      },
      {
        "epoch": 975,
        "reward": 0.18171383440494537,
        "val_loss": 0.05866757833531925,
        "train_loss": 0.019074831790931057
      },
      {
        "epoch": 976,
        "reward": 0.45705753564834595,
        "val_loss": 0.004082531934337956,
        "train_loss": 0.009752689173463015
      },
      {
        "epoch": 977,
        "reward": 0.41078171133995056,
        "val_loss": 0.005952424070398722,
        "train_loss": 0.0019810838566627353
      },
      {
        "epoch": 978,
        "reward": 0.6294383406639099,
        "val_loss": 0.0010027169482782483,
        "train_loss": 0.002766263348838458
      },
      {
        "epoch": 979,
        "reward": 0.5640798211097717,
        "val_loss": 0.001727811958906906,
        "train_loss": 0.0011472335239746966
      },
      {
        "epoch": 980,
        "reward": 0.5363497734069824,
        "val_loss": 0.002161964092270604,
        "train_loss": 0.001216626690830498
      },
      {
        "epoch": 981,
        "reward": 0.41401752829551697,
        "val_loss": 0.005795559712818691,
        "train_loss": 0.001357502982360669
      },
      {
        "epoch": 982,
        "reward": 0.5826811194419861,
        "val_loss": 0.001484013644845358,
        "train_loss": 0.0030280462300512367
      },
      {
        "epoch": 983,
        "reward": 0.6352356672286987,
        "val_loss": 0.0009539350285194814,
        "train_loss": 0.0015166093743083854
      },
      {
        "epoch": 984,
        "reward": 0.6673032641410828,
        "val_loss": 0.0007191411485629422,
        "train_loss": 0.0021668155767166843
      },
      {
        "epoch": 985,
        "reward": 0.4745965003967285,
        "val_loss": 0.0035456892302525894,
        "train_loss": 0.0012353597099158482
      },
      {
        "epoch": 986,
        "reward": 0.3700575828552246,
        "val_loss": 0.008383525468941246,
        "train_loss": 0.005857273695605377
      },
      {
        "epoch": 987,
        "reward": 0.4893059730529785,
        "val_loss": 0.0031515495252928565,
        "train_loss": 0.0032535615833834386
      },
      {
        "epoch": 988,
        "reward": 0.4295690953731537,
        "val_loss": 0.005101567001215049,
        "train_loss": 0.0020746084292813274
      },
      {
        "epoch": 989,
        "reward": 0.5085214972496033,
        "val_loss": 0.002702428161033562,
        "train_loss": 0.0021872311492468445
      },
      {
        "epoch": 990,
        "reward": 0.6017369031906128,
        "val_loss": 0.0012673322011583618,
        "train_loss": 0.004094192246646764
      },
      {
        "epoch": 991,
        "reward": 0.6066556572914124,
        "val_loss": 0.001216256508736738,
        "train_loss": 0.003063812548554359
      },
      {
        "epoch": 992,
        "reward": 0.5221031308174133,
        "val_loss": 0.0024239265226892064,
        "train_loss": 0.0010228739296368216
      },
      {
        "epoch": 993,
        "reward": 0.6424728035926819,
        "val_loss": 0.0008959268036830638,
        "train_loss": 0.0024036135325262034
      },
      {
        "epoch": 994,
        "reward": 0.5573434829711914,
        "val_loss": 0.0018249521464375512,
        "train_loss": 0.0009136194969939354
      },
      {
        "epoch": 995,
        "reward": 0.12462621927261353,
        "val_loss": 0.14273544720241002,
        "train_loss": 0.004265337318289452
      },
      {
        "epoch": 996,
        "reward": 0.2421070784330368,
        "val_loss": 0.028350736679775373,
        "train_loss": 0.02293445676780091
      },
      {
        "epoch": 997,
        "reward": 0.26699161529541016,
        "val_loss": 0.02180652360298804,
        "train_loss": 0.04652198653748813
      },
      {
        "epoch": 998,
        "reward": 0.3805875778198242,
        "val_loss": 0.007663271123809474,
        "train_loss": 0.009684224088862091
      },
      {
        "epoch": 999,
        "reward": 0.46435508131980896,
        "val_loss": 0.003849615010299853,
        "train_loss": 0.0033720874142510672
      },
      {
        "epoch": 1000,
        "reward": 0.4830891191959381,
        "val_loss": 0.003312382780547653,
        "train_loss": 0.0030402865936943833
      },
      {
        "epoch": 1001,
        "reward": 0.4581831991672516,
        "val_loss": 0.004045668773220054,
        "train_loss": 0.0036606870842381166
      },
      {
        "epoch": 1002,
        "reward": 0.2309279888868332,
        "val_loss": 0.03208813949355057,
        "train_loss": 0.005626379852541364
      },
      {
        "epoch": 1003,
        "reward": 0.43128618597984314,
        "val_loss": 0.005030603763381285,
        "train_loss": 0.010737029491932705
      },
      {
        "epoch": 1004,
        "reward": 0.4249745011329651,
        "val_loss": 0.005296781825433884,
        "train_loss": 0.012945405807561027
      },
      {
        "epoch": 1005,
        "reward": 0.519000768661499,
        "val_loss": 0.002484942686610988,
        "train_loss": 0.002636236447590188
      },
      {
        "epoch": 1006,
        "reward": 0.30293843150138855,
        "val_loss": 0.015317830456686872,
        "train_loss": 0.0025613104226067662
      },
      {
        "epoch": 1007,
        "reward": 0.22067295014858246,
        "val_loss": 0.03608320280909538,
        "train_loss": 0.02216603196799182
      },
      {
        "epoch": 1008,
        "reward": 0.3704800605773926,
        "val_loss": 0.008353202271142177,
        "train_loss": 0.00576994722807565
      },
      {
        "epoch": 1009,
        "reward": 0.14066459238529205,
        "val_loss": 0.1079740801027843,
        "train_loss": 0.005933630217511494
      },
      {
        "epoch": 1010,
        "reward": 0.06633854657411575,
        "val_loss": 0.5730738448245185,
        "train_loss": 0.021654801953655597
      },
      {
        "epoch": 1011,
        "reward": 0.19814345240592957,
        "val_loss": 0.047380268573760986,
        "train_loss": 0.8700691925522943
      },
      {
        "epoch": 1012,
        "reward": 0.3452267050743103,
        "val_loss": 0.010407270996698312,
        "train_loss": 0.011081943154959636
      },
      {
        "epoch": 1013,
        "reward": 0.6465281844139099,
        "val_loss": 0.0008647656234513436,
        "train_loss": 0.0035271190001647202
      },
      {
        "epoch": 1014,
        "reward": 0.43390941619873047,
        "val_loss": 0.004924218486329275,
        "train_loss": 0.0010512821821836182
      },
      {
        "epoch": 1015,
        "reward": 0.3487043082714081,
        "val_loss": 0.010092658190322774,
        "train_loss": 0.00442239448602777
      },
      {
        "epoch": 1016,
        "reward": 0.5109495520591736,
        "val_loss": 0.0026504209132066797,
        "train_loss": 0.002799060521143614
      },
      {
        "epoch": 1017,
        "reward": 0.5196256637573242,
        "val_loss": 0.0024725329130887985,
        "train_loss": 0.002047173862452977
      },
      {
        "epoch": 1018,
        "reward": 0.612064003944397,
        "val_loss": 0.0011622247236248637,
        "train_loss": 0.0011217948927668869
      },
      {
        "epoch": 1019,
        "reward": 0.48677363991737366,
        "val_loss": 0.003216084392209138,
        "train_loss": 0.001009563306979544
      },
      {
        "epoch": 1020,
        "reward": 0.11980509757995605,
        "val_loss": 0.15616035142115184,
        "train_loss": 0.006313575669012677
      },
      {
        "epoch": 1021,
        "reward": 0.1550387293100357,
        "val_loss": 0.08593238384595939,
        "train_loss": 0.04377669318077656
      },
      {
        "epoch": 1022,
        "reward": 0.31894874572753906,
        "val_loss": 0.013191112982375281,
        "train_loss": 0.01879876794835302
      },
      {
        "epoch": 1023,
        "reward": 0.31566789746284485,
        "val_loss": 0.013596802883382355,
        "train_loss": 0.0052273846779896235
      },
      {
        "epoch": 1024,
        "reward": 0.20193858444690704,
        "val_loss": 0.04518536238798073,
        "train_loss": 0.03226502871033377
      },
      {
        "epoch": 1025,
        "reward": 0.23555532097816467,
        "val_loss": 0.03046983134533678,
        "train_loss": 0.049975695160145946
      },
      {
        "epoch": 1026,
        "reward": 0.15311765670776367,
        "val_loss": 0.08850326016545296,
        "train_loss": 0.032359573748320915
      },
      {
        "epoch": 1027,
        "reward": 0.08471740782260895,
        "val_loss": 0.33769828506878447,
        "train_loss": 0.1217076974750783
      },
      {
        "epoch": 1028,
        "reward": 0.2562893331050873,
        "val_loss": 0.024361876903900077,
        "train_loss": 0.11789889108891097
      },
      {
        "epoch": 1029,
        "reward": 0.10757487267255783,
        "val_loss": 0.19910658257348196,
        "train_loss": 0.06751773138351452
      },
      {
        "epoch": 1030,
        "reward": 0.2538738548755646,
        "val_loss": 0.024989193571465357,
        "train_loss": 0.03429995318695616
      },
      {
        "epoch": 1031,
        "reward": 0.4761415421962738,
        "val_loss": 0.003502026732478823,
        "train_loss": 0.01150480996315869
      },
      {
        "epoch": 1032,
        "reward": 0.4051337242126465,
        "val_loss": 0.0062374278038207975,
        "train_loss": 0.0035247348714619875
      },
      {
        "epoch": 1033,
        "reward": 0.4343407154083252,
        "val_loss": 0.0049069587673459735,
        "train_loss": 0.00533387738379623
      },
      {
        "epoch": 1034,
        "reward": 0.3538200855255127,
        "val_loss": 0.009649517347237893,
        "train_loss": 0.0026692836702120705
      },
      {
        "epoch": 1035,
        "reward": 0.542569100856781,
        "val_loss": 0.0020563851409990874,
        "train_loss": 0.002826328872917936
      },
      {
        "epoch": 1036,
        "reward": 0.6595630049705505,
        "val_loss": 0.0007707693896788571,
        "train_loss": 0.000917350985009062
      },
      {
        "epoch": 1037,
        "reward": 0.5317389965057373,
        "val_loss": 0.0022435860675094382,
        "train_loss": 0.0012785411296975396
      },
      {
        "epoch": 1038,
        "reward": 0.6493793725967407,
        "val_loss": 0.0008434157436048346,
        "train_loss": 0.0016135525783143889
      },
      {
        "epoch": 1039,
        "reward": 0.518714189529419,
        "val_loss": 0.0024906541387151393,
        "train_loss": 0.0009574636642355472
      },
      {
        "epoch": 1040,
        "reward": 0.3696790635585785,
        "val_loss": 0.008410805171089513,
        "train_loss": 0.002603240186894814
      },
      {
        "epoch": 1041,
        "reward": 0.5248927474021912,
        "val_loss": 0.002370312876467194,
        "train_loss": 0.0024884984483763287
      },
      {
        "epoch": 1042,
        "reward": 0.5949479341506958,
        "val_loss": 0.0013409960832047676,
        "train_loss": 0.001418989301153208
      },
      {
        "epoch": 1043,
        "reward": 0.4975404739379883,
        "val_loss": 0.002950590669310519,
        "train_loss": 0.0010723780052593122
      },
      {
        "epoch": 1044,
        "reward": 0.4611909091472626,
        "val_loss": 0.003948863163324339,
        "train_loss": 0.003548214901596881
      },
      {
        "epoch": 1045,
        "reward": 0.5182735323905945,
        "val_loss": 0.0024994631114948008,
        "train_loss": 0.0027794147782305326
      },
      {
        "epoch": 1046,
        "reward": 0.6811892986297607,
        "val_loss": 0.0006337145168799907,
        "train_loss": 0.0022452719332739855
      },
      {
        "epoch": 1047,
        "reward": 0.21177978813648224,
        "val_loss": 0.040076508319803646,
        "train_loss": 0.0013346896526994756
      },
      {
        "epoch": 1048,
        "reward": 0.2974991500377655,
        "val_loss": 0.016131915218595947,
        "train_loss": 0.028468445426999375
      },
      {
        "epoch": 1049,
        "reward": 0.2188566029071808,
        "val_loss": 0.036855803802609444,
        "train_loss": 0.008534808374511508
      },
      {
        "epoch": 1050,
        "reward": 0.32843074202537537,
        "val_loss": 0.012096444277891092,
        "train_loss": 0.016207049508991007
      },
      {
        "epoch": 1051,
        "reward": 0.25768351554870605,
        "val_loss": 0.02400869955973966,
        "train_loss": 0.004167305493655686
      },
      {
        "epoch": 1052,
        "reward": 0.08559836447238922,
        "val_loss": 0.3301465149436678,
        "train_loss": 0.01591876955129779
      },
      {
        "epoch": 1053,
        "reward": 0.2122434377670288,
        "val_loss": 0.03985467233828136,
        "train_loss": 0.20247717216037786
      },
      {
        "epoch": 1054,
        "reward": 0.10928136110305786,
        "val_loss": 0.19219965381281717,
        "train_loss": 0.16741163828052008
      },
      {
        "epoch": 1055,
        "reward": 0.2901897430419922,
        "val_loss": 0.017309481145015786,
        "train_loss": 0.1681874177302234
      },
      {
        "epoch": 1056,
        "reward": 0.18485692143440247,
        "val_loss": 0.05625484724129949,
        "train_loss": 0.03183006825174044
      },
      {
        "epoch": 1057,
        "reward": 0.3131090998649597,
        "val_loss": 0.013923480840665954,
        "train_loss": 0.02637900091492786
      },
      {
        "epoch": 1058,
        "reward": 0.36913543939590454,
        "val_loss": 0.008450150988729936,
        "train_loss": 0.007358620380098448
      },
      {
        "epoch": 1059,
        "reward": 0.26263079047203064,
        "val_loss": 0.022805653113339628,
        "train_loss": 0.006486648421252119
      },
      {
        "epoch": 1060,
        "reward": 0.40788283944129944,
        "val_loss": 0.006096886337867805,
        "train_loss": 0.007362023992195295
      },
      {
        "epoch": 1061,
        "reward": 0.39421936869621277,
        "val_loss": 0.006831536601696696,
        "train_loss": 0.0075990071670205975
      },
      {
        "epoch": 1062,
        "reward": 0.2589434087276459,
        "val_loss": 0.02369499845164163,
        "train_loss": 0.0037214977581662913
      },
      {
        "epoch": 1063,
        "reward": 0.36525699496269226,
        "val_loss": 0.008737003696816308,
        "train_loss": 0.019303138282758973
      },
      {
        "epoch": 1064,
        "reward": 0.43341121077537537,
        "val_loss": 0.004944235884717533,
        "train_loss": 0.0025592582801786754
      },
      {
        "epoch": 1065,
        "reward": 0.24423551559448242,
        "val_loss": 0.027702503704598973,
        "train_loss": 0.008678547115638278
      },
      {
        "epoch": 1066,
        "reward": 0.3575138747692108,
        "val_loss": 0.00934341097516673,
        "train_loss": 0.022219812938531574
      },
      {
        "epoch": 1067,
        "reward": 0.428521066904068,
        "val_loss": 0.005145408579015306,
        "train_loss": 0.013161539377716299
      },
      {
        "epoch": 1068,
        "reward": 0.32749733328819275,
        "val_loss": 0.012199332006275654,
        "train_loss": 0.0038443955530125936
      },
      {
        "epoch": 1069,
        "reward": 0.3118508756160736,
        "val_loss": 0.014087529852986336,
        "train_loss": 0.004216928543218483
      },
      {
        "epoch": 1070,
        "reward": 0.51955646276474,
        "val_loss": 0.0024739050339641316,
        "train_loss": 0.006781516688463923
      },
      {
        "epoch": 1071,
        "reward": 0.6840828061103821,
        "val_loss": 0.0006170110303043787,
        "train_loss": 0.0012416097810133719
      },
      {
        "epoch": 1072,
        "reward": 0.38778313994407654,
        "val_loss": 0.00721101466167186,
        "train_loss": 0.0009375370629221344
      },
      {
        "epoch": 1073,
        "reward": 0.5263893008232117,
        "val_loss": 0.002342030223059867,
        "train_loss": 0.003698509556040965
      },
      {
        "epoch": 1074,
        "reward": 0.09798985719680786,
        "val_loss": 0.24514572428805487,
        "train_loss": 0.005112122343584465
      },
      {
        "epoch": 1075,
        "reward": 0.09250371903181076,
        "val_loss": 0.27844218058245523,
        "train_loss": 0.08879308542236686
      },
      {
        "epoch": 1076,
        "reward": 0.20772793889045715,
        "val_loss": 0.04208454090569701,
        "train_loss": 0.08808455783918571
      },
      {
        "epoch": 1077,
        "reward": 0.4430394172668457,
        "val_loss": 0.004572227231359908,
        "train_loss": 0.02180888064098186
      },
      {
        "epoch": 1078,
        "reward": 0.39828193187713623,
        "val_loss": 0.00660341399322663,
        "train_loss": 0.005328936458401865
      },
      {
        "epoch": 1079,
        "reward": 0.2425520271062851,
        "val_loss": 0.028213664889335632,
        "train_loss": 0.002307504854308298
      },
      {
        "epoch": 1080,
        "reward": 0.3018420338630676,
        "val_loss": 0.015477886157376426,
        "train_loss": 0.006037797510194091
      },
      {
        "epoch": 1081,
        "reward": 0.23977291584014893,
        "val_loss": 0.029083738369601115,
        "train_loss": 0.01200040817583123
      },
      {
        "epoch": 1082,
        "reward": 0.1978049874305725,
        "val_loss": 0.04758270324340889,
        "train_loss": 0.022576669163894482
      },
      {
        "epoch": 1083,
        "reward": 0.3262312114238739,
        "val_loss": 0.012340548315218516,
        "train_loss": 0.0232752175294221
      },
      {
        "epoch": 1084,
        "reward": 0.4385530650615692,
        "val_loss": 0.004741728072986007,
        "train_loss": 0.0025252942689873567
      },
      {
        "epoch": 1085,
        "reward": 0.6376295685768127,
        "val_loss": 0.00093439914884844,
        "train_loss": 0.0016360875212320445
      },
      {
        "epoch": 1086,
        "reward": 0.5814689993858337,
        "val_loss": 0.0014988761894138797,
        "train_loss": 0.0014660084785786099
      },
      {
        "epoch": 1087,
        "reward": 0.5311094522476196,
        "val_loss": 0.0022549587468217525,
        "train_loss": 0.0028913876135797743
      },
      {
        "epoch": 1088,
        "reward": 0.27366241812705994,
        "val_loss": 0.02038029195474727,
        "train_loss": 0.002471033761349435
      },
      {
        "epoch": 1089,
        "reward": 0.4003620147705078,
        "val_loss": 0.006489872799388,
        "train_loss": 0.005178626214798827
      },
      {
        "epoch": 1090,
        "reward": 0.5223487019538879,
        "val_loss": 0.0024191594483064754,
        "train_loss": 0.003252464192113481
      },
      {
        "epoch": 1091,
        "reward": 0.6787263751029968,
        "val_loss": 0.0006482231339240181,
        "train_loss": 0.001572902775548685
      },
      {
        "epoch": 1092,
        "reward": 0.4684241712093353,
        "val_loss": 0.0037257649736212833,
        "train_loss": 0.0008182795473448306
      },
      {
        "epoch": 1093,
        "reward": 0.4506109654903412,
        "val_loss": 0.0043005118412630895,
        "train_loss": 0.002846527612956169
      },
      {
        "epoch": 1094,
        "reward": 0.6105465292930603,
        "val_loss": 0.0011771655408665538,
        "train_loss": 0.0011485327771739461
      },
      {
        "epoch": 1095,
        "reward": 0.5426662564277649,
        "val_loss": 0.0020547761814668775,
        "train_loss": 0.0010290618632167864
      },
      {
        "epoch": 1096,
        "reward": 0.21940720081329346,
        "val_loss": 0.036619385172213824,
        "train_loss": 0.0020290119483923684
      },
      {
        "epoch": 1097,
        "reward": 0.07054051756858826,
        "val_loss": 0.5022815849099841,
        "train_loss": 0.12559036559496933
      },
      {
        "epoch": 1098,
        "reward": 0.16461920738220215,
        "val_loss": 0.07450262776442937,
        "train_loss": 0.15251479321159422
      },
      {
        "epoch": 1099,
        "reward": 0.3610282242298126,
        "val_loss": 0.009062429890036583,
        "train_loss": 0.03231439818605745
      },
      {
        "epoch": 1100,
        "reward": 0.3162789046764374,
        "val_loss": 0.013520142130021538,
        "train_loss": 0.0028012027122223605
      },
      {
        "epoch": 1101,
        "reward": 0.6738623976707458,
        "val_loss": 0.0006776774243917316,
        "train_loss": 0.002839916284406522
      },
      {
        "epoch": 1102,
        "reward": 0.41672977805137634,
        "val_loss": 0.00566753455703812,
        "train_loss": 0.001326287283938235
      },
      {
        "epoch": 1103,
        "reward": 0.26989778876304626,
        "val_loss": 0.021170557609626224,
        "train_loss": 0.002012260095887961
      },
      {
        "epoch": 1104,
        "reward": 0.3139103353023529,
        "val_loss": 0.013820194971880742,
        "train_loss": 0.008146610220697207
      },
      {
        "epoch": 1105,
        "reward": 0.23731505870819092,
        "val_loss": 0.029881573681320463,
        "train_loss": 0.009559142116743784
      },
      {
        "epoch": 1106,
        "reward": 0.11735393106937408,
        "val_loss": 0.16365965189678328,
        "train_loss": 0.011578930562021784
      },
      {
        "epoch": 1107,
        "reward": 0.6599645018577576,
        "val_loss": 0.0007680173813631492,
        "train_loss": 0.15396736398263153
      },
      {
        "epoch": 1108,
        "reward": 0.4785735309123993,
        "val_loss": 0.0034344122811619726,
        "train_loss": 0.002388594049709634
      },
      {
        "epoch": 1109,
        "reward": 0.1594480723142624,
        "val_loss": 0.08039967662521771,
        "train_loss": 0.001963321710578524
      },
      {
        "epoch": 1110,
        "reward": 0.3128460943698883,
        "val_loss": 0.013957585873348373,
        "train_loss": 0.03501672103392103
      },
      {
        "epoch": 1111,
        "reward": 0.3555436134338379,
        "val_loss": 0.009505281623985087,
        "train_loss": 0.006948014290173887
      },
      {
        "epoch": 1112,
        "reward": 0.48845958709716797,
        "val_loss": 0.0031729729047843386,
        "train_loss": 0.0033560385121605718
      },
      {
        "epoch": 1113,
        "reward": 0.5567135214805603,
        "val_loss": 0.0018342947587370872,
        "train_loss": 0.005945156523151896
      },
      {
        "epoch": 1114,
        "reward": 0.33210819959640503,
        "val_loss": 0.011700829357973166,
        "train_loss": 0.006973828073779049
      },
      {
        "epoch": 1115,
        "reward": 0.3639095425605774,
        "val_loss": 0.00883923184924892,
        "train_loss": 0.003230789352808363
      },
      {
        "epoch": 1116,
        "reward": 0.5211830735206604,
        "val_loss": 0.0024418678866433246,
        "train_loss": 0.0050737144147905595
      },
      {
        "epoch": 1117,
        "reward": 0.4638133943080902,
        "val_loss": 0.0038664191296058042,
        "train_loss": 0.002097108631390326
      },
      {
        "epoch": 1118,
        "reward": 0.38504907488822937,
        "val_loss": 0.007379252929240465,
        "train_loss": 0.0034340592437029746
      },
      {
        "epoch": 1119,
        "reward": 0.3584577441215515,
        "val_loss": 0.009266981721988745,
        "train_loss": 0.0017883457495862297
      },
      {
        "epoch": 1120,
        "reward": 0.27724558115005493,
        "val_loss": 0.01966146898588964,
        "train_loss": 0.0077823380169530325
      },
      {
        "epoch": 1121,
        "reward": 0.2915402352809906,
        "val_loss": 0.017084297058837756,
        "train_loss": 0.015483679012994309
      },
      {
        "epoch": 1122,
        "reward": 0.5392202734947205,
        "val_loss": 0.002112603613308498,
        "train_loss": 0.004681651258859067
      },
      {
        "epoch": 1123,
        "reward": 0.34455999732017517,
        "val_loss": 0.010468869070921625,
        "train_loss": 0.001816381203333059
      },
      {
        "epoch": 1124,
        "reward": 0.5744063258171082,
        "val_loss": 0.0015882387857085892,
        "train_loss": 0.010895456460555298
      },
      {
        "epoch": 1125,
        "reward": 0.2702643573284149,
        "val_loss": 0.02109197593693222,
        "train_loss": 0.0023962302254333804
      },
      {
        "epoch": 1126,
        "reward": 0.1776658147573471,
        "val_loss": 0.06198015968714442,
        "train_loss": 0.026984092072010614
      },
      {
        "epoch": 1127,
        "reward": 0.43681079149246216,
        "val_loss": 0.0048093425243028575,
        "train_loss": 0.011360525744608961
      },
      {
        "epoch": 1128,
        "reward": 0.37098929286003113,
        "val_loss": 0.008316815764244114,
        "train_loss": 0.004702520412278178
      },
      {
        "epoch": 1129,
        "reward": 0.49347734451293945,
        "val_loss": 0.00304808424386595,
        "train_loss": 0.0038270773948170245
      },
      {
        "epoch": 1130,
        "reward": 0.2307644635438919,
        "val_loss": 0.03214729763567448,
        "train_loss": 0.005855754740948144
      },
      {
        "epoch": 1131,
        "reward": 0.3435019552707672,
        "val_loss": 0.010567495266773872,
        "train_loss": 0.007288613684347813
      },
      {
        "epoch": 1132,
        "reward": 0.630899965763092,
        "val_loss": 0.0009902180837733404,
        "train_loss": 0.003595869377022609
      },
      {
        "epoch": 1133,
        "reward": 0.20705945789813995,
        "val_loss": 0.04242821303861482,
        "train_loss": 0.00121986465036081
      },
      {
        "epoch": 1134,
        "reward": 0.4748295843601227,
        "val_loss": 0.0035390646662563086,
        "train_loss": 0.006487104390264274
      },
      {
        "epoch": 1135,
        "reward": 0.428147554397583,
        "val_loss": 0.005161129470382418,
        "train_loss": 0.01740625956042025
      },
      {
        "epoch": 1136,
        "reward": 0.5560323596000671,
        "val_loss": 0.001844447189276772,
        "train_loss": 0.0019575397869070563
      },
      {
        "epoch": 1137,
        "reward": 0.42701107263565063,
        "val_loss": 0.005209281841026885,
        "train_loss": 0.002068687774366341
      },
      {
        "epoch": 1138,
        "reward": 0.4500482678413391,
        "val_loss": 0.004320109429370079,
        "train_loss": 0.0030279188425853276
      },
      {
        "epoch": 1139,
        "reward": 0.30383479595184326,
        "val_loss": 0.01518844413970198,
        "train_loss": 0.0015087193236328089
      },
      {
        "epoch": 1140,
        "reward": 0.514657199382782,
        "val_loss": 0.0025729118413957103,
        "train_loss": 0.01633931205679591
      },
      {
        "epoch": 1141,
        "reward": 0.6530426740646362,
        "val_loss": 0.0008166439947672188,
        "train_loss": 0.001141576876342207
      },
      {
        "epoch": 1142,
        "reward": 0.47270891070365906,
        "val_loss": 0.0035997893095814754,
        "train_loss": 0.0019275427352672873
      },
      {
        "epoch": 1143,
        "reward": 0.48249801993370056,
        "val_loss": 0.003328101776008095,
        "train_loss": 0.011822470219228238
      },
      {
        "epoch": 1144,
        "reward": 0.5391877293586731,
        "val_loss": 0.0021131569353331414,
        "train_loss": 0.0010620764671609951
      },
      {
        "epoch": 1145,
        "reward": 0.44044026732444763,
        "val_loss": 0.004669630201533437,
        "train_loss": 0.0026657124175331914
      },
      {
        "epoch": 1146,
        "reward": 0.36205071210861206,
        "val_loss": 0.008982499928346701,
        "train_loss": 0.002440687093230036
      },
      {
        "epoch": 1147,
        "reward": 0.13184377551078796,
        "val_loss": 0.12544119677373342,
        "train_loss": 0.004386769718481586
      },
      {
        "epoch": 1148,
        "reward": 0.24462607502937317,
        "val_loss": 0.027585582408521856,
        "train_loss": 0.0318750584034258
      },
      {
        "epoch": 1149,
        "reward": 0.6694315671920776,
        "val_loss": 0.0007054626226558217,
        "train_loss": 0.10732827639619175
      },
      {
        "epoch": 1150,
        "reward": 0.07089627534151077,
        "val_loss": 0.4968728508268084,
        "train_loss": 0.029418567773133803
      },
      {
        "epoch": 1151,
        "reward": 0.27581787109375,
        "val_loss": 0.019944101039852415,
        "train_loss": 0.13977334152262372
      },
      {
        "epoch": 1152,
        "reward": 0.2941344380378723,
        "val_loss": 0.016661570673542365,
        "train_loss": 0.003558406765268256
      },
      {
        "epoch": 1153,
        "reward": 0.6317471265792847,
        "val_loss": 0.000983036364362176,
        "train_loss": 0.008028539562544141
      },
      {
        "epoch": 1154,
        "reward": 0.5898512005805969,
        "val_loss": 0.0013988193074640418,
        "train_loss": 0.0012807710243997951
      },
      {
        "epoch": 1155,
        "reward": 0.6592311859130859,
        "val_loss": 0.0007730507890560798,
        "train_loss": 0.0020814566187954578
      },
      {
        "epoch": 1156,
        "reward": 0.5120155215263367,
        "val_loss": 0.0026279049260275705,
        "train_loss": 0.0012357331848201843
      },
      {
        "epoch": 1157,
        "reward": 0.40779128670692444,
        "val_loss": 0.006101512483188084,
        "train_loss": 0.006260484277915496
      },
      {
        "epoch": 1158,
        "reward": 0.3259229362010956,
        "val_loss": 0.012375219858118467,
        "train_loss": 0.004999029154602725
      },
      {
        "epoch": 1159,
        "reward": 0.6708402037620544,
        "val_loss": 0.0006965289524357234,
        "train_loss": 0.005445080961530598
      },
      {
        "epoch": 1160,
        "reward": 0.6904810070991516,
        "val_loss": 0.000581346036467169,
        "train_loss": 0.0013182836932733504
      },
      {
        "epoch": 1161,
        "reward": 0.5195984244346619,
        "val_loss": 0.0024730730801820755,
        "train_loss": 0.0017227884270071697
      },
      {
        "epoch": 1162,
        "reward": 0.6108092665672302,
        "val_loss": 0.0011745666186990483,
        "train_loss": 0.0011766657519799012
      },
      {
        "epoch": 1163,
        "reward": 0.5910125970840454,
        "val_loss": 0.0013854481346373046,
        "train_loss": 0.0010044143351618773
      },
      {
        "epoch": 1164,
        "reward": 0.6607427000999451,
        "val_loss": 0.0007627059905124563,
        "train_loss": 0.002231665001510499
      },
      {
        "epoch": 1165,
        "reward": 0.3604261875152588,
        "val_loss": 0.009109871129372291,
        "train_loss": 0.0009139786819175172
      },
      {
        "epoch": 1166,
        "reward": 0.27146193385124207,
        "val_loss": 0.02083772753498384,
        "train_loss": 0.008829473784247126
      },
      {
        "epoch": 1167,
        "reward": 0.5352036356925964,
        "val_loss": 0.002181981091520616,
        "train_loss": 0.010507133337131772
      },
      {
        "epoch": 1168,
        "reward": 0.6489697694778442,
        "val_loss": 0.0008464548819964486,
        "train_loss": 0.004534321992161075
      },
      {
        "epoch": 1169,
        "reward": 0.35076701641082764,
        "val_loss": 0.009911226707377605,
        "train_loss": 0.002327998201228463
      },
      {
        "epoch": 1170,
        "reward": 0.3826083838939667,
        "val_loss": 0.007533143474055188,
        "train_loss": 0.011351411736821039
      },
      {
        "epoch": 1171,
        "reward": 0.0885058343410492,
        "val_loss": 0.30685101981673923,
        "train_loss": 0.06272880494809495
      },
      {
        "epoch": 1172,
        "reward": 0.1145489439368248,
        "val_loss": 0.17286639234849385,
        "train_loss": 0.3947327056756386
      },
      {
        "epoch": 1173,
        "reward": 0.07309801131486893,
        "val_loss": 0.4651790623153959,
        "train_loss": 0.09248778319894112
      },
      {
        "epoch": 1174,
        "reward": 0.26179179549217224,
        "val_loss": 0.023004315261329924,
        "train_loss": 0.12088639748533471
      },
      {
        "epoch": 1175,
        "reward": 0.5861742496490479,
        "val_loss": 0.001441933331079781,
        "train_loss": 0.02156109239037435
      },
      {
        "epoch": 1176,
        "reward": 0.26595357060432434,
        "val_loss": 0.022039369280849184,
        "train_loss": 0.002244519719030135
      },
      {
        "epoch": 1177,
        "reward": 0.33510032296180725,
        "val_loss": 0.011390068169151033,
        "train_loss": 0.01111222875792569
      },
      {
        "epoch": 1178,
        "reward": 0.42780232429504395,
        "val_loss": 0.005175705999135971,
        "train_loss": 0.002775780248787039
      },
      {
        "epoch": 1179,
        "reward": 0.5363237857818604,
        "val_loss": 0.0021624156673039708,
        "train_loss": 0.0028587493311183956
      },
      {
        "epoch": 1180,
        "reward": 0.6710560321807861,
        "val_loss": 0.0006951683649926313,
        "train_loss": 0.0015078450982960372
      },
      {
        "epoch": 1181,
        "reward": 0.6014816164970398,
        "val_loss": 0.00127003453339317,
        "train_loss": 0.0015455541959874188
      },
      {
        "epoch": 1182,
        "reward": 0.4005003869533539,
        "val_loss": 0.006482396075235946,
        "train_loss": 0.0013902804818756592
      },
      {
        "epoch": 1183,
        "reward": 0.6756331324577332,
        "val_loss": 0.0006668296659232251,
        "train_loss": 0.002165668637294752
      },
      {
        "epoch": 1184,
        "reward": 0.22960586845874786,
        "val_loss": 0.032570447506649156,
        "train_loss": 0.001020223653400675
      },
      {
        "epoch": 1185,
        "reward": 0.4733404219150543,
        "val_loss": 0.00358159512480987,
        "train_loss": 0.015427651709894864
      },
      {
        "epoch": 1186,
        "reward": 0.31976190209388733,
        "val_loss": 0.013092789532882827,
        "train_loss": 0.009951741808506016
      },
      {
        "epoch": 1187,
        "reward": 0.658010721206665,
        "val_loss": 0.0007814884551667742,
        "train_loss": 0.005649138264393864
      },
      {
        "epoch": 1188,
        "reward": 0.44706985354423523,
        "val_loss": 0.004425409682361143,
        "train_loss": 0.0012768023790648351
      },
      {
        "epoch": 1189,
        "reward": 0.6683557629585266,
        "val_loss": 0.0007123495285798397,
        "train_loss": 0.00150065935639969
      },
      {
        "epoch": 1190,
        "reward": 0.6223236918449402,
        "val_loss": 0.0010655418736860156,
        "train_loss": 0.0008321025659545109
      },
      {
        "epoch": 1191,
        "reward": 0.5282861590385437,
        "val_loss": 0.00230665403484766,
        "train_loss": 0.0007639039507082019
      },
      {
        "epoch": 1192,
        "reward": 0.4001593589782715,
        "val_loss": 0.006500839189227138,
        "train_loss": 0.0008638796828633461
      },
      {
        "epoch": 1193,
        "reward": 0.40352120995521545,
        "val_loss": 0.006321510033948081,
        "train_loss": 0.008141358013605125
      },
      {
        "epoch": 1194,
        "reward": 0.5430027842521667,
        "val_loss": 0.0020492105644994547,
        "train_loss": 0.007611063784749534
      },
      {
        "epoch": 1195,
        "reward": 0.5966759920120239,
        "val_loss": 0.0013218878801645978,
        "train_loss": 0.0009722575274421475
      },
      {
        "epoch": 1196,
        "reward": 0.5962242484092712,
        "val_loss": 0.0013268598122522235,
        "train_loss": 0.001018337979285906
      },
      {
        "epoch": 1197,
        "reward": 0.5114279389381409,
        "val_loss": 0.00264029301303838,
        "train_loss": 0.001001057301227075
      },
      {
        "epoch": 1198,
        "reward": 0.18561582267284393,
        "val_loss": 0.05569194017776421,
        "train_loss": 0.012603958564935826
      },
      {
        "epoch": 1199,
        "reward": 0.07903122156858444,
        "val_loss": 0.3928765846150262,
        "train_loss": 0.06326589188896693
      },
      {
        "epoch": 1200,
        "reward": 0.09298993647098541,
        "val_loss": 0.275242879986763,
        "train_loss": 0.2323249252513051
      },
      {
        "epoch": 1201,
        "reward": 0.5686405301094055,
        "val_loss": 0.0016648172833291547,
        "train_loss": 0.07634522268199362
      },
      {
        "epoch": 1202,
        "reward": 0.486351877450943,
        "val_loss": 0.0032269624810266706,
        "train_loss": 0.00290352994607719
      },
      {
        "epoch": 1203,
        "reward": 0.40538763999938965,
        "val_loss": 0.006224301510623523,
        "train_loss": 0.0014129158672193836
      },
      {
        "epoch": 1204,
        "reward": 0.6817352175712585,
        "val_loss": 0.0006305358422520969,
        "train_loss": 0.0015585767687298357
      },
      {
        "epoch": 1205,
        "reward": 0.48593130707740784,
        "val_loss": 0.003237846473764096,
        "train_loss": 0.0011861172925609236
      },
      {
        "epoch": 1206,
        "reward": 0.6519505381584167,
        "val_loss": 0.0008245488944729524,
        "train_loss": 0.00342608936648503
      },
      {
        "epoch": 1207,
        "reward": 0.6320501565933228,
        "val_loss": 0.0009804781875573099,
        "train_loss": 0.0006709502264619424
      },
      {
        "epoch": 1208,
        "reward": 0.643774151802063,
        "val_loss": 0.0008858239743858576,
        "train_loss": 0.0009473702386738016
      },
      {
        "epoch": 1209,
        "reward": 0.6868606805801392,
        "val_loss": 0.0006013142951165459,
        "train_loss": 0.001265852441764974
      },
      {
        "epoch": 1210,
        "reward": 0.6131969094276428,
        "val_loss": 0.0011511811088504536,
        "train_loss": 0.0009042190283183188
      },
      {
        "epoch": 1211,
        "reward": 0.5968018174171448,
        "val_loss": 0.0013205066456326417,
        "train_loss": 0.0014238471390294412
      },
      {
        "epoch": 1212,
        "reward": 0.48214098811149597,
        "val_loss": 0.0033376343947436127,
        "train_loss": 0.0018241360129860158
      },
      {
        "epoch": 1213,
        "reward": 0.4191710948944092,
        "val_loss": 0.005554915804948125,
        "train_loss": 0.0019423669498556033
      },
      {
        "epoch": 1214,
        "reward": 0.5183358788490295,
        "val_loss": 0.0024982140665607794,
        "train_loss": 0.0018765941959617732
      },
      {
        "epoch": 1215,
        "reward": 0.3974367082118988,
        "val_loss": 0.006650175100990704,
        "train_loss": 0.002672332931139793
      },
      {
        "epoch": 1216,
        "reward": 0.3866984248161316,
        "val_loss": 0.00727724510111979,
        "train_loss": 0.003559771649564097
      },
      {
        "epoch": 1217,
        "reward": 0.5117504000663757,
        "val_loss": 0.0026334854607869473,
        "train_loss": 0.0027530329434039933
      },
      {
        "epoch": 1218,
        "reward": 0.234101340174675,
        "val_loss": 0.030966954305768013,
        "train_loss": 0.0031899729141374477
      },
      {
        "epoch": 1219,
        "reward": 0.26285281777381897,
        "val_loss": 0.022753430397382805,
        "train_loss": 0.0678845806877899
      },
      {
        "epoch": 1220,
        "reward": 0.46107372641563416,
        "val_loss": 0.003952589384945375,
        "train_loss": 0.007054024808754688
      },
      {
        "epoch": 1221,
        "reward": 0.25437718629837036,
        "val_loss": 0.024856834273253168,
        "train_loss": 0.0025366546939879367
      },
      {
        "epoch": 1222,
        "reward": 0.38515862822532654,
        "val_loss": 0.007372429161997778,
        "train_loss": 0.011590545104879241
      },
      {
        "epoch": 1223,
        "reward": 0.20371711254119873,
        "val_loss": 0.0442021590258394,
        "train_loss": 0.018866954989229832
      },
      {
        "epoch": 1224,
        "reward": 0.2576431334018707,
        "val_loss": 0.0240188366068261,
        "train_loss": 0.014725150992699828
      },
      {
        "epoch": 1225,
        "reward": 0.34121009707450867,
        "val_loss": 0.010784842206963472,
        "train_loss": 0.019002136416160144
      },
      {
        "epoch": 1226,
        "reward": 0.2706206738948822,
        "val_loss": 0.021015929856470654,
        "train_loss": 0.005461147610241404
      },
      {
        "epoch": 1227,
        "reward": 0.3845212459564209,
        "val_loss": 0.007412232724683625,
        "train_loss": 0.0048209778581692194
      },
      {
        "epoch": 1228,
        "reward": 0.39422473311424255,
        "val_loss": 0.006831233788813863,
        "train_loss": 0.003817990207328246
      },
      {
        "epoch": 1229,
        "reward": 0.4301038682460785,
        "val_loss": 0.005079352729288595,
        "train_loss": 0.002979239507112652
      },
      {
        "epoch": 1230,
        "reward": 0.5854357481002808,
        "val_loss": 0.0014507380547001958,
        "train_loss": 0.003282909412519075
      },
      {
        "epoch": 1231,
        "reward": 0.6106037497520447,
        "val_loss": 0.0011765985400415957,
        "train_loss": 0.000873148153634527
      },
      {
        "epoch": 1232,
        "reward": 0.49705415964126587,
        "val_loss": 0.0029620936007371972,
        "train_loss": 0.0018023652552913588
      },
      {
        "epoch": 1233,
        "reward": 0.46477434039115906,
        "val_loss": 0.0038366594152258976,
        "train_loss": 0.0015164881925609454
      },
      {
        "epoch": 1234,
        "reward": 0.4641639292240143,
        "val_loss": 0.003855536159660135,
        "train_loss": 0.0028586633684776295
      },
      {
        "epoch": 1235,
        "reward": 0.5424289107322693,
        "val_loss": 0.0020587108696677853,
        "train_loss": 0.001494846322412531
      },
      {
        "epoch": 1236,
        "reward": 0.41043195128440857,
        "val_loss": 0.005969655367412737,
        "train_loss": 0.00422576426647608
      },
      {
        "epoch": 1237,
        "reward": 0.330616295337677,
        "val_loss": 0.011859474437577384,
        "train_loss": 0.006761426718535054
      },
      {
        "epoch": 1238,
        "reward": 0.38423413038253784,
        "val_loss": 0.007430243971092361,
        "train_loss": 0.014430521732160391
      },
      {
        "epoch": 1239,
        "reward": 0.4154670238494873,
        "val_loss": 0.0057267553306051665,
        "train_loss": 0.010367201992686694
      },
      {
        "epoch": 1240,
        "reward": 0.23388905823230743,
        "val_loss": 0.03104039587612663,
        "train_loss": 0.006642650029299637
      },
      {
        "epoch": 1241,
        "reward": 0.10872882604598999,
        "val_loss": 0.19439898218427384,
        "train_loss": 0.0343052359441152
      },
      {
        "epoch": 1242,
        "reward": 0.2402980774641037,
        "val_loss": 0.02891674917191267,
        "train_loss": 0.03944347492562464
      },
      {
        "epoch": 1243,
        "reward": 0.20150087773799896,
        "val_loss": 0.045431667140551975,
        "train_loss": 0.06125014236358066
      },
      {
        "epoch": 1244,
        "reward": 0.3733794391155243,
        "val_loss": 0.008148398982094867,
        "train_loss": 0.012592585537976656
      },
      {
        "epoch": 1245,
        "reward": 0.230877086520195,
        "val_loss": 0.0321065414963024,
        "train_loss": 0.026888314204720352
      },
      {
        "epoch": 1246,
        "reward": 0.12925541400909424,
        "val_loss": 0.13129484334162303,
        "train_loss": 0.020387175434734672
      },
      {
        "epoch": 1247,
        "reward": 0.6478330492973328,
        "val_loss": 0.0008549379999749362,
        "train_loss": 0.022749325582900874
      },
      {
        "epoch": 1248,
        "reward": 0.36435869336128235,
        "val_loss": 0.008805005811154842,
        "train_loss": 0.0013671237292538325
      },
      {
        "epoch": 1249,
        "reward": 0.6031242609024048,
        "val_loss": 0.0012527350502620851,
        "train_loss": 0.005841611509542697
      },
      {
        "epoch": 1250,
        "reward": 0.576415479183197,
        "val_loss": 0.0015623292503213243,
        "train_loss": 0.0022632399453029325
      },
      {
        "epoch": 1251,
        "reward": 0.4086308479309082,
        "val_loss": 0.006059246869491679,
        "train_loss": 0.0018967040263165613
      },
      {
        "epoch": 1252,
        "reward": 0.40364399552345276,
        "val_loss": 0.006315065082162619,
        "train_loss": 0.0035608580868798667
      },
      {
        "epoch": 1253,
        "reward": 0.22257311642169952,
        "val_loss": 0.03529697071228709,
        "train_loss": 0.012372336014567945
      },
      {
        "epoch": 1254,
        "reward": 0.36309221386909485,
        "val_loss": 0.008901905135384627,
        "train_loss": 0.022100552530341353
      },
      {
        "epoch": 1255,
        "reward": 0.37104108929634094,
        "val_loss": 0.008313124201127462,
        "train_loss": 0.006587040372323827
      },
      {
        "epoch": 1256,
        "reward": 0.26912829279899597,
        "val_loss": 0.021336700235094343,
        "train_loss": 0.005834726124213865
      },
      {
        "epoch": 1257,
        "reward": 0.31450870633125305,
        "val_loss": 0.013743655223931586,
        "train_loss": 0.010398579080804037
      },
      {
        "epoch": 1258,
        "reward": 0.2486049234867096,
        "val_loss": 0.026429015610899245,
        "train_loss": 0.007750913862764719
      },
      {
        "epoch": 1259,
        "reward": 0.21715429425239563,
        "val_loss": 0.03759925067424774,
        "train_loss": 0.00632662278006207
      },
      {
        "epoch": 1260,
        "reward": 0.2836157977581024,
        "val_loss": 0.018458441565079347,
        "train_loss": 0.00980773200101864
      },
      {
        "epoch": 1261,
        "reward": 0.18740245699882507,
        "val_loss": 0.05439564372811999,
        "train_loss": 0.10585645937289183
      },
      {
        "epoch": 1262,
        "reward": 0.14335577189922333,
        "val_loss": 0.10330808269126075,
        "train_loss": 0.014467130253951136
      },
      {
        "epoch": 1263,
        "reward": 0.385290265083313,
        "val_loss": 0.007364238595723042,
        "train_loss": 0.023362500955744717
      },
      {
        "epoch": 1264,
        "reward": 0.20554521679878235,
        "val_loss": 0.043220260845763345,
        "train_loss": 0.00538622531054828
      },
      {
        "epoch": 1265,
        "reward": 0.40850725769996643,
        "val_loss": 0.006065449743930783,
        "train_loss": 0.010282505599137109
      },
      {
        "epoch": 1266,
        "reward": 0.28598737716674805,
        "val_loss": 0.018033569678664207,
        "train_loss": 0.002965034916996956
      },
      {
        "epoch": 1267,
        "reward": 0.5715747475624084,
        "val_loss": 0.0016254279928814089,
        "train_loss": 0.003013114173777117
      },
      {
        "epoch": 1268,
        "reward": 0.6157552003860474,
        "val_loss": 0.0011265840813783662,
        "train_loss": 0.0010012710758578929
      },
      {
        "epoch": 1269,
        "reward": 0.6589181423187256,
        "val_loss": 0.000775207212427631,
        "train_loss": 0.0013779151452651534
      },
      {
        "epoch": 1270,
        "reward": 0.5414912700653076,
        "val_loss": 0.0020743206176640733,
        "train_loss": 0.0010662588564488173
      },
      {
        "epoch": 1271,
        "reward": 0.6127601265907288,
        "val_loss": 0.0011554275323370738,
        "train_loss": 0.0031121943499713848
      },
      {
        "epoch": 1272,
        "reward": 0.3996104896068573,
        "val_loss": 0.006530646035181624,
        "train_loss": 0.002811235657785661
      },
      {
        "epoch": 1273,
        "reward": 0.2435244619846344,
        "val_loss": 0.027916977714215006,
        "train_loss": 0.004896219289198948
      },
      {
        "epoch": 1274,
        "reward": 0.34054747223854065,
        "val_loss": 0.010848643291475517,
        "train_loss": 0.02470543975225435
      },
      {
        "epoch": 1275,
        "reward": 0.4859257638454437,
        "val_loss": 0.0032379905793017577,
        "train_loss": 0.015840921622629348
      },
      {
        "epoch": 1276,
        "reward": 0.5096117854118347,
        "val_loss": 0.0026789518971262233,
        "train_loss": 0.001956118958052964
      },
      {
        "epoch": 1277,
        "reward": 0.5522536635398865,
        "val_loss": 0.0019017386117151805,
        "train_loss": 0.002341370943423289
      },
      {
        "epoch": 1278,
        "reward": 0.31316399574279785,
        "val_loss": 0.013916377377297198,
        "train_loss": 0.0013384161203738097
      },
      {
        "epoch": 1279,
        "reward": 0.4541320502758026,
        "val_loss": 0.004179982701316476,
        "train_loss": 0.0048225389842767846
      },
      {
        "epoch": 1280,
        "reward": 0.20664480328559875,
        "val_loss": 0.04264323439981256,
        "train_loss": 0.0055586967299369955
      },
      {
        "epoch": 1281,
        "reward": 0.5998254418373108,
        "val_loss": 0.0012876945547759533,
        "train_loss": 0.012357154380634502
      },
      {
        "epoch": 1282,
        "reward": 0.48763591051101685,
        "val_loss": 0.0031939620218638864,
        "train_loss": 0.0010661368488889332
      },
      {
        "epoch": 1283,
        "reward": 0.6211331486701965,
        "val_loss": 0.001076384721922555,
        "train_loss": 0.0011723418361865557
      },
      {
        "epoch": 1284,
        "reward": 0.4844687879085541,
        "val_loss": 0.0032759856465937836,
        "train_loss": 0.0013049696684062767
      },
      {
        "epoch": 1285,
        "reward": 0.3581295907497406,
        "val_loss": 0.00929347172911678,
        "train_loss": 0.0023332635643712888
      },
      {
        "epoch": 1286,
        "reward": 0.47320958971977234,
        "val_loss": 0.0035853563209197353,
        "train_loss": 0.0027597174518562565
      },
      {
        "epoch": 1287,
        "reward": 0.5762978196144104,
        "val_loss": 0.0015638358475241279,
        "train_loss": 0.003994137550202699
      },
      {
        "epoch": 1288,
        "reward": 0.3182651698589325,
        "val_loss": 0.013274446928075381,
        "train_loss": 0.005457272971398197
      },
      {
        "epoch": 1289,
        "reward": 0.6624101400375366,
        "val_loss": 0.0007514300357018198,
        "train_loss": 0.004775995861004608
      },
      {
        "epoch": 1290,
        "reward": 0.22929313778877258,
        "val_loss": 0.03268587176821062,
        "train_loss": 0.003299948175761249
      },
      {
        "epoch": 1291,
        "reward": 0.11334256082773209,
        "val_loss": 0.17704729310103826,
        "train_loss": 0.030872722625854995
      },
      {
        "epoch": 1292,
        "reward": 0.12317490577697754,
        "val_loss": 0.14660375033106124,
        "train_loss": 0.045779855259192676
      },
      {
        "epoch": 1293,
        "reward": 0.11847652494907379,
        "val_loss": 0.16016470960208348,
        "train_loss": 0.05652952557088261
      },
      {
        "epoch": 1294,
        "reward": 0.5741734504699707,
        "val_loss": 0.001591266565290945,
        "train_loss": 0.02249206024302671
      },
      {
        "epoch": 1295,
        "reward": 0.5970264673233032,
        "val_loss": 0.0013180429065999175,
        "train_loss": 0.0016346152164120353
      },
      {
        "epoch": 1296,
        "reward": 0.28831806778907776,
        "val_loss": 0.017627551087311337,
        "train_loss": 0.001963729245919519
      },
      {
        "epoch": 1297,
        "reward": 0.07468640804290771,
        "val_loss": 0.4440770745277405,
        "train_loss": 0.03494974334563057
      },
      {
        "epoch": 1298,
        "reward": 0.5593860745429993,
        "val_loss": 0.0017949686984398536,
        "train_loss": 0.22113749599129034
      },
      {
        "epoch": 1299,
        "reward": 0.3118920922279358,
        "val_loss": 0.014082123791532857,
        "train_loss": 0.005050567727616558
      },
      {
        "epoch": 1300,
        "reward": 0.34148532152175903,
        "val_loss": 0.01075846841558814,
        "train_loss": 0.003812957019992889
      },
      {
        "epoch": 1301,
        "reward": 0.2938764989376068,
        "val_loss": 0.016703033753271614,
        "train_loss": 0.007296520486796418
      },
      {
        "epoch": 1302,
        "reward": 0.6308698654174805,
        "val_loss": 0.000990474272319781,
        "train_loss": 0.009046075861148823
      },
      {
        "epoch": 1303,
        "reward": 0.6790868043899536,
        "val_loss": 0.0006460828548629902,
        "train_loss": 0.00128088776993816
      },
      {
        "epoch": 1304,
        "reward": 0.5228208899497986,
        "val_loss": 0.0024100207291277392,
        "train_loss": 0.0012320737744000955
      },
      {
        "epoch": 1305,
        "reward": 0.40128371119499207,
        "val_loss": 0.006440251832827926,
        "train_loss": 0.002305452866354384
      },
      {
        "epoch": 1306,
        "reward": 0.22942017018795013,
        "val_loss": 0.0326389256598694,
        "train_loss": 0.015357006842700334
      },
      {
        "epoch": 1307,
        "reward": 0.2844372093677521,
        "val_loss": 0.018309916502663066,
        "train_loss": 0.01905499090655492
      },
      {
        "epoch": 1308,
        "reward": 0.23596246540546417,
        "val_loss": 0.03033243545464107,
        "train_loss": 0.014614950943863593
      },
      {
        "epoch": 1309,
        "reward": 0.4743287265300751,
        "val_loss": 0.0035533123383564608,
        "train_loss": 0.006957389343789635
      },
      {
        "epoch": 1310,
        "reward": 0.34318968653678894,
        "val_loss": 0.010596808312194688,
        "train_loss": 0.004979345645271958
      },
      {
        "epoch": 1311,
        "reward": 0.16985882818698883,
        "val_loss": 0.06910212151706219,
        "train_loss": 0.018685126189106647
      },
      {
        "epoch": 1312,
        "reward": 0.15274909138679504,
        "val_loss": 0.0890082988355841,
        "train_loss": 0.03770602746786048
      },
      {
        "epoch": 1313,
        "reward": 0.1976347416639328,
        "val_loss": 0.04768494835921696,
        "train_loss": 0.05800710000375357
      },
      {
        "epoch": 1314,
        "reward": 0.23591366410255432,
        "val_loss": 0.030348863718765124,
        "train_loss": 0.04684380282952379
      },
      {
        "epoch": 1315,
        "reward": 0.15729476511478424,
        "val_loss": 0.08303983722414289,
        "train_loss": 0.026941812409159657
      },
      {
        "epoch": 1316,
        "reward": 0.2280409336090088,
        "val_loss": 0.033153287534202845,
        "train_loss": 0.02087079499884007
      },
      {
        "epoch": 1317,
        "reward": 0.6589937210083008,
        "val_loss": 0.0007746860584510225,
        "train_loss": 0.010524910615808599
      },
      {
        "epoch": 1318,
        "reward": 0.5013050436973572,
        "val_loss": 0.002863053881031062,
        "train_loss": 0.0013995544203540843
      },
      {
        "epoch": 1319,
        "reward": 0.2919336259365082,
        "val_loss": 0.017019367377672876,
        "train_loss": 0.001815544788349563
      },
      {
        "epoch": 1320,
        "reward": 0.4661920964717865,
        "val_loss": 0.0037931836476283415,
        "train_loss": 0.00555039977413029
      },
      {
        "epoch": 1321,
        "reward": 0.36817869544029236,
        "val_loss": 0.008519908080675773,
        "train_loss": 0.0021968992055357937
      },
      {
        "epoch": 1322,
        "reward": 0.24279280006885529,
        "val_loss": 0.02813983815056937,
        "train_loss": 0.007132649838100546
      },
      {
        "epoch": 1323,
        "reward": 0.5179101228713989,
        "val_loss": 0.0025067495880648494,
        "train_loss": 0.017028589504591834
      },
      {
        "epoch": 1324,
        "reward": 0.281863272190094,
        "val_loss": 0.018780237728995935,
        "train_loss": 0.006958103098440915
      },
      {
        "epoch": 1325,
        "reward": 0.28292545676231384,
        "val_loss": 0.018584383518568108,
        "train_loss": 0.008287548177087536
      },
      {
        "epoch": 1326,
        "reward": 0.18138039112091064,
        "val_loss": 0.05893148189144475,
        "train_loss": 0.019202482273193218
      },
      {
        "epoch": 1327,
        "reward": 0.2066957801580429,
        "val_loss": 0.0426167223070349,
        "train_loss": 0.015254407661569321
      },
      {
        "epoch": 1328,
        "reward": 0.5539295077323914,
        "val_loss": 0.0018761257441448314,
        "train_loss": 0.02168605034911217
      },
      {
        "epoch": 1329,
        "reward": 0.5476376414299011,
        "val_loss": 0.0019740128690110786,
        "train_loss": 0.001470486655867157
      },
      {
        "epoch": 1330,
        "reward": 0.5350036025047302,
        "val_loss": 0.0021854930923187305,
        "train_loss": 0.0012644649843703238
      },
      {
        "epoch": 1331,
        "reward": 0.670160710811615,
        "val_loss": 0.0007008263242564031,
        "train_loss": 0.0013383974348051618
      },
      {
        "epoch": 1332,
        "reward": 0.6033446192741394,
        "val_loss": 0.0012504296111209051,
        "train_loss": 0.0008232592260285926
      },
      {
        "epoch": 1333,
        "reward": 0.5159192085266113,
        "val_loss": 0.0025470402823495014,
        "train_loss": 0.0011318793368935496
      },
      {
        "epoch": 1334,
        "reward": 0.4592367708683014,
        "val_loss": 0.004011480437059488,
        "train_loss": 0.0009208245572573595
      },
      {
        "epoch": 1335,
        "reward": 0.22315573692321777,
        "val_loss": 0.035060284925358634,
        "train_loss": 0.0063319025032867035
      },
      {
        "epoch": 1336,
        "reward": 0.4616214334964752,
        "val_loss": 0.003935202823153564,
        "train_loss": 0.008650971688509274
      },
      {
        "epoch": 1337,
        "reward": 0.4438292682170868,
        "val_loss": 0.004543056578508445,
        "train_loss": 0.002172191336285323
      },
      {
        "epoch": 1338,
        "reward": 0.26555731892585754,
        "val_loss": 0.022129054580416,
        "train_loss": 0.004499401311757258
      },
      {
        "epoch": 1339,
        "reward": 0.3342317044734955,
        "val_loss": 0.01147927955857345,
        "train_loss": 0.011969660066265183
      },
      {
        "epoch": 1340,
        "reward": 0.5145410299301147,
        "val_loss": 0.0025753063881503685,
        "train_loss": 0.0024307910229813736
      },
      {
        "epoch": 1341,
        "reward": 0.23683808743953705,
        "val_loss": 0.0300395917147398,
        "train_loss": 0.0016627219995895687
      },
      {
        "epoch": 1342,
        "reward": 0.34764477610588074,
        "val_loss": 0.010187331454030104,
        "train_loss": 0.009145038768810291
      },
      {
        "epoch": 1343,
        "reward": 0.5564758777618408,
        "val_loss": 0.0018378300093380468,
        "train_loss": 0.010972041925504947
      },
      {
        "epoch": 1344,
        "reward": 0.4842151701450348,
        "val_loss": 0.003282644844148308,
        "train_loss": 0.0016062999582992722
      },
      {
        "epoch": 1345,
        "reward": 0.6134994626045227,
        "val_loss": 0.0011482472514866718,
        "train_loss": 0.0028291773532356066
      },
      {
        "epoch": 1346,
        "reward": 0.6505091190338135,
        "val_loss": 0.0008350810135847756,
        "train_loss": 0.0036314432755506667
      },
      {
        "epoch": 1347,
        "reward": 0.4050524830818176,
        "val_loss": 0.006241637514904141,
        "train_loss": 0.0047199808218815285
      },
      {
        "epoch": 1348,
        "reward": 0.5961625576019287,
        "val_loss": 0.0013275388295629195,
        "train_loss": 0.003225127779387549
      },
      {
        "epoch": 1349,
        "reward": 0.6244193911552429,
        "val_loss": 0.0010466875807781304,
        "train_loss": 0.0015882928788554496
      },
      {
        "epoch": 1350,
        "reward": 0.6081847548484802,
        "val_loss": 0.001200757554865309,
        "train_loss": 0.0007200142609168945
      },
      {
        "epoch": 1351,
        "reward": 0.5357061624526978,
        "val_loss": 0.002173182870527463,
        "train_loss": 0.0013782889268790872
      },
      {
        "epoch": 1352,
        "reward": 0.4752858579158783,
        "val_loss": 0.0035261377758745637,
        "train_loss": 0.006643379205692886
      },
      {
        "epoch": 1353,
        "reward": 0.3295908570289612,
        "val_loss": 0.011969974896471416,
        "train_loss": 0.005169800458064016
      },
      {
        "epoch": 1354,
        "reward": 0.28202056884765625,
        "val_loss": 0.018751072896910564,
        "train_loss": 0.011834681051998185
      },
      {
        "epoch": 1355,
        "reward": 0.6234031915664673,
        "val_loss": 0.0010557936704052345,
        "train_loss": 0.03052655229336009
      },
      {
        "epoch": 1356,
        "reward": 0.49350419640541077,
        "val_loss": 0.003047429707034358,
        "train_loss": 0.000998252927764462
      },
      {
        "epoch": 1357,
        "reward": 0.5438628792762756,
        "val_loss": 0.0020350528980738352,
        "train_loss": 0.0013732435416806345
      },
      {
        "epoch": 1358,
        "reward": 0.6671714782714844,
        "val_loss": 0.0007199953459868473,
        "train_loss": 0.0011666188242648228
      },
      {
        "epoch": 1359,
        "reward": 0.5651930570602417,
        "val_loss": 0.0017122336264167512,
        "train_loss": 0.0014394229063047813
      },
      {
        "epoch": 1360,
        "reward": 0.3892267942428589,
        "val_loss": 0.007123905965792281,
        "train_loss": 0.003170401023593373
      },
      {
        "epoch": 1361,
        "reward": 0.20054936408996582,
        "val_loss": 0.045973168153847964,
        "train_loss": 0.00541597568259861
      },
      {
        "epoch": 1362,
        "reward": 0.17632807791233063,
        "val_loss": 0.06312904400484902,
        "train_loss": 0.04975731774734763
      },
      {
        "epoch": 1363,
        "reward": 0.1305876523256302,
        "val_loss": 0.12823630603296415,
        "train_loss": 0.11275500979704353
      },
      {
        "epoch": 1364,
        "reward": 0.2491462230682373,
        "val_loss": 0.02627639818404402,
        "train_loss": 0.11003223086635654
      },
      {
        "epoch": 1365,
        "reward": 0.13828419148921967,
        "val_loss": 0.11234321125916072,
        "train_loss": 0.07196845813618544
      },
      {
        "epoch": 1366,
        "reward": 0.37334227561950684,
        "val_loss": 0.008150984133992876,
        "train_loss": 0.13879453451730883
      },
      {
        "epoch": 1367,
        "reward": 0.4831113815307617,
        "val_loss": 0.0033117917565894978,
        "train_loss": 0.006941057850221673
      },
      {
        "epoch": 1368,
        "reward": 0.6082870960235596,
        "val_loss": 0.001199726655613631,
        "train_loss": 0.0022991862596637267
      },
      {
        "epoch": 1369,
        "reward": 0.43656525015830994,
        "val_loss": 0.004818950247551713,
        "train_loss": 0.001358113268417163
      },
      {
        "epoch": 1370,
        "reward": 0.5855850577354431,
        "val_loss": 0.0014489539483162975,
        "train_loss": 0.0018300458983643553
      },
      {
        "epoch": 1371,
        "reward": 0.6728953123092651,
        "val_loss": 0.0006836632466209787,
        "train_loss": 0.0008240905732376492
      },
      {
        "epoch": 1372,
        "reward": 0.5042058229446411,
        "val_loss": 0.0027973758322852,
        "train_loss": 0.000874560190893065
      },
      {
        "epoch": 1373,
        "reward": 0.4325719475746155,
        "val_loss": 0.00497815791251404,
        "train_loss": 0.002932107774540782
      },
      {
        "epoch": 1374,
        "reward": 0.5325803756713867,
        "val_loss": 0.0022284726978146602,
        "train_loss": 0.002002199719964455
      },
      {
        "epoch": 1375,
        "reward": 0.48298516869544983,
        "val_loss": 0.0033151422228131977,
        "train_loss": 0.0015302640833677007
      },
      {
        "epoch": 1376,
        "reward": 0.6983588933944702,
        "val_loss": 0.00053974350365544,
        "train_loss": 0.002524692327894557
      },
      {
        "epoch": 1377,
        "reward": 0.40319815278053284,
        "val_loss": 0.006338506670934814,
        "train_loss": 0.0012736555106060293
      },
      {
        "epoch": 1378,
        "reward": 0.3651743233203888,
        "val_loss": 0.008743235974439554,
        "train_loss": 0.005984974071347656
      },
      {
        "epoch": 1379,
        "reward": 0.4403300881385803,
        "val_loss": 0.004673807848510998,
        "train_loss": 0.0029601556480674143
      },
      {
        "epoch": 1380,
        "reward": 0.4550531506538391,
        "val_loss": 0.0041490419036043545,
        "train_loss": 0.0027071425429312512
      },
      {
        "epoch": 1381,
        "reward": 0.618672788143158,
        "val_loss": 0.0010990994217406427,
        "train_loss": 0.0014633227334483168
      },
      {
        "epoch": 1382,
        "reward": 0.6888052225112915,
        "val_loss": 0.0005905212227454675,
        "train_loss": 0.0010029362277306903
      },
      {
        "epoch": 1383,
        "reward": 0.2876012325286865,
        "val_loss": 0.017751234849648818,
        "train_loss": 0.0009025098026121178
      },
      {
        "epoch": 1384,
        "reward": 0.6171865463256836,
        "val_loss": 0.00111302562956033,
        "train_loss": 0.0038644832048493507
      },
      {
        "epoch": 1385,
        "reward": 0.511628270149231,
        "val_loss": 0.0026360631288428393,
        "train_loss": 0.000973963129441612
      },
      {
        "epoch": 1386,
        "reward": 0.684220016002655,
        "val_loss": 0.0006162278420690979,
        "train_loss": 0.00111596731247888
      },
      {
        "epoch": 1387,
        "reward": 0.5139948129653931,
        "val_loss": 0.0025865924212017228,
        "train_loss": 0.0011930496839340776
      },
      {
        "epoch": 1388,
        "reward": 0.5873907208442688,
        "val_loss": 0.0014275377200517272,
        "train_loss": 0.0021183824215908176
      },
      {
        "epoch": 1389,
        "reward": 0.36949312686920166,
        "val_loss": 0.00842423630612237,
        "train_loss": 0.0012222884170814024
      },
      {
        "epoch": 1390,
        "reward": 0.2527056038379669,
        "val_loss": 0.025299818920237676,
        "train_loss": 0.004796763530556256
      },
      {
        "epoch": 1391,
        "reward": 0.13041596114635468,
        "val_loss": 0.12862495545830047,
        "train_loss": 0.024981328250410464
      },
      {
        "epoch": 1392,
        "reward": 0.22434230148792267,
        "val_loss": 0.03458450920879841,
        "train_loss": 0.05013038886066239
      },
      {
        "epoch": 1393,
        "reward": 0.26534733176231384,
        "val_loss": 0.022176774750862802,
        "train_loss": 0.03705946738437678
      },
      {
        "epoch": 1394,
        "reward": 0.5386704802513123,
        "val_loss": 0.0021219729096628726,
        "train_loss": 0.009194229913051598
      },
      {
        "epoch": 1395,
        "reward": 0.6928003430366516,
        "val_loss": 0.0005688387609552592,
        "train_loss": 0.0023961418659242694
      },
      {
        "epoch": 1396,
        "reward": 0.6094115972518921,
        "val_loss": 0.0011884499939956836,
        "train_loss": 0.0007066455108752751
      },
      {
        "epoch": 1397,
        "reward": 0.25844207406044006,
        "val_loss": 0.02381921306784664,
        "train_loss": 0.0016054260262395614
      },
      {
        "epoch": 1398,
        "reward": 0.28950035572052,
        "val_loss": 0.0174258186348847,
        "train_loss": 0.0096384174774777
      },
      {
        "epoch": 1399,
        "reward": 0.3713300824165344,
        "val_loss": 0.008292563991355044,
        "train_loss": 0.0034395506529388232
      },
      {
        "epoch": 1400,
        "reward": 0.24401794373989105,
        "val_loss": 0.02776790357061795,
        "train_loss": 0.008925155006671468
      },
      {
        "epoch": 1401,
        "reward": 0.1888265758752823,
        "val_loss": 0.053390615220580785,
        "train_loss": 0.018933064778348826
      },
      {
        "epoch": 1402,
        "reward": 0.26648733019828796,
        "val_loss": 0.021919257938861847,
        "train_loss": 0.02652852574451222
      },
      {
        "epoch": 1403,
        "reward": 0.6657655835151672,
        "val_loss": 0.0007291607159589018,
        "train_loss": 0.003611407827030724
      },
      {
        "epoch": 1404,
        "reward": 0.4732309877872467,
        "val_loss": 0.0035847402842981474,
        "train_loss": 0.0009207269042515411
      },
      {
        "epoch": 1405,
        "reward": 0.548444390296936,
        "val_loss": 0.0019611959744776997,
        "train_loss": 0.001191509944664386
      },
      {
        "epoch": 1406,
        "reward": 0.5198149085044861,
        "val_loss": 0.0024687866015093668,
        "train_loss": 0.0015951318827529366
      },
      {
        "epoch": 1407,
        "reward": 0.24535901844501495,
        "val_loss": 0.027367832139134407,
        "train_loss": 0.002891720189766672
      },
      {
        "epoch": 1408,
        "reward": 0.38651329278945923,
        "val_loss": 0.007288617348032338,
        "train_loss": 0.01753415017782782
      },
      {
        "epoch": 1409,
        "reward": 0.3377276360988617,
        "val_loss": 0.01112509605341724,
        "train_loss": 0.007841172075131908
      },
      {
        "epoch": 1410,
        "reward": 0.3034662902355194,
        "val_loss": 0.0152414772393448,
        "train_loss": 0.04219515204357986
      },
      {
        "epoch": 1411,
        "reward": 0.5913438200950623,
        "val_loss": 0.0013816555313366865,
        "train_loss": 0.028071188144027613
      },
      {
        "epoch": 1412,
        "reward": 0.3712509572505951,
        "val_loss": 0.008298186186168875,
        "train_loss": 0.004275218090557386
      },
      {
        "epoch": 1413,
        "reward": 0.19417497515678406,
        "val_loss": 0.04982630669006279,
        "train_loss": 0.013662382937931957
      },
      {
        "epoch": 1414,
        "reward": 0.3779321610927582,
        "val_loss": 0.007838111204494323,
        "train_loss": 0.015961132110812917
      },
      {
        "epoch": 1415,
        "reward": 0.2758719325065613,
        "val_loss": 0.019933307277304784,
        "train_loss": 0.009202667527670901
      },
      {
        "epoch": 1416,
        "reward": 0.2938689887523651,
        "val_loss": 0.016704242609973465,
        "train_loss": 0.01510460769238237
      },
      {
        "epoch": 1417,
        "reward": 0.4181552827358246,
        "val_loss": 0.005601478075342519,
        "train_loss": 0.007186242432978291
      },
      {
        "epoch": 1418,
        "reward": 0.48203691840171814,
        "val_loss": 0.00334041632179703,
        "train_loss": 0.003217304756757445
      },
      {
        "epoch": 1419,
        "reward": 0.49424371123313904,
        "val_loss": 0.003029451672253864,
        "train_loss": 0.0024505149754426945
      },
      {
        "epoch": 1420,
        "reward": 0.5295202136039734,
        "val_loss": 0.0022839187045714687,
        "train_loss": 0.0018825492236199072
      },
      {
        "epoch": 1421,
        "reward": 0.6921383738517761,
        "val_loss": 0.000572385873445975,
        "train_loss": 0.0018458338622272445
      },
      {
        "epoch": 1422,
        "reward": 0.5745812654495239,
        "val_loss": 0.0015859666247186916,
        "train_loss": 0.000952400725089739
      },
      {
        "epoch": 1423,
        "reward": 0.5015758275985718,
        "val_loss": 0.0028568580580343094,
        "train_loss": 0.0010696971663500894
      },
      {
        "epoch": 1424,
        "reward": 0.4166205823421478,
        "val_loss": 0.0056726290411981085,
        "train_loss": 0.004050816731670728
      },
      {
        "epoch": 1425,
        "reward": 0.5554014444351196,
        "val_loss": 0.001853898200871689,
        "train_loss": 0.004666871702423892
      },
      {
        "epoch": 1426,
        "reward": 0.545809268951416,
        "val_loss": 0.0020033567312306593,
        "train_loss": 0.0022993089302102677
      },
      {
        "epoch": 1427,
        "reward": 0.4877359867095947,
        "val_loss": 0.003191403013521007,
        "train_loss": 0.0012897029846849013
      },
      {
        "epoch": 1428,
        "reward": 0.313117116689682,
        "val_loss": 0.013922446806515967,
        "train_loss": 0.004666754269587377
      },
      {
        "epoch": 1429,
        "reward": 0.19119144976139069,
        "val_loss": 0.051774777472019196,
        "train_loss": 0.018671398937630538
      },
      {
        "epoch": 1430,
        "reward": 0.36883875727653503,
        "val_loss": 0.00847171586272972,
        "train_loss": 0.011045485084580902
      },
      {
        "epoch": 1431,
        "reward": 0.4881229102611542,
        "val_loss": 0.003181535318227751,
        "train_loss": 0.0028595019293089327
      },
      {
        "epoch": 1432,
        "reward": 0.422262042760849,
        "val_loss": 0.005415784062019416,
        "train_loss": 0.0017480926320646317
      },
      {
        "epoch": 1433,
        "reward": 0.31364092230796814,
        "val_loss": 0.013854822143912315,
        "train_loss": 0.0064763459376990795
      },
      {
        "epoch": 1434,
        "reward": 0.2818128168582916,
        "val_loss": 0.01878959672259433,
        "train_loss": 0.010429098734256024
      },
      {
        "epoch": 1435,
        "reward": 0.21732352674007416,
        "val_loss": 0.03752448848847832,
        "train_loss": 0.006950913350850057
      },
      {
        "epoch": 1436,
        "reward": 0.34473374485969543,
        "val_loss": 0.010452778278184789,
        "train_loss": 0.02127659473962222
      },
      {
        "epoch": 1437,
        "reward": 0.11467427015304565,
        "val_loss": 0.17243995091744832,
        "train_loss": 0.007185824372125073
      },
      {
        "epoch": 1438,
        "reward": 0.22195231914520264,
        "val_loss": 0.03555140404828957,
        "train_loss": 0.04431074521450613
      },
      {
        "epoch": 1439,
        "reward": 0.5129730105400085,
        "val_loss": 0.002607838882665549,
        "train_loss": 0.0084882905706995
      },
      {
        "epoch": 1440,
        "reward": 0.4739108681678772,
        "val_loss": 0.0035652417157377514,
        "train_loss": 0.00573331581052536
      },
      {
        "epoch": 1441,
        "reward": 0.398561954498291,
        "val_loss": 0.006588002999446222,
        "train_loss": 0.0023229993427006635
      },
      {
        "epoch": 1442,
        "reward": 0.6623824834823608,
        "val_loss": 0.0007516157015093736,
        "train_loss": 0.0015276285054054684
      },
      {
        "epoch": 1443,
        "reward": 0.4742531478404999,
        "val_loss": 0.003555467917716929,
        "train_loss": 0.000723794758344481
      },
      {
        "epoch": 1444,
        "reward": 0.22061137855052948,
        "val_loss": 0.03610904488180365,
        "train_loss": 0.006119944981037406
      },
      {
        "epoch": 1445,
        "reward": 0.37357789278030396,
        "val_loss": 0.008134588665728058,
        "train_loss": 0.008073881157123161
      },
      {
        "epoch": 1446,
        "reward": 0.31970328092575073,
        "val_loss": 0.013099847427968467,
        "train_loss": 0.0053023563277047984
      },
      {
        "epoch": 1447,
        "reward": 0.5418676137924194,
        "val_loss": 0.002068042372619467,
        "train_loss": 0.006377848773039519
      },
      {
        "epoch": 1448,
        "reward": 0.12489531189203262,
        "val_loss": 0.14203369191714696,
        "train_loss": 0.002297085940461749
      },
      {
        "epoch": 1449,
        "reward": 0.17193716764450073,
        "val_loss": 0.06710435450077057,
        "train_loss": 0.08265241976970664
      },
      {
        "epoch": 1450,
        "reward": 0.3086268901824951,
        "val_loss": 0.014518476823078734,
        "train_loss": 0.01915765666084413
      },
      {
        "epoch": 1451,
        "reward": 0.4656383693218231,
        "val_loss": 0.0038101026854876962,
        "train_loss": 0.006108290368501912
      },
      {
        "epoch": 1452,
        "reward": 0.42085036635398865,
        "val_loss": 0.0054788560207401004,
        "train_loss": 0.0018727106776518317
      },
      {
        "epoch": 1453,
        "reward": 0.3592033088207245,
        "val_loss": 0.009207115907754217,
        "train_loss": 0.002734739469395628
      },
      {
        "epoch": 1454,
        "reward": 0.428447961807251,
        "val_loss": 0.0051484808791428804,
        "train_loss": 0.005732904075277754
      },
      {
        "epoch": 1455,
        "reward": 0.3835495710372925,
        "val_loss": 0.007473377677212868,
        "train_loss": 0.003065841223220699
      },
      {
        "epoch": 1456,
        "reward": 0.2147608995437622,
        "val_loss": 0.038677382948143144,
        "train_loss": 0.010598170718787095
      },
      {
        "epoch": 1457,
        "reward": 0.07283943146467209,
        "val_loss": 0.4687491995947702,
        "train_loss": 0.029717232960347947
      },
      {
        "epoch": 1458,
        "reward": 0.11784323304891586,
        "val_loss": 0.16212345659732819,
        "train_loss": 0.2787303524808242
      },
      {
        "epoch": 1459,
        "reward": 0.469713419675827,
        "val_loss": 0.0036873898103034924,
        "train_loss": 0.06513884453586517
      },
      {
        "epoch": 1460,
        "reward": 0.21192681789398193,
        "val_loss": 0.040005986977900775,
        "train_loss": 0.022697519901647374
      },
      {
        "epoch": 1461,
        "reward": 0.4720233380794525,
        "val_loss": 0.00361964655374842,
        "train_loss": 0.012949694727117626
      },
      {
        "epoch": 1462,
        "reward": 0.5123557448387146,
        "val_loss": 0.002620756160467863,
        "train_loss": 0.003111293942380983
      },
      {
        "epoch": 1463,
        "reward": 0.4868488907814026,
        "val_loss": 0.0032141479064843486,
        "train_loss": 0.002237856768680593
      },
      {
        "epoch": 1464,
        "reward": 0.25346243381500244,
        "val_loss": 0.02509803936949798,
        "train_loss": 0.005067377103422097
      },
      {
        "epoch": 1465,
        "reward": 0.4342215657234192,
        "val_loss": 0.004911720686193023,
        "train_loss": 0.009010461136662902
      },
      {
        "epoch": 1466,
        "reward": 0.5974341630935669,
        "val_loss": 0.001313582727951663,
        "train_loss": 0.00432414399424138
      },
      {
        "epoch": 1467,
        "reward": 0.6223428845405579,
        "val_loss": 0.0010653675084800593,
        "train_loss": 0.0010124498151596456
      },
      {
        "epoch": 1468,
        "reward": 0.2120985984802246,
        "val_loss": 0.039923793503216336,
        "train_loss": 0.0011378226313704194
      },
      {
        "epoch": 1469,
        "reward": 0.43356138467788696,
        "val_loss": 0.0049381945947451255,
        "train_loss": 0.010868679424255298
      },
      {
        "epoch": 1470,
        "reward": 0.4576595723628998,
        "val_loss": 0.004062773659825325,
        "train_loss": 0.005399720470170275
      },
      {
        "epoch": 1471,
        "reward": 0.6571124792098999,
        "val_loss": 0.0007877486225749765,
        "train_loss": 0.0035664605205126395
      },
      {
        "epoch": 1472,
        "reward": 0.6157674193382263,
        "val_loss": 0.0011264682398177683,
        "train_loss": 0.002119842661788705
      },
      {
        "epoch": 1473,
        "reward": 0.42382970452308655,
        "val_loss": 0.005346660236162799,
        "train_loss": 0.0016561385249535586
      },
      {
        "epoch": 1474,
        "reward": 0.5662986636161804,
        "val_loss": 0.0016968908520149334,
        "train_loss": 0.0018113307551874851
      },
      {
        "epoch": 1475,
        "reward": 0.6077865362167358,
        "val_loss": 0.0012047766358591616,
        "train_loss": 0.0013431402577015643
      },
      {
        "epoch": 1476,
        "reward": 0.40397000312805176,
        "val_loss": 0.006297985823558909,
        "train_loss": 0.0016312238382782268
      },
      {
        "epoch": 1477,
        "reward": 0.5958685278892517,
        "val_loss": 0.0013307864012728845,
        "train_loss": 0.0015267015573604463
      },
      {
        "epoch": 1478,
        "reward": 0.5008126497268677,
        "val_loss": 0.0028743548983974116,
        "train_loss": 0.0008163782163487318
      },
      {
        "epoch": 1479,
        "reward": 0.5474476218223572,
        "val_loss": 0.0019770437252840827,
        "train_loss": 0.008485512837069109
      },
      {
        "epoch": 1480,
        "reward": 0.6647077202796936,
        "val_loss": 0.0007361210300587118,
        "train_loss": 0.0024429291041507474
      },
      {
        "epoch": 1481,
        "reward": 0.6970187425613403,
        "val_loss": 0.0005466461214902145,
        "train_loss": 0.000626197880662333
      },
      {
        "epoch": 1482,
        "reward": 0.48047319054603577,
        "val_loss": 0.0033825268702847616,
        "train_loss": 0.0010419766823850716
      },
      {
        "epoch": 1483,
        "reward": 0.3630238175392151,
        "val_loss": 0.008907173095004899,
        "train_loss": 0.0036580740527894636
      },
      {
        "epoch": 1484,
        "reward": 0.4803940951824188,
        "val_loss": 0.00338467227161995,
        "train_loss": 0.004444327077810437
      },
      {
        "epoch": 1485,
        "reward": 0.3165442645549774,
        "val_loss": 0.013487005872385842,
        "train_loss": 0.003691384414336286
      },
      {
        "epoch": 1486,
        "reward": 0.49889546632766724,
        "val_loss": 0.002918779683698501,
        "train_loss": 0.004949745039661698
      },
      {
        "epoch": 1487,
        "reward": 0.15467996895313263,
        "val_loss": 0.08640479668974876,
        "train_loss": 0.004309968725115491
      },
      {
        "epoch": 1488,
        "reward": 0.2729349136352539,
        "val_loss": 0.020530149872813905,
        "train_loss": 0.027658455622328732
      },
      {
        "epoch": 1489,
        "reward": 0.4502142071723938,
        "val_loss": 0.004314320394769311,
        "train_loss": 0.012514348311994512
      },
      {
        "epoch": 1490,
        "reward": 0.5392313599586487,
        "val_loss": 0.0021124143552567276,
        "train_loss": 0.004267811741626177
      },
      {
        "epoch": 1491,
        "reward": 0.6250184178352356,
        "val_loss": 0.0010413531895859965,
        "train_loss": 0.003524273987680387
      },
      {
        "epoch": 1492,
        "reward": 0.32069364190101624,
        "val_loss": 0.012981186620891094,
        "train_loss": 0.0025383671118806186
      },
      {
        "epoch": 1493,
        "reward": 0.466322660446167,
        "val_loss": 0.0037892062017428024,
        "train_loss": 0.006122103874986351
      },
      {
        "epoch": 1494,
        "reward": 0.3783092200756073,
        "val_loss": 0.007813013890492064,
        "train_loss": 0.0038933863039486683
      },
      {
        "epoch": 1495,
        "reward": 0.4588063359260559,
        "val_loss": 0.004025412374176085,
        "train_loss": 0.004812919395939948
      },
      {
        "epoch": 1496,
        "reward": 0.3670850694179535,
        "val_loss": 0.008600445464253426,
        "train_loss": 0.0037021769155846694
      },
      {
        "epoch": 1497,
        "reward": 0.6856037974357605,
        "val_loss": 0.0006083753417312567,
        "train_loss": 0.00415761373229683
      },
      {
        "epoch": 1498,
        "reward": 0.4409235119819641,
        "val_loss": 0.004651357935342405,
        "train_loss": 0.001613872768267846
      },
      {
        "epoch": 1499,
        "reward": 0.49532023072242737,
        "val_loss": 0.003003469917790166,
        "train_loss": 0.00497862755414994
      },
      {
        "epoch": 1500,
        "reward": 0.5133984088897705,
        "val_loss": 0.002598971951686378,
        "train_loss": 0.004149832995608449
      },
      {
        "epoch": 1501,
        "reward": 0.24577997624874115,
        "val_loss": 0.027243744315845624,
        "train_loss": 0.009545554908422323
      },
      {
        "epoch": 1502,
        "reward": 0.5754931569099426,
        "val_loss": 0.001574174451109554,
        "train_loss": 0.015092579616556087
      },
      {
        "epoch": 1503,
        "reward": 0.6933507323265076,
        "val_loss": 0.0005659026002311813,
        "train_loss": 0.002866672057559929
      },
      {
        "epoch": 1504,
        "reward": 0.6368806958198547,
        "val_loss": 0.0009404726692342333,
        "train_loss": 0.0012186398514761375
      },
      {
        "epoch": 1505,
        "reward": 0.3354201018810272,
        "val_loss": 0.011357424980295556,
        "train_loss": 0.0019026623062228072
      },
      {
        "epoch": 1506,
        "reward": 0.4736305773258209,
        "val_loss": 0.0035732678869473083,
        "train_loss": 0.008269811178951595
      },
      {
        "epoch": 1507,
        "reward": 0.5214109420776367,
        "val_loss": 0.0024374123562925626,
        "train_loss": 0.00191327185278239
      },
      {
        "epoch": 1508,
        "reward": 0.5883272290229797,
        "val_loss": 0.0014165434154814907,
        "train_loss": 0.0014505942213313223
      },
      {
        "epoch": 1509,
        "reward": 0.3183199465274811,
        "val_loss": 0.013267745663012778,
        "train_loss": 0.0023395281638771007
      },
      {
        "epoch": 1510,
        "reward": 0.40982624888420105,
        "val_loss": 0.005999623598264796,
        "train_loss": 0.013469041714695497
      },
      {
        "epoch": 1511,
        "reward": 0.44602757692337036,
        "val_loss": 0.004462894085528595,
        "train_loss": 0.0057221473118541045
      },
      {
        "epoch": 1512,
        "reward": 0.5708031058311462,
        "val_loss": 0.0016357014620942728,
        "train_loss": 0.0018234642221404312
      },
      {
        "epoch": 1513,
        "reward": 0.48523464798927307,
        "val_loss": 0.0032559565401503016,
        "train_loss": 0.00142320941197865
      },
      {
        "epoch": 1514,
        "reward": 0.20682421326637268,
        "val_loss": 0.042550036417586465,
        "train_loss": 0.0025786627878775247
      },
      {
        "epoch": 1515,
        "reward": 0.3827718496322632,
        "val_loss": 0.007522723770567349,
        "train_loss": 0.020257341899335958
      },
      {
        "epoch": 1516,
        "reward": 0.40223413705825806,
        "val_loss": 0.006389518401452473,
        "train_loss": 0.02628177947973689
      },
      {
        "epoch": 1517,
        "reward": 0.4437572956085205,
        "val_loss": 0.00454570639080235,
        "train_loss": 0.00335820165939647
      },
      {
        "epoch": 1518,
        "reward": 0.5385690331459045,
        "val_loss": 0.0021237058764589684,
        "train_loss": 0.0031378418095230768
      },
      {
        "epoch": 1519,
        "reward": 0.1273740530014038,
        "val_loss": 0.13578691759279796,
        "train_loss": 0.007452689066457634
      },
      {
        "epoch": 1520,
        "reward": 0.36495742201805115,
        "val_loss": 0.008759614944990193,
        "train_loss": 0.042097125589722194
      },
      {
        "epoch": 1521,
        "reward": 0.37135419249534607,
        "val_loss": 0.008290850191510149,
        "train_loss": 0.004632553579330516
      },
      {
        "epoch": 1522,
        "reward": 0.4447398781776428,
        "val_loss": 0.004509667200701577,
        "train_loss": 0.0041857637003816376
      },
      {
        "epoch": 1523,
        "reward": 0.5606632232666016,
        "val_loss": 0.0017764571156086667,
        "train_loss": 0.0029217125590478713
      },
      {
        "epoch": 1524,
        "reward": 0.4730520248413086,
        "val_loss": 0.003589891138420041,
        "train_loss": 0.0016725344948309402
      },
      {
        "epoch": 1525,
        "reward": 0.428782194852829,
        "val_loss": 0.0051344458812049455,
        "train_loss": 0.0023992219514464242
      },
      {
        "epoch": 1526,
        "reward": 0.5086278915405273,
        "val_loss": 0.0027001280769971864,
        "train_loss": 0.004675053239155274
      },
      {
        "epoch": 1527,
        "reward": 0.7034081816673279,
        "val_loss": 0.0005143598329076278,
        "train_loss": 0.0010944177625928065
      },
      {
        "epoch": 1528,
        "reward": 0.6399725079536438,
        "val_loss": 0.0009156141812647027,
        "train_loss": 0.0006048687064321712
      },
      {
        "epoch": 1529,
        "reward": 0.42319247126579285,
        "val_loss": 0.005374643086854901,
        "train_loss": 0.0009349077254927789
      },
      {
        "epoch": 1530,
        "reward": 0.6134456992149353,
        "val_loss": 0.0011487683514133096,
        "train_loss": 0.003173536383725989
      },
      {
        "epoch": 1531,
        "reward": 0.5810840725898743,
        "val_loss": 0.0015036247038681591,
        "train_loss": 0.0010068339433928486
      },
      {
        "epoch": 1532,
        "reward": 0.49438855051994324,
        "val_loss": 0.003025942132808268,
        "train_loss": 0.0018060543046046335
      },
      {
        "epoch": 1533,
        "reward": 0.29568561911582947,
        "val_loss": 0.016414829662867954,
        "train_loss": 0.0013246719676177376
      },
      {
        "epoch": 1534,
        "reward": 0.3393140733242035,
        "val_loss": 0.010968570397900683,
        "train_loss": 0.012078674765339551
      },
      {
        "epoch": 1535,
        "reward": 0.27967867255210876,
        "val_loss": 0.019191000876682147,
        "train_loss": 0.03187750117145837
      },
      {
        "epoch": 1536,
        "reward": 0.6050874590873718,
        "val_loss": 0.0012323366328408675,
        "train_loss": 0.007582043895336728
      },
      {
        "epoch": 1537,
        "reward": 0.6197730898857117,
        "val_loss": 0.0010888903634622693,
        "train_loss": 0.001841690595028922
      },
      {
        "epoch": 1538,
        "reward": 0.7040386199951172,
        "val_loss": 0.0005112588821378138,
        "train_loss": 0.001202121094907992
      },
      {
        "epoch": 1539,
        "reward": 0.6944445967674255,
        "val_loss": 0.0005601033668166824,
        "train_loss": 0.0006772410595324083
      },
      {
        "epoch": 1540,
        "reward": 0.419795423746109,
        "val_loss": 0.005526503814118249,
        "train_loss": 0.0026804541793913252
      },
      {
        "epoch": 1541,
        "reward": 0.5438444018363953,
        "val_loss": 0.0020353561766179545,
        "train_loss": 0.0020547697527385587
      },
      {
        "epoch": 1542,
        "reward": 0.6602672934532166,
        "val_loss": 0.0007659474254718848,
        "train_loss": 0.0022967737056135843
      },
      {
        "epoch": 1543,
        "reward": 0.5563693046569824,
        "val_loss": 0.0018394182635737316,
        "train_loss": 0.0012311718220679234
      },
      {
        "epoch": 1544,
        "reward": 0.3774976134300232,
        "val_loss": 0.007867149276924985,
        "train_loss": 0.0068791642686567055
      },
      {
        "epoch": 1545,
        "reward": 0.44864851236343384,
        "val_loss": 0.0043692632711359435,
        "train_loss": 0.014737046198346294
      },
      {
        "epoch": 1546,
        "reward": 0.38062986731529236,
        "val_loss": 0.007660524786583015,
        "train_loss": 0.0041208212586263055
      },
      {
        "epoch": 1547,
        "reward": 0.5068816542625427,
        "val_loss": 0.0027381221797051175,
        "train_loss": 0.002947810450538012
      },
      {
        "epoch": 1548,
        "reward": 0.2712079584598541,
        "val_loss": 0.020891329273581505,
        "train_loss": 0.0014180787089012133
      },
      {
        "epoch": 1549,
        "reward": 0.14711341261863708,
        "val_loss": 0.09723927506378718,
        "train_loss": 0.052041747535650544
      },
      {
        "epoch": 1550,
        "reward": 0.16999395191669464,
        "val_loss": 0.06896984151431493,
        "train_loss": 0.034319057514389545
      },
      {
        "epoch": 1551,
        "reward": 0.08270777016878128,
        "val_loss": 0.355866014957428,
        "train_loss": 0.15814592141228226
      },
      {
        "epoch": 1552,
        "reward": 0.17999212443828583,
        "val_loss": 0.06004719915134566,
        "train_loss": 0.11936234169227716
      },
      {
        "epoch": 1553,
        "reward": 0.32828253507614136,
        "val_loss": 0.01211271235453231,
        "train_loss": 0.03407656602268197
      },
      {
        "epoch": 1554,
        "reward": 0.5902653932571411,
        "val_loss": 0.0013940375398046204,
        "train_loss": 0.0037644910514175603
      },
      {
        "epoch": 1555,
        "reward": 0.6063385009765625,
        "val_loss": 0.0012194926551144039,
        "train_loss": 0.0010762963032063383
      },
      {
        "epoch": 1556,
        "reward": 0.6808871626853943,
        "val_loss": 0.0006354801340161689,
        "train_loss": 0.0008709281776366249
      },
      {
        "epoch": 1557,
        "reward": 0.6832200884819031,
        "val_loss": 0.0006219536964116352,
        "train_loss": 0.0006193180895654502
      },
      {
        "epoch": 1558,
        "reward": 0.3990976810455322,
        "val_loss": 0.006558628287166357,
        "train_loss": 0.0010019865176918057
      },
      {
        "epoch": 1559,
        "reward": 0.5845316648483276,
        "val_loss": 0.0014615831647201308,
        "train_loss": 0.00309208678215957
      },
      {
        "epoch": 1560,
        "reward": 0.5795069932937622,
        "val_loss": 0.0015232244373432227,
        "train_loss": 0.0023408262764300723
      },
      {
        "epoch": 1561,
        "reward": 0.4404335021972656,
        "val_loss": 0.004669886980471867,
        "train_loss": 0.0008362819274994903
      },
      {
        "epoch": 1562,
        "reward": 0.46693840622901917,
        "val_loss": 0.003770502151123115,
        "train_loss": 0.001962321629434882
      },
      {
        "epoch": 1563,
        "reward": 0.49025940895080566,
        "val_loss": 0.0031275932643828647,
        "train_loss": 0.003267609435939588
      },
      {
        "epoch": 1564,
        "reward": 0.6430993676185608,
        "val_loss": 0.0008910503903669971,
        "train_loss": 0.001508492903667502
      },
      {
        "epoch": 1565,
        "reward": 0.6810566186904907,
        "val_loss": 0.0006344896890888256,
        "train_loss": 0.0008364612143710614
      },
      {
        "epoch": 1566,
        "reward": 0.5167478919029236,
        "val_loss": 0.002530192756759269,
        "train_loss": 0.0006407965321649009
      },
      {
        "epoch": 1567,
        "reward": 0.6335340142250061,
        "val_loss": 0.0009680354227644525,
        "train_loss": 0.001265043725232737
      },
      {
        "epoch": 1568,
        "reward": 0.46556147933006287,
        "val_loss": 0.003812457235263927,
        "train_loss": 0.0014077527941061328
      },
      {
        "epoch": 1569,
        "reward": 0.3323422372341156,
        "val_loss": 0.011676170863211155,
        "train_loss": 0.0014706814396189516
      },
      {
        "epoch": 1570,
        "reward": 0.6602434515953064,
        "val_loss": 0.0007661097250612718,
        "train_loss": 0.0022418632680245745
      },
      {
        "epoch": 1571,
        "reward": 0.6176978945732117,
        "val_loss": 0.0011082165708233202,
        "train_loss": 0.0009046530612977222
      },
      {
        "epoch": 1572,
        "reward": 0.7111222147941589,
        "val_loss": 0.0004774232552985528,
        "train_loss": 0.0012147328390990598
      },
      {
        "epoch": 1573,
        "reward": 0.36670589447021484,
        "val_loss": 0.008628569543361664,
        "train_loss": 0.0009932247832274209
      },
      {
        "epoch": 1574,
        "reward": 0.6272943615913391,
        "val_loss": 0.0010212991370021232,
        "train_loss": 0.0019800967554776715
      },
      {
        "epoch": 1575,
        "reward": 0.2848726212978363,
        "val_loss": 0.01823177986911365,
        "train_loss": 0.0010534336918051569
      },
      {
        "epoch": 1576,
        "reward": 0.2826128304004669,
        "val_loss": 0.01864177254693849,
        "train_loss": 0.015739197173388675
      },
      {
        "epoch": 1577,
        "reward": 0.4334677755832672,
        "val_loss": 0.004941959333206926,
        "train_loss": 0.010288017869103126
      },
      {
        "epoch": 1578,
        "reward": 0.5658982396125793,
        "val_loss": 0.001702433335594833,
        "train_loss": 0.00238250303125544
      },
      {
        "epoch": 1579,
        "reward": 0.6137391924858093,
        "val_loss": 0.001145927792614592,
        "train_loss": 0.0049320405792409126
      },
      {
        "epoch": 1580,
        "reward": 0.6697974801063538,
        "val_loss": 0.0007031328693431403,
        "train_loss": 0.0008551337086828426
      },
      {
        "epoch": 1581,
        "reward": 0.3334951102733612,
        "val_loss": 0.011555566918104887,
        "train_loss": 0.0007951466317396038
      },
      {
        "epoch": 1582,
        "reward": 0.3159676194190979,
        "val_loss": 0.013559131483946527,
        "train_loss": 0.0018258176065641097
      },
      {
        "epoch": 1583,
        "reward": 0.6471995711326599,
        "val_loss": 0.0008596973660002862,
        "train_loss": 0.004299661093122827
      },
      {
        "epoch": 1584,
        "reward": 0.48932990431785583,
        "val_loss": 0.003150945978372225,
        "train_loss": 0.0007671859868703625
      },
      {
        "epoch": 1585,
        "reward": 0.5294488668441772,
        "val_loss": 0.0022852266140814337,
        "train_loss": 0.001175989073369867
      },
      {
        "epoch": 1586,
        "reward": 0.4936758577823639,
        "val_loss": 0.003043246438859829,
        "train_loss": 0.0017651858075763672
      },
      {
        "epoch": 1587,
        "reward": 0.45991936326026917,
        "val_loss": 0.0039894911793193644,
        "train_loss": 0.0025777083176832935
      },
      {
        "epoch": 1588,
        "reward": 0.5006174445152283,
        "val_loss": 0.0028788458688982894,
        "train_loss": 0.001596277093855091
      },
      {
        "epoch": 1589,
        "reward": 0.6509589552879333,
        "val_loss": 0.0008317820361948439,
        "train_loss": 0.0009633098933800983
      },
      {
        "epoch": 1590,
        "reward": 0.38960573077201843,
        "val_loss": 0.007101236576480525,
        "train_loss": 0.0007566175683258245
      },
      {
        "epoch": 1591,
        "reward": 0.4504571557044983,
        "val_loss": 0.004305859661794135,
        "train_loss": 0.001830529340972694
      },
      {
        "epoch": 1592,
        "reward": 0.6792561411857605,
        "val_loss": 0.0006450793838926724,
        "train_loss": 0.0038614711554076234
      },
      {
        "epoch": 1593,
        "reward": 0.39435768127441406,
        "val_loss": 0.006823631136545113,
        "train_loss": 0.000886476350457927
      },
      {
        "epoch": 1594,
        "reward": 0.5910825133323669,
        "val_loss": 0.0013846455424624895,
        "train_loss": 0.0021289782128475895
      },
      {
        "epoch": 1595,
        "reward": 0.45545902848243713,
        "val_loss": 0.004135481813656432,
        "train_loss": 0.0009583014918741985
      },
      {
        "epoch": 1596,
        "reward": 0.7072331309318542,
        "val_loss": 0.0004957724138096507,
        "train_loss": 0.0019079149435408628
      },
      {
        "epoch": 1597,
        "reward": 0.4191438853740692,
        "val_loss": 0.005556157823385937,
        "train_loss": 0.0016602397512402744
      },
      {
        "epoch": 1598,
        "reward": 0.3861062228679657,
        "val_loss": 0.007313692410077367,
        "train_loss": 0.0021864607989112547
      },
      {
        "epoch": 1599,
        "reward": 0.31610557436943054,
        "val_loss": 0.013541833963245153,
        "train_loss": 0.00450132609022638
      },
      {
        "epoch": 1600,
        "reward": 0.6259796619415283,
        "val_loss": 0.0010328415831151818,
        "train_loss": 0.004564674940551273
      },
      {
        "epoch": 1601,
        "reward": 0.5375582575798035,
        "val_loss": 0.0021410503457965596,
        "train_loss": 0.0010991682423851811
      },
      {
        "epoch": 1602,
        "reward": 0.36648741364479065,
        "val_loss": 0.008644823018195373,
        "train_loss": 0.012375300700149148
      },
      {
        "epoch": 1603,
        "reward": 0.3715534210205078,
        "val_loss": 0.008276713878980704,
        "train_loss": 0.006573331799770061
      },
      {
        "epoch": 1604,
        "reward": 0.5436508059501648,
        "val_loss": 0.0020385357784107327,
        "train_loss": 0.004621201985103723
      },
      {
        "epoch": 1605,
        "reward": 0.48287445306777954,
        "val_loss": 0.003318083505811436,
        "train_loss": 0.0015346617952813036
      },
      {
        "epoch": 1606,
        "reward": 0.47336897253990173,
        "val_loss": 0.003580774346898709,
        "train_loss": 0.0022384537822710206
      },
      {
        "epoch": 1607,
        "reward": 0.4296625256538391,
        "val_loss": 0.005097680625372699,
        "train_loss": 0.0029521321322625647
      },
      {
        "epoch": 1608,
        "reward": 0.5849340558052063,
        "val_loss": 0.0014567468814285739,
        "train_loss": 0.003998648561089515
      },
      {
        "epoch": 1609,
        "reward": 0.15176273882389069,
        "val_loss": 0.09037910614694868,
        "train_loss": 0.010594150638028692
      },
      {
        "epoch": 1610,
        "reward": 0.18781499564647675,
        "val_loss": 0.054101974836417606,
        "train_loss": 0.043343229398417935
      },
      {
        "epoch": 1611,
        "reward": 0.10091334581375122,
        "val_loss": 0.22965160650866373,
        "train_loss": 0.03492190746160654
      },
      {
        "epoch": 1612,
        "reward": 0.14922355115413666,
        "val_loss": 0.0940415688923427,
        "train_loss": 0.10159465976847479
      },
      {
        "epoch": 1613,
        "reward": 0.31462612748146057,
        "val_loss": 0.013728696320738112,
        "train_loss": 0.030294122371392753
      },
      {
        "epoch": 1614,
        "reward": 0.08154009282588959,
        "val_loss": 0.3670639246702194,
        "train_loss": 0.009429971517350238
      },
      {
        "epoch": 1615,
        "reward": 0.061433982104063034,
        "val_loss": 0.675267721925463,
        "train_loss": 0.12911995586294395
      },
      {
        "epoch": 1616,
        "reward": 0.1875482052564621,
        "val_loss": 0.05429165916783469,
        "train_loss": 0.45599787008876985
      },
      {
        "epoch": 1617,
        "reward": 0.292868435382843,
        "val_loss": 0.01686627311365945,
        "train_loss": 0.07380574768803154
      },
      {
        "epoch": 1618,
        "reward": 0.36967533826828003,
        "val_loss": 0.008411069201039416,
        "train_loss": 0.006644825713010505
      },
      {
        "epoch": 1619,
        "reward": 0.576673686504364,
        "val_loss": 0.0015590277533712132,
        "train_loss": 0.004175272980669083
      },
      {
        "epoch": 1620,
        "reward": 0.5205597877502441,
        "val_loss": 0.002454094962948667,
        "train_loss": 0.00126138220478494
      },
      {
        "epoch": 1621,
        "reward": 0.6097584366798401,
        "val_loss": 0.0011849917937070131,
        "train_loss": 0.0015033731909240417
      },
      {
        "epoch": 1622,
        "reward": 0.6976912617683411,
        "val_loss": 0.0005431733360247952,
        "train_loss": 0.0007146013371171788
      },
      {
        "epoch": 1623,
        "reward": 0.5683481097221375,
        "val_loss": 0.0016687919768238707,
        "train_loss": 0.0006940399314491794
      },
      {
        "epoch": 1624,
        "reward": 0.5700392127037048,
        "val_loss": 0.0016459325062377112,
        "train_loss": 0.0008836488125850267
      },
      {
        "epoch": 1625,
        "reward": 0.5500878691673279,
        "val_loss": 0.0019353300698899797,
        "train_loss": 0.0008065584552241489
      },
      {
        "epoch": 1626,
        "reward": 0.5929686427116394,
        "val_loss": 0.0013631888182966837,
        "train_loss": 0.0009437814819998144
      },
      {
        "epoch": 1627,
        "reward": 0.578969419002533,
        "val_loss": 0.0015299582737497985,
        "train_loss": 0.0006617858066769819
      },
      {
        "epoch": 1628,
        "reward": 0.7053312659263611,
        "val_loss": 0.0005049465772961932,
        "train_loss": 0.0008227352605340107
      },
      {
        "epoch": 1629,
        "reward": 0.6821717023849487,
        "val_loss": 0.0006280027030568038,
        "train_loss": 0.0005444900044284833
      },
      {
        "epoch": 1630,
        "reward": 0.7061331272125244,
        "val_loss": 0.0005010625630218003,
        "train_loss": 0.000579238755073255
      },
      {
        "epoch": 1631,
        "reward": 0.5461079478263855,
        "val_loss": 0.0019985351245850325,
        "train_loss": 0.0007472512034627681
      },
      {
        "epoch": 1632,
        "reward": 0.5433055758476257,
        "val_loss": 0.0020442165633929627,
        "train_loss": 0.0010402522513266797
      },
      {
        "epoch": 1633,
        "reward": 0.6834020018577576,
        "val_loss": 0.0006209084281830915,
        "train_loss": 0.0010529897531691508
      },
      {
        "epoch": 1634,
        "reward": 0.6252807974815369,
        "val_loss": 0.0010390237688885204,
        "train_loss": 0.0005546929261562092
      },
      {
        "epoch": 1635,
        "reward": 0.5258105397224426,
        "val_loss": 0.0023529297239812358,
        "train_loss": 0.0007507148906230354
      },
      {
        "epoch": 1636,
        "reward": 0.3415214717388153,
        "val_loss": 0.010755013807543687,
        "train_loss": 0.0011259822819668513
      },
      {
        "epoch": 1637,
        "reward": 0.349890798330307,
        "val_loss": 0.009987832346398915,
        "train_loss": 0.0044933904069834035
      },
      {
        "epoch": 1638,
        "reward": 0.42937764525413513,
        "val_loss": 0.005109548003279737,
        "train_loss": 0.0041178483862985065
      },
      {
        "epoch": 1639,
        "reward": 0.5859692096710205,
        "val_loss": 0.0014443731467638696,
        "train_loss": 0.004252675110295128
      },
      {
        "epoch": 1640,
        "reward": 0.6626405715942383,
        "val_loss": 0.0007498824769364936,
        "train_loss": 0.002376583423028933
      },
      {
        "epoch": 1641,
        "reward": 0.6833158135414124,
        "val_loss": 0.0006214032099316162,
        "train_loss": 0.0007059032878504905
      },
      {
        "epoch": 1642,
        "reward": 0.5517086982727051,
        "val_loss": 0.001910137927292713,
        "train_loss": 0.0006740344025414602
      },
      {
        "epoch": 1643,
        "reward": 0.5488882064819336,
        "val_loss": 0.0019541779599551645,
        "train_loss": 0.0010321253631432753
      },
      {
        "epoch": 1644,
        "reward": 0.4699419438838959,
        "val_loss": 0.0036806303542107344,
        "train_loss": 0.0017002429700159365
      },
      {
        "epoch": 1645,
        "reward": 0.5268086791038513,
        "val_loss": 0.002334163574102734,
        "train_loss": 0.001685448398907633
      },
      {
        "epoch": 1646,
        "reward": 0.3904765248298645,
        "val_loss": 0.007049441038231764,
        "train_loss": 0.001486206044669066
      },
      {
        "epoch": 1647,
        "reward": 0.6900380849838257,
        "val_loss": 0.0005837600287382624,
        "train_loss": 0.0013942886790363656
      },
      {
        "epoch": 1648,
        "reward": 0.5819178223609924,
        "val_loss": 0.0014933571053136671,
        "train_loss": 0.0009198794130218
      },
      {
        "epoch": 1649,
        "reward": 0.44762617349624634,
        "val_loss": 0.004405539050432188,
        "train_loss": 0.0020733728216817747
      },
      {
        "epoch": 1650,
        "reward": 0.4424859583377838,
        "val_loss": 0.00459278657633279,
        "train_loss": 0.0027684605358025203
      },
      {
        "epoch": 1651,
        "reward": 0.642798125743866,
        "val_loss": 0.0008933916272196386,
        "train_loss": 0.0013212323918616255
      },
      {
        "epoch": 1652,
        "reward": 0.542804479598999,
        "val_loss": 0.002052488354300814,
        "train_loss": 0.0007349427077525223
      },
      {
        "epoch": 1653,
        "reward": 0.673205554485321,
        "val_loss": 0.0006817383857976113,
        "train_loss": 0.0014424127540013825
      },
      {
        "epoch": 1654,
        "reward": 0.6626536250114441,
        "val_loss": 0.0007497952818604452,
        "train_loss": 0.0005805722435136082
      },
      {
        "epoch": 1655,
        "reward": 0.6071029901504517,
        "val_loss": 0.0012117039794767542,
        "train_loss": 0.0007933636124317462
      },
      {
        "epoch": 1656,
        "reward": 0.5636035799980164,
        "val_loss": 0.0017345170490443707,
        "train_loss": 0.001069629815622018
      },
      {
        "epoch": 1657,
        "reward": 0.30783531069755554,
        "val_loss": 0.014626678811120135,
        "train_loss": 0.001463862537863091
      },
      {
        "epoch": 1658,
        "reward": 0.5998351573944092,
        "val_loss": 0.0012875901302322745,
        "train_loss": 0.005920836666169075
      },
      {
        "epoch": 1659,
        "reward": 0.6113889813423157,
        "val_loss": 0.0011688500110592162,
        "train_loss": 0.0014444332460138516
      },
      {
        "epoch": 1660,
        "reward": 0.32387199997901917,
        "val_loss": 0.012608825162585293,
        "train_loss": 0.0012732247269013897
      },
      {
        "epoch": 1661,
        "reward": 0.36110642552375793,
        "val_loss": 0.009056289148117815,
        "train_loss": 0.00526874745488525
      },
      {
        "epoch": 1662,
        "reward": 0.6518852114677429,
        "val_loss": 0.000825023656943813,
        "train_loss": 0.004233331577359842
      },
      {
        "epoch": 1663,
        "reward": 0.6766035556793213,
        "val_loss": 0.0006609453287507806,
        "train_loss": 0.000771183771147522
      },
      {
        "epoch": 1664,
        "reward": 0.5598642230033875,
        "val_loss": 0.0017880166082509927,
        "train_loss": 0.0007087679752238238
      },
      {
        "epoch": 1665,
        "reward": 0.5510792136192322,
        "val_loss": 0.0019198845839127898,
        "train_loss": 0.0024253640798493647
      },
      {
        "epoch": 1666,
        "reward": 0.5895611643791199,
        "val_loss": 0.0014021770829068764,
        "train_loss": 0.0013828792893596424
      },
      {
        "epoch": 1667,
        "reward": 0.5823909044265747,
        "val_loss": 0.0014875601212094938,
        "train_loss": 0.0013717528658722027
      },
      {
        "epoch": 1668,
        "reward": 0.5169011950492859,
        "val_loss": 0.0025270894236330476,
        "train_loss": 0.001035834783509087
      },
      {
        "epoch": 1669,
        "reward": 0.5415241122245789,
        "val_loss": 0.002073772484436631,
        "train_loss": 0.0018987209992841459
      },
      {
        "epoch": 1670,
        "reward": 0.6396755576133728,
        "val_loss": 0.0009179763895060335,
        "train_loss": 0.0011813366492368425
      },
      {
        "epoch": 1671,
        "reward": 0.6836358904838562,
        "val_loss": 0.0006195670658988613,
        "train_loss": 0.0012953809077421634
      },
      {
        "epoch": 1672,
        "reward": 0.47045108675956726,
        "val_loss": 0.00366561597080103,
        "train_loss": 0.002148344081293684
      },
      {
        "epoch": 1673,
        "reward": 0.36590293049812317,
        "val_loss": 0.008688473142683506,
        "train_loss": 0.0023427981397897103
      },
      {
        "epoch": 1674,
        "reward": 0.43048205971717834,
        "val_loss": 0.0050637042981439406,
        "train_loss": 0.008732164765555913
      },
      {
        "epoch": 1675,
        "reward": 0.5165456533432007,
        "val_loss": 0.0025342952992234912,
        "train_loss": 0.0028871835619121646
      },
      {
        "epoch": 1676,
        "reward": 0.6157657504081726,
        "val_loss": 0.0011264826503715345,
        "train_loss": 0.0018819042065640718
      },
      {
        "epoch": 1677,
        "reward": 0.1725991815328598,
        "val_loss": 0.0664841468845095,
        "train_loss": 0.008226875475464532
      },
      {
        "epoch": 1678,
        "reward": 0.26664772629737854,
        "val_loss": 0.02188332032944475,
        "train_loss": 0.02224122650827317
      },
      {
        "epoch": 1679,
        "reward": 0.52750164270401,
        "val_loss": 0.0023212217991905554,
        "train_loss": 0.014712298194913624
      },
      {
        "epoch": 1680,
        "reward": 0.37259143590927124,
        "val_loss": 0.008203494029917888,
        "train_loss": 0.007385043973604647
      },
      {
        "epoch": 1681,
        "reward": 0.39926382899284363,
        "val_loss": 0.006549548756863389,
        "train_loss": 0.0064563454345016695
      },
      {
        "epoch": 1682,
        "reward": 0.7067856788635254,
        "val_loss": 0.0004979188670404255,
        "train_loss": 0.0037679250984253418
      },
      {
        "epoch": 1683,
        "reward": 0.6930223107337952,
        "val_loss": 0.0005676529045948493,
        "train_loss": 0.0007604794441446162
      },
      {
        "epoch": 1684,
        "reward": 0.48554179072380066,
        "val_loss": 0.003247960138001612,
        "train_loss": 0.0013067313064731513
      },
      {
        "epoch": 1685,
        "reward": 0.4267769455909729,
        "val_loss": 0.005219262043413307,
        "train_loss": 0.0038559546676249458
      },
      {
        "epoch": 1686,
        "reward": 0.15159569680690765,
        "val_loss": 0.09061408096126147,
        "train_loss": 0.005072444367512547
      },
      {
        "epoch": 1687,
        "reward": 0.24404363334178925,
        "val_loss": 0.027760166408760206,
        "train_loss": 0.03061191430942227
      },
      {
        "epoch": 1688,
        "reward": 0.10118807852268219,
        "val_loss": 0.22826675644942693,
        "train_loss": 0.040906628882602
      },
      {
        "epoch": 1689,
        "reward": 0.12745089828968048,
        "val_loss": 0.1355993545481137,
        "train_loss": 0.11758270286596738
      },
      {
        "epoch": 1690,
        "reward": 0.26598426699638367,
        "val_loss": 0.022032434719481638,
        "train_loss": 0.07429928078468387
      },
      {
        "epoch": 1691,
        "reward": 0.5181235671043396,
        "val_loss": 0.0025024678158972946,
        "train_loss": 0.012139784103335561
      },
      {
        "epoch": 1692,
        "reward": 0.6704736351966858,
        "val_loss": 0.0006988448356943471,
        "train_loss": 0.0015708492176669936
      },
      {
        "epoch": 1693,
        "reward": 0.4720679819583893,
        "val_loss": 0.00361835041881672,
        "train_loss": 0.0008313611089341486
      },
      {
        "epoch": 1694,
        "reward": 0.653951108455658,
        "val_loss": 0.0008101178432947823,
        "train_loss": 0.0017169171153979662
      },
      {
        "epoch": 1695,
        "reward": 0.6190938949584961,
        "val_loss": 0.0010951825700301146,
        "train_loss": 0.0011488506662807106
      },
      {
        "epoch": 1696,
        "reward": 0.5307173132896423,
        "val_loss": 0.0022620705255706397,
        "train_loss": 0.0012557015389365216
      },
      {
        "epoch": 1697,
        "reward": 0.5049911737442017,
        "val_loss": 0.0027798545280737536,
        "train_loss": 0.0009344619286891359
      },
      {
        "epoch": 1698,
        "reward": 0.5231131911277771,
        "val_loss": 0.002404379059693643,
        "train_loss": 0.0014212423680314364
      },
      {
        "epoch": 1699,
        "reward": 0.4392250180244446,
        "val_loss": 0.004715923918411136,
        "train_loss": 0.0019321092180549526
      },
      {
        "epoch": 1700,
        "reward": 0.3542780578136444,
        "val_loss": 0.009610949217208795,
        "train_loss": 0.0023224587661948484
      },
      {
        "epoch": 1701,
        "reward": 0.4185120761394501,
        "val_loss": 0.0055850759880351165,
        "train_loss": 0.0071531017176592005
      },
      {
        "epoch": 1702,
        "reward": 0.34747952222824097,
        "val_loss": 0.010202194364475352,
        "train_loss": 0.004965645830872325
      },
      {
        "epoch": 1703,
        "reward": 0.545183002948761,
        "val_loss": 0.0020135035904656562,
        "train_loss": 0.002056581393564836
      },
      {
        "epoch": 1704,
        "reward": 0.6366562247276306,
        "val_loss": 0.000942299616456564,
        "train_loss": 0.0026722400261160848
      },
      {
        "epoch": 1705,
        "reward": 0.6863424777984619,
        "val_loss": 0.0006042176766121494,
        "train_loss": 0.0013263172653611177
      },
      {
        "epoch": 1706,
        "reward": 0.6738302707672119,
        "val_loss": 0.0006778757129463234,
        "train_loss": 0.0008506294454017157
      },
      {
        "epoch": 1707,
        "reward": 0.5072640776634216,
        "val_loss": 0.0027297562919557095,
        "train_loss": 0.000804283348910618
      },
      {
        "epoch": 1708,
        "reward": 0.6051524877548218,
        "val_loss": 0.0012316658228103603,
        "train_loss": 0.0010429182629405449
      },
      {
        "epoch": 1709,
        "reward": 0.6694744825363159,
        "val_loss": 0.0007051890549649085,
        "train_loss": 0.0006213546943828218
      },
      {
        "epoch": 1710,
        "reward": 0.7089993357658386,
        "val_loss": 0.00048737128963693976,
        "train_loss": 0.0006302133771476712
      },
      {
        "epoch": 1711,
        "reward": 0.5888058543205261,
        "val_loss": 0.0014109552555185343,
        "train_loss": 0.0004935432326209804
      },
      {
        "epoch": 1712,
        "reward": 0.4758666455745697,
        "val_loss": 0.0035097550467721055,
        "train_loss": 0.0012018548429925712
      },
      {
        "epoch": 1713,
        "reward": 0.5803744792938232,
        "val_loss": 0.0015124140440353326,
        "train_loss": 0.0030266885867324443
      },
      {
        "epoch": 1714,
        "reward": 0.6356239318847656,
        "val_loss": 0.0009507423965260386,
        "train_loss": 0.0007612010516682998
      },
      {
        "epoch": 1715,
        "reward": 0.5641414523124695,
        "val_loss": 0.0017269464775121637,
        "train_loss": 0.000900771890883334
      },
      {
        "epoch": 1716,
        "reward": 0.31814929842948914,
        "val_loss": 0.013288630438702447,
        "train_loss": 0.0008644629292225895
      },
      {
        "epoch": 1717,
        "reward": 0.6196824312210083,
        "val_loss": 0.0010897282128488378,
        "train_loss": 0.004753879420324945
      },
      {
        "epoch": 1718,
        "reward": 0.6664837002754211,
        "val_loss": 0.0007244670913288635,
        "train_loss": 0.0016114617509839053
      },
      {
        "epoch": 1719,
        "reward": 0.6543520092964172,
        "val_loss": 0.0008072515899714615,
        "train_loss": 0.0006765722668765542
      },
      {
        "epoch": 1720,
        "reward": 0.4075842499732971,
        "val_loss": 0.006111982544617993,
        "train_loss": 0.0006508932576532691
      },
      {
        "epoch": 1721,
        "reward": 0.40121403336524963,
        "val_loss": 0.006443988598350968,
        "train_loss": 0.001656740735947656
      },
      {
        "epoch": 1722,
        "reward": 0.4750198423862457,
        "val_loss": 0.0035336705456886974,
        "train_loss": 0.0018825759198429855
      },
      {
        "epoch": 1723,
        "reward": 0.6348674297332764,
        "val_loss": 0.0009569708241282829,
        "train_loss": 0.0013394689680913312
      },
      {
        "epoch": 1724,
        "reward": 0.5392180681228638,
        "val_loss": 0.0021126410491498454,
        "train_loss": 0.0009679705536445209
      },
      {
        "epoch": 1725,
        "reward": 0.4805617332458496,
        "val_loss": 0.003380128648132086,
        "train_loss": 0.0010822753191370373
      },
      {
        "epoch": 1726,
        "reward": 0.674891471862793,
        "val_loss": 0.000671355561020651,
        "train_loss": 0.0015164269379266233
      },
      {
        "epoch": 1727,
        "reward": 0.5262863039970398,
        "val_loss": 0.0023439660601850066,
        "train_loss": 0.000731301711661777
      },
      {
        "epoch": 1728,
        "reward": 0.6170670390129089,
        "val_loss": 0.0011141523053603514,
        "train_loss": 0.0014936254614999948
      },
      {
        "epoch": 1729,
        "reward": 0.4800296723842621,
        "val_loss": 0.0033945690042206217,
        "train_loss": 0.0015271616676517834
      },
      {
        "epoch": 1730,
        "reward": 0.4842192232608795,
        "val_loss": 0.003282539114089949,
        "train_loss": 0.0012002401770307468
      },
      {
        "epoch": 1731,
        "reward": 0.591067910194397,
        "val_loss": 0.0013848140869023545,
        "train_loss": 0.0033134353579953313
      },
      {
        "epoch": 1732,
        "reward": 0.5606917142868042,
        "val_loss": 0.0017760462859379394,
        "train_loss": 0.001018999124146201
      },
      {
        "epoch": 1733,
        "reward": 0.5388689637184143,
        "val_loss": 0.002118586379635547,
        "train_loss": 0.0011108286069849362
      },
      {
        "epoch": 1734,
        "reward": 0.4205096364021301,
        "val_loss": 0.005494197497942618,
        "train_loss": 0.0024608254461782053
      },
      {
        "epoch": 1735,
        "reward": 0.3298674523830414,
        "val_loss": 0.01194005346457873,
        "train_loss": 0.00275102666973208
      },
      {
        "epoch": 1736,
        "reward": 0.48453569412231445,
        "val_loss": 0.0032742309849709272,
        "train_loss": 0.007285518032194187
      },
      {
        "epoch": 1737,
        "reward": 0.4365769028663635,
        "val_loss": 0.004818494531459042,
        "train_loss": 0.0026123257711543166
      },
      {
        "epoch": 1738,
        "reward": 0.5888544917106628,
        "val_loss": 0.0014103879470245115,
        "train_loss": 0.001690049628936007
      },
      {
        "epoch": 1739,
        "reward": 0.6757904291152954,
        "val_loss": 0.0006658728276046791,
        "train_loss": 0.0013986409590310918
      },
      {
        "epoch": 1740,
        "reward": 0.3409406244754791,
        "val_loss": 0.010810736965920244,
        "train_loss": 0.0009623100296056902
      },
      {
        "epoch": 1741,
        "reward": 0.5465594530105591,
        "val_loss": 0.001991267873173846,
        "train_loss": 0.0028706739180611642
      },
      {
        "epoch": 1742,
        "reward": 0.4754555821418762,
        "val_loss": 0.0035213432607374023,
        "train_loss": 0.0008810335421003401
      },
      {
        "epoch": 1743,
        "reward": 0.24242334067821503,
        "val_loss": 0.028253221352185522,
        "train_loss": 0.0038570753844956365
      },
      {
        "epoch": 1744,
        "reward": 0.5648669004440308,
        "val_loss": 0.0017167841350393637,
        "train_loss": 0.008638316848261569
      },
      {
        "epoch": 1745,
        "reward": 0.38809719681739807,
        "val_loss": 0.0071919662212686876,
        "train_loss": 0.001930376722699433
      },
      {
        "epoch": 1746,
        "reward": 0.2854108214378357,
        "val_loss": 0.018135759447302138,
        "train_loss": 0.0032831915416933885
      },
      {
        "epoch": 1747,
        "reward": 0.3175501823425293,
        "val_loss": 0.013362274904336249,
        "train_loss": 0.009793234734948223
      },
      {
        "epoch": 1748,
        "reward": 0.27849695086479187,
        "val_loss": 0.019417762756347656,
        "train_loss": 0.010431622611716963
      },
      {
        "epoch": 1749,
        "reward": 0.29560038447380066,
        "val_loss": 0.01642827263900212,
        "train_loss": 0.008179665252100676
      },
      {
        "epoch": 1750,
        "reward": 0.36280447244644165,
        "val_loss": 0.00892408677775945,
        "train_loss": 0.015741352005324397
      },
      {
        "epoch": 1751,
        "reward": 0.6360847353935242,
        "val_loss": 0.000946965189151732,
        "train_loss": 0.004654344039199014
      },
      {
        "epoch": 1752,
        "reward": 0.460839182138443,
        "val_loss": 0.003960058824824435,
        "train_loss": 0.0015166899395528443
      },
      {
        "epoch": 1753,
        "reward": 0.5748054385185242,
        "val_loss": 0.0015830598006557142,
        "train_loss": 0.002960556326830608
      },
      {
        "epoch": 1754,
        "reward": 0.35447725653648376,
        "val_loss": 0.009594229848257132,
        "train_loss": 0.0009680678888868827
      },
      {
        "epoch": 1755,
        "reward": 0.523087739944458,
        "val_loss": 0.002404869583967541,
        "train_loss": 0.0016331936438711216
      },
      {
        "epoch": 1756,
        "reward": 0.2706476151943207,
        "val_loss": 0.02101020169045244,
        "train_loss": 0.0026031160758485873
      },
      {
        "epoch": 1757,
        "reward": 0.4289492666721344,
        "val_loss": 0.005127446459872382,
        "train_loss": 0.0032713675934176603
      },
      {
        "epoch": 1758,
        "reward": 0.6724441051483154,
        "val_loss": 0.0006864708598836192,
        "train_loss": 0.0036293493489770647
      },
      {
        "epoch": 1759,
        "reward": 0.6740635633468628,
        "val_loss": 0.0006764375721104443,
        "train_loss": 0.0008411842823429302
      },
      {
        "epoch": 1760,
        "reward": 0.4605924189090729,
        "val_loss": 0.003967932026301112,
        "train_loss": 0.000929349737886626
      },
      {
        "epoch": 1761,
        "reward": 0.4804184138774872,
        "val_loss": 0.0033840121967451914,
        "train_loss": 0.0020567639977133903
      },
      {
        "epoch": 1762,
        "reward": 0.4572976529598236,
        "val_loss": 0.00407463894225657,
        "train_loss": 0.0033081945491106194
      },
      {
        "epoch": 1763,
        "reward": 0.1950511336326599,
        "val_loss": 0.04927234165370464,
        "train_loss": 0.005371307805314875
      },
      {
        "epoch": 1764,
        "reward": 0.6116955876350403,
        "val_loss": 0.0011658363094154214,
        "train_loss": 0.021529102850203905
      },
      {
        "epoch": 1765,
        "reward": 0.3727385401725769,
        "val_loss": 0.00819317703800542,
        "train_loss": 0.002081767308901852
      },
      {
        "epoch": 1766,
        "reward": 0.1711343228816986,
        "val_loss": 0.06786686182022095,
        "train_loss": 0.014929072789247865
      },
      {
        "epoch": 1767,
        "reward": 0.2338198870420456,
        "val_loss": 0.03106436532522951,
        "train_loss": 0.0440338062225447
      },
      {
        "epoch": 1768,
        "reward": 0.5726513266563416,
        "val_loss": 0.0016111940744199923,
        "train_loss": 0.010494259439068489
      },
      {
        "epoch": 1769,
        "reward": 0.47749391198158264,
        "val_loss": 0.0034642616020781653,
        "train_loss": 0.0011152476699163134
      },
      {
        "epoch": 1770,
        "reward": 0.526896059513092,
        "val_loss": 0.002332528487646154,
        "train_loss": 0.002426715229655831
      },
      {
        "epoch": 1771,
        "reward": 0.6442033648490906,
        "val_loss": 0.000882513979117253,
        "train_loss": 0.0012730701858726635
      },
      {
        "epoch": 1772,
        "reward": 0.6579932570457458,
        "val_loss": 0.0007816099345551006,
        "train_loss": 0.00066646745521946
      },
      {
        "epoch": 1773,
        "reward": 0.5397366881370544,
        "val_loss": 0.0021038383045899017,
        "train_loss": 0.0013583475620879864
      },
      {
        "epoch": 1774,
        "reward": 0.22585241496562958,
        "val_loss": 0.033990826191646714,
        "train_loss": 0.00705414900305466
      },
      {
        "epoch": 1775,
        "reward": 0.18765892088413239,
        "val_loss": 0.054212824042354314,
        "train_loss": 0.014239873891570963
      },
      {
        "epoch": 1776,
        "reward": 0.34850552678108215,
        "val_loss": 0.010110341212046998,
        "train_loss": 0.02204384042460543
      },
      {
        "epoch": 1777,
        "reward": 0.7063490748405457,
        "val_loss": 0.0005000200804456004,
        "train_loss": 0.004491118978666446
      },
      {
        "epoch": 1778,
        "reward": 0.5210115313529968,
        "val_loss": 0.0024452271505392025,
        "train_loss": 0.0010053423723617855
      },
      {
        "epoch": 1779,
        "reward": 0.646436870098114,
        "val_loss": 0.0008654568810015917,
        "train_loss": 0.0009910601154563036
      },
      {
        "epoch": 1780,
        "reward": 0.46771788597106934,
        "val_loss": 0.0037469638378492425,
        "train_loss": 0.0008172944071702659
      },
      {
        "epoch": 1781,
        "reward": 0.42137789726257324,
        "val_loss": 0.005455193908086845,
        "train_loss": 0.004409434474207676
      },
      {
        "epoch": 1782,
        "reward": 0.2252085655927658,
        "val_loss": 0.0342423426253455,
        "train_loss": 0.0033329950394825293
      },
      {
        "epoch": 1783,
        "reward": 0.40049076080322266,
        "val_loss": 0.006482916618032115,
        "train_loss": 0.007998773266500883
      },
      {
        "epoch": 1784,
        "reward": 0.5489562153816223,
        "val_loss": 0.0019531052093952894,
        "train_loss": 0.0016669035853388219
      },
      {
        "epoch": 1785,
        "reward": 0.28505179286003113,
        "val_loss": 0.01819974197340863,
        "train_loss": 0.0015224936393608984
      },
      {
        "epoch": 1786,
        "reward": 0.443157434463501,
        "val_loss": 0.004567855702979224,
        "train_loss": 0.005993454466358974
      },
      {
        "epoch": 1787,
        "reward": 0.6615645289421082,
        "val_loss": 0.0007571312432576503,
        "train_loss": 0.002099973555442165
      },
      {
        "epoch": 1788,
        "reward": 0.44859710335731506,
        "val_loss": 0.004371080481048141,
        "train_loss": 0.0008847036083002772
      },
      {
        "epoch": 1789,
        "reward": 0.5544355511665344,
        "val_loss": 0.0018684555377279008,
        "train_loss": 0.003621172491246118
      },
      {
        "epoch": 1790,
        "reward": 0.3025103509426117,
        "val_loss": 0.01538008517984833,
        "train_loss": 0.003625556025116776
      },
      {
        "epoch": 1791,
        "reward": 0.588586688041687,
        "val_loss": 0.0014135117858781346,
        "train_loss": 0.006157459317172162
      },
      {
        "epoch": 1792,
        "reward": 0.24576304852962494,
        "val_loss": 0.027248730350817953,
        "train_loss": 0.0016088298188361267
      },
      {
        "epoch": 1793,
        "reward": 0.3611774444580078,
        "val_loss": 0.009050715548385466,
        "train_loss": 0.01195747514765344
      },
      {
        "epoch": 1794,
        "reward": 0.722377598285675,
        "val_loss": 0.0004273111907033516,
        "train_loss": 0.0025819002439675387
      },
      {
        "epoch": 1795,
        "reward": 0.5997442007064819,
        "val_loss": 0.0012885670959284262,
        "train_loss": 0.0005981686449208959
      },
      {
        "epoch": 1796,
        "reward": 0.6470292806625366,
        "val_loss": 0.0008609803210544799,
        "train_loss": 0.0007173419768859136
      },
      {
        "epoch": 1797,
        "reward": 0.6468431949615479,
        "val_loss": 0.0008623839821666479,
        "train_loss": 0.0008815758466460885
      },
      {
        "epoch": 1798,
        "reward": 0.3920319974422455,
        "val_loss": 0.006957964705569404,
        "train_loss": 0.0009128842486041741
      },
      {
        "epoch": 1799,
        "reward": 0.5269235372543335,
        "val_loss": 0.0023320144142157267,
        "train_loss": 0.004834238327860545
      },
      {
        "epoch": 1800,
        "reward": 0.5987865924835205,
        "val_loss": 0.0012988839880563319,
        "train_loss": 0.0011526856430394289
      },
      {
        "epoch": 1801,
        "reward": 0.3069637715816498,
        "val_loss": 0.014746922068297863,
        "train_loss": 0.001036271919684413
      },
      {
        "epoch": 1802,
        "reward": 0.37051519751548767,
        "val_loss": 0.008350689396528261,
        "train_loss": 0.0064169400127586694
      },
      {
        "epoch": 1803,
        "reward": 0.1036079153418541,
        "val_loss": 0.21655775819505965,
        "train_loss": 0.005782618309380128
      },
      {
        "epoch": 1804,
        "reward": 0.2858434319496155,
        "val_loss": 0.018059021261121546,
        "train_loss": 0.06722815984931703
      },
      {
        "epoch": 1805,
        "reward": 0.6609265208244324,
        "val_loss": 0.0007614563801325858,
        "train_loss": 0.004980690318356769
      },
      {
        "epoch": 1806,
        "reward": 0.6256155967712402,
        "val_loss": 0.0010360579638342773,
        "train_loss": 0.0009587143655293263
      },
      {
        "epoch": 1807,
        "reward": 0.6419126987457275,
        "val_loss": 0.0009003048887409802,
        "train_loss": 0.0011567314750908946
      },
      {
        "epoch": 1808,
        "reward": 0.7227646708488464,
        "val_loss": 0.00042566415504552424,
        "train_loss": 0.0007491694671513799
      },
      {
        "epoch": 1809,
        "reward": 0.6386857628822327,
        "val_loss": 0.0009258900369916644,
        "train_loss": 0.0008433277634349696
      },
      {
        "epoch": 1810,
        "reward": 0.6525720953941345,
        "val_loss": 0.0008200423658958503,
        "train_loss": 0.0009926359103841465
      },
      {
        "epoch": 1811,
        "reward": 0.5487509369850159,
        "val_loss": 0.0019563466776162386,
        "train_loss": 0.0007478903798283471
      },
      {
        "epoch": 1812,
        "reward": 0.3079087734222412,
        "val_loss": 0.014616597576865129,
        "train_loss": 0.0019732730445237113
      },
      {
        "epoch": 1813,
        "reward": 0.1595182567834854,
        "val_loss": 0.08031551912426949,
        "train_loss": 0.010513901123956133
      },
      {
        "epoch": 1814,
        "reward": 0.34686681628227234,
        "val_loss": 0.010257500755999769,
        "train_loss": 0.011187848202937927
      },
      {
        "epoch": 1815,
        "reward": 0.34839460253715515,
        "val_loss": 0.010120223741978407,
        "train_loss": 0.005569390019025797
      },
      {
        "epoch": 1816,
        "reward": 0.5111004710197449,
        "val_loss": 0.002647221670486033,
        "train_loss": 0.003043109721217591
      },
      {
        "epoch": 1817,
        "reward": 0.6647512316703796,
        "val_loss": 0.0007358337087290627,
        "train_loss": 0.0012130109756141722
      },
      {
        "epoch": 1818,
        "reward": 0.3256199359893799,
        "val_loss": 0.012409408177648271,
        "train_loss": 0.0005583930738234463
      },
      {
        "epoch": 1819,
        "reward": 0.578236997127533,
        "val_loss": 0.0015391789077382003,
        "train_loss": 0.012354229720166096
      },
      {
        "epoch": 1820,
        "reward": 0.6273679733276367,
        "val_loss": 0.00102065597561055,
        "train_loss": 0.00107091394350461
      },
      {
        "epoch": 1821,
        "reward": 0.7096059918403625,
        "val_loss": 0.0004845117385100041,
        "train_loss": 0.000705082609224169
      },
      {
        "epoch": 1822,
        "reward": 0.5774344801902771,
        "val_loss": 0.0015493396536580154,
        "train_loss": 0.0006108119503971046
      },
      {
        "epoch": 1823,
        "reward": 0.45688948035240173,
        "val_loss": 0.004088064788707665,
        "train_loss": 0.0006436302825862255
      },
      {
        "epoch": 1824,
        "reward": 0.5929998755455017,
        "val_loss": 0.0013628358304101443,
        "train_loss": 0.0016630650061415508
      },
      {
        "epoch": 1825,
        "reward": 0.46522054076194763,
        "val_loss": 0.003822920045682362,
        "train_loss": 0.0013596506178146228
      },
      {
        "epoch": 1826,
        "reward": 0.39230453968048096,
        "val_loss": 0.0069420682931584975,
        "train_loss": 0.0038686029214519435
      },
      {
        "epoch": 1827,
        "reward": 0.4771884083747864,
        "val_loss": 0.003472757076711527,
        "train_loss": 0.0016086464847656036
      },
      {
        "epoch": 1828,
        "reward": 0.6982741355895996,
        "val_loss": 0.0005401779365326677,
        "train_loss": 0.001635225888234205
      },
      {
        "epoch": 1829,
        "reward": 0.5308437347412109,
        "val_loss": 0.002259775497285383,
        "train_loss": 0.0006415200229569634
      },
      {
        "epoch": 1830,
        "reward": 0.43303829431533813,
        "val_loss": 0.004959278091389153,
        "train_loss": 0.0013194862560619814
      },
      {
        "epoch": 1831,
        "reward": 0.6750136613845825,
        "val_loss": 0.0006706080831853407,
        "train_loss": 0.0023716500418406493
      },
      {
        "epoch": 1832,
        "reward": 0.5429401993751526,
        "val_loss": 0.0020502446152802023,
        "train_loss": 0.0007171123254990492
      },
      {
        "epoch": 1833,
        "reward": 0.2566486895084381,
        "val_loss": 0.02427022877548422,
        "train_loss": 0.003311574732903794
      },
      {
        "epoch": 1834,
        "reward": 0.2958199083805084,
        "val_loss": 0.016393677863691534,
        "train_loss": 0.017200145917461038
      },
      {
        "epoch": 1835,
        "reward": 0.22537367045879364,
        "val_loss": 0.034177623955266814,
        "train_loss": 0.011016866534751339
      },
      {
        "epoch": 1836,
        "reward": 0.29514580965042114,
        "val_loss": 0.016500192428273813,
        "train_loss": 0.009412603330789492
      },
      {
        "epoch": 1837,
        "reward": 0.558032751083374,
        "val_loss": 0.0018147821371842707,
        "train_loss": 0.0035998943987159203
      },
      {
        "epoch": 1838,
        "reward": 0.7242058515548706,
        "val_loss": 0.0004195754507756127,
        "train_loss": 0.0006719690376782567
      },
      {
        "epoch": 1839,
        "reward": 0.6176965832710266,
        "val_loss": 0.0011082293931394815,
        "train_loss": 0.0006765114016043474
      },
      {
        "epoch": 1840,
        "reward": 0.7232341170310974,
        "val_loss": 0.0004236733199962016,
        "train_loss": 0.0007363277980188671
      },
      {
        "epoch": 1841,
        "reward": 0.5467126369476318,
        "val_loss": 0.0019888077430160983,
        "train_loss": 0.0011812985523227747
      },
      {
        "epoch": 1842,
        "reward": 0.5152196288108826,
        "val_loss": 0.0025613494466857185,
        "train_loss": 0.002426867032996737
      },
      {
        "epoch": 1843,
        "reward": 0.6539632081985474,
        "val_loss": 0.0008100309475724186,
        "train_loss": 0.0033927769657723797
      },
      {
        "epoch": 1844,
        "reward": 0.5901290774345398,
        "val_loss": 0.0013956091050723834,
        "train_loss": 0.0009535462091802261
      },
      {
        "epoch": 1845,
        "reward": 0.5602006316184998,
        "val_loss": 0.0017831408518499561,
        "train_loss": 0.0008907207800523163
      },
      {
        "epoch": 1846,
        "reward": 0.313901424407959,
        "val_loss": 0.013821340565170561,
        "train_loss": 0.0015033424547604786
      },
      {
        "epoch": 1847,
        "reward": 0.5904318690299988,
        "val_loss": 0.0013921194144391588,
        "train_loss": 0.006920572282979265
      },
      {
        "epoch": 1848,
        "reward": 0.3283749520778656,
        "val_loss": 0.012102565195943629,
        "train_loss": 0.0008287171602625257
      },
      {
        "epoch": 1849,
        "reward": 0.48887166380882263,
        "val_loss": 0.0031625242637736456,
        "train_loss": 0.002188899166491445
      },
      {
        "epoch": 1850,
        "reward": 0.41548362374305725,
        "val_loss": 0.0057259720217968735,
        "train_loss": 0.003152216372095259
      },
      {
        "epoch": 1851,
        "reward": 0.33900049328804016,
        "val_loss": 0.010999306504215513,
        "train_loss": 0.0021906255558580877
      },
      {
        "epoch": 1852,
        "reward": 0.2241446077823639,
        "val_loss": 0.03466320037841797,
        "train_loss": 0.009483336359083366
      },
      {
        "epoch": 1853,
        "reward": 0.23619942367076874,
        "val_loss": 0.030252829859299318,
        "train_loss": 0.02067285841062235
      },
      {
        "epoch": 1854,
        "reward": 0.44309449195861816,
        "val_loss": 0.004570188333413431,
        "train_loss": 0.013227426565628355
      },
      {
        "epoch": 1855,
        "reward": 0.6095117926597595,
        "val_loss": 0.0011874496205044644,
        "train_loss": 0.004963612515264406
      },
      {
        "epoch": 1856,
        "reward": 0.48032671213150024,
        "val_loss": 0.0033864990608500583,
        "train_loss": 0.0027218930817280826
      },
      {
        "epoch": 1857,
        "reward": 0.5024532079696655,
        "val_loss": 0.0028368756507656406,
        "train_loss": 0.0017632162388718615
      },
      {
        "epoch": 1858,
        "reward": 0.6227573752403259,
        "val_loss": 0.0010616157586420222,
        "train_loss": 0.002373266611427355
      },
      {
        "epoch": 1859,
        "reward": 0.49018627405166626,
        "val_loss": 0.0031294242279337986,
        "train_loss": 0.002025346254343346
      },
      {
        "epoch": 1860,
        "reward": 0.6530801057815552,
        "val_loss": 0.0008163741523666042,
        "train_loss": 0.0012022627007144575
      },
      {
        "epoch": 1861,
        "reward": 0.6744904518127441,
        "val_loss": 0.0006738132963489209,
        "train_loss": 0.0006783723469407749
      },
      {
        "epoch": 1862,
        "reward": 0.5257507562637329,
        "val_loss": 0.0023540587530338337,
        "train_loss": 0.0005753341471203244
      },
      {
        "epoch": 1863,
        "reward": 0.6067954301834106,
        "val_loss": 0.0012148319427589221,
        "train_loss": 0.0013363424133366118
      },
      {
        "epoch": 1864,
        "reward": 0.45341816544532776,
        "val_loss": 0.004204131197184324,
        "train_loss": 0.0008313765444584603
      },
      {
        "epoch": 1865,
        "reward": 0.21080946922302246,
        "val_loss": 0.040545925231916566,
        "train_loss": 0.008190901371283242
      },
      {
        "epoch": 1866,
        "reward": 0.17411212623119354,
        "val_loss": 0.06509502711040634,
        "train_loss": 0.03323052042441514
      },
      {
        "epoch": 1867,
        "reward": 0.31880247592926025,
        "val_loss": 0.013208894192108087,
        "train_loss": 0.01977644351406455
      },
      {
        "epoch": 1868,
        "reward": 0.5267146825790405,
        "val_loss": 0.00233592462193753,
        "train_loss": 0.006164548239142347
      },
      {
        "epoch": 1869,
        "reward": 0.7054023146629333,
        "val_loss": 0.0005046014765477074,
        "train_loss": 0.001356135795783932
      },
      {
        "epoch": 1870,
        "reward": 0.6910538673400879,
        "val_loss": 0.0005782364377020193,
        "train_loss": 0.000918507142789447
      },
      {
        "epoch": 1871,
        "reward": 0.707019031047821,
        "val_loss": 0.0004967988393868186,
        "train_loss": 0.0006262899959647956
      },
      {
        "epoch": 1872,
        "reward": 0.470742791891098,
        "val_loss": 0.0036570412505950245,
        "train_loss": 0.0006230441716839918
      },
      {
        "epoch": 1873,
        "reward": 0.5880531072616577,
        "val_loss": 0.001419754499303443,
        "train_loss": 0.0014690002472679436
      },
      {
        "epoch": 1874,
        "reward": 0.657553493976593,
        "val_loss": 0.0007846697616124791,
        "train_loss": 0.0013038605191888143
      },
      {
        "epoch": 1875,
        "reward": 0.5870257616043091,
        "val_loss": 0.0014318425008761032,
        "train_loss": 0.0006389668582974431
      },
      {
        "epoch": 1876,
        "reward": 0.2860778272151947,
        "val_loss": 0.018017606011458805,
        "train_loss": 0.0024611561563618193
      },
      {
        "epoch": 1877,
        "reward": 0.23139815032482147,
        "val_loss": 0.03191881573625973,
        "train_loss": 0.021009589313717488
      },
      {
        "epoch": 1878,
        "reward": 0.5637184381484985,
        "val_loss": 0.0017328981276867645,
        "train_loss": 0.016376940152930237
      },
      {
        "epoch": 1879,
        "reward": 0.6197406053543091,
        "val_loss": 0.0010891903324850968,
        "train_loss": 0.0017660390137909697
      },
      {
        "epoch": 1880,
        "reward": 0.3043169379234314,
        "val_loss": 0.015119391493499279,
        "train_loss": 0.0039946841671525575
      },
      {
        "epoch": 1881,
        "reward": 0.6092095375061035,
        "val_loss": 0.0011904697998293809,
        "train_loss": 0.003978899842387853
      },
      {
        "epoch": 1882,
        "reward": 0.5835625529289246,
        "val_loss": 0.0014732913613053305,
        "train_loss": 0.0008098578921187884
      },
      {
        "epoch": 1883,
        "reward": 0.3644903600215912,
        "val_loss": 0.00879500008055142,
        "train_loss": 0.0012429570902335958
      },
      {
        "epoch": 1884,
        "reward": 0.5471383333206177,
        "val_loss": 0.0019819867364796145,
        "train_loss": 0.0026720214061697334
      },
      {
        "epoch": 1885,
        "reward": 0.5028581023216248,
        "val_loss": 0.0028277020568826367,
        "train_loss": 0.0006916808478374478
      },
      {
        "epoch": 1886,
        "reward": 0.5641544461250305,
        "val_loss": 0.0017267638717644981,
        "train_loss": 0.001051929536445711
      },
      {
        "epoch": 1887,
        "reward": 0.47663265466690063,
        "val_loss": 0.0034882643459630863,
        "train_loss": 0.0011716468557446764
      },
      {
        "epoch": 1888,
        "reward": 0.4673316478729248,
        "val_loss": 0.0037586071994155645,
        "train_loss": 0.005284818002389959
      },
      {
        "epoch": 1889,
        "reward": 0.5591514706611633,
        "val_loss": 0.001798388797656766,
        "train_loss": 0.0025501369919556263
      },
      {
        "epoch": 1890,
        "reward": 0.6737058758735657,
        "val_loss": 0.000678643272424649,
        "train_loss": 0.0008660037117526651
      },
      {
        "epoch": 1891,
        "reward": 0.6656524538993835,
        "val_loss": 0.0007299024603396122,
        "train_loss": 0.0005438028119197742
      },
      {
        "epoch": 1892,
        "reward": 0.6694435477256775,
        "val_loss": 0.0007053861377893814,
        "train_loss": 0.0008839048044207559
      },
      {
        "epoch": 1893,
        "reward": 0.3176630735397339,
        "val_loss": 0.013348362541624479,
        "train_loss": 0.0035312213462580424
      },
      {
        "epoch": 1894,
        "reward": 0.6744818091392517,
        "val_loss": 0.0006738659410205271,
        "train_loss": 0.0033739254800960994
      },
      {
        "epoch": 1895,
        "reward": 0.4259639382362366,
        "val_loss": 0.005254074931144714,
        "train_loss": 0.0006832168952454454
      },
      {
        "epoch": 1896,
        "reward": 0.6006139516830444,
        "val_loss": 0.0012792597990483046,
        "train_loss": 0.001935370829484712
      },
      {
        "epoch": 1897,
        "reward": 0.672057032585144,
        "val_loss": 0.0006888872511418802,
        "train_loss": 0.0010499372119039225
      },
      {
        "epoch": 1898,
        "reward": 0.48875221610069275,
        "val_loss": 0.00316554939906512,
        "train_loss": 0.0008225421490631282
      },
      {
        "epoch": 1899,
        "reward": 0.25341877341270447,
        "val_loss": 0.025109630610261644,
        "train_loss": 0.0016370091224626566
      },
      {
        "epoch": 1900,
        "reward": 0.39195266366004944,
        "val_loss": 0.006962595840117761,
        "train_loss": 0.008897517563757272
      },
      {
        "epoch": 1901,
        "reward": 0.6150185465812683,
        "val_loss": 0.0011336179325423603,
        "train_loss": 0.00365885849057052
      },
      {
        "epoch": 1902,
        "reward": 0.5389401912689209,
        "val_loss": 0.0021173718019521664,
        "train_loss": 0.0009394773257484373
      },
      {
        "epoch": 1903,
        "reward": 0.5931655764579773,
        "val_loss": 0.0013609658926725388,
        "train_loss": 0.0010179253451776905
      },
      {
        "epoch": 1904,
        "reward": 0.6960383653640747,
        "val_loss": 0.000551740510023332,
        "train_loss": 0.0008085386798817659
      },
      {
        "epoch": 1905,
        "reward": 0.5739371180534363,
        "val_loss": 0.0015943455177226237,
        "train_loss": 0.0006220816710713104
      },
      {
        "epoch": 1906,
        "reward": 0.4495820105075836,
        "val_loss": 0.0043364174863589665,
        "train_loss": 0.0011136208217626868
      },
      {
        "epoch": 1907,
        "reward": 0.5224518179893494,
        "val_loss": 0.0024171606304922272,
        "train_loss": 0.002229424103951225
      },
      {
        "epoch": 1908,
        "reward": 0.4612607955932617,
        "val_loss": 0.003946641576476395,
        "train_loss": 0.001557669052719855
      },
      {
        "epoch": 1909,
        "reward": 0.5446508526802063,
        "val_loss": 0.002022164042240807,
        "train_loss": 0.0010348244230639326
      },
      {
        "epoch": 1910,
        "reward": 0.3180796802043915,
        "val_loss": 0.013297165744006634,
        "train_loss": 0.0012878673005616292
      },
      {
        "epoch": 1911,
        "reward": 0.24358521401882172,
        "val_loss": 0.027898566531283513,
        "train_loss": 0.00516005015211144
      },
      {
        "epoch": 1912,
        "reward": 0.2023574411869049,
        "val_loss": 0.04495127445885113,
        "train_loss": 0.013363050554359619
      },
      {
        "epoch": 1913,
        "reward": 0.29275044798851013,
        "val_loss": 0.016885499070797647,
        "train_loss": 0.010831923988567164
      },
      {
        "epoch": 1914,
        "reward": 0.4180683195590973,
        "val_loss": 0.005605484425489392,
        "train_loss": 0.0077792647582380315
      },
      {
        "epoch": 1915,
        "reward": 0.34978553652763367,
        "val_loss": 0.00999708300722497,
        "train_loss": 0.0024009416162278706
      },
      {
        "epoch": 1916,
        "reward": 0.6215872168540955,
        "val_loss": 0.0010722385736049286,
        "train_loss": 0.0019970344307624214
      },
      {
        "epoch": 1917,
        "reward": 0.28091129660606384,
        "val_loss": 0.01895789908511298,
        "train_loss": 0.0009610852945255688
      },
      {
        "epoch": 1918,
        "reward": 0.27387940883636475,
        "val_loss": 0.02033585137022393,
        "train_loss": 0.01863903920345295
      },
      {
        "epoch": 1919,
        "reward": 0.7293353080749512,
        "val_loss": 0.0003984484522204314,
        "train_loss": 0.006019264526772671
      },
      {
        "epoch": 1920,
        "reward": 0.3981717526912689,
        "val_loss": 0.0066094900747495034,
        "train_loss": 0.0012602246458230254
      },
      {
        "epoch": 1921,
        "reward": 0.6473850607872009,
        "val_loss": 0.0008583011720994753,
        "train_loss": 0.0017308223054547294
      },
      {
        "epoch": 1922,
        "reward": 0.6046479940414429,
        "val_loss": 0.0012368762233693684,
        "train_loss": 0.0011114254449729253
      },
      {
        "epoch": 1923,
        "reward": 0.5865604877471924,
        "val_loss": 0.0014373482471065862,
        "train_loss": 0.0005236978456825734
      },
      {
        "epoch": 1924,
        "reward": 0.46614184975624084,
        "val_loss": 0.0037947158395711866,
        "train_loss": 0.0010868467540533927
      },
      {
        "epoch": 1925,
        "reward": 0.42400240898132324,
        "val_loss": 0.005339103385007807,
        "train_loss": 0.0012652385843326696
      },
      {
        "epoch": 1926,
        "reward": 0.49441346526145935,
        "val_loss": 0.003025338253272431,
        "train_loss": 0.004641310315069911
      },
      {
        "epoch": 1927,
        "reward": 0.6585334539413452,
        "val_loss": 0.0007778654814631279,
        "train_loss": 0.001142257488167021
      },
      {
        "epoch": 1928,
        "reward": 0.5423045754432678,
        "val_loss": 0.002060774031893483,
        "train_loss": 0.0006048294666330689
      },
      {
        "epoch": 1929,
        "reward": 0.725385844707489,
        "val_loss": 0.0004146399857875492,
        "train_loss": 0.001454338134023531
      },
      {
        "epoch": 1930,
        "reward": 0.7192777395248413,
        "val_loss": 0.0004406806879809925,
        "train_loss": 0.0008295511887319243
      },
      {
        "epoch": 1931,
        "reward": 0.4625225067138672,
        "val_loss": 0.003906776529869863,
        "train_loss": 0.0005233153541876862
      },
      {
        "epoch": 1932,
        "reward": 0.4496862590312958,
        "val_loss": 0.004332765504451734,
        "train_loss": 0.003829629824268138
      },
      {
        "epoch": 1933,
        "reward": 0.6839321255683899,
        "val_loss": 0.0006178716180979141,
        "train_loss": 0.0026390320003534164
      },
      {
        "epoch": 1934,
        "reward": 0.7043331861495972,
        "val_loss": 0.000509815028635785,
        "train_loss": 0.0004901674619759433
      },
      {
        "epoch": 1935,
        "reward": 0.5334343910217285,
        "val_loss": 0.0022132331172802617,
        "train_loss": 0.0006735836118773128
      },
      {
        "epoch": 1936,
        "reward": 0.7166438102722168,
        "val_loss": 0.00045229552363577696,
        "train_loss": 0.0008435179513001528
      },
      {
        "epoch": 1937,
        "reward": 0.4071483612060547,
        "val_loss": 0.006134091477308955,
        "train_loss": 0.0007337719692329231
      },
      {
        "epoch": 1938,
        "reward": 0.24709542095661163,
        "val_loss": 0.026860505076391355,
        "train_loss": 0.0019153624799890588
      },
      {
        "epoch": 1939,
        "reward": 0.4065917134284973,
        "val_loss": 0.006162457168102264,
        "train_loss": 0.008610461144528996
      },
      {
        "epoch": 1940,
        "reward": 0.4822362959384918,
        "val_loss": 0.003335086728579232,
        "train_loss": 0.003951174637292682
      },
      {
        "epoch": 1941,
        "reward": 0.33763250708580017,
        "val_loss": 0.01113456248172692,
        "train_loss": 0.0027026434981962666
      },
      {
        "epoch": 1942,
        "reward": 0.3464266359806061,
        "val_loss": 0.010297455292727267,
        "train_loss": 0.00291303423336313
      },
      {
        "epoch": 1943,
        "reward": 0.12619072198867798,
        "val_loss": 0.13872095250657626,
        "train_loss": 0.009612572780147625
      },
      {
        "epoch": 1944,
        "reward": 0.10641705989837646,
        "val_loss": 0.20399095756667002,
        "train_loss": 0.14673220925033092
      },
      {
        "epoch": 1945,
        "reward": 0.31042617559432983,
        "val_loss": 0.014276067992406232,
        "train_loss": 0.08092218004570056
      },
      {
        "epoch": 1946,
        "reward": 0.3277125060558319,
        "val_loss": 0.012175523276839937,
        "train_loss": 0.007202508682474637
      },
      {
        "epoch": 1947,
        "reward": 0.5727989673614502,
        "val_loss": 0.0016092505871451326,
        "train_loss": 0.002700598574637507
      },
      {
        "epoch": 1948,
        "reward": 0.6900985240936279,
        "val_loss": 0.0005834299497239824,
        "train_loss": 0.0007719167467887298
      },
      {
        "epoch": 1949,
        "reward": 0.7239395976066589,
        "val_loss": 0.0004206952331255057,
        "train_loss": 0.0006067356600676879
      },
      {
        "epoch": 1950,
        "reward": 0.5269935131072998,
        "val_loss": 0.0023307044923837695,
        "train_loss": 0.0004968284965098763
      },
      {
        "epoch": 1951,
        "reward": 0.5017300844192505,
        "val_loss": 0.0028533355964879903,
        "train_loss": 0.0011679899303439574
      },
      {
        "epoch": 1952,
        "reward": 0.6199814081192017,
        "val_loss": 0.001086966142923172,
        "train_loss": 0.0011869673169432925
      },
      {
        "epoch": 1953,
        "reward": 0.6212417483329773,
        "val_loss": 0.001075391358296786,
        "train_loss": 0.0009837491614654516
      },
      {
        "epoch": 1954,
        "reward": 0.7003622651100159,
        "val_loss": 0.0005295555123926274,
        "train_loss": 0.000796306773386627
      },
      {
        "epoch": 1955,
        "reward": 0.5365301370620728,
        "val_loss": 0.002158830058760941,
        "train_loss": 0.0005947546778770629
      },
      {
        "epoch": 1956,
        "reward": 0.682047963142395,
        "val_loss": 0.0006287200376391411,
        "train_loss": 0.0007237385703214946
      },
      {
        "epoch": 1957,
        "reward": 0.5145657658576965,
        "val_loss": 0.002574795058795384,
        "train_loss": 0.0005466666077084553
      },
      {
        "epoch": 1958,
        "reward": 0.42515307664871216,
        "val_loss": 0.005289047424282346,
        "train_loss": 0.0022218881360738752
      },
      {
        "epoch": 1959,
        "reward": 0.6649114489555359,
        "val_loss": 0.0007347763665685696,
        "train_loss": 0.0015940384339326276
      },
      {
        "epoch": 1960,
        "reward": 0.18222706019878387,
        "val_loss": 0.05826441358242716,
        "train_loss": 0.0036176582059572237
      },
      {
        "epoch": 1961,
        "reward": 0.3084840178489685,
        "val_loss": 0.014537939269627844,
        "train_loss": 0.0884243730778018
      },
      {
        "epoch": 1962,
        "reward": 0.46625611186027527,
        "val_loss": 0.0037912334581570967,
        "train_loss": 0.008367253755120775
      },
      {
        "epoch": 1963,
        "reward": 0.6568893790245056,
        "val_loss": 0.0007893100472366703,
        "train_loss": 0.001237403070263099
      },
      {
        "epoch": 1964,
        "reward": 0.39101362228393555,
        "val_loss": 0.007017703926456826,
        "train_loss": 0.000814538533002353
      },
      {
        "epoch": 1965,
        "reward": 0.6247475147247314,
        "val_loss": 0.0010437628703324922,
        "train_loss": 0.0015985259535507513
      },
      {
        "epoch": 1966,
        "reward": 0.6684513092041016,
        "val_loss": 0.0007117353130265006,
        "train_loss": 0.001195444909031861
      },
      {
        "epoch": 1967,
        "reward": 0.6571968197822571,
        "val_loss": 0.0007871589415507125,
        "train_loss": 0.0007625943815226649
      },
      {
        "epoch": 1968,
        "reward": 0.7094902992248535,
        "val_loss": 0.0004850562212855688,
        "train_loss": 0.0004868743115086825
      },
      {
        "epoch": 1969,
        "reward": 0.5815625786781311,
        "val_loss": 0.001497724392850484,
        "train_loss": 0.0005399502042564563
      },
      {
        "epoch": 1970,
        "reward": 0.7325634360313416,
        "val_loss": 0.00038558054698764214,
        "train_loss": 0.000771622789146092
      },
      {
        "epoch": 1971,
        "reward": 0.5505537390708923,
        "val_loss": 0.001928057022658842,
        "train_loss": 0.0006551214744551823
      },
      {
        "epoch": 1972,
        "reward": 0.6808245778083801,
        "val_loss": 0.0006358464431416776,
        "train_loss": 0.0011955410087606511
      },
      {
        "epoch": 1973,
        "reward": 0.5672563910484314,
        "val_loss": 0.0016837064176797867,
        "train_loss": 0.0007091490417503967
      },
      {
        "epoch": 1974,
        "reward": 0.478083997964859,
        "val_loss": 0.0034479147288948298,
        "train_loss": 0.0008621518594990308
      },
      {
        "epoch": 1975,
        "reward": 0.5685731768608093,
        "val_loss": 0.0016657318753589476,
        "train_loss": 0.0008107569178369326
      },
      {
        "epoch": 1976,
        "reward": 0.3184579312801361,
        "val_loss": 0.013250885464783226,
        "train_loss": 0.001361344996929312
      },
      {
        "epoch": 1977,
        "reward": 0.42737579345703125,
        "val_loss": 0.00519377611843603,
        "train_loss": 0.008831734392935267
      },
      {
        "epoch": 1978,
        "reward": 0.34855222702026367,
        "val_loss": 0.010106185052011694,
        "train_loss": 0.004450876074350582
      },
      {
        "epoch": 1979,
        "reward": 0.5523489713668823,
        "val_loss": 0.0019002717952909215,
        "train_loss": 0.0035731577806403106
      },
      {
        "epoch": 1980,
        "reward": 0.48007509112358093,
        "val_loss": 0.0033933339374405997,
        "train_loss": 0.001226348588646103
      },
      {
        "epoch": 1981,
        "reward": 0.6065091490745544,
        "val_loss": 0.0012177498345928533,
        "train_loss": 0.002296300450465284
      },
      {
        "epoch": 1982,
        "reward": 0.34095415472984314,
        "val_loss": 0.010809434511299645,
        "train_loss": 0.0009647182607575535
      },
      {
        "epoch": 1983,
        "reward": 0.41690635681152344,
        "val_loss": 0.00565930618904531,
        "train_loss": 0.006760301710948205
      },
      {
        "epoch": 1984,
        "reward": 0.44675761461257935,
        "val_loss": 0.004436603314908487,
        "train_loss": 0.002182273063226603
      },
      {
        "epoch": 1985,
        "reward": 0.5535727143287659,
        "val_loss": 0.0018815500495423163,
        "train_loss": 0.0021360945090866433
      },
      {
        "epoch": 1986,
        "reward": 0.7215117812156677,
        "val_loss": 0.00043101327693355937,
        "train_loss": 0.0007641101720554826
      },
      {
        "epoch": 1987,
        "reward": 0.5073691606521606,
        "val_loss": 0.002727462111839226,
        "train_loss": 0.0006198040332842189
      },
      {
        "epoch": 1988,
        "reward": 0.6891385912895203,
        "val_loss": 0.0005886866627926273,
        "train_loss": 0.0009678708671484715
      },
      {
        "epoch": 1989,
        "reward": 0.7326164841651917,
        "val_loss": 0.0003853714110196701,
        "train_loss": 0.0005297318521815424
      },
      {
        "epoch": 1990,
        "reward": 0.700433611869812,
        "val_loss": 0.0005291951487639121,
        "train_loss": 0.0005012589386366856
      },
      {
        "epoch": 1991,
        "reward": 0.5877029895782471,
        "val_loss": 0.001423862629703113,
        "train_loss": 0.0004543454941505423
      },
      {
        "epoch": 1992,
        "reward": 0.7005230188369751,
        "val_loss": 0.0005287443179570671,
        "train_loss": 0.0007092919561098545
      },
      {
        "epoch": 1993,
        "reward": 0.7046026587486267,
        "val_loss": 0.0005084970824620021,
        "train_loss": 0.0005976462528521481
      },
      {
        "epoch": 1994,
        "reward": 0.4127151668071747,
        "val_loss": 0.0058581483151231495,
        "train_loss": 0.0008602150597793157
      },
      {
        "epoch": 1995,
        "reward": 0.5371229648590088,
        "val_loss": 0.002148560531038259,
        "train_loss": 0.001200251908113177
      },
      {
        "epoch": 1996,
        "reward": 0.3995520770549774,
        "val_loss": 0.0065338255704513615,
        "train_loss": 0.001875405676680832
      },
      {
        "epoch": 1997,
        "reward": 0.5501294136047363,
        "val_loss": 0.0019346796242254122,
        "train_loss": 0.0020084498224045653
      },
      {
        "epoch": 1998,
        "reward": 0.6158053278923035,
        "val_loss": 0.0011261069032895779,
        "train_loss": 0.001392926751018072
      },
      {
        "epoch": 1999,
        "reward": 0.6131266355514526,
        "val_loss": 0.0011518635354670031,
        "train_loss": 0.0006994148128657029
      },
      {
        "epoch": 2000,
        "reward": 0.6578585505485535,
        "val_loss": 0.0007825464376115374,
        "train_loss": 0.0006336710984424616
      },
      {
        "epoch": 2001,
        "reward": 0.5622751116752625,
        "val_loss": 0.0017533483582415751,
        "train_loss": 0.0006254147059967006
      },
      {
        "epoch": 2002,
        "reward": 0.7252089381217957,
        "val_loss": 0.0004153770028746554,
        "train_loss": 0.0009489253044683629
      },
      {
        "epoch": 2003,
        "reward": 0.6472387909889221,
        "val_loss": 0.000859401683555916,
        "train_loss": 0.0006262893293751404
      },
      {
        "epoch": 2004,
        "reward": 0.5717827677726746,
        "val_loss": 0.0016226682263160391,
        "train_loss": 0.002149057378224265
      },
      {
        "epoch": 2005,
        "reward": 0.49271318316459656,
        "val_loss": 0.0030667787151677267,
        "train_loss": 0.0006953008963207069
      },
      {
        "epoch": 2006,
        "reward": 0.5616657137870789,
        "val_loss": 0.0017620523576624691,
        "train_loss": 0.0031024743886798834
      },
      {
        "epoch": 2007,
        "reward": 0.47509846091270447,
        "val_loss": 0.0035314420570752452,
        "train_loss": 0.001674372246690417
      },
      {
        "epoch": 2008,
        "reward": 0.6950496435165405,
        "val_loss": 0.000556916555589331,
        "train_loss": 0.0013384061144629063
      },
      {
        "epoch": 2009,
        "reward": 0.26940974593162537,
        "val_loss": 0.021275749297014306,
        "train_loss": 0.0007894046430010349
      },
      {
        "epoch": 2010,
        "reward": 0.4525332450866699,
        "val_loss": 0.004234264870839459,
        "train_loss": 0.006429044086521922
      },
      {
        "epoch": 2011,
        "reward": 0.6194596290588379,
        "val_loss": 0.0010917897618907904,
        "train_loss": 0.0013401260563953726
      },
      {
        "epoch": 2012,
        "reward": 0.6041370630264282,
        "val_loss": 0.0012421740601504488,
        "train_loss": 0.0007549880135159653
      },
      {
        "epoch": 2013,
        "reward": 0.6716127991676331,
        "val_loss": 0.0006916689037877534,
        "train_loss": 0.0005596507086151037
      },
      {
        "epoch": 2014,
        "reward": 0.6585617661476135,
        "val_loss": 0.0007776693881688905,
        "train_loss": 0.0007987266858085954
      },
      {
        "epoch": 2015,
        "reward": 0.665550947189331,
        "val_loss": 0.0007305686012841761,
        "train_loss": 0.0006925414306281779
      },
      {
        "epoch": 2016,
        "reward": 0.6521908640861511,
        "val_loss": 0.000822803654175784,
        "train_loss": 0.0008441413693407623
      },
      {
        "epoch": 2017,
        "reward": 0.38616496324539185,
        "val_loss": 0.007310067702616964,
        "train_loss": 0.0008525666400181273
      },
      {
        "epoch": 2018,
        "reward": 0.5544677376747131,
        "val_loss": 0.0018679681400369322,
        "train_loss": 0.0022316534850688186
      },
      {
        "epoch": 2019,
        "reward": 0.5798553824424744,
        "val_loss": 0.0015188749946121658,
        "train_loss": 0.0021873975537556154
      },
      {
        "epoch": 2020,
        "reward": 0.6493893265724182,
        "val_loss": 0.0008433420360753578,
        "train_loss": 0.0011353401932865381
      },
      {
        "epoch": 2021,
        "reward": 0.35440704226493835,
        "val_loss": 0.00960011747000473,
        "train_loss": 0.0015455626366579405
      },
      {
        "epoch": 2022,
        "reward": 0.4508277475833893,
        "val_loss": 0.004292986588552594,
        "train_loss": 0.0039028159236435245
      },
      {
        "epoch": 2023,
        "reward": 0.5340931415557861,
        "val_loss": 0.0022015461332297753,
        "train_loss": 0.00238016870795176
      },
      {
        "epoch": 2024,
        "reward": 0.7353277802467346,
        "val_loss": 0.0003748164079817278,
        "train_loss": 0.0009424940721006491
      },
      {
        "epoch": 2025,
        "reward": 0.7065519094467163,
        "val_loss": 0.000499043069014858,
        "train_loss": 0.000521858852992479
      },
      {
        "epoch": 2026,
        "reward": 0.5067286491394043,
        "val_loss": 0.0027414762880653143,
        "train_loss": 0.0007226540832422101
      },
      {
        "epoch": 2027,
        "reward": 0.5822957158088684,
        "val_loss": 0.001488724523889167,
        "train_loss": 0.0011768101138351574
      },
      {
        "epoch": 2028,
        "reward": 0.662476122379303,
        "val_loss": 0.0007509867427870631,
        "train_loss": 0.0011754056982821426
      },
      {
        "epoch": 2029,
        "reward": 0.6765069961547852,
        "val_loss": 0.000661528910443719,
        "train_loss": 0.0011818096011736018
      },
      {
        "epoch": 2030,
        "reward": 0.6962782144546509,
        "val_loss": 0.0005504909827972629,
        "train_loss": 0.0006499254814116284
      },
      {
        "epoch": 2031,
        "reward": 0.7151215672492981,
        "val_loss": 0.00045911671726831367,
        "train_loss": 0.00043009280559020297
      },
      {
        "epoch": 2032,
        "reward": 0.5298345685005188,
        "val_loss": 0.0022781620334301677,
        "train_loss": 0.000670442743005249
      },
      {
        "epoch": 2033,
        "reward": 0.4684557616710663,
        "val_loss": 0.003724819581423487,
        "train_loss": 0.0007795018755132332
      },
      {
        "epoch": 2034,
        "reward": 0.6967138648033142,
        "val_loss": 0.0005482265509531967,
        "train_loss": 0.0023504617688908745
      },
      {
        "epoch": 2035,
        "reward": 0.5205545425415039,
        "val_loss": 0.002454197150655091,
        "train_loss": 0.0018677364282229274
      },
      {
        "epoch": 2036,
        "reward": 0.3498300611972809,
        "val_loss": 0.009993167793644326,
        "train_loss": 0.0024454497106489725
      },
      {
        "epoch": 2037,
        "reward": 0.6227236986160278,
        "val_loss": 0.0010619203759623425,
        "train_loss": 0.0036140728040593853
      },
      {
        "epoch": 2038,
        "reward": 0.5388875603675842,
        "val_loss": 0.0021182692476681302,
        "train_loss": 0.0016507386149337085
      },
      {
        "epoch": 2039,
        "reward": 0.5054627060890198,
        "val_loss": 0.002769386661904199,
        "train_loss": 0.0013478109822944344
      },
      {
        "epoch": 2040,
        "reward": 0.6798731684684753,
        "val_loss": 0.0006414339295588434,
        "train_loss": 0.0014652699834326855
      },
      {
        "epoch": 2041,
        "reward": 0.5336337685585022,
        "val_loss": 0.0022096899836989386,
        "train_loss": 0.002392665222242403
      },
      {
        "epoch": 2042,
        "reward": 0.6009141206741333,
        "val_loss": 0.0012760618036346777,
        "train_loss": 0.00697519753773052
      },
      {
        "epoch": 2043,
        "reward": 0.33356598019599915,
        "val_loss": 0.011548203549214773,
        "train_loss": 0.0033546171012298707
      },
      {
        "epoch": 2044,
        "reward": 0.6565021872520447,
        "val_loss": 0.0007920260042218226,
        "train_loss": 0.0022675150827616074
      },
      {
        "epoch": 2045,
        "reward": 0.6302145719528198,
        "val_loss": 0.0009960619499906898,
        "train_loss": 0.0008060399525745127
      },
      {
        "epoch": 2046,
        "reward": 0.6838809847831726,
        "val_loss": 0.0006181642030631858,
        "train_loss": 0.001275378314088672
      },
      {
        "epoch": 2047,
        "reward": 0.6606084704399109,
        "val_loss": 0.0007636203039770148,
        "train_loss": 0.0020282461639442753
      },
      {
        "epoch": 2048,
        "reward": 0.27852797508239746,
        "val_loss": 0.019411767699888775,
        "train_loss": 0.0012296395277819382
      },
      {
        "epoch": 2049,
        "reward": 0.25251924991607666,
        "val_loss": 0.02534981071949005,
        "train_loss": 0.03258712431236815
      },
      {
        "epoch": 2050,
        "reward": 0.30649447441101074,
        "val_loss": 0.014812155294099025,
        "train_loss": 0.016485731068174712
      },
      {
        "epoch": 2051,
        "reward": 0.6889548897743225,
        "val_loss": 0.0005896970272130732,
        "train_loss": 0.004307459012264959
      },
      {
        "epoch": 2052,
        "reward": 0.6211054921150208,
        "val_loss": 0.0010766375843169434,
        "train_loss": 0.0005199800042856413
      },
      {
        "epoch": 2053,
        "reward": 0.5365025401115417,
        "val_loss": 0.002159310138917395,
        "train_loss": 0.0006114251115762342
      },
      {
        "epoch": 2054,
        "reward": 0.6094697713851929,
        "val_loss": 0.0011878695638318146,
        "train_loss": 0.002388293514601313
      },
      {
        "epoch": 2055,
        "reward": 0.6990591287612915,
        "val_loss": 0.00053616489666248,
        "train_loss": 0.0007384216912144509
      },
      {
        "epoch": 2056,
        "reward": 0.6746731996536255,
        "val_loss": 0.0006726921170151659,
        "train_loss": 0.0005369247796457225
      },
      {
        "epoch": 2057,
        "reward": 0.6240683794021606,
        "val_loss": 0.0010498255391472153,
        "train_loss": 0.0006049656701109668
      },
      {
        "epoch": 2058,
        "reward": 0.5958635807037354,
        "val_loss": 0.0013308396779133805,
        "train_loss": 0.0005322088131921331
      },
      {
        "epoch": 2059,
        "reward": 0.48874393105506897,
        "val_loss": 0.003165758148367916,
        "train_loss": 0.001010601300199946
      },
      {
        "epoch": 2060,
        "reward": 0.6026957631111145,
        "val_loss": 0.0012572274510083453,
        "train_loss": 0.0014001261137869174
      },
      {
        "epoch": 2061,
        "reward": 0.6859988570213318,
        "val_loss": 0.0006061492895241827,
        "train_loss": 0.0005564235568901774
      },
      {
        "epoch": 2062,
        "reward": 0.4830993115901947,
        "val_loss": 0.003312111333278673,
        "train_loss": 0.0006556366097619013
      },
      {
        "epoch": 2063,
        "reward": 0.4669736921787262,
        "val_loss": 0.003769434240114476,
        "train_loss": 0.0011793180532759624
      },
      {
        "epoch": 2064,
        "reward": 0.460151731967926,
        "val_loss": 0.003982034578387227,
        "train_loss": 0.0012752408231160818
      },
      {
        "epoch": 2065,
        "reward": 0.6275037527084351,
        "val_loss": 0.0010194710672034749,
        "train_loss": 0.00171760763455845
      },
      {
        "epoch": 2066,
        "reward": 0.45765289664268494,
        "val_loss": 0.00406299062472369,
        "train_loss": 0.000687378168759796
      },
      {
        "epoch": 2067,
        "reward": 0.4855654835700989,
        "val_loss": 0.00324734380202634,
        "train_loss": 0.0013830866368012861
      },
      {
        "epoch": 2068,
        "reward": 0.6761889457702637,
        "val_loss": 0.0006634541579322624,
        "train_loss": 0.0010695862040392967
      },
      {
        "epoch": 2069,
        "reward": 0.725372314453125,
        "val_loss": 0.000414696305857173,
        "train_loss": 0.0009233807403898726
      },
      {
        "epoch": 2070,
        "reward": 0.4679853022098541,
        "val_loss": 0.003738922698955451,
        "train_loss": 0.0021055009016820872
      },
      {
        "epoch": 2071,
        "reward": 0.6114615201950073,
        "val_loss": 0.0011681367135939322,
        "train_loss": 0.002087933951630615
      },
      {
        "epoch": 2072,
        "reward": 0.2643100917339325,
        "val_loss": 0.02241433265485934,
        "train_loss": 0.003270592260658025
      },
      {
        "epoch": 2073,
        "reward": 0.50651615858078,
        "val_loss": 0.0027461422474256585,
        "train_loss": 0.012297062285002679
      },
      {
        "epoch": 2074,
        "reward": 0.6348716616630554,
        "val_loss": 0.000956935907847115,
        "train_loss": 0.0010444763306622917
      },
      {
        "epoch": 2075,
        "reward": 0.7257699370384216,
        "val_loss": 0.00041304351803514043,
        "train_loss": 0.00063083296397683
      },
      {
        "epoch": 2076,
        "reward": 0.3968700170516968,
        "val_loss": 0.0066817298065871,
        "train_loss": 0.000524739105737983
      },
      {
        "epoch": 2077,
        "reward": 0.2747521698474884,
        "val_loss": 0.020158321729728153,
        "train_loss": 0.003942710237774568
      },
      {
        "epoch": 2078,
        "reward": 0.5274805426597595,
        "val_loss": 0.0023216149836246458,
        "train_loss": 0.007901961882977888
      },
      {
        "epoch": 2079,
        "reward": 0.739876925945282,
        "val_loss": 0.0003576038746229772,
        "train_loss": 0.001492633018642664
      },
      {
        "epoch": 2080,
        "reward": 0.7011401057243347,
        "val_loss": 0.0005256407644732722,
        "train_loss": 0.0006504682726070035
      },
      {
        "epoch": 2081,
        "reward": 0.6798295378684998,
        "val_loss": 0.0006416913820430636,
        "train_loss": 0.0005490797339007258
      },
      {
        "epoch": 2082,
        "reward": 0.6878658533096313,
        "val_loss": 0.0005957154415747416,
        "train_loss": 0.001040134559913825
      },
      {
        "epoch": 2083,
        "reward": 0.6722361445426941,
        "val_loss": 0.0006877683335915208,
        "train_loss": 0.0005974792741024151
      },
      {
        "epoch": 2084,
        "reward": 0.7059822678565979,
        "val_loss": 0.0005017913395671972,
        "train_loss": 0.0005543373240820634
      },
      {
        "epoch": 2085,
        "reward": 0.5165942311286926,
        "val_loss": 0.0025333100597241093,
        "train_loss": 0.0006929834398061547
      },
      {
        "epoch": 2086,
        "reward": 0.7367889881134033,
        "val_loss": 0.00036922031930381697,
        "train_loss": 0.001967388958571694
      },
      {
        "epoch": 2087,
        "reward": 0.7155620455741882,
        "val_loss": 0.00045713468404885916,
        "train_loss": 0.0005036613488650451
      },
      {
        "epoch": 2088,
        "reward": 0.5410783290863037,
        "val_loss": 0.0020812319624902947,
        "train_loss": 0.0008757491843705514
      },
      {
        "epoch": 2089,
        "reward": 0.5840398073196411,
        "val_loss": 0.0014675144172672714,
        "train_loss": 0.0006476593810545567
      },
      {
        "epoch": 2090,
        "reward": 0.4145274758338928,
        "val_loss": 0.00577125304179,
        "train_loss": 0.0007751378915809954
      },
      {
        "epoch": 2091,
        "reward": 0.49338507652282715,
        "val_loss": 0.0030503353170518365,
        "train_loss": 0.0034830785119153848
      },
      {
        "epoch": 2092,
        "reward": 0.7218344807624817,
        "val_loss": 0.00042963043337554803,
        "train_loss": 0.0009360661239882645
      },
      {
        "epoch": 2093,
        "reward": 0.6516897082328796,
        "val_loss": 0.0008264465099533222,
        "train_loss": 0.0007029168124203212
      },
      {
        "epoch": 2094,
        "reward": 0.6212453246116638,
        "val_loss": 0.0010753588368450956,
        "train_loss": 0.0006778432413931604
      },
      {
        "epoch": 2095,
        "reward": 0.6036749482154846,
        "val_loss": 0.0012469829276337155,
        "train_loss": 0.000667246701246208
      },
      {
        "epoch": 2096,
        "reward": 0.510006844997406,
        "val_loss": 0.002670494024641812,
        "train_loss": 0.0008700951735730856
      },
      {
        "epoch": 2097,
        "reward": 0.4708431661128998,
        "val_loss": 0.003654095277722393,
        "train_loss": 0.0009058541926116539
      },
      {
        "epoch": 2098,
        "reward": 0.2996675670146942,
        "val_loss": 0.015801290582333292,
        "train_loss": 0.0016391336125357507
      },
      {
        "epoch": 2099,
        "reward": 0.41910526156425476,
        "val_loss": 0.0055579219146498614,
        "train_loss": 0.011513593330444284
      },
      {
        "epoch": 2100,
        "reward": 0.7291803359985352,
        "val_loss": 0.00039907464192115834,
        "train_loss": 0.002317806408077908
      },
      {
        "epoch": 2101,
        "reward": 0.6846156120300293,
        "val_loss": 0.000613974523730576,
        "train_loss": 0.0004320092403811661
      },
      {
        "epoch": 2102,
        "reward": 0.6778861880302429,
        "val_loss": 0.0006532341566136372,
        "train_loss": 0.0004322926826996711
      },
      {
        "epoch": 2103,
        "reward": 0.6330801844596863,
        "val_loss": 0.0009718264087236353,
        "train_loss": 0.0009783125737717806
      },
      {
        "epoch": 2104,
        "reward": 0.5004159808158875,
        "val_loss": 0.0028834897093474865,
        "train_loss": 0.001464417133180317
      },
      {
        "epoch": 2105,
        "reward": 0.6498242020606995,
        "val_loss": 0.0008401256470408823,
        "train_loss": 0.0012123718255539783
      },
      {
        "epoch": 2106,
        "reward": 0.6133078932762146,
        "val_loss": 0.0011501039677698696,
        "train_loss": 0.0005633525646631964
      },
      {
        "epoch": 2107,
        "reward": 0.3541451394557953,
        "val_loss": 0.00962212442287377,
        "train_loss": 0.002677691628028137
      },
      {
        "epoch": 2108,
        "reward": 0.5620548129081726,
        "val_loss": 0.0017564902414700814,
        "train_loss": 0.007295084566486856
      },
      {
        "epoch": 2109,
        "reward": 0.742000937461853,
        "val_loss": 0.00034977685053101074,
        "train_loss": 0.003219699404256132
      },
      {
        "epoch": 2110,
        "reward": 0.6856136322021484,
        "val_loss": 0.0006083199987187982,
        "train_loss": 0.001056278808391653
      },
      {
        "epoch": 2111,
        "reward": 0.6053346991539001,
        "val_loss": 0.0012297885924843805,
        "train_loss": 0.0007762613756417872
      },
      {
        "epoch": 2112,
        "reward": 0.48489484190940857,
        "val_loss": 0.0032648281526884864,
        "train_loss": 0.001108402715404876
      },
      {
        "epoch": 2113,
        "reward": 0.5752634406089783,
        "val_loss": 0.0015771375869267754,
        "train_loss": 0.002291263319001211
      },
      {
        "epoch": 2114,
        "reward": 0.5013652443885803,
        "val_loss": 0.0028616752242669463,
        "train_loss": 0.0005915129524789966
      },
      {
        "epoch": 2115,
        "reward": 0.6569995284080505,
        "val_loss": 0.0007885389329333391,
        "train_loss": 0.0019965082991313045
      },
      {
        "epoch": 2116,
        "reward": 0.5815572142601013,
        "val_loss": 0.0014977899014151522,
        "train_loss": 0.0012880820431746542
      },
      {
        "epoch": 2117,
        "reward": 0.4787808060646057,
        "val_loss": 0.003428712587005326,
        "train_loss": 0.0028607387038601492
      },
      {
        "epoch": 2118,
        "reward": 0.5197266936302185,
        "val_loss": 0.0024705323656754835,
        "train_loss": 0.0019116393646422343
      },
      {
        "epoch": 2119,
        "reward": 0.6196679472923279,
        "val_loss": 0.0010898620239458978,
        "train_loss": 0.001363766539725475
      },
      {
        "epoch": 2120,
        "reward": 0.5851895213127136,
        "val_loss": 0.0014536838945267455,
        "train_loss": 0.0010354352547997574
      },
      {
        "epoch": 2121,
        "reward": 0.3736279606819153,
        "val_loss": 0.00813110831326672,
        "train_loss": 0.0006601346775334185
      },
      {
        "epoch": 2122,
        "reward": 0.6633129119873047,
        "val_loss": 0.0007453836567167725,
        "train_loss": 0.002988765382234795
      },
      {
        "epoch": 2123,
        "reward": 0.5025837421417236,
        "val_loss": 0.0028339132467018707,
        "train_loss": 0.0007719951760149202
      },
      {
        "epoch": 2124,
        "reward": 0.7228685021400452,
        "val_loss": 0.00042522303660267165,
        "train_loss": 0.0011180652184590984
      },
      {
        "epoch": 2125,
        "reward": 0.602897584438324,
        "val_loss": 0.0012551096816813307,
        "train_loss": 0.0010101790730214606
      },
      {
        "epoch": 2126,
        "reward": 0.6579920053482056,
        "val_loss": 0.0007816188735887408,
        "train_loss": 0.001179717130561095
      },
      {
        "epoch": 2127,
        "reward": 0.6386916637420654,
        "val_loss": 0.0009258427474248622,
        "train_loss": 0.0006355546826783281
      },
      {
        "epoch": 2128,
        "reward": 0.44937023520469666,
        "val_loss": 0.0043438444180147985,
        "train_loss": 0.0012805869605822058
      },
      {
        "epoch": 2129,
        "reward": 0.5005603432655334,
        "val_loss": 0.002880160962896688,
        "train_loss": 0.003306147862951128
      },
      {
        "epoch": 2130,
        "reward": 0.44142937660217285,
        "val_loss": 0.004632309112431747,
        "train_loss": 0.001876304939637171
      },
      {
        "epoch": 2131,
        "reward": 0.6107842326164246,
        "val_loss": 0.00117481396799641,
        "train_loss": 0.0014266035621823482
      },
      {
        "epoch": 2132,
        "reward": 0.6240084767341614,
        "val_loss": 0.0010503616815965091,
        "train_loss": 0.0006098108091324461
      },
      {
        "epoch": 2133,
        "reward": 0.21567927300930023,
        "val_loss": 0.03825906637523856,
        "train_loss": 0.0034994761674449993
      },
      {
        "epoch": 2134,
        "reward": 0.15244434773921967,
        "val_loss": 0.08942882344126701,
        "train_loss": 0.018532374327500854
      },
      {
        "epoch": 2135,
        "reward": 0.17838746309280396,
        "val_loss": 0.061371838940041404,
        "train_loss": 0.035601656758584656
      },
      {
        "epoch": 2136,
        "reward": 0.688747763633728,
        "val_loss": 0.0005908377310593746,
        "train_loss": 0.013941912915190468
      },
      {
        "epoch": 2137,
        "reward": 0.5238315463066101,
        "val_loss": 0.0023905703315644394,
        "train_loss": 0.0016710289273760282
      },
      {
        "epoch": 2138,
        "reward": 0.6754249930381775,
        "val_loss": 0.0006680973123625986,
        "train_loss": 0.0012741579143599106
      },
      {
        "epoch": 2139,
        "reward": 0.7243215441703796,
        "val_loss": 0.0004190891777398065,
        "train_loss": 0.0007359740489986367
      },
      {
        "epoch": 2140,
        "reward": 0.5954994559288025,
        "val_loss": 0.0013348714481773122,
        "train_loss": 0.001064444023471039
      },
      {
        "epoch": 2141,
        "reward": 0.5599092841148376,
        "val_loss": 0.0017873637843877077,
        "train_loss": 0.000766662516980432
      },
      {
        "epoch": 2142,
        "reward": 0.7112545967102051,
        "val_loss": 0.0004768081583149199,
        "train_loss": 0.0007627943638139046
      },
      {
        "epoch": 2143,
        "reward": 0.688241183757782,
        "val_loss": 0.0005936354947542506,
        "train_loss": 0.00042493415262120275
      },
      {
        "epoch": 2144,
        "reward": 0.6988459825515747,
        "val_loss": 0.000537252107668402,
        "train_loss": 0.00038499442374674033
      },
      {
        "epoch": 2145,
        "reward": 0.5033766627311707,
        "val_loss": 0.0028159944340586662,
        "train_loss": 0.0005490057631574858
      },
      {
        "epoch": 2146,
        "reward": 0.3590390980243683,
        "val_loss": 0.009220262723309653,
        "train_loss": 0.0015839445315158139
      },
      {
        "epoch": 2147,
        "reward": 0.39529380202293396,
        "val_loss": 0.006770371625732098,
        "train_loss": 0.004354883753246843
      },
      {
        "epoch": 2148,
        "reward": 0.37648269534111023,
        "val_loss": 0.007935433582003628,
        "train_loss": 0.0023676821953043914
      },
      {
        "epoch": 2149,
        "reward": 0.7229840755462646,
        "val_loss": 0.00042473255806336444,
        "train_loss": 0.004979197591847668
      },
      {
        "epoch": 2150,
        "reward": 0.4267871379852295,
        "val_loss": 0.005218826899571078,
        "train_loss": 0.0005452042045922448
      },
      {
        "epoch": 2151,
        "reward": 0.6714462637901306,
        "val_loss": 0.0006927139391856534,
        "train_loss": 0.0017829999601155157
      },
      {
        "epoch": 2152,
        "reward": 0.6662665009498596,
        "val_loss": 0.0007258841734645623,
        "train_loss": 0.0006619998412833621
      },
      {
        "epoch": 2153,
        "reward": 0.7324545383453369,
        "val_loss": 0.00038600890963737456,
        "train_loss": 0.0004695557290688157
      },
      {
        "epoch": 2154,
        "reward": 0.6678964495658875,
        "val_loss": 0.0007153070847769934,
        "train_loss": 0.00044262359974621944
      },
      {
        "epoch": 2155,
        "reward": 0.6820630431175232,
        "val_loss": 0.0006286320110250797,
        "train_loss": 0.0005164394539091378
      },
      {
        "epoch": 2156,
        "reward": 0.6853631138801575,
        "val_loss": 0.0006097355383514826,
        "train_loss": 0.0005909757669891965
      },
      {
        "epoch": 2157,
        "reward": 0.7205685377120972,
        "val_loss": 0.0004350748328891184,
        "train_loss": 0.0004424954736350628
      },
      {
        "epoch": 2158,
        "reward": 0.6266788244247437,
        "val_loss": 0.0010266894574410149,
        "train_loss": 0.00044408744963457644
      },
      {
        "epoch": 2159,
        "reward": 0.7172922492027283,
        "val_loss": 0.0004494142984705312,
        "train_loss": 0.0006128373061073944
      },
      {
        "epoch": 2160,
        "reward": 0.5232030749320984,
        "val_loss": 0.0024026461511052082,
        "train_loss": 0.0007610061640242258
      },
      {
        "epoch": 2161,
        "reward": 0.48789459466934204,
        "val_loss": 0.003187354787119797,
        "train_loss": 0.001856333843800957
      },
      {
        "epoch": 2162,
        "reward": 0.6044237613677979,
        "val_loss": 0.0012391987506167165,
        "train_loss": 0.0014814093659739369
      },
      {
        "epoch": 2163,
        "reward": 0.718718945980072,
        "val_loss": 0.0004431253016394164,
        "train_loss": 0.0007272177731815296
      },
      {
        "epoch": 2164,
        "reward": 0.7189071178436279,
        "val_loss": 0.0004423009647455599,
        "train_loss": 0.0008996497826256717
      },
      {
        "epoch": 2165,
        "reward": 0.722000241279602,
        "val_loss": 0.0004289217301577862,
        "train_loss": 0.00047459560244953114
      },
      {
        "epoch": 2166,
        "reward": 0.5393632054328918,
        "val_loss": 0.00211017465751086,
        "train_loss": 0.000563339836214884
      },
      {
        "epoch": 2167,
        "reward": 0.512567937374115,
        "val_loss": 0.0026163093113739577,
        "train_loss": 0.000846071702723678
      },
      {
        "epoch": 2168,
        "reward": 0.6201604008674622,
        "val_loss": 0.0010853157145902514,
        "train_loss": 0.0012453959965429162
      },
      {
        "epoch": 2169,
        "reward": 0.5609650015830994,
        "val_loss": 0.0017721087455616466,
        "train_loss": 0.0005300883303789306
      },
      {
        "epoch": 2170,
        "reward": 0.5824782252311707,
        "val_loss": 0.0014864924929237791,
        "train_loss": 0.0004991449498517725
      },
      {
        "epoch": 2171,
        "reward": 0.5265670418739319,
        "val_loss": 0.0023386942422283547,
        "train_loss": 0.0007928466948214918
      },
      {
        "epoch": 2172,
        "reward": 0.47175875306129456,
        "val_loss": 0.00362734029269112,
        "train_loss": 0.001116588362492621
      },
      {
        "epoch": 2173,
        "reward": 0.5472480058670044,
        "val_loss": 0.0019802317755030735,
        "train_loss": 0.001415199375165125
      },
      {
        "epoch": 2174,
        "reward": 0.609085202217102,
        "val_loss": 0.0011917133566125163,
        "train_loss": 0.0017509265554298719
      },
      {
        "epoch": 2175,
        "reward": 0.4209742546081543,
        "val_loss": 0.005473286911313023,
        "train_loss": 0.0008272325414089629
      },
      {
        "epoch": 2176,
        "reward": 0.6223630309104919,
        "val_loss": 0.0010651855762781842,
        "train_loss": 0.0012331899530671274
      },
      {
        "epoch": 2177,
        "reward": 0.7228412628173828,
        "val_loss": 0.00042533878669408817,
        "train_loss": 0.0011058641696133865
      },
      {
        "epoch": 2178,
        "reward": 0.7452296018600464,
        "val_loss": 0.000338128354217458,
        "train_loss": 0.0008524842101346272
      },
      {
        "epoch": 2179,
        "reward": 0.5364834666252136,
        "val_loss": 0.0021596405089699794,
        "train_loss": 0.0005794736890283485
      },
      {
        "epoch": 2180,
        "reward": 0.32461199164390564,
        "val_loss": 0.01252394967845508,
        "train_loss": 0.0013166893432543685
      },
      {
        "epoch": 2181,
        "reward": 0.34620219469070435,
        "val_loss": 0.010317891836166382,
        "train_loss": 0.006457995778279068
      },
      {
        "epoch": 2182,
        "reward": 0.2875310480594635,
        "val_loss": 0.017763401913855757,
        "train_loss": 0.0035701336724182162
      },
      {
        "epoch": 2183,
        "reward": 0.4870282709598541,
        "val_loss": 0.0032095349826184766,
        "train_loss": 0.009408614791867036
      },
      {
        "epoch": 2184,
        "reward": 0.5717653632164001,
        "val_loss": 0.0016228997431296324,
        "train_loss": 0.0019429837014355983
      },
      {
        "epoch": 2185,
        "reward": 0.6807910203933716,
        "val_loss": 0.0006360426403781665,
        "train_loss": 0.0009999276103022008
      },
      {
        "epoch": 2186,
        "reward": 0.6176629662513733,
        "val_loss": 0.001108545161384557,
        "train_loss": 0.0007116425941393783
      },
      {
        "epoch": 2187,
        "reward": 0.48254647850990295,
        "val_loss": 0.003326810397473829,
        "train_loss": 0.0007113118537325555
      },
      {
        "epoch": 2188,
        "reward": 0.7030168771743774,
        "val_loss": 0.0005162926307613296,
        "train_loss": 0.0032605270993931647
      },
      {
        "epoch": 2189,
        "reward": 0.49745702743530273,
        "val_loss": 0.0029525611815708025,
        "train_loss": 0.001616357533348579
      },
      {
        "epoch": 2190,
        "reward": 0.4226982593536377,
        "val_loss": 0.005396452865430287,
        "train_loss": 0.001243020826502918
      },
      {
        "epoch": 2191,
        "reward": 0.6796714663505554,
        "val_loss": 0.0006426237440401954,
        "train_loss": 0.0020881913470265526
      },
      {
        "epoch": 2192,
        "reward": 0.7315282225608826,
        "val_loss": 0.0003896714146581611,
        "train_loss": 0.00048213737598136783
      },
      {
        "epoch": 2193,
        "reward": 0.7336581945419312,
        "val_loss": 0.0003812896819519145,
        "train_loss": 0.0004888989604716279
      },
      {
        "epoch": 2194,
        "reward": 0.7182436585426331,
        "val_loss": 0.0004452125119444515,
        "train_loss": 0.00042266944477048057
      },
      {
        "epoch": 2195,
        "reward": 0.5812192559242249,
        "val_loss": 0.0015019557405529277,
        "train_loss": 0.0004154477937845513
      },
      {
        "epoch": 2196,
        "reward": 0.7479168772697449,
        "val_loss": 0.00032865849581347514,
        "train_loss": 0.0006176476084734672
      },
      {
        "epoch": 2197,
        "reward": 0.5377282500267029,
        "val_loss": 0.002138122176152787,
        "train_loss": 0.00042733518757114117
      },
      {
        "epoch": 2198,
        "reward": 0.3320908844470978,
        "val_loss": 0.011702659939016615,
        "train_loss": 0.0014581822001323767
      },
      {
        "epoch": 2199,
        "reward": 0.5644816756248474,
        "val_loss": 0.0017221738484555057,
        "train_loss": 0.012262833511508338
      },
      {
        "epoch": 2200,
        "reward": 0.7329960465431213,
        "val_loss": 0.0003838802139008684,
        "train_loss": 0.001744689726575206
      },
      {
        "epoch": 2201,
        "reward": 0.6174247860908508,
        "val_loss": 0.0011107832210005394,
        "train_loss": 0.0005154370793696636
      },
      {
        "epoch": 2202,
        "reward": 0.5651077628135681,
        "val_loss": 0.0017134220605450018,
        "train_loss": 0.001140887093452665
      },
      {
        "epoch": 2203,
        "reward": 0.41525036096572876,
        "val_loss": 0.005736985110810825,
        "train_loss": 0.001206084143912169
      },
      {
        "epoch": 2204,
        "reward": 0.7181079983711243,
        "val_loss": 0.0004458099470606872,
        "train_loss": 0.002103657514313594
      },
      {
        "epoch": 2205,
        "reward": 0.6506894826889038,
        "val_loss": 0.0008337568350335849,
        "train_loss": 0.00042784280510834203
      },
      {
        "epoch": 2206,
        "reward": 0.6364294290542603,
        "val_loss": 0.00094414920645899,
        "train_loss": 0.0007381704083225207
      },
      {
        "epoch": 2207,
        "reward": 0.5831175446510315,
        "val_loss": 0.0014786949073563197,
        "train_loss": 0.0007446616979835269
      },
      {
        "epoch": 2208,
        "reward": 0.6068493723869324,
        "val_loss": 0.0012142824541245187,
        "train_loss": 0.0010838797327148942
      },
      {
        "epoch": 2209,
        "reward": 0.4340880513191223,
        "val_loss": 0.004917062952050141,
        "train_loss": 0.0008984782650189188
      },
      {
        "epoch": 2210,
        "reward": 0.361897349357605,
        "val_loss": 0.008994435758462973,
        "train_loss": 0.0053373445838448014
      },
      {
        "epoch": 2211,
        "reward": 0.6313183903694153,
        "val_loss": 0.0009866652627741651,
        "train_loss": 0.003010456162603357
      },
      {
        "epoch": 2212,
        "reward": 0.29891377687454224,
        "val_loss": 0.015915301495364735,
        "train_loss": 0.002021944233162615
      },
      {
        "epoch": 2213,
        "reward": 0.4874795377254486,
        "val_loss": 0.003197960921430162,
        "train_loss": 0.004201427993393736
      },
      {
        "epoch": 2214,
        "reward": 0.29550665616989136,
        "val_loss": 0.016443069225975444,
        "train_loss": 0.002601531498769943
      },
      {
        "epoch": 2215,
        "reward": 0.3325779139995575,
        "val_loss": 0.011651394489620413,
        "train_loss": 0.005034703588954961
      },
      {
        "epoch": 2216,
        "reward": 0.32575714588165283,
        "val_loss": 0.012393914495727845,
        "train_loss": 0.009478163250483144
      },
      {
        "epoch": 2217,
        "reward": 0.3985232412815094,
        "val_loss": 0.006590132401990039,
        "train_loss": 0.003073784802556754
      },
      {
        "epoch": 2218,
        "reward": 0.7062809467315674,
        "val_loss": 0.0005003490826181535,
        "train_loss": 0.005099244353634556
      },
      {
        "epoch": 2219,
        "reward": 0.7015527486801147,
        "val_loss": 0.0005235744008262243,
        "train_loss": 0.0007352440370596014
      },
      {
        "epoch": 2220,
        "reward": 0.6435956954956055,
        "val_loss": 0.0008872035375264074,
        "train_loss": 0.0007022855433416015
      },
      {
        "epoch": 2221,
        "reward": 0.5810433030128479,
        "val_loss": 0.0015041289402038924,
        "train_loss": 0.0013181725931085215
      },
      {
        "epoch": 2222,
        "reward": 0.6084575057029724,
        "val_loss": 0.0011980114255233534,
        "train_loss": 0.0016679755129958861
      },
      {
        "epoch": 2223,
        "reward": 0.6058973670005798,
        "val_loss": 0.001224008172617427,
        "train_loss": 0.0005507550141513862
      },
      {
        "epoch": 2224,
        "reward": 0.6626632809638977,
        "val_loss": 0.0007497305549415094,
        "train_loss": 0.0006129317268390039
      },
      {
        "epoch": 2225,
        "reward": 0.42640405893325806,
        "val_loss": 0.005235199317602175,
        "train_loss": 0.0006174957905806458
      },
      {
        "epoch": 2226,
        "reward": 0.7030746340751648,
        "val_loss": 0.0005160068186731743,
        "train_loss": 0.0027822145919064777
      },
      {
        "epoch": 2227,
        "reward": 0.41820988059043884,
        "val_loss": 0.005598963936790824,
        "train_loss": 0.0017494469972846743
      },
      {
        "epoch": 2228,
        "reward": 0.7282590866088867,
        "val_loss": 0.00040281142407496063,
        "train_loss": 0.0017520999289655054
      },
      {
        "epoch": 2229,
        "reward": 0.6833381652832031,
        "val_loss": 0.000621274862039302,
        "train_loss": 0.0007708369734106013
      },
      {
        "epoch": 2230,
        "reward": 0.623511552810669,
        "val_loss": 0.0010548194654152862,
        "train_loss": 0.00045343923445146246
      },
      {
        "epoch": 2231,
        "reward": 0.647812008857727,
        "val_loss": 0.0008550960587204567,
        "train_loss": 0.0005719648869356975
      },
      {
        "epoch": 2232,
        "reward": 0.5984407067298889,
        "val_loss": 0.001302629559566932,
        "train_loss": 0.00046862850901491655
      },
      {
        "epoch": 2233,
        "reward": 0.6866934895515442,
        "val_loss": 0.000602249800327367,
        "train_loss": 0.000631123714041538
      },
      {
        "epoch": 2234,
        "reward": 0.555081307888031,
        "val_loss": 0.001858710710491453,
        "train_loss": 0.00043719384792404104
      },
      {
        "epoch": 2235,
        "reward": 0.6368905901908875,
        "val_loss": 0.0009403923218737223,
        "train_loss": 0.0007945804318296723
      },
      {
        "epoch": 2236,
        "reward": 0.6710690855979919,
        "val_loss": 0.0006950864834444863,
        "train_loss": 0.0004975579565955111
      },
      {
        "epoch": 2237,
        "reward": 0.6797646284103394,
        "val_loss": 0.0006420740641520492,
        "train_loss": 0.0004581843632667397
      },
      {
        "epoch": 2238,
        "reward": 0.7112923264503479,
        "val_loss": 0.00047663291999404985,
        "train_loss": 0.0005395781425669646
      },
      {
        "epoch": 2239,
        "reward": 0.7185249328613281,
        "val_loss": 0.00044397636000732224,
        "train_loss": 0.00044256097708757105
      },
      {
        "epoch": 2240,
        "reward": 0.7252528667449951,
        "val_loss": 0.00041519422666169703,
        "train_loss": 0.0005143159740747741
      },
      {
        "epoch": 2241,
        "reward": 0.6632980704307556,
        "val_loss": 0.0007454820817136871,
        "train_loss": 0.0010580427333479747
      },
      {
        "epoch": 2242,
        "reward": 0.47850990295410156,
        "val_loss": 0.003436164664370673,
        "train_loss": 0.0014071435804138533
      },
      {
        "epoch": 2243,
        "reward": 0.693157970905304,
        "val_loss": 0.0005669292919005134,
        "train_loss": 0.0008968074234871892
      },
      {
        "epoch": 2244,
        "reward": 0.6709014773368835,
        "val_loss": 0.0006961426988709718,
        "train_loss": 0.0005027149454690516
      },
      {
        "epoch": 2245,
        "reward": 0.7450879812240601,
        "val_loss": 0.0003386330894759989,
        "train_loss": 0.0007135204650694504
      },
      {
        "epoch": 2246,
        "reward": 0.4521961212158203,
        "val_loss": 0.004245806751506669,
        "train_loss": 0.0007841636526371496
      },
      {
        "epoch": 2247,
        "reward": 0.6060489416122437,
        "val_loss": 0.0012224552296434662,
        "train_loss": 0.0020617183145777043
      },
      {
        "epoch": 2248,
        "reward": 0.6517084240913391,
        "val_loss": 0.0008263098757847079,
        "train_loss": 0.0009163172082760587
      },
      {
        "epoch": 2249,
        "reward": 0.6694000363349915,
        "val_loss": 0.0007056637301242777,
        "train_loss": 0.0011640893721610506
      },
      {
        "epoch": 2250,
        "reward": 0.4173889756202698,
        "val_loss": 0.005636885662430099,
        "train_loss": 0.0007710209017834411
      },
      {
        "epoch": 2251,
        "reward": 0.5260911583900452,
        "val_loss": 0.0023476394957729746,
        "train_loss": 0.003629866308004309
      },
      {
        "epoch": 2252,
        "reward": 0.5238930583000183,
        "val_loss": 0.002389392117038369,
        "train_loss": 0.002098599616706801
      },
      {
        "epoch": 2253,
        "reward": 0.6818702220916748,
        "val_loss": 0.0006297510657792113,
        "train_loss": 0.001242608814768923
      },
      {
        "epoch": 2254,
        "reward": 0.7239221930503845,
        "val_loss": 0.00042076817771885544,
        "train_loss": 0.0008244314779473755
      },
      {
        "epoch": 2255,
        "reward": 0.7127954363822937,
        "val_loss": 0.00046969548982035903,
        "train_loss": 0.0006782812630402846
      },
      {
        "epoch": 2256,
        "reward": 0.7427814602851868,
        "val_loss": 0.00034693327117046077,
        "train_loss": 0.0003885164696839638
      },
      {
        "epoch": 2257,
        "reward": 0.6434979438781738,
        "val_loss": 0.0008879599128184574,
        "train_loss": 0.0005182716351835272
      },
      {
        "epoch": 2258,
        "reward": 0.5888807773590088,
        "val_loss": 0.0014100827060506812,
        "train_loss": 0.0006617422635687175
      },
      {
        "epoch": 2259,
        "reward": 0.6772759556770325,
        "val_loss": 0.0006568932440131903,
        "train_loss": 0.0005661268727495694
      },
      {
        "epoch": 2260,
        "reward": 0.6544652581214905,
        "val_loss": 0.0008064438755224858,
        "train_loss": 0.0009584918404400994
      },
      {
        "epoch": 2261,
        "reward": 0.5023848414421082,
        "val_loss": 0.0028384281821282847,
        "train_loss": 0.001383965045253997
      },
      {
        "epoch": 2262,
        "reward": 0.528627336025238,
        "val_loss": 0.0023003455384501387,
        "train_loss": 0.0011024762744245192
      },
      {
        "epoch": 2263,
        "reward": 0.23350892961025238,
        "val_loss": 0.03117244823702744,
        "train_loss": 0.0031840816843144307
      },
      {
        "epoch": 2264,
        "reward": 0.22839899361133575,
        "val_loss": 0.03301877262336867,
        "train_loss": 0.015245038680194948
      },
      {
        "epoch": 2265,
        "reward": 0.47484827041625977,
        "val_loss": 0.0035385352093726397,
        "train_loss": 0.005461963641349799
      },
      {
        "epoch": 2266,
        "reward": 0.3349115550518036,
        "val_loss": 0.011409386659839324,
        "train_loss": 0.0027063722484924188
      },
      {
        "epoch": 2267,
        "reward": 0.5279016494750977,
        "val_loss": 0.0023137824942490886,
        "train_loss": 0.007118373500326505
      },
      {
        "epoch": 2268,
        "reward": 0.6817802786827087,
        "val_loss": 0.0006302736624742725,
        "train_loss": 0.0019776171986730052
      },
      {
        "epoch": 2269,
        "reward": 0.7501619458198547,
        "val_loss": 0.0003209007201283904,
        "train_loss": 0.0006188232688635673
      },
      {
        "epoch": 2270,
        "reward": 0.6925389766693115,
        "val_loss": 0.0005702367676089384,
        "train_loss": 0.0003722882756846957
      },
      {
        "epoch": 2271,
        "reward": 0.6206114888191223,
        "val_loss": 0.0010811660239206894,
        "train_loss": 0.0004540069315295953
      },
      {
        "epoch": 2272,
        "reward": 0.7023000717163086,
        "val_loss": 0.0005198474058748356,
        "train_loss": 0.0006768910523253278
      },
      {
        "epoch": 2273,
        "reward": 0.6382294297218323,
        "val_loss": 0.0009295579844287463,
        "train_loss": 0.0006393635199996284
      },
      {
        "epoch": 2274,
        "reward": 0.5369183421134949,
        "val_loss": 0.002152099839544722,
        "train_loss": 0.0011479067469246308
      },
      {
        "epoch": 2275,
        "reward": 0.7090511918067932,
        "val_loss": 0.00048712638506133644,
        "train_loss": 0.0005354544566496491
      },
      {
        "epoch": 2276,
        "reward": 0.7473059296607971,
        "val_loss": 0.0003307933303793626,
        "train_loss": 0.00047246409607300146
      },
      {
        "epoch": 2277,
        "reward": 0.6311414241790771,
        "val_loss": 0.0009881665547644453,
        "train_loss": 0.00041209793674240174
      },
      {
        "epoch": 2278,
        "reward": 0.7033718228340149,
        "val_loss": 0.0005145394617492067,
        "train_loss": 0.000691798486514017
      },
      {
        "epoch": 2279,
        "reward": 0.6953567862510681,
        "val_loss": 0.0005553047521971166,
        "train_loss": 0.0009359878928919968
      },
      {
        "epoch": 2280,
        "reward": 0.5525519847869873,
        "val_loss": 0.0018971533281728625,
        "train_loss": 0.0004995157986950988
      },
      {
        "epoch": 2281,
        "reward": 0.7399663329124451,
        "val_loss": 0.0003572720327481095,
        "train_loss": 0.0008510831696464895
      },
      {
        "epoch": 2282,
        "reward": 0.6044789552688599,
        "val_loss": 0.00123862740084795,
        "train_loss": 0.0008656049243514785
      },
      {
        "epoch": 2283,
        "reward": 0.6922134757041931,
        "val_loss": 0.0005719824943558446,
        "train_loss": 0.0009842968307739197
      },
      {
        "epoch": 2284,
        "reward": 0.7414658665657043,
        "val_loss": 0.0003517363386760865,
        "train_loss": 0.0005595277465405301
      },
      {
        "epoch": 2285,
        "reward": 0.742023766040802,
        "val_loss": 0.0003496936239701297,
        "train_loss": 0.0005521092825802043
      },
      {
        "epoch": 2286,
        "reward": 0.5583295822143555,
        "val_loss": 0.0018104186913530742,
        "train_loss": 0.00048529854393564165
      },
      {
        "epoch": 2287,
        "reward": 0.6130606532096863,
        "val_loss": 0.0011525048924210881,
        "train_loss": 0.0008769790863600344
      },
      {
        "epoch": 2288,
        "reward": 0.6449548602104187,
        "val_loss": 0.000876742581437741,
        "train_loss": 0.0010924236916113072
      },
      {
        "epoch": 2289,
        "reward": 0.610325276851654,
        "val_loss": 0.0011793575332766132,
        "train_loss": 0.0006030065112729342
      },
      {
        "epoch": 2290,
        "reward": 0.5003992915153503,
        "val_loss": 0.0028838759421237876,
        "train_loss": 0.000739862169351769
      },
      {
        "epoch": 2291,
        "reward": 0.6895380616188049,
        "val_loss": 0.0005864944666557546,
        "train_loss": 0.0029468523386570336
      },
      {
        "epoch": 2292,
        "reward": 0.52027827501297,
        "val_loss": 0.0024596373217978646,
        "train_loss": 0.0013029433018975677
      },
      {
        "epoch": 2293,
        "reward": 0.5696693062782288,
        "val_loss": 0.0016509071241931192,
        "train_loss": 0.0011125467944321616
      },
      {
        "epoch": 2294,
        "reward": 0.5001477599143982,
        "val_loss": 0.0028896837694836514,
        "train_loss": 0.001816800712101842
      },
      {
        "epoch": 2295,
        "reward": 0.64763343334198,
        "val_loss": 0.0008564349347060281,
        "train_loss": 0.0008302464395036133
      },
      {
        "epoch": 2296,
        "reward": 0.6296840310096741,
        "val_loss": 0.001000606213762824,
        "train_loss": 0.0004450718819008706
      },
      {
        "epoch": 2297,
        "reward": 0.7336983680725098,
        "val_loss": 0.0003811326875750508,
        "train_loss": 0.0004307372873881832
      },
      {
        "epoch": 2298,
        "reward": 0.483570396900177,
        "val_loss": 0.0032996402587741613,
        "train_loss": 0.00040238309562622674
      },
      {
        "epoch": 2299,
        "reward": 0.7133676409721375,
        "val_loss": 0.00046707594551012984,
        "train_loss": 0.001074791836659782
      },
      {
        "epoch": 2300,
        "reward": 0.7244934439659119,
        "val_loss": 0.0004183680929210303,
        "train_loss": 0.0006741414366003412
      },
      {
        "epoch": 2301,
        "reward": 0.4234481751918793,
        "val_loss": 0.005363395637167352,
        "train_loss": 0.000437633306808913
      },
      {
        "epoch": 2302,
        "reward": 0.2553059160709381,
        "val_loss": 0.02461488571550165,
        "train_loss": 0.0045164419044830045
      },
      {
        "epoch": 2303,
        "reward": 0.47665196657180786,
        "val_loss": 0.003487723896146885,
        "train_loss": 0.004956567250281716
      },
      {
        "epoch": 2304,
        "reward": 0.37276491522789,
        "val_loss": 0.008191329027925218,
        "train_loss": 0.001810592857964366
      },
      {
        "epoch": 2305,
        "reward": 0.5258976817131042,
        "val_loss": 0.002351284758853061,
        "train_loss": 0.004397514933281435
      },
      {
        "epoch": 2306,
        "reward": 0.7533454298973083,
        "val_loss": 0.0003101370675722137,
        "train_loss": 0.0008534997737464997
      },
      {
        "epoch": 2307,
        "reward": 0.7313238382339478,
        "val_loss": 0.00039048334916255305,
        "train_loss": 0.0004650730155005406
      },
      {
        "epoch": 2308,
        "reward": 0.624381959438324,
        "val_loss": 0.0010470217343286744,
        "train_loss": 0.00044374948265613057
      },
      {
        "epoch": 2309,
        "reward": 0.69804447889328,
        "val_loss": 0.0005413564379393522,
        "train_loss": 0.0005656859092281453
      },
      {
        "epoch": 2310,
        "reward": 0.5883695483207703,
        "val_loss": 0.0014160485505791648,
        "train_loss": 0.0009449602814409166
      },
      {
        "epoch": 2311,
        "reward": 0.7124883532524109,
        "val_loss": 0.00047110647678242197,
        "train_loss": 0.000761993991685673
      },
      {
        "epoch": 2312,
        "reward": 0.7024210691452026,
        "val_loss": 0.0005192459294838565,
        "train_loss": 0.0004390634953429421
      },
      {
        "epoch": 2313,
        "reward": 0.5753492712974548,
        "val_loss": 0.0015760292964322226,
        "train_loss": 0.00041456965734071744
      },
      {
        "epoch": 2314,
        "reward": 0.7521162033081055,
        "val_loss": 0.0003142606687366164,
        "train_loss": 0.0007418787320672821
      },
      {
        "epoch": 2315,
        "reward": 0.6198248267173767,
        "val_loss": 0.001088412245735526,
        "train_loss": 0.000455516949072122
      },
      {
        "epoch": 2316,
        "reward": 0.6484889388084412,
        "val_loss": 0.0008500342124274798,
        "train_loss": 0.0014465166118148214
      },
      {
        "epoch": 2317,
        "reward": 0.3643858730792999,
        "val_loss": 0.008802939938115222,
        "train_loss": 0.0008775751652697531
      },
      {
        "epoch": 2318,
        "reward": 0.5165717005729675,
        "val_loss": 0.002533766258108829,
        "train_loss": 0.0029153649184781197
      },
      {
        "epoch": 2319,
        "reward": 0.7072705626487732,
        "val_loss": 0.0004955930552179259,
        "train_loss": 0.0016399064132621368
      },
      {
        "epoch": 2320,
        "reward": 0.7464668154716492,
        "val_loss": 0.0003337431844556704,
        "train_loss": 0.00045188515147086804
      },
      {
        "epoch": 2321,
        "reward": 0.7514234781265259,
        "val_loss": 0.0003166025230062327,
        "train_loss": 0.00038278370588019385
      },
      {
        "epoch": 2322,
        "reward": 0.571846067905426,
        "val_loss": 0.001621829528760697,
        "train_loss": 0.0003635374299707249
      },
      {
        "epoch": 2323,
        "reward": 0.7441980242729187,
        "val_loss": 0.00034181786343521835,
        "train_loss": 0.0011817477430808
      },
      {
        "epoch": 2324,
        "reward": 0.6553515791893005,
        "val_loss": 0.0008001428130748016,
        "train_loss": 0.00045671798188078147
      },
      {
        "epoch": 2325,
        "reward": 0.6114570498466492,
        "val_loss": 0.0011681801074051432,
        "train_loss": 0.0005487092740412874
      },
      {
        "epoch": 2326,
        "reward": 0.7535521984100342,
        "val_loss": 0.0003094474980441321,
        "train_loss": 0.0005869930777967406
      },
      {
        "epoch": 2327,
        "reward": 0.701575756072998,
        "val_loss": 0.0005234592577575573,
        "train_loss": 0.0004932479916113572
      },
      {
        "epoch": 2328,
        "reward": 0.5669678449630737,
        "val_loss": 0.0016876685632658856,
        "train_loss": 0.0005843719901839414
      },
      {
        "epoch": 2329,
        "reward": 0.44335389137268066,
        "val_loss": 0.004560588260314294,
        "train_loss": 0.001434877345253391
      },
      {
        "epoch": 2330,
        "reward": 0.6384120583534241,
        "val_loss": 0.0009280885652905064,
        "train_loss": 0.0017318601458100602
      },
      {
        "epoch": 2331,
        "reward": 0.6893177032470703,
        "val_loss": 0.0005877027537540666,
        "train_loss": 0.0005013349347371751
      },
      {
        "epoch": 2332,
        "reward": 0.5492777228355408,
        "val_loss": 0.0019480395962351135,
        "train_loss": 0.00043905861401491653
      },
      {
        "epoch": 2333,
        "reward": 0.7400569319725037,
        "val_loss": 0.0003569357130410416,
        "train_loss": 0.0009578337384692321
      },
      {
        "epoch": 2334,
        "reward": 0.6299165487289429,
        "val_loss": 0.0009986122770767128,
        "train_loss": 0.0004702660662587732
      },
      {
        "epoch": 2335,
        "reward": 0.488150030374527,
        "val_loss": 0.003180843445339373,
        "train_loss": 0.0006029175850786627
      },
      {
        "epoch": 2336,
        "reward": 0.5672356486320496,
        "val_loss": 0.0016839899056191956,
        "train_loss": 0.002254017976855931
      },
      {
        "epoch": 2337,
        "reward": 0.6469448208808899,
        "val_loss": 0.0008616175535800201,
        "train_loss": 0.0033195122389140753
      },
      {
        "epoch": 2338,
        "reward": 0.545220673084259,
        "val_loss": 0.002012892676118229,
        "train_loss": 0.001782792671432477
      },
      {
        "epoch": 2339,
        "reward": 0.6602057218551636,
        "val_loss": 0.0007663678261451423,
        "train_loss": 0.0009748835526360941
      },
      {
        "epoch": 2340,
        "reward": 0.7480961680412292,
        "val_loss": 0.0003280336448889492,
        "train_loss": 0.0005145668818351204
      },
      {
        "epoch": 2341,
        "reward": 0.7475215792655945,
        "val_loss": 0.00033003844769804606,
        "train_loss": 0.0004162736344579361
      },
      {
        "epoch": 2342,
        "reward": 0.7403440475463867,
        "val_loss": 0.0003558712757824521,
        "train_loss": 0.0004049847562922738
      },
      {
        "epoch": 2343,
        "reward": 0.5594285726547241,
        "val_loss": 0.0017943496516506588,
        "train_loss": 0.0004309587770526727
      },
      {
        "epoch": 2344,
        "reward": 0.5575498938560486,
        "val_loss": 0.0018219016658674394,
        "train_loss": 0.0009278840752507187
      },
      {
        "epoch": 2345,
        "reward": 0.3142688572406769,
        "val_loss": 0.01377427438274026,
        "train_loss": 0.0010665520060753736
      },
      {
        "epoch": 2346,
        "reward": 0.6186506152153015,
        "val_loss": 0.001099307123305542,
        "train_loss": 0.00585997040280535
      },
      {
        "epoch": 2347,
        "reward": 0.6182030439376831,
        "val_loss": 0.001103484645552401,
        "train_loss": 0.0008822104388785262
      },
      {
        "epoch": 2348,
        "reward": 0.7491191625595093,
        "val_loss": 0.0003244866363404851,
        "train_loss": 0.0004407884614640632
      },
      {
        "epoch": 2349,
        "reward": 0.5960473418235779,
        "val_loss": 0.0013288110328306044,
        "train_loss": 0.00037525906317079294
      },
      {
        "epoch": 2350,
        "reward": 0.7548572421073914,
        "val_loss": 0.00030512097250071486,
        "train_loss": 0.000629147398915218
      },
      {
        "epoch": 2351,
        "reward": 0.6480900049209595,
        "val_loss": 0.0008530139041665409,
        "train_loss": 0.0005068283364660322
      },
      {
        "epoch": 2352,
        "reward": 0.551764190196991,
        "val_loss": 0.0019092803080898843,
        "train_loss": 0.0009411404842886931
      },
      {
        "epoch": 2353,
        "reward": 0.6040104627609253,
        "val_loss": 0.0012434898443253978,
        "train_loss": 0.0008046010278541452
      },
      {
        "epoch": 2354,
        "reward": 0.6410250067710876,
        "val_loss": 0.0009072818128126008,
        "train_loss": 0.0009382927640287492
      },
      {
        "epoch": 2355,
        "reward": 0.6519298553466797,
        "val_loss": 0.0008246987875151847,
        "train_loss": 0.0005143966073564326
      },
      {
        "epoch": 2356,
        "reward": 0.6018012762069702,
        "val_loss": 0.0012666515124562597,
        "train_loss": 0.0005119995252103903
      },
      {
        "epoch": 2357,
        "reward": 0.739314079284668,
        "val_loss": 0.00035970036489223797,
        "train_loss": 0.0006105083901694833
      },
      {
        "epoch": 2358,
        "reward": 0.728751003742218,
        "val_loss": 0.00040081276009524506,
        "train_loss": 0.00040365137605336855
      },
      {
        "epoch": 2359,
        "reward": 0.7022312879562378,
        "val_loss": 0.000520189359251942,
        "train_loss": 0.0004907476886203837
      },
      {
        "epoch": 2360,
        "reward": 0.6995787620544434,
        "val_loss": 0.0005335210340230592,
        "train_loss": 0.0004865967021032702
      },
      {
        "epoch": 2361,
        "reward": 0.5544688701629639,
        "val_loss": 0.0018679510768769042,
        "train_loss": 0.0006763707027018357
      },
      {
        "epoch": 2362,
        "reward": 0.6981875896453857,
        "val_loss": 0.0005406217075817819,
        "train_loss": 0.0007673652563915731
      },
      {
        "epoch": 2363,
        "reward": 0.6394345760345459,
        "val_loss": 0.0009198978410235473,
        "train_loss": 0.0004214067773248714
      },
      {
        "epoch": 2364,
        "reward": 0.6519414782524109,
        "val_loss": 0.0008246141951531172,
        "train_loss": 0.0006255968272363624
      },
      {
        "epoch": 2365,
        "reward": 0.5311876535415649,
        "val_loss": 0.002253542754000851,
        "train_loss": 0.0004912104363589046
      },
      {
        "epoch": 2366,
        "reward": 0.40776705741882324,
        "val_loss": 0.006102735309728554,
        "train_loss": 0.0007800321277150383
      },
      {
        "epoch": 2367,
        "reward": 0.384715735912323,
        "val_loss": 0.007400065028507795,
        "train_loss": 0.00659974739937752
      },
      {
        "epoch": 2368,
        "reward": 0.5251187682151794,
        "val_loss": 0.00236602162476629,
        "train_loss": 0.00527162262901234
      },
      {
        "epoch": 2369,
        "reward": 0.6362396478652954,
        "val_loss": 0.0009456988773308694,
        "train_loss": 0.0010079861852388533
      },
      {
        "epoch": 2370,
        "reward": 0.7021247744560242,
        "val_loss": 0.0005207195728352028,
        "train_loss": 0.0003692967413651506
      },
      {
        "epoch": 2371,
        "reward": 0.6218238472938538,
        "val_loss": 0.0010700822708063892,
        "train_loss": 0.00040870571095953125
      },
      {
        "epoch": 2372,
        "reward": 0.67235267162323,
        "val_loss": 0.0006870408625608044,
        "train_loss": 0.00048036575896486075
      },
      {
        "epoch": 2373,
        "reward": 0.7507621645927429,
        "val_loss": 0.00031885043426882476,
        "train_loss": 0.00047053128051070066
      },
      {
        "epoch": 2374,
        "reward": 0.5835813879966736,
        "val_loss": 0.0014730615740908043,
        "train_loss": 0.0007394089166504833
      },
      {
        "epoch": 2375,
        "reward": 0.7388836741447449,
        "val_loss": 0.00036130973811460923,
        "train_loss": 0.0007756328716193541
      },
      {
        "epoch": 2376,
        "reward": 0.7139098644256592,
        "val_loss": 0.0004646035751128303,
        "train_loss": 0.0008255132966391662
      },
      {
        "epoch": 2377,
        "reward": 0.46064063906669617,
        "val_loss": 0.003966391685285738,
        "train_loss": 0.0006327999390822907
      },
      {
        "epoch": 2378,
        "reward": 0.7008405327796936,
        "val_loss": 0.0005271458233307515,
        "train_loss": 0.0017563763173641816
      },
      {
        "epoch": 2379,
        "reward": 0.6422127485275269,
        "val_loss": 0.0008979571284726262,
        "train_loss": 0.00045206768537844677
      },
      {
        "epoch": 2380,
        "reward": 0.7316786646842957,
        "val_loss": 0.00038907513953745365,
        "train_loss": 0.0005254402405206257
      },
      {
        "epoch": 2381,
        "reward": 0.6541077494621277,
        "val_loss": 0.0008089968219532498,
        "train_loss": 0.0003819831668247039
      },
      {
        "epoch": 2382,
        "reward": 0.6731300354003906,
        "val_loss": 0.0006822063587605953,
        "train_loss": 0.0006722719554090872
      },
      {
        "epoch": 2383,
        "reward": 0.7218542098999023,
        "val_loss": 0.00042954605305567384,
        "train_loss": 0.00044538660061404627
      },
      {
        "epoch": 2384,
        "reward": 0.6224085688591003,
        "val_loss": 0.0010647723517779792,
        "train_loss": 0.0005063753476581321
      },
      {
        "epoch": 2385,
        "reward": 0.6108008027076721,
        "val_loss": 0.0011746503046846815,
        "train_loss": 0.0005891767605834713
      },
      {
        "epoch": 2386,
        "reward": 0.5325088500976562,
        "val_loss": 0.0022297532663547565,
        "train_loss": 0.0006074505911853451
      },
      {
        "epoch": 2387,
        "reward": 0.6696321964263916,
        "val_loss": 0.0007041847108796771,
        "train_loss": 0.000900245536356054
      },
      {
        "epoch": 2388,
        "reward": 0.674822986125946,
        "val_loss": 0.0006717744191908943,
        "train_loss": 0.0005560770005104132
      },
      {
        "epoch": 2389,
        "reward": 0.42748260498046875,
        "val_loss": 0.005189243138634733,
        "train_loss": 0.0004869670060893091
      },
      {
        "epoch": 2390,
        "reward": 0.51626056432724,
        "val_loss": 0.0025400885746681263,
        "train_loss": 0.0023988137903730744
      },
      {
        "epoch": 2391,
        "reward": 0.7141661643981934,
        "val_loss": 0.00046343899365248423,
        "train_loss": 0.0013094875175738707
      },
      {
        "epoch": 2392,
        "reward": 0.7133356928825378,
        "val_loss": 0.00046722175570071807,
        "train_loss": 0.0004668202717976573
      },
      {
        "epoch": 2393,
        "reward": 0.6652286648750305,
        "val_loss": 0.0007326870108954608,
        "train_loss": 0.00045755675931174593
      },
      {
        "epoch": 2394,
        "reward": 0.72532057762146,
        "val_loss": 0.000414912002660068,
        "train_loss": 0.0004301207801867909
      },
      {
        "epoch": 2395,
        "reward": 0.7076243162155151,
        "val_loss": 0.0004939020810914892,
        "train_loss": 0.0003858138023553273
      },
      {
        "epoch": 2396,
        "reward": 0.7401914000511169,
        "val_loss": 0.0003564368234947324,
        "train_loss": 0.0004053219448766098
      },
      {
        "epoch": 2397,
        "reward": 0.7005166411399841,
        "val_loss": 0.000528776498478172,
        "train_loss": 0.000342422376189251
      },
      {
        "epoch": 2398,
        "reward": 0.5263552069664001,
        "val_loss": 0.0023426720539906193,
        "train_loss": 0.0006193220965192617
      },
      {
        "epoch": 2399,
        "reward": 0.2766577899456024,
        "val_loss": 0.019777235441974232,
        "train_loss": 0.0012975636289831107
      },
      {
        "epoch": 2400,
        "reward": 0.5176940560340881,
        "val_loss": 0.0025110917631536722,
        "train_loss": 0.018410425731697336
      },
      {
        "epoch": 2401,
        "reward": 0.40765929222106934,
        "val_loss": 0.006108183214174849,
        "train_loss": 0.003976262287324062
      },
      {
        "epoch": 2402,
        "reward": 0.5031543374061584,
        "val_loss": 0.0028210067290014456,
        "train_loss": 0.0021630378077343968
      },
      {
        "epoch": 2403,
        "reward": 0.6826877593994141,
        "val_loss": 0.0006250187787892563,
        "train_loss": 0.001888776633467597
      },
      {
        "epoch": 2404,
        "reward": 0.7145695090293884,
        "val_loss": 0.0004616104789809989,
        "train_loss": 0.0004866450528005281
      },
      {
        "epoch": 2405,
        "reward": 0.7201480865478516,
        "val_loss": 0.0004368945124692151,
        "train_loss": 0.00035940229127417154
      },
      {
        "epoch": 2406,
        "reward": 0.5377799272537231,
        "val_loss": 0.0021372343679623945,
        "train_loss": 0.00042225034681345837
      },
      {
        "epoch": 2407,
        "reward": 0.655035138130188,
        "val_loss": 0.0008023878700831639,
        "train_loss": 0.0008708196047608069
      },
      {
        "epoch": 2408,
        "reward": 0.7355252504348755,
        "val_loss": 0.0003740562554282535,
        "train_loss": 0.0003711679377234899
      },
      {
        "epoch": 2409,
        "reward": 0.7149338126182556,
        "val_loss": 0.000459963281173259,
        "train_loss": 0.00040363453277118073
      },
      {
        "epoch": 2410,
        "reward": 0.7033666968345642,
        "val_loss": 0.0005145644536241889,
        "train_loss": 0.0004147683049758108
      },
      {
        "epoch": 2411,
        "reward": 0.7330114841461182,
        "val_loss": 0.0003838197319834892,
        "train_loss": 0.00040009014180843503
      },
      {
        "epoch": 2412,
        "reward": 0.7488949298858643,
        "val_loss": 0.0003252616526359426,
        "train_loss": 0.00037880862957815855
      },
      {
        "epoch": 2413,
        "reward": 0.7169416546821594,
        "val_loss": 0.00045097037634280113,
        "train_loss": 0.00036070135795923235
      },
      {
        "epoch": 2414,
        "reward": 0.7058076858520508,
        "val_loss": 0.0005026361031923443,
        "train_loss": 0.0005890326552057209
      },
      {
        "epoch": 2415,
        "reward": 0.5744093656539917,
        "val_loss": 0.001588198239915073,
        "train_loss": 0.00037597220999976765
      },
      {
        "epoch": 2416,
        "reward": 0.7026997208595276,
        "val_loss": 0.0005178629695105233,
        "train_loss": 0.0008124493262864865
      },
      {
        "epoch": 2417,
        "reward": 0.6506969332695007,
        "val_loss": 0.0008337016915902495,
        "train_loss": 0.0004515430907933758
      },
      {
        "epoch": 2418,
        "reward": 0.7385706305503845,
        "val_loss": 0.0003624835517257452,
        "train_loss": 0.0005972843489591748
      },
      {
        "epoch": 2419,
        "reward": 0.6927489638328552,
        "val_loss": 0.0005691132225495364,
        "train_loss": 0.00041230789425893675
      },
      {
        "epoch": 2420,
        "reward": 0.6861670017242432,
        "val_loss": 0.0006052028163269695,
        "train_loss": 0.0003613532395460285
      },
      {
        "epoch": 2421,
        "reward": 0.7299534678459167,
        "val_loss": 0.00039595916002456633,
        "train_loss": 0.0004340649410061395
      },
      {
        "epoch": 2422,
        "reward": 0.714879035949707,
        "val_loss": 0.0004602106304706207,
        "train_loss": 0.0004775036062570647
      },
      {
        "epoch": 2423,
        "reward": 0.5747344493865967,
        "val_loss": 0.0015839794567520066,
        "train_loss": 0.0006071671484208379
      },
      {
        "epoch": 2424,
        "reward": 0.7308017611503601,
        "val_loss": 0.0003925627700352509,
        "train_loss": 0.0010304319394680744
      },
      {
        "epoch": 2425,
        "reward": 0.7164613008499146,
        "val_loss": 0.0004531091627930956,
        "train_loss": 0.0004803576795473838
      },
      {
        "epoch": 2426,
        "reward": 0.7256752848625183,
        "val_loss": 0.00041343644053475667,
        "train_loss": 0.00047373398914575006
      },
      {
        "epoch": 2427,
        "reward": 0.6964404582977295,
        "val_loss": 0.00054964648526428,
        "train_loss": 0.0004285528764460021
      },
      {
        "epoch": 2428,
        "reward": 0.751900851726532,
        "val_loss": 0.000314987322781235,
        "train_loss": 0.00034615543476180534
      },
      {
        "epoch": 2429,
        "reward": 0.6838588118553162,
        "val_loss": 0.000618290900352544,
        "train_loss": 0.0003455932422254521
      },
      {
        "epoch": 2430,
        "reward": 0.6090255975723267,
        "val_loss": 0.0011923102761751839,
        "train_loss": 0.0007099234941191613
      },
      {
        "epoch": 2431,
        "reward": 0.7065752744674683,
        "val_loss": 0.000498930607656283,
        "train_loss": 0.0006274842310701318
      },
      {
        "epoch": 2432,
        "reward": 0.7585565447807312,
        "val_loss": 0.00029310189919280153,
        "train_loss": 0.0006833404421251124
      },
      {
        "epoch": 2433,
        "reward": 0.7292768955230713,
        "val_loss": 0.0003986845050738858,
        "train_loss": 0.0003268126180885772
      },
      {
        "epoch": 2434,
        "reward": 0.7409374713897705,
        "val_loss": 0.0003536794060242495,
        "train_loss": 0.0005510920869150701
      },
      {
        "epoch": 2435,
        "reward": 0.5405229926109314,
        "val_loss": 0.0020905620019350734,
        "train_loss": 0.0005086337198288395
      },
      {
        "epoch": 2436,
        "reward": 0.601069986820221,
        "val_loss": 0.001274403084867767,
        "train_loss": 0.0010391758239795589
      },
      {
        "epoch": 2437,
        "reward": 0.47774162888526917,
        "val_loss": 0.0034573893728000776,
        "train_loss": 0.0008863984302689249
      },
      {
        "epoch": 2438,
        "reward": 0.6869542598724365,
        "val_loss": 0.000600791078925665,
        "train_loss": 0.001804933364977702
      },
      {
        "epoch": 2439,
        "reward": 0.6342965364456177,
        "val_loss": 0.0009616948664188385,
        "train_loss": 0.00038655484296703857
      },
      {
        "epoch": 2440,
        "reward": 0.7244139313697815,
        "val_loss": 0.0004187018660429333,
        "train_loss": 0.0006397901664828309
      },
      {
        "epoch": 2441,
        "reward": 0.7288343906402588,
        "val_loss": 0.0004004747877063762,
        "train_loss": 0.0004960714774754776
      },
      {
        "epoch": 2442,
        "reward": 0.7137080430984497,
        "val_loss": 0.0004655229692746486,
        "train_loss": 0.0005362467244804765
      },
      {
        "epoch": 2443,
        "reward": 0.6914986371994019,
        "val_loss": 0.0005758310061147702,
        "train_loss": 0.0005138516799678865
      },
      {
        "epoch": 2444,
        "reward": 0.652368426322937,
        "val_loss": 0.0008215165580622852,
        "train_loss": 0.000552750876522623
      },
      {
        "epoch": 2445,
        "reward": 0.7496219873428345,
        "val_loss": 0.0003227538732712024,
        "train_loss": 0.0003741725995496381
      },
      {
        "epoch": 2446,
        "reward": 0.6910247206687927,
        "val_loss": 0.0005783944091360484,
        "train_loss": 0.00041791427849183004
      },
      {
        "epoch": 2447,
        "reward": 0.6579756140708923,
        "val_loss": 0.0007817328483464994,
        "train_loss": 0.0006932975327869756
      },
      {
        "epoch": 2448,
        "reward": 0.5722805261611938,
        "val_loss": 0.0016160833349983608,
        "train_loss": 0.0006362566222938207
      },
      {
        "epoch": 2449,
        "reward": 0.7340598106384277,
        "val_loss": 0.00037972455694606263,
        "train_loss": 0.0005862537811761006
      },
      {
        "epoch": 2450,
        "reward": 0.638401210308075,
        "val_loss": 0.0009281756688973733,
        "train_loss": 0.00047048333572792425
      },
      {
        "epoch": 2451,
        "reward": 0.6844543218612671,
        "val_loss": 0.0006148926373238542,
        "train_loss": 0.0004264517781568709
      },
      {
        "epoch": 2452,
        "reward": 0.5151415467262268,
        "val_loss": 0.0025629522278904915,
        "train_loss": 0.0007433996529121381
      },
      {
        "epoch": 2453,
        "reward": 0.6580170392990112,
        "val_loss": 0.000781445057197873,
        "train_loss": 0.0009559451522223894
      },
      {
        "epoch": 2454,
        "reward": 0.5890979766845703,
        "val_loss": 0.001407554339883583,
        "train_loss": 0.0005495714520713171
      },
      {
        "epoch": 2455,
        "reward": 0.5730510950088501,
        "val_loss": 0.0016059384381930744,
        "train_loss": 0.0011818747689875846
      },
      {
        "epoch": 2456,
        "reward": 0.6573681831359863,
        "val_loss": 0.0007859623791383845,
        "train_loss": 0.0009440938875531384
      },
      {
        "epoch": 2457,
        "reward": 0.6634595990180969,
        "val_loss": 0.0007444046662255589,
        "train_loss": 0.00046933830610494345
      },
      {
        "epoch": 2458,
        "reward": 0.7053558826446533,
        "val_loss": 0.000504827031233747,
        "train_loss": 0.00043141724591595656
      },
      {
        "epoch": 2459,
        "reward": 0.6656723618507385,
        "val_loss": 0.0007297721292291369,
        "train_loss": 0.00040575862875322433
      },
      {
        "epoch": 2460,
        "reward": 0.7021265625953674,
        "val_loss": 0.000520710733586124,
        "train_loss": 0.0004559763465994575
      },
      {
        "epoch": 2461,
        "reward": 0.6814037561416626,
        "val_loss": 0.000632464187219739,
        "train_loss": 0.0006842617955184183
      },
      {
        "epoch": 2462,
        "reward": 0.6420117020606995,
        "val_loss": 0.000899529957678169,
        "train_loss": 0.0005882788492062201
      },
      {
        "epoch": 2463,
        "reward": 0.46795177459716797,
        "val_loss": 0.0037399292923510075,
        "train_loss": 0.0006464154866989702
      },
      {
        "epoch": 2464,
        "reward": 0.7035159468650818,
        "val_loss": 0.0005138288293632545,
        "train_loss": 0.001734567887839288
      },
      {
        "epoch": 2465,
        "reward": 0.6574209928512573,
        "val_loss": 0.0007855939911678433,
        "train_loss": 0.0006039935598472276
      },
      {
        "epoch": 2466,
        "reward": 0.4488430917263031,
        "val_loss": 0.004362395432378564,
        "train_loss": 0.000495370369977676
      },
      {
        "epoch": 2467,
        "reward": 0.5229557752609253,
        "val_loss": 0.0024074150548715678,
        "train_loss": 0.0023675528310167673
      },
      {
        "epoch": 2468,
        "reward": 0.7085810899734497,
        "val_loss": 0.0004893503417926175,
        "train_loss": 0.000755140344643643
      },
      {
        "epoch": 2469,
        "reward": 0.6573653817176819,
        "val_loss": 0.0007859817539740886,
        "train_loss": 0.0007401712786164493
      },
      {
        "epoch": 2470,
        "reward": 0.6323127746582031,
        "val_loss": 0.000978265647842948,
        "train_loss": 0.0003557694735718542
      },
      {
        "epoch": 2471,
        "reward": 0.7278220653533936,
        "val_loss": 0.00040459341003692577,
        "train_loss": 0.0004521304413524027
      },
      {
        "epoch": 2472,
        "reward": 0.51675945520401,
        "val_loss": 0.0025299591777314034,
        "train_loss": 0.00038836549916035996
      },
      {
        "epoch": 2473,
        "reward": 0.7565588355064392,
        "val_loss": 0.00029954799018534165,
        "train_loss": 0.0017066859805849022
      },
      {
        "epoch": 2474,
        "reward": 0.5716855525970459,
        "val_loss": 0.001623957185074687,
        "train_loss": 0.0005137421092233405
      },
      {
        "epoch": 2475,
        "reward": 0.7407013773918152,
        "val_loss": 0.00035455023836610574,
        "train_loss": 0.0007324978785338596
      },
      {
        "epoch": 2476,
        "reward": 0.7134556174278259,
        "val_loss": 0.000466673743046288,
        "train_loss": 0.0005854358521621459
      },
      {
        "epoch": 2477,
        "reward": 0.6080490350723267,
        "val_loss": 0.001202125642781279,
        "train_loss": 0.0005203719718757874
      },
      {
        "epoch": 2478,
        "reward": 0.652990460395813,
        "val_loss": 0.0008170204486564866,
        "train_loss": 0.0007223224541891026
      },
      {
        "epoch": 2479,
        "reward": 0.6432706713676453,
        "val_loss": 0.0008897208276071719,
        "train_loss": 0.000767539982217176
      },
      {
        "epoch": 2480,
        "reward": 0.7417966723442078,
        "val_loss": 0.00035052383568004837,
        "train_loss": 0.0005491488801243787
      },
      {
        "epoch": 2481,
        "reward": 0.5390433073043823,
        "val_loss": 0.00211561522779188,
        "train_loss": 0.00069968896815016
      },
      {
        "epoch": 2482,
        "reward": 0.6707763075828552,
        "val_loss": 0.000696932289948953,
        "train_loss": 0.0007089821322971637
      },
      {
        "epoch": 2483,
        "reward": 0.6279754638671875,
        "val_loss": 0.0010153633525728115,
        "train_loss": 0.0005558585577930969
      },
      {
        "epoch": 2484,
        "reward": 0.6915292143821716,
        "val_loss": 0.0005756660913383323,
        "train_loss": 0.000761765045284007
      },
      {
        "epoch": 2485,
        "reward": 0.7269411087036133,
        "val_loss": 0.00040820434514898807,
        "train_loss": 0.0003708814866303538
      },
      {
        "epoch": 2486,
        "reward": 0.5597774386405945,
        "val_loss": 0.0017892757563718728,
        "train_loss": 0.00048046496018427063
      },
      {
        "epoch": 2487,
        "reward": 0.690369725227356,
        "val_loss": 0.0005819518784327167,
        "train_loss": 0.0005425066489036768
      },
      {
        "epoch": 2488,
        "reward": 0.6535229682922363,
        "val_loss": 0.0008131874076622937,
        "train_loss": 0.0005418307549776868
      },
      {
        "epoch": 2489,
        "reward": 0.604392945766449,
        "val_loss": 0.001239518917697881,
        "train_loss": 0.0008644010930975827
      },
      {
        "epoch": 2490,
        "reward": 0.6088218092918396,
        "val_loss": 0.0011943525667967541,
        "train_loss": 0.0013295295312463378
      },
      {
        "epoch": 2491,
        "reward": 0.5308145880699158,
        "val_loss": 0.0022603035239236696,
        "train_loss": 0.0008525660859259705
      },
      {
        "epoch": 2492,
        "reward": 0.5294647812843323,
        "val_loss": 0.002284934212054525,
        "train_loss": 0.0013135450225001057
      },
      {
        "epoch": 2493,
        "reward": 0.49753084778785706,
        "val_loss": 0.0029508185107260942,
        "train_loss": 0.0023778038918792913
      },
      {
        "epoch": 2494,
        "reward": 0.6648420691490173,
        "val_loss": 0.0007352343860215374,
        "train_loss": 0.001721176204835746
      },
      {
        "epoch": 2495,
        "reward": 0.7242493033409119,
        "val_loss": 0.0004193928949202278,
        "train_loss": 0.0005610006726503623
      },
      {
        "epoch": 2496,
        "reward": 0.7062250971794128,
        "val_loss": 0.0005006182805768081,
        "train_loss": 0.00037141007935413375
      },
      {
        "epoch": 2497,
        "reward": 0.7454375624656677,
        "val_loss": 0.00033738815026091676,
        "train_loss": 0.0003817318873258885
      },
      {
        "epoch": 2498,
        "reward": 0.7441055178642273,
        "val_loss": 0.0003421501065271774,
        "train_loss": 0.00038001232279874297
      },
      {
        "epoch": 2499,
        "reward": 0.7320860624313354,
        "val_loss": 0.0003874627291224897,
        "train_loss": 0.0003142230226120983
      },
      {
        "epoch": 2500,
        "reward": 0.7371482253074646,
        "val_loss": 0.00036785437883476594,
        "train_loss": 0.000363521887965572
      },
      {
        "epoch": 2501,
        "reward": 0.7558113932609558,
        "val_loss": 0.00030198655856241075,
        "train_loss": 0.0004511097223047937
      },
      {
        "epoch": 2502,
        "reward": 0.7587129473686218,
        "val_loss": 0.0002926017644183178,
        "train_loss": 0.0003218124837233588
      },
      {
        "epoch": 2503,
        "reward": 0.7166515588760376,
        "val_loss": 0.00045226100649285527,
        "train_loss": 0.0004542838074625112
      },
      {
        "epoch": 2504,
        "reward": 0.6192774176597595,
        "val_loss": 0.0010934789232643588,
        "train_loss": 0.0005630516959802032
      },
      {
        "epoch": 2505,
        "reward": 0.7320836782455444,
        "val_loss": 0.00038747220034045834,
        "train_loss": 0.0006843174286097145
      },
      {
        "epoch": 2506,
        "reward": 0.7479332685470581,
        "val_loss": 0.0003286012215539813,
        "train_loss": 0.0005830097036848131
      },
      {
        "epoch": 2507,
        "reward": 0.7220203280448914,
        "val_loss": 0.00042883567428881567,
        "train_loss": 0.00035929945862825174
      },
      {
        "epoch": 2508,
        "reward": 0.7281518578529358,
        "val_loss": 0.000403248260097046,
        "train_loss": 0.00044559504606065905
      },
      {
        "epoch": 2509,
        "reward": 0.68514484167099,
        "val_loss": 0.0006109705885007445,
        "train_loss": 0.0003825807311491539
      },
      {
        "epoch": 2510,
        "reward": 0.5840822458267212,
        "val_loss": 0.00146700199028211,
        "train_loss": 0.0005270717441677474
      },
      {
        "epoch": 2511,
        "reward": 0.702559232711792,
        "val_loss": 0.0005185597068962774,
        "train_loss": 0.0015917512298004183
      },
      {
        "epoch": 2512,
        "reward": 0.7443540692329407,
        "val_loss": 0.00034125739226250777,
        "train_loss": 0.00041940579159507673
      },
      {
        "epoch": 2513,
        "reward": 0.6869092583656311,
        "val_loss": 0.0006010426150169224,
        "train_loss": 0.00046100285320650216
      },
      {
        "epoch": 2514,
        "reward": 0.7425678968429565,
        "val_loss": 0.00034770987362467816,
        "train_loss": 0.0003898571656184056
      },
      {
        "epoch": 2515,
        "reward": 0.7620120644569397,
        "val_loss": 0.0002821952054676201,
        "train_loss": 0.0003461843415817174
      },
      {
        "epoch": 2516,
        "reward": 0.6724081039428711,
        "val_loss": 0.0006866952046818499,
        "train_loss": 0.00040314561808302713
      },
      {
        "epoch": 2517,
        "reward": 0.5996667742729187,
        "val_loss": 0.0012893985424722945,
        "train_loss": 0.00047265656422286364
      },
      {
        "epoch": 2518,
        "reward": 0.7212086319923401,
        "val_loss": 0.00043231542388509424,
        "train_loss": 0.0005479491480680456
      },
      {
        "epoch": 2519,
        "reward": 0.7603396773338318,
        "val_loss": 0.0002874357555161363,
        "train_loss": 0.0003328315287944861
      },
      {
        "epoch": 2520,
        "reward": 0.7437120676040649,
        "val_loss": 0.0003435660556923332,
        "train_loss": 0.00031515630493791273
      },
      {
        "epoch": 2521,
        "reward": 0.7276161313056946,
        "val_loss": 0.0004054356416288231,
        "train_loss": 0.00034698159008537634
      },
      {
        "epoch": 2522,
        "reward": 0.7057546973228455,
        "val_loss": 0.0005028925869347793,
        "train_loss": 0.000353285666103777
      },
      {
        "epoch": 2523,
        "reward": 0.7435005307197571,
        "val_loss": 0.0003443292807787657,
        "train_loss": 0.00047447444991960836
      },
      {
        "epoch": 2524,
        "reward": 0.7367406487464905,
        "val_loss": 0.0003694044384506664,
        "train_loss": 0.0003809473603094095
      },
      {
        "epoch": 2525,
        "reward": 0.7534347772598267,
        "val_loss": 0.00030983898821952086,
        "train_loss": 0.00042950777200390945
      },
      {
        "epoch": 2526,
        "reward": 0.6954616904258728,
        "val_loss": 0.0005547546399092036,
        "train_loss": 0.0003412354505179302
      },
      {
        "epoch": 2527,
        "reward": 0.4865129888057709,
        "val_loss": 0.0032228027204317705,
        "train_loss": 0.0006465524974583576
      },
      {
        "epoch": 2528,
        "reward": 0.6537014842033386,
        "val_loss": 0.0008119062944647989,
        "train_loss": 0.0013994318076304179
      },
      {
        "epoch": 2529,
        "reward": 0.7238578796386719,
        "val_loss": 0.00042103882879018784,
        "train_loss": 0.0004036662770746401
      },
      {
        "epoch": 2530,
        "reward": 0.6564297080039978,
        "val_loss": 0.0007925347641243466,
        "train_loss": 0.0003386510775621551
      },
      {
        "epoch": 2531,
        "reward": 0.7323775887489319,
        "val_loss": 0.0003863122027334092,
        "train_loss": 0.0005668938695005357
      },
      {
        "epoch": 2532,
        "reward": 0.7117414474487305,
        "val_loss": 0.0004745516967627087,
        "train_loss": 0.00041877527858629875
      },
      {
        "epoch": 2533,
        "reward": 0.5056070685386658,
        "val_loss": 0.0027661891986749004,
        "train_loss": 0.0004500758010320939
      },
      {
        "epoch": 2534,
        "reward": 0.7574838995933533,
        "val_loss": 0.0002965501168676253,
        "train_loss": 0.0011446859414438503
      },
      {
        "epoch": 2535,
        "reward": 0.7603470683097839,
        "val_loss": 0.00028741229367109815,
        "train_loss": 0.00035837014169933705
      },
      {
        "epoch": 2536,
        "reward": 0.7495743632316589,
        "val_loss": 0.00032291767170785794,
        "train_loss": 0.00031126906945316406
      },
      {
        "epoch": 2537,
        "reward": 0.5612258315086365,
        "val_loss": 0.0017683601638834392,
        "train_loss": 0.0004895052854688122
      },
      {
        "epoch": 2538,
        "reward": 0.4806865155696869,
        "val_loss": 0.0033767506413693938,
        "train_loss": 0.000831937934540642
      },
      {
        "epoch": 2539,
        "reward": 0.6107028722763062,
        "val_loss": 0.0011756181733549706,
        "train_loss": 0.001270795593042679
      },
      {
        "epoch": 2540,
        "reward": 0.6730623841285706,
        "val_loss": 0.0006826259611573603,
        "train_loss": 0.0003975491671064027
      },
      {
        "epoch": 2541,
        "reward": 0.7464227080345154,
        "val_loss": 0.0003338987776909822,
        "train_loss": 0.0006983591145119414
      },
      {
        "epoch": 2542,
        "reward": 0.7461997866630554,
        "val_loss": 0.0003346860342259918,
        "train_loss": 0.0006297288404871674
      },
      {
        "epoch": 2543,
        "reward": 0.7074036002159119,
        "val_loss": 0.0004949564546612757,
        "train_loss": 0.00038784747504485916
      },
      {
        "epoch": 2544,
        "reward": 0.6255190968513489,
        "val_loss": 0.0010369117371737957,
        "train_loss": 0.0008648730234619087
      },
      {
        "epoch": 2545,
        "reward": 0.5831965804100037,
        "val_loss": 0.0014777337866170065,
        "train_loss": 0.0009426878680712364
      },
      {
        "epoch": 2546,
        "reward": 0.6725545525550842,
        "val_loss": 0.0006857829617469438,
        "train_loss": 0.0006905342497003193
      },
      {
        "epoch": 2547,
        "reward": 0.712510883808136,
        "val_loss": 0.0004710029170382768,
        "train_loss": 0.0004251974975117124
      },
      {
        "epoch": 2548,
        "reward": 0.6453206539154053,
        "val_loss": 0.000873945395661784,
        "train_loss": 0.000555611743038753
      },
      {
        "epoch": 2549,
        "reward": 0.4504588544368744,
        "val_loss": 0.00430579949170351,
        "train_loss": 0.00044217146093545196
      },
      {
        "epoch": 2550,
        "reward": 0.7438398599624634,
        "val_loss": 0.00034310578485019505,
        "train_loss": 0.001976965254401036
      },
      {
        "epoch": 2551,
        "reward": 0.5931849479675293,
        "val_loss": 0.001360747081759785,
        "train_loss": 0.0004477951689085995
      },
      {
        "epoch": 2552,
        "reward": 0.7486891150474548,
        "val_loss": 0.0003259741622189592,
        "train_loss": 0.0008095590371969872
      },
      {
        "epoch": 2553,
        "reward": 0.7634181380271912,
        "val_loss": 0.00027784446345841777,
        "train_loss": 0.0004098299877652013
      },
      {
        "epoch": 2554,
        "reward": 0.6273719668388367,
        "val_loss": 0.0010206209262833,
        "train_loss": 0.0003097536240462572
      },
      {
        "epoch": 2555,
        "reward": 0.7342330813407898,
        "val_loss": 0.000379051044417013,
        "train_loss": 0.00045840800549530494
      },
      {
        "epoch": 2556,
        "reward": 0.6956879496574402,
        "val_loss": 0.0005535706004593521,
        "train_loss": 0.00047280465290756326
      },
      {
        "epoch": 2557,
        "reward": 0.7291561961174011,
        "val_loss": 0.00039917251810298434,
        "train_loss": 0.00032888873211771416
      },
      {
        "epoch": 2558,
        "reward": 0.6755855679512024,
        "val_loss": 0.0006671189330518246,
        "train_loss": 0.00048733859819969017
      },
      {
        "epoch": 2559,
        "reward": 0.7235394716262817,
        "val_loss": 0.00042238194977731576,
        "train_loss": 0.0007830832764739171
      },
      {
        "epoch": 2560,
        "reward": 0.7430799603462219,
        "val_loss": 0.0003458505546274994,
        "train_loss": 0.00037802803014458803
      },
      {
        "epoch": 2561,
        "reward": 0.5987472534179688,
        "val_loss": 0.0012993096107883112,
        "train_loss": 0.00037259937996098486
      },
      {
        "epoch": 2562,
        "reward": 0.5596828460693359,
        "val_loss": 0.0017906509871993745,
        "train_loss": 0.0010650886888529025
      },
      {
        "epoch": 2563,
        "reward": 0.759722113609314,
        "val_loss": 0.0002893889613915235,
        "train_loss": 0.001092133436871406
      },
      {
        "epoch": 2564,
        "reward": 0.7058922052383423,
        "val_loss": 0.000502227115378316,
        "train_loss": 0.00038120445830057946
      },
      {
        "epoch": 2565,
        "reward": 0.6857983469963074,
        "val_loss": 0.0006072784807266933,
        "train_loss": 0.00042812040583857405
      },
      {
        "epoch": 2566,
        "reward": 0.7596395015716553,
        "val_loss": 0.00028965083765797317,
        "train_loss": 0.0004834154068913239
      },
      {
        "epoch": 2567,
        "reward": 0.7600526213645935,
        "val_loss": 0.0002883422670752874,
        "train_loss": 0.0003613277237771119
      },
      {
        "epoch": 2568,
        "reward": 0.552498996257782,
        "val_loss": 0.001897967719872083,
        "train_loss": 0.0003936564949421714
      },
      {
        "epoch": 2569,
        "reward": 0.6600872874259949,
        "val_loss": 0.0007671772494047348,
        "train_loss": 0.0012490280899398315
      },
      {
        "epoch": 2570,
        "reward": 0.7549630999565125,
        "val_loss": 0.0003047723148483783,
        "train_loss": 0.000378937419065131
      },
      {
        "epoch": 2571,
        "reward": 0.7477245926856995,
        "val_loss": 0.00032932933286896775,
        "train_loss": 0.0003007306871635452
      },
      {
        "epoch": 2572,
        "reward": 0.5187729597091675,
        "val_loss": 0.0024894830671006014,
        "train_loss": 0.00034609329528533493
      },
      {
        "epoch": 2573,
        "reward": 0.519176185131073,
        "val_loss": 0.0024814544428539064,
        "train_loss": 0.001155520240270282
      },
      {
        "epoch": 2574,
        "reward": 0.7048644423484802,
        "val_loss": 0.0005072190251667053,
        "train_loss": 0.0008862879750757621
      },
      {
        "epoch": 2575,
        "reward": 0.7032322287559509,
        "val_loss": 0.0005152283743622579,
        "train_loss": 0.0005025069471090459
      },
      {
        "epoch": 2576,
        "reward": 0.48891329765319824,
        "val_loss": 0.0031614701064037426,
        "train_loss": 0.0006468535362868211
      },
      {
        "epoch": 2577,
        "reward": 0.7644625306129456,
        "val_loss": 0.0002746446157938668,
        "train_loss": 0.0021125596103956923
      },
      {
        "epoch": 2578,
        "reward": 0.7673137784004211,
        "val_loss": 0.00026604734427694766,
        "train_loss": 0.0003028951323358342
      },
      {
        "epoch": 2579,
        "reward": 0.7533535361289978,
        "val_loss": 0.00031011030244241865,
        "train_loss": 0.00030050471230844356
      },
      {
        "epoch": 2580,
        "reward": 0.7628995180130005,
        "val_loss": 0.00027944365034012923,
        "train_loss": 0.0002977379860497492
      },
      {
        "epoch": 2581,
        "reward": 0.5689375996589661,
        "val_loss": 0.0016607893630862236,
        "train_loss": 0.00035128548971932527
      },
      {
        "epoch": 2582,
        "reward": 0.7492069602012634,
        "val_loss": 0.00032418357191740403,
        "train_loss": 0.0012889907766643423
      },
      {
        "epoch": 2583,
        "reward": 0.7418742775917053,
        "val_loss": 0.00035023968458907414,
        "train_loss": 0.00031977579996687557
      },
      {
        "epoch": 2584,
        "reward": 0.7311525344848633,
        "val_loss": 0.0003911647779334869,
        "train_loss": 0.00039494854270462663
      },
      {
        "epoch": 2585,
        "reward": 0.6915758848190308,
        "val_loss": 0.0005754142600510802,
        "train_loss": 0.00039376724117363873
      },
      {
        "epoch": 2586,
        "reward": 0.7654789686203003,
        "val_loss": 0.00027155689479384037,
        "train_loss": 0.0004365361847493869
      },
      {
        "epoch": 2587,
        "reward": 0.5705281496047974,
        "val_loss": 0.0016393777914345264,
        "train_loss": 0.00029317718760397
      },
      {
        "epoch": 2588,
        "reward": 0.7650956511497498,
        "val_loss": 0.00027271831017320177,
        "train_loss": 0.0007254823559868293
      },
      {
        "epoch": 2589,
        "reward": 0.7553750872612,
        "val_loss": 0.0003034171511119764,
        "train_loss": 0.0003226504290453774
      },
      {
        "epoch": 2590,
        "reward": 0.7559558749198914,
        "val_loss": 0.000301513951853849,
        "train_loss": 0.0003557454538255255
      },
      {
        "epoch": 2591,
        "reward": 0.7099489569664001,
        "val_loss": 0.00048290100364413647,
        "train_loss": 0.0003833035113460098
      },
      {
        "epoch": 2592,
        "reward": 0.5233204364776611,
        "val_loss": 0.002400387610707964,
        "train_loss": 0.00044259878240364534
      },
      {
        "epoch": 2593,
        "reward": 0.6945452094078064,
        "val_loss": 0.000559572471372251,
        "train_loss": 0.0008837501473653202
      },
      {
        "epoch": 2594,
        "reward": 0.7293672561645508,
        "val_loss": 0.0003983195929322392,
        "train_loss": 0.00039459502715124894
      },
      {
        "epoch": 2595,
        "reward": 0.6726749539375305,
        "val_loss": 0.0006850329976129745,
        "train_loss": 0.00038558945995576394
      },
      {
        "epoch": 2596,
        "reward": 0.7383276224136353,
        "val_loss": 0.00036339685071392784,
        "train_loss": 0.0004022876427580531
      },
      {
        "epoch": 2597,
        "reward": 0.7313708662986755,
        "val_loss": 0.00039029644852104994,
        "train_loss": 0.00030133204304897494
      },
      {
        "epoch": 2598,
        "reward": 0.6312035322189331,
        "val_loss": 0.000987639301456511,
        "train_loss": 0.000359338229687777
      },
      {
        "epoch": 2599,
        "reward": 0.7446209788322449,
        "val_loss": 0.00034030114641479613,
        "train_loss": 0.0006656355578273248
      },
      {
        "epoch": 2600,
        "reward": 0.7429192662239075,
        "val_loss": 0.00034643303661141545,
        "train_loss": 0.0004126441971703361
      },
      {
        "epoch": 2601,
        "reward": 0.7415658235549927,
        "val_loss": 0.0003513696574373171,
        "train_loss": 0.00029704613832738966
      },
      {
        "epoch": 2602,
        "reward": 0.6541134715080261,
        "val_loss": 0.0008089555028293814,
        "train_loss": 0.00042993611042710167
      },
      {
        "epoch": 2603,
        "reward": 0.6795519590377808,
        "val_loss": 0.0006433298487016666,
        "train_loss": 0.0005483072589133651
      },
      {
        "epoch": 2604,
        "reward": 0.7528254389762878,
        "val_loss": 0.0003118762043803664,
        "train_loss": 0.0004360072373926344
      },
      {
        "epoch": 2605,
        "reward": 0.7345672249794006,
        "val_loss": 0.0003777543960105894,
        "train_loss": 0.00038340982344100036
      },
      {
        "epoch": 2606,
        "reward": 0.7155175805091858,
        "val_loss": 0.0004573347229909684,
        "train_loss": 0.00030293708047023614
      },
      {
        "epoch": 2607,
        "reward": 0.6880357265472412,
        "val_loss": 0.0005947733048482665,
        "train_loss": 0.0005249624888305194
      },
      {
        "epoch": 2608,
        "reward": 0.7688421607017517,
        "val_loss": 0.0002615210957758661,
        "train_loss": 0.00045118866658482986
      },
      {
        "epoch": 2609,
        "reward": 0.7029769420623779,
        "val_loss": 0.0005164898216857442,
        "train_loss": 0.00039110410860023246
      },
      {
        "epoch": 2610,
        "reward": 0.7586590051651001,
        "val_loss": 0.000292774142248423,
        "train_loss": 0.00038736160786356777
      },
      {
        "epoch": 2611,
        "reward": 0.7444503307342529,
        "val_loss": 0.0003409122333063611,
        "train_loss": 0.0003507315122988075
      },
      {
        "epoch": 2612,
        "reward": 0.7052521109580994,
        "val_loss": 0.0005053312966733106,
        "train_loss": 0.0004320921815143755
      },
      {
        "epoch": 2613,
        "reward": 0.7506169676780701,
        "val_loss": 0.0003193453573788117,
        "train_loss": 0.000684806969589912
      },
      {
        "epoch": 2614,
        "reward": 0.7534171938896179,
        "val_loss": 0.0003098976594628766,
        "train_loss": 0.0003499559064109165
      },
      {
        "epoch": 2615,
        "reward": 0.7111762166023254,
        "val_loss": 0.0004771721391339919,
        "train_loss": 0.000337312605831987
      },
      {
        "epoch": 2616,
        "reward": 0.5396175980567932,
        "val_loss": 0.0021058567300704972,
        "train_loss": 0.0003908565855593994
      },
      {
        "epoch": 2617,
        "reward": 0.7186548113822937,
        "val_loss": 0.0004434065236377397,
        "train_loss": 0.0012649816422848604
      },
      {
        "epoch": 2618,
        "reward": 0.7227090001106262,
        "val_loss": 0.0004259004157834819,
        "train_loss": 0.000314649399884869
      },
      {
        "epoch": 2619,
        "reward": 0.7436864972114563,
        "val_loss": 0.0003436582171291645,
        "train_loss": 0.000341570029027375
      },
      {
        "epoch": 2620,
        "reward": 0.66044682264328,
        "val_loss": 0.0007647219213790127,
        "train_loss": 0.0003406018659006804
      },
      {
        "epoch": 2621,
        "reward": 0.7450451850891113,
        "val_loss": 0.0003387855062361008,
        "train_loss": 0.0004491519422957096
      },
      {
        "epoch": 2622,
        "reward": 0.6146025657653809,
        "val_loss": 0.0011376078639711653,
        "train_loss": 0.00041525780006150645
      },
      {
        "epoch": 2623,
        "reward": 0.7686614394187927,
        "val_loss": 0.00026205332999649854,
        "train_loss": 0.0005766621377635881
      },
      {
        "epoch": 2624,
        "reward": 0.7463001012802124,
        "val_loss": 0.00033433141444610167,
        "train_loss": 0.000282180422240904
      },
      {
        "epoch": 2625,
        "reward": 0.6938614249229431,
        "val_loss": 0.0005631890505485769,
        "train_loss": 0.00031585057149641216
      },
      {
        "epoch": 2626,
        "reward": 0.7069148421287537,
        "val_loss": 0.0004972983068520469,
        "train_loss": 0.00037325929476467607
      },
      {
        "epoch": 2627,
        "reward": 0.7683879733085632,
        "val_loss": 0.0002628599925498877,
        "train_loss": 0.00035489360687699024
      },
      {
        "epoch": 2628,
        "reward": 0.6984590888023376,
        "val_loss": 0.0005392301619784641,
        "train_loss": 0.00033277551315572613
      },
      {
        "epoch": 2629,
        "reward": 0.7053953409194946,
        "val_loss": 0.0005046355654485524,
        "train_loss": 0.0004183200877518035
      },
      {
        "epoch": 2630,
        "reward": 0.7066218852996826,
        "val_loss": 0.0004987062545426722,
        "train_loss": 0.0004427851353494379
      },
      {
        "epoch": 2631,
        "reward": 0.6904953122138977,
        "val_loss": 0.0005812682377706681,
        "train_loss": 0.0004280212776323494
      },
      {
        "epoch": 2632,
        "reward": 0.7550989389419556,
        "val_loss": 0.0003043248684012464,
        "train_loss": 0.00037353757383803336
      },
      {
        "epoch": 2633,
        "reward": 0.7119958996772766,
        "val_loss": 0.0004733759311160871,
        "train_loss": 0.00030441858689300716
      },
      {
        "epoch": 2634,
        "reward": 0.713650643825531,
        "val_loss": 0.00046578449213744273,
        "train_loss": 0.000386901217727707
      },
      {
        "epoch": 2635,
        "reward": 0.7510706782341003,
        "val_loss": 0.00031780021838910343,
        "train_loss": 0.0004754948447673367
      },
      {
        "epoch": 2636,
        "reward": 0.698724091053009,
        "val_loss": 0.0005378745097134795,
        "train_loss": 0.00039974616083782166
      },
      {
        "epoch": 2637,
        "reward": 0.7367510199546814,
        "val_loss": 0.0003693651482795498,
        "train_loss": 0.00048357629678391205
      },
      {
        "epoch": 2638,
        "reward": 0.7565266489982605,
        "val_loss": 0.00029965285752301237,
        "train_loss": 0.00042842924057577667
      },
      {
        "epoch": 2639,
        "reward": 0.6545974612236023,
        "val_loss": 0.0008055004707005407,
        "train_loss": 0.0003659806204198573
      },
      {
        "epoch": 2640,
        "reward": 0.7533851265907288,
        "val_loss": 0.0003100044933879482,
        "train_loss": 0.0004209983510288741
      },
      {
        "epoch": 2641,
        "reward": 0.7329131960868835,
        "val_loss": 0.00038420552196579853,
        "train_loss": 0.00031890440628173493
      },
      {
        "epoch": 2642,
        "reward": 0.7472200393676758,
        "val_loss": 0.00033109426606513025,
        "train_loss": 0.00034221842083052953
      },
      {
        "epoch": 2643,
        "reward": 0.7425777316093445,
        "val_loss": 0.00034767401770555547,
        "train_loss": 0.0003070210183907945
      },
      {
        "epoch": 2644,
        "reward": 0.7596872448921204,
        "val_loss": 0.0002894993667723611,
        "train_loss": 0.00034530337031285925
      },
      {
        "epoch": 2645,
        "reward": 0.7134739756584167,
        "val_loss": 0.0004665900321145143,
        "train_loss": 0.0002935307996206295
      },
      {
        "epoch": 2646,
        "reward": 0.752807080745697,
        "val_loss": 0.00031193820177577436,
        "train_loss": 0.00042356583337375644
      },
      {
        "epoch": 2647,
        "reward": 0.763631284236908,
        "val_loss": 0.00027718931960407645,
        "train_loss": 0.0003016512112949954
      },
      {
        "epoch": 2648,
        "reward": 0.7215971350669861,
        "val_loss": 0.0004306472775559606,
        "train_loss": 0.00028359661519061774
      },
      {
        "epoch": 2649,
        "reward": 0.7350367307662964,
        "val_loss": 0.00037593879304560166,
        "train_loss": 0.0003888296249407666
      },
      {
        "epoch": 2650,
        "reward": 0.6906954646110535,
        "val_loss": 0.0005801808064071727,
        "train_loss": 0.0003866791126807374
      },
      {
        "epoch": 2651,
        "reward": 0.6881279945373535,
        "val_loss": 0.0005942621085393642,
        "train_loss": 0.00034635337103211967
      },
      {
        "epoch": 2652,
        "reward": 0.7480512261390686,
        "val_loss": 0.0003281900592680488,
        "train_loss": 0.00048333995216755563
      },
      {
        "epoch": 2653,
        "reward": 0.763654887676239,
        "val_loss": 0.0002771164831106684,
        "train_loss": 0.00042992363020088163
      },
      {
        "epoch": 2654,
        "reward": 0.7179887294769287,
        "val_loss": 0.0004463353709849928,
        "train_loss": 0.0003545069831978673
      },
      {
        "epoch": 2655,
        "reward": 0.7093589901924133,
        "val_loss": 0.0004856743367521891,
        "train_loss": 0.0003328448387597186
      },
      {
        "epoch": 2656,
        "reward": 0.5042740106582642,
        "val_loss": 0.0027958505254771027,
        "train_loss": 0.0004162963596172631
      },
      {
        "epoch": 2657,
        "reward": 0.7458788752555847,
        "val_loss": 0.00033582141830785465,
        "train_loss": 0.00143211329801191
      },
      {
        "epoch": 2658,
        "reward": 0.6208986639976501,
        "val_loss": 0.0010785319360106119,
        "train_loss": 0.00032186942441442696
      },
      {
        "epoch": 2659,
        "reward": 0.7489362359046936,
        "val_loss": 0.00032511896071290333,
        "train_loss": 0.0005926959806506952
      },
      {
        "epoch": 2660,
        "reward": 0.7074364423751831,
        "val_loss": 0.0004947993646575404,
        "train_loss": 0.00035545492014185025
      },
      {
        "epoch": 2661,
        "reward": 0.5967609882354736,
        "val_loss": 0.001320954761467874,
        "train_loss": 0.00042190843109542935
      },
      {
        "epoch": 2662,
        "reward": 0.6953045725822449,
        "val_loss": 0.0005555785776648138,
        "train_loss": 0.0009502378122236293
      },
      {
        "epoch": 2663,
        "reward": 0.7449954748153687,
        "val_loss": 0.0003389628046923982,
        "train_loss": 0.00036356647923149954
      },
      {
        "epoch": 2664,
        "reward": 0.734358012676239,
        "val_loss": 0.00037856582327679334,
        "train_loss": 0.0003397515079436394
      },
      {
        "epoch": 2665,
        "reward": 0.6805338859558105,
        "val_loss": 0.0006375490920618176,
        "train_loss": 0.0004984455818675298
      },
      {
        "epoch": 2666,
        "reward": 0.709086000919342,
        "val_loss": 0.0004869619359461857,
        "train_loss": 0.00045083629298950167
      },
      {
        "epoch": 2667,
        "reward": 0.7111825346946716,
        "val_loss": 0.00047714272763447037,
        "train_loss": 0.0004056116326515061
      },
      {
        "epoch": 2668,
        "reward": 0.6504375338554382,
        "val_loss": 0.000835607194208673,
        "train_loss": 0.0004663711426491528
      },
      {
        "epoch": 2669,
        "reward": 0.666532039642334,
        "val_loss": 0.0007241522336179125,
        "train_loss": 0.0005164106828138196
      },
      {
        "epoch": 2670,
        "reward": 0.7606054544448853,
        "val_loss": 0.0002865981389602114,
        "train_loss": 0.0004720269950597028
      },
      {
        "epoch": 2671,
        "reward": 0.7476828694343567,
        "val_loss": 0.00032947495596350303,
        "train_loss": 0.00029848740982393234
      },
      {
        "epoch": 2672,
        "reward": 0.6927744746208191,
        "val_loss": 0.0005689765966963023,
        "train_loss": 0.00032039903229675616
      },
      {
        "epoch": 2673,
        "reward": 0.7177897691726685,
        "val_loss": 0.00044721328387303013,
        "train_loss": 0.000437347473052796
      },
      {
        "epoch": 2674,
        "reward": 0.7426096796989441,
        "val_loss": 0.000347557758297106,
        "train_loss": 0.000456233488176412
      },
      {
        "epoch": 2675,
        "reward": 0.7668453454971313,
        "val_loss": 0.00026744618662633,
        "train_loss": 0.00036258202789422986
      },
      {
        "epoch": 2676,
        "reward": 0.7665577530860901,
        "val_loss": 0.0002683074354925858,
        "train_loss": 0.00028295108215668454
      },
      {
        "epoch": 2677,
        "reward": 0.730186402797699,
        "val_loss": 0.00039502401653278085,
        "train_loss": 0.0002984400469953331
      },
      {
        "epoch": 2678,
        "reward": 0.750093936920166,
        "val_loss": 0.0003211338314161237,
        "train_loss": 0.0003129731695445606
      },
      {
        "epoch": 2679,
        "reward": 0.7236127853393555,
        "val_loss": 0.0004220726259518415,
        "train_loss": 0.0002865261743024278
      },
      {
        "epoch": 2680,
        "reward": 0.7153601050376892,
        "val_loss": 0.00045804266119375825,
        "train_loss": 0.0003319104235314486
      },
      {
        "epoch": 2681,
        "reward": 0.735068678855896,
        "val_loss": 0.00037581546556404125,
        "train_loss": 0.0002977560786978127
      },
      {
        "epoch": 2682,
        "reward": 0.7169205546379089,
        "val_loss": 0.00045106448981511803,
        "train_loss": 0.00034364684688625857
      },
      {
        "epoch": 2683,
        "reward": 0.6940817832946777,
        "val_loss": 0.0005620218497434897,
        "train_loss": 0.0003711253022909379
      },
      {
        "epoch": 2684,
        "reward": 0.7111040949821472,
        "val_loss": 0.00047750735289550254,
        "train_loss": 0.000450172497356614
      },
      {
        "epoch": 2685,
        "reward": 0.7704693675041199,
        "val_loss": 0.00025676426386261094,
        "train_loss": 0.0003355000153533183
      },
      {
        "epoch": 2686,
        "reward": 0.7620447278022766,
        "val_loss": 0.00028209370170121213,
        "train_loss": 0.0004138415763288951
      },
      {
        "epoch": 2687,
        "reward": 0.6334022283554077,
        "val_loss": 0.0009691348033291953,
        "train_loss": 0.0004159688396612182
      },
      {
        "epoch": 2688,
        "reward": 0.7004061341285706,
        "val_loss": 0.0005293340904505125,
        "train_loss": 0.00038126315652894287
      },
      {
        "epoch": 2689,
        "reward": 0.7194293737411499,
        "val_loss": 0.000440019482214536,
        "train_loss": 0.0004045845616929
      },
      {
        "epoch": 2690,
        "reward": 0.7229189276695251,
        "val_loss": 0.0004250092980717974,
        "train_loss": 0.00034006357544477884
      },
      {
        "epoch": 2691,
        "reward": 0.7713677287101746,
        "val_loss": 0.00025416495087223927,
        "train_loss": 0.0002954824124642003
      },
      {
        "epoch": 2692,
        "reward": 0.7592021226882935,
        "val_loss": 0.0002910409717255139,
        "train_loss": 0.00027328538103924634
      },
      {
        "epoch": 2693,
        "reward": 0.6858171224594116,
        "val_loss": 0.0006071723141108773,
        "train_loss": 0.0003274212560007492
      },
      {
        "epoch": 2694,
        "reward": 0.7683924436569214,
        "val_loss": 0.00026284699145305367,
        "train_loss": 0.0004265845334605099
      },
      {
        "epoch": 2695,
        "reward": 0.7333714365959167,
        "val_loss": 0.0003824097428670419,
        "train_loss": 0.00027220112902936165
      },
      {
        "epoch": 2696,
        "reward": 0.698070228099823,
        "val_loss": 0.0005412244395951607,
        "train_loss": 0.0003429955132350397
      },
      {
        "epoch": 2697,
        "reward": 0.7275584936141968,
        "val_loss": 0.00040567160717078617,
        "train_loss": 0.00038507371209561825
      },
      {
        "epoch": 2698,
        "reward": 0.722598671913147,
        "val_loss": 0.00042636971920728683,
        "train_loss": 0.0003295955695928289
      },
      {
        "epoch": 2699,
        "reward": 0.771988570690155,
        "val_loss": 0.0002523801023406642,
        "train_loss": 0.0004188777300162026
      },
      {
        "epoch": 2700,
        "reward": 0.7591260075569153,
        "val_loss": 0.0002912833442678675,
        "train_loss": 0.0004048294784017624
      },
      {
        "epoch": 2701,
        "reward": 0.7447791695594788,
        "val_loss": 0.00033973518709119944,
        "train_loss": 0.00039463529537897557
      },
      {
        "epoch": 2702,
        "reward": 0.7681219577789307,
        "val_loss": 0.0002636467605563147,
        "train_loss": 0.00030066458734486683
      },
      {
        "epoch": 2703,
        "reward": 0.6879526972770691,
        "val_loss": 0.0005952334779846881,
        "train_loss": 0.0002868976807803847
      },
      {
        "epoch": 2704,
        "reward": 0.7473601698875427,
        "val_loss": 0.00033060328860301524,
        "train_loss": 0.00039519047081389895
      },
      {
        "epoch": 2705,
        "reward": 0.7356327176094055,
        "val_loss": 0.00037364326167984733,
        "train_loss": 0.0003141498746117577
      },
      {
        "epoch": 2706,
        "reward": 0.7660568952560425,
        "val_loss": 0.000269812550478881,
        "train_loss": 0.0003401622960574549
      },
      {
        "epoch": 2707,
        "reward": 0.7446560263633728,
        "val_loss": 0.000340175602884431,
        "train_loss": 0.00030533796682273253
      },
      {
        "epoch": 2708,
        "reward": 0.7003297209739685,
        "val_loss": 0.0005297193170658179,
        "train_loss": 0.0004402644559517145
      },
      {
        "epoch": 2709,
        "reward": 0.7656168341636658,
        "val_loss": 0.0002711399533187172,
        "train_loss": 0.0006003946742007079
      },
      {
        "epoch": 2710,
        "reward": 0.7299931049346924,
        "val_loss": 0.0003957999953334885,
        "train_loss": 0.00028051078936641716
      },
      {
        "epoch": 2711,
        "reward": 0.7531940340995789,
        "val_loss": 0.0003106429025397769,
        "train_loss": 0.0003154708759281605
      },
      {
        "epoch": 2712,
        "reward": 0.7606751322746277,
        "val_loss": 0.0002863788519919451,
        "train_loss": 0.00030586404787195183
      },
      {
        "epoch": 2713,
        "reward": 0.7112261652946472,
        "val_loss": 0.00047693989888232736,
        "train_loss": 0.0002966052096990797
      },
      {
        "epoch": 2714,
        "reward": 0.7695303559303284,
        "val_loss": 0.00025950142506709587,
        "train_loss": 0.00036054475136692275
      },
      {
        "epoch": 2715,
        "reward": 0.770638644695282,
        "val_loss": 0.0002562728789468695,
        "train_loss": 0.00029948372747849836
      },
      {
        "epoch": 2716,
        "reward": 0.7664806842803955,
        "val_loss": 0.00026853856148331294,
        "train_loss": 0.00028157447251522593
      },
      {
        "epoch": 2717,
        "reward": 0.7671929001808167,
        "val_loss": 0.00026640770374797285,
        "train_loss": 0.00029332974708477897
      },
      {
        "epoch": 2718,
        "reward": 0.7512490153312683,
        "val_loss": 0.00031719446165620217,
        "train_loss": 0.00030943970649297204
      },
      {
        "epoch": 2719,
        "reward": 0.7717908620834351,
        "val_loss": 0.00025294761040381024,
        "train_loss": 0.00028180520649374765
      },
      {
        "epoch": 2720,
        "reward": 0.720491886138916,
        "val_loss": 0.00043540564781453995,
        "train_loss": 0.00027285811235672625
      },
      {
        "epoch": 2721,
        "reward": 0.6143368482589722,
        "val_loss": 0.001140162947454623,
        "train_loss": 0.0003308192625319442
      },
      {
        "epoch": 2722,
        "reward": 0.6815363764762878,
        "val_loss": 0.0006316919669708503,
        "train_loss": 0.0006160971130996656
      },
      {
        "epoch": 2723,
        "reward": 0.7725914120674133,
        "val_loss": 0.00025065571493801793,
        "train_loss": 0.0004627568433695964
      },
      {
        "epoch": 2724,
        "reward": 0.7394465208053589,
        "val_loss": 0.0003592062151126031,
        "train_loss": 0.0002814119512689873
      },
      {
        "epoch": 2725,
        "reward": 0.7606406211853027,
        "val_loss": 0.00028648751530064534,
        "train_loss": 0.00043284711920512986
      },
      {
        "epoch": 2726,
        "reward": 0.6719496250152588,
        "val_loss": 0.0006895586598797568,
        "train_loss": 0.0005002866564347222
      },
      {
        "epoch": 2727,
        "reward": 0.7587682604789734,
        "val_loss": 0.00029242476947339516,
        "train_loss": 0.000412297447418006
      },
      {
        "epoch": 2728,
        "reward": 0.7587217092514038,
        "val_loss": 0.00029257363556618135,
        "train_loss": 0.0003242143709660293
      },
      {
        "epoch": 2729,
        "reward": 0.7461883425712585,
        "val_loss": 0.00033472630145427374,
        "train_loss": 0.0003636823329053676
      },
      {
        "epoch": 2730,
        "reward": 0.7542614340782166,
        "val_loss": 0.00030709067816912593,
        "train_loss": 0.0005679084581340878
      },
      {
        "epoch": 2731,
        "reward": 0.5688939094543457,
        "val_loss": 0.0016613817008744394,
        "train_loss": 0.00037714151123789354
      },
      {
        "epoch": 2732,
        "reward": 0.7354688048362732,
        "val_loss": 0.0003742735051283879,
        "train_loss": 0.0010078048067393515
      },
      {
        "epoch": 2733,
        "reward": 0.7411958575248718,
        "val_loss": 0.00035272829700261354,
        "train_loss": 0.00036640279666663933
      },
      {
        "epoch": 2734,
        "reward": 0.7429052591323853,
        "val_loss": 0.00034648414709538756,
        "train_loss": 0.00039282589065036376
      },
      {
        "epoch": 2735,
        "reward": 0.7119492888450623,
        "val_loss": 0.0004735911206807941,
        "train_loss": 0.00030430372448091267
      },
      {
        "epoch": 2736,
        "reward": 0.7395524382591248,
        "val_loss": 0.00035881143828321783,
        "train_loss": 0.0003976705668789621
      },
      {
        "epoch": 2737,
        "reward": 0.7572625875473022,
        "val_loss": 0.00029726534350109953,
        "train_loss": 0.0003460429646880724
      },
      {
        "epoch": 2738,
        "reward": 0.628638505935669,
        "val_loss": 0.0010096139906506454,
        "train_loss": 0.00035243160024177854
      },
      {
        "epoch": 2739,
        "reward": 0.6888063549995422,
        "val_loss": 0.0005905150277872703,
        "train_loss": 0.0014534742266942675
      },
      {
        "epoch": 2740,
        "reward": 0.7453395128250122,
        "val_loss": 0.00033773692432857515,
        "train_loss": 0.0004567977935389186
      },
      {
        "epoch": 2741,
        "reward": 0.7555949687957764,
        "val_loss": 0.00030269520149366666,
        "train_loss": 0.0003267796568812068
      },
      {
        "epoch": 2742,
        "reward": 0.7726537585258484,
        "val_loss": 0.0002504778510358717,
        "train_loss": 0.00031822765259466204
      },
      {
        "epoch": 2743,
        "reward": 0.769262969493866,
        "val_loss": 0.0002602847359542336,
        "train_loss": 0.000285874402974374
      },
      {
        "epoch": 2744,
        "reward": 0.7078561782836914,
        "val_loss": 0.0004927959068611797,
        "train_loss": 0.0003035460456605786
      },
      {
        "epoch": 2745,
        "reward": 0.7527310252189636,
        "val_loss": 0.000312192876923031,
        "train_loss": 0.00037134540896379174
      },
      {
        "epoch": 2746,
        "reward": 0.7627561688423157,
        "val_loss": 0.00027988657322047014,
        "train_loss": 0.00036270456061734317
      },
      {
        "epoch": 2747,
        "reward": 0.7646088004112244,
        "val_loss": 0.0002741988760785067,
        "train_loss": 0.000305980458506383
      },
      {
        "epoch": 2748,
        "reward": 0.7055068612098694,
        "val_loss": 0.0005040938600099512,
        "train_loss": 0.0003145404776800066
      },
      {
        "epoch": 2749,
        "reward": 0.6822664141654968,
        "val_loss": 0.0006274538962835712,
        "train_loss": 0.0005102822077997888
      },
      {
        "epoch": 2750,
        "reward": 0.6588128805160522,
        "val_loss": 0.0007759341388009489,
        "train_loss": 0.000467249966347411
      },
      {
        "epoch": 2751,
        "reward": 0.7231137752532959,
        "val_loss": 0.00042418275344451625,
        "train_loss": 0.0006505102915420699
      },
      {
        "epoch": 2752,
        "reward": 0.7413078546524048,
        "val_loss": 0.00035231667321308384,
        "train_loss": 0.00029907438885000095
      },
      {
        "epoch": 2753,
        "reward": 0.7655784487724304,
        "val_loss": 0.00027125614412528066,
        "train_loss": 0.00036237636343755113
      },
      {
        "epoch": 2754,
        "reward": 0.7092565298080444,
        "val_loss": 0.00048615745618008077,
        "train_loss": 0.00042710505266978335
      },
      {
        "epoch": 2755,
        "reward": 0.7724114060401917,
        "val_loss": 0.000251169825787656,
        "train_loss": 0.00046534244700943906
      },
      {
        "epoch": 2756,
        "reward": 0.7658340930938721,
        "val_loss": 0.00027048386566873105,
        "train_loss": 0.00031130855243715743
      },
      {
        "epoch": 2757,
        "reward": 0.771737277507782,
        "val_loss": 0.00025310145325160453,
        "train_loss": 0.00028759058645496576
      },
      {
        "epoch": 2758,
        "reward": 0.7585400938987732,
        "val_loss": 0.0002931542881664687,
        "train_loss": 0.00028635911775591713
      },
      {
        "epoch": 2759,
        "reward": 0.7617100477218628,
        "val_loss": 0.00028313648155225176,
        "train_loss": 0.000264565173088508
      },
      {
        "epoch": 2760,
        "reward": 0.7729244828224182,
        "val_loss": 0.0002497068282017218,
        "train_loss": 0.00029131298511996505
      },
      {
        "epoch": 2761,
        "reward": 0.7696067690849304,
        "val_loss": 0.0002592778390473021,
        "train_loss": 0.00027057147179640684
      },
      {
        "epoch": 2762,
        "reward": 0.7575216293334961,
        "val_loss": 0.0002964282175526023,
        "train_loss": 0.0002742970630676539
      },
      {
        "epoch": 2763,
        "reward": 0.7700405716896057,
        "val_loss": 0.00025801139002266737,
        "train_loss": 0.00030112344393273816
      },
      {
        "epoch": 2764,
        "reward": 0.7332615256309509,
        "val_loss": 0.0003828399764773037,
        "train_loss": 0.0002962584067762901
      },
      {
        "epoch": 2765,
        "reward": 0.7677406668663025,
        "val_loss": 0.00026477737992536277,
        "train_loss": 0.00037041474850131915
      },
      {
        "epoch": 2766,
        "reward": 0.7598555684089661,
        "val_loss": 0.0002889659621619752,
        "train_loss": 0.00039173493860289454
      },
      {
        "epoch": 2767,
        "reward": 0.7666003704071045,
        "val_loss": 0.000268179748672992,
        "train_loss": 0.00029934275517007336
      },
      {
        "epoch": 2768,
        "reward": 0.7684394717216492,
        "val_loss": 0.0002627081017375791,
        "train_loss": 0.00029054890970096143
      },
      {
        "epoch": 2769,
        "reward": 0.7715627551078796,
        "val_loss": 0.0002536032594174945,
        "train_loss": 0.0002875108072587934
      },
      {
        "epoch": 2770,
        "reward": 0.6969875693321228,
        "val_loss": 0.0005468076976415302,
        "train_loss": 0.00027573444206679525
      },
      {
        "epoch": 2771,
        "reward": 0.7727242112159729,
        "val_loss": 0.00025027693897884874,
        "train_loss": 0.00037816935162901733
      },
      {
        "epoch": 2772,
        "reward": 0.7719801068305969,
        "val_loss": 0.00025240426267763335,
        "train_loss": 0.0002951736381734148
      },
      {
        "epoch": 2773,
        "reward": 0.7735880613327026,
        "val_loss": 0.00024782357546168247,
        "train_loss": 0.0003005805086174335
      },
      {
        "epoch": 2774,
        "reward": 0.7302297949790955,
        "val_loss": 0.00039485043297255676,
        "train_loss": 0.0003238453427911736
      },
      {
        "epoch": 2775,
        "reward": 0.7661218047142029,
        "val_loss": 0.0002696171535977295,
        "train_loss": 0.00043432736688723357
      },
      {
        "epoch": 2776,
        "reward": 0.7596611380577087,
        "val_loss": 0.0002895822253776714,
        "train_loss": 0.0003763824995705643
      },
      {
        "epoch": 2777,
        "reward": 0.7618765830993652,
        "val_loss": 0.00028261722764000297,
        "train_loss": 0.0002863308064451513
      },
      {
        "epoch": 2778,
        "reward": 0.7594131827354431,
        "val_loss": 0.0002903695359626519,
        "train_loss": 0.0003065816140756047
      },
      {
        "epoch": 2779,
        "reward": 0.7673475742340088,
        "val_loss": 0.0002659466471024124,
        "train_loss": 0.00028999273378688557
      },
      {
        "epoch": 2780,
        "reward": 0.7445268034934998,
        "val_loss": 0.0003406383122117924,
        "train_loss": 0.00029640168773207383
      },
      {
        "epoch": 2781,
        "reward": 0.7317041754722595,
        "val_loss": 0.00038897386860168936,
        "train_loss": 0.0003636657732456045
      },
      {
        "epoch": 2782,
        "reward": 0.7707351446151733,
        "val_loss": 0.0002559931682688849,
        "train_loss": 0.00030898122685567406
      },
      {
        "epoch": 2783,
        "reward": 0.7653177976608276,
        "val_loss": 0.00027204484961527797,
        "train_loss": 0.00025928999324465764
      },
      {
        "epoch": 2784,
        "reward": 0.7725514769554138,
        "val_loss": 0.00025076971464191696,
        "train_loss": 0.00026157017982068984
      },
      {
        "epoch": 2785,
        "reward": 0.7023205757141113,
        "val_loss": 0.0005197452347991722,
        "train_loss": 0.0002589635612541595
      },
      {
        "epoch": 2786,
        "reward": 0.7728102803230286,
        "val_loss": 0.0002500318078091368,
        "train_loss": 0.00033512514710309915
      },
      {
        "epoch": 2787,
        "reward": 0.770757257938385,
        "val_loss": 0.0002559291523149503,
        "train_loss": 0.00026488030394270585
      },
      {
        "epoch": 2788,
        "reward": 0.7468242049217224,
        "val_loss": 0.0003324843024269545,
        "train_loss": 0.0003405336912972136
      },
      {
        "epoch": 2789,
        "reward": 0.7738298773765564,
        "val_loss": 0.0002471399909284498,
        "train_loss": 0.00031468277078462194
      },
      {
        "epoch": 2790,
        "reward": 0.7727615237236023,
        "val_loss": 0.00025017070583999157,
        "train_loss": 0.00026373461220758216
      },
      {
        "epoch": 2791,
        "reward": 0.7726759314537048,
        "val_loss": 0.0002504148454006229,
        "train_loss": 0.00027409967515268363
      },
      {
        "epoch": 2792,
        "reward": 0.7354889512062073,
        "val_loss": 0.0003741958935279399,
        "train_loss": 0.0003143669840098412
      },
      {
        "epoch": 2793,
        "reward": 0.6709167957305908,
        "val_loss": 0.0006960457041194397,
        "train_loss": 0.0003366800732552432
      },
      {
        "epoch": 2794,
        "reward": 0.7505662441253662,
        "val_loss": 0.0003195184378585379,
        "train_loss": 0.0004697690856119152
      },
      {
        "epoch": 2795,
        "reward": 0.7557895183563232,
        "val_loss": 0.00030205817685262967,
        "train_loss": 0.00029319978784769773
      },
      {
        "epoch": 2796,
        "reward": 0.773429274559021,
        "val_loss": 0.0002482733211114204,
        "train_loss": 0.0002805273376837319
      },
      {
        "epoch": 2797,
        "reward": 0.767217755317688,
        "val_loss": 0.0002663337467570922,
        "train_loss": 0.0002846769566531293
      },
      {
        "epoch": 2798,
        "reward": 0.7589788436889648,
        "val_loss": 0.000291752558301336,
        "train_loss": 0.0002743807260860474
      },
      {
        "epoch": 2799,
        "reward": 0.7163278460502625,
        "val_loss": 0.00045370503877555687,
        "train_loss": 0.0002792052400764078
      },
      {
        "epoch": 2800,
        "reward": 0.733147144317627,
        "val_loss": 0.0003832878636395825,
        "train_loss": 0.00034468283019333077
      },
      {
        "epoch": 2801,
        "reward": 0.7696611285209656,
        "val_loss": 0.0002591186639619991,
        "train_loss": 0.000318105584973147
      },
      {
        "epoch": 2802,
        "reward": 0.6989206075668335,
        "val_loss": 0.0005368712674161154,
        "train_loss": 0.00029538806344275
      },
      {
        "epoch": 2803,
        "reward": 0.7472821474075317,
        "val_loss": 0.0003308767606670569,
        "train_loss": 0.0004272325678847175
      },
      {
        "epoch": 2804,
        "reward": 0.773160994052887,
        "val_loss": 0.00024903452348163616,
        "train_loss": 0.0003042788791320233
      },
      {
        "epoch": 2805,
        "reward": 0.7660105228424072,
        "val_loss": 0.00026995211789783625,
        "train_loss": 0.0002735235786810965
      },
      {
        "epoch": 2806,
        "reward": 0.771045982837677,
        "val_loss": 0.000255093676969409,
        "train_loss": 0.0002917333654120459
      },
      {
        "epoch": 2807,
        "reward": 0.767800509929657,
        "val_loss": 0.0002645998216134363,
        "train_loss": 0.0002962155267596245
      },
      {
        "epoch": 2808,
        "reward": 0.7669422030448914,
        "val_loss": 0.00026715641849607764,
        "train_loss": 0.00032954781720316253
      },
      {
        "epoch": 2809,
        "reward": 0.7651975154876709,
        "val_loss": 0.00027240926491296183,
        "train_loss": 0.00028664856417475013
      },
      {
        "epoch": 2810,
        "reward": 0.7730936408042908,
        "val_loss": 0.0002492256254689502,
        "train_loss": 0.0002731799543723285
      },
      {
        "epoch": 2811,
        "reward": 0.7536184191703796,
        "val_loss": 0.00030922682448622903,
        "train_loss": 0.0002706121986893077
      },
      {
        "epoch": 2812,
        "reward": 0.7621731162071228,
        "val_loss": 0.00028169439506850073,
        "train_loss": 0.0003596742867207817
      },
      {
        "epoch": 2813,
        "reward": 0.7509406805038452,
        "val_loss": 0.0003182425196947796,
        "train_loss": 0.0002657514816326931
      },
      {
        "epoch": 2814,
        "reward": 0.7715679407119751,
        "val_loss": 0.0002535885765350291,
        "train_loss": 0.00026961387070164515
      },
      {
        "epoch": 2815,
        "reward": 0.7737063765525818,
        "val_loss": 0.0002474890248517373,
        "train_loss": 0.0002787259498011106
      },
      {
        "epoch": 2816,
        "reward": 0.7429201602935791,
        "val_loss": 0.00034642980400738973,
        "train_loss": 0.00028980611234776286
      },
      {
        "epoch": 2817,
        "reward": 0.7739883065223694,
        "val_loss": 0.00024669293738302907,
        "train_loss": 0.0002775956587496554
      },
      {
        "epoch": 2818,
        "reward": 0.7518216967582703,
        "val_loss": 0.00031525477243121713,
        "train_loss": 0.0002599833193156743
      },
      {
        "epoch": 2819,
        "reward": 0.7511470913887024,
        "val_loss": 0.0003175403814696308,
        "train_loss": 0.00026945001641601825
      },
      {
        "epoch": 2820,
        "reward": 0.7267958521842957,
        "val_loss": 0.0004088021981130753,
        "train_loss": 0.0002984854218084365
      },
      {
        "epoch": 2821,
        "reward": 0.7567561864852905,
        "val_loss": 0.0002989065708659057,
        "train_loss": 0.00032929980919177
      },
      {
        "epoch": 2822,
        "reward": 0.7681724429130554,
        "val_loss": 0.000263497418408016,
        "train_loss": 0.00029949477818893053
      },
      {
        "epoch": 2823,
        "reward": 0.7602370977401733,
        "val_loss": 0.0002877594982107569,
        "train_loss": 0.0003105568231638664
      },
      {
        "epoch": 2824,
        "reward": 0.7170550227165222,
        "val_loss": 0.00045046671792598706,
        "train_loss": 0.0003891283989875004
      },
      {
        "epoch": 2825,
        "reward": 0.7239195704460144,
        "val_loss": 0.00042077936814166605,
        "train_loss": 0.0005272173108936001
      },
      {
        "epoch": 2826,
        "reward": 0.7735466957092285,
        "val_loss": 0.0002479409013176337,
        "train_loss": 0.00032617049440047523
      },
      {
        "epoch": 2827,
        "reward": 0.7566819190979004,
        "val_loss": 0.0002991477335204503,
        "train_loss": 0.00027219350046764774
      },
      {
        "epoch": 2828,
        "reward": 0.7727987170219421,
        "val_loss": 0.0002500647263202284,
        "train_loss": 0.00026614534614894254
      },
      {
        "epoch": 2829,
        "reward": 0.7666763663291931,
        "val_loss": 0.0002679521795861157,
        "train_loss": 0.0002614088821596502
      },
      {
        "epoch": 2830,
        "reward": 0.7519648671150208,
        "val_loss": 0.0003147711478439825,
        "train_loss": 0.000285431163949677
      },
      {
        "epoch": 2831,
        "reward": 0.7524682879447937,
        "val_loss": 0.0003130754672123918,
        "train_loss": 0.00031359892678805266
      },
      {
        "epoch": 2832,
        "reward": 0.7580282688140869,
        "val_loss": 0.00029479648635190515,
        "train_loss": 0.00041003262986823055
      },
      {
        "epoch": 2833,
        "reward": 0.766075074672699,
        "val_loss": 0.00026975774172959585,
        "train_loss": 0.00026922694907555595
      },
      {
        "epoch": 2834,
        "reward": 0.7624493837356567,
        "val_loss": 0.0002808367446829964,
        "train_loss": 0.00028460744831066293
      },
      {
        "epoch": 2835,
        "reward": 0.7708339095115662,
        "val_loss": 0.00025570695704248337,
        "train_loss": 0.0002647953492144622
      },
      {
        "epoch": 2836,
        "reward": 0.7703556418418884,
        "val_loss": 0.0002570943657441863,
        "train_loss": 0.0002610099433625762
      },
      {
        "epoch": 2837,
        "reward": 0.7627846002578735,
        "val_loss": 0.00027979869212556096,
        "train_loss": 0.0003151707395982857
      },
      {
        "epoch": 2838,
        "reward": 0.7736780047416687,
        "val_loss": 0.0002475693659757131,
        "train_loss": 0.00034749900861732807
      },
      {
        "epoch": 2839,
        "reward": 0.76866614818573,
        "val_loss": 0.00026203945578475086,
        "train_loss": 0.00027909509195139364
      },
      {
        "epoch": 2840,
        "reward": 0.766997218132019,
        "val_loss": 0.0002669922001327255,
        "train_loss": 0.00028110756550002127
      },
      {
        "epoch": 2841,
        "reward": 0.7703656554222107,
        "val_loss": 0.0002570653222002355,
        "train_loss": 0.00035817203528355236
      },
      {
        "epoch": 2842,
        "reward": 0.7731086611747742,
        "val_loss": 0.0002491828948093046,
        "train_loss": 0.00030145394199420337
      },
      {
        "epoch": 2843,
        "reward": 0.7704752683639526,
        "val_loss": 0.0002567469533200243,
        "train_loss": 0.00026412987398753804
      },
      {
        "epoch": 2844,
        "reward": 0.7739018797874451,
        "val_loss": 0.0002469367193823148,
        "train_loss": 0.0002626686109579168
      },
      {
        "epoch": 2845,
        "reward": 0.7658482193946838,
        "val_loss": 0.0002704415424627119,
        "train_loss": 0.00026729484055137547
      },
      {
        "epoch": 2846,
        "reward": 0.774422287940979,
        "val_loss": 0.0002454712230246514,
        "train_loss": 0.0002749920223812716
      },
      {
        "epoch": 2847,
        "reward": 0.7727148532867432,
        "val_loss": 0.0002503037456855444,
        "train_loss": 0.0002867382823191852
      },
      {
        "epoch": 2848,
        "reward": 0.7641001343727112,
        "val_loss": 0.00027575208930232165,
        "train_loss": 0.00026107454267240915
      },
      {
        "epoch": 2849,
        "reward": 0.763655424118042,
        "val_loss": 0.00027711493021342903,
        "train_loss": 0.00026870740587652946
      },
      {
        "epoch": 2850,
        "reward": 0.7667359709739685,
        "val_loss": 0.0002677734654363511,
        "train_loss": 0.0002593039473420224
      },
      {
        "epoch": 2851,
        "reward": 0.7474318742752075,
        "val_loss": 0.0003303525986016861,
        "train_loss": 0.0002692766121561782
      },
      {
        "epoch": 2852,
        "reward": 0.7541558742523193,
        "val_loss": 0.0003074404209785696,
        "train_loss": 0.00027871448792911205
      },
      {
        "epoch": 2853,
        "reward": 0.7694460153579712,
        "val_loss": 0.00025974826088973453,
        "train_loss": 0.00028300879169434594
      },
      {
        "epoch": 2854,
        "reward": 0.7734861373901367,
        "val_loss": 0.0002481122813021232,
        "train_loss": 0.0002683992727095476
      },
      {
        "epoch": 2855,
        "reward": 0.7698022723197937,
        "val_loss": 0.00025870674497647475,
        "train_loss": 0.0002696978335734457
      },
      {
        "epoch": 2856,
        "reward": 0.7744614481925964,
        "val_loss": 0.000245361083735978,
        "train_loss": 0.0002522760758213193
      },
      {
        "epoch": 2857,
        "reward": 0.7448918223381042,
        "val_loss": 0.0003393331925118608,
        "train_loss": 0.00028459412267413706
      },
      {
        "epoch": 2858,
        "reward": 0.761366069316864,
        "val_loss": 0.0002842112111725977,
        "train_loss": 0.0004078859078268019
      },
      {
        "epoch": 2859,
        "reward": 0.7551290392875671,
        "val_loss": 0.0003042254497164062,
        "train_loss": 0.000264032201392603
      },
      {
        "epoch": 2860,
        "reward": 0.7717466354370117,
        "val_loss": 0.00025307453220843205,
        "train_loss": 0.0002669176319614053
      },
      {
        "epoch": 2861,
        "reward": 0.7485948801040649,
        "val_loss": 0.00032630078203510493,
        "train_loss": 0.0002625084106022349
      },
      {
        "epoch": 2862,
        "reward": 0.7383227348327637,
        "val_loss": 0.0003634152401770864,
        "train_loss": 0.0003029110980255959
      },
      {
        "epoch": 2863,
        "reward": 0.7674057483673096,
        "val_loss": 0.0002657732942939869,
        "train_loss": 0.00039509590099511953
      },
      {
        "epoch": 2864,
        "reward": 0.7600108981132507,
        "val_loss": 0.00028847435065212527,
        "train_loss": 0.00033136193871122
      },
      {
        "epoch": 2865,
        "reward": 0.7726146578788757,
        "val_loss": 0.00025058920229119915,
        "train_loss": 0.0002710807874301771
      },
      {
        "epoch": 2866,
        "reward": 0.7744506597518921,
        "val_loss": 0.0002453913787446384,
        "train_loss": 0.000257709174268082
      },
      {
        "epoch": 2867,
        "reward": 0.7729985117912292,
        "val_loss": 0.0002494961455730455,
        "train_loss": 0.0002599790196444911
      },
      {
        "epoch": 2868,
        "reward": 0.770695149898529,
        "val_loss": 0.00025610915534863513,
        "train_loss": 0.00025657084720128647
      },
      {
        "epoch": 2869,
        "reward": 0.7745059728622437,
        "val_loss": 0.0002452359809207597,
        "train_loss": 0.00025252801326412457
      },
      {
        "epoch": 2870,
        "reward": 0.7680045366287231,
        "val_loss": 0.00026399466566674946,
        "train_loss": 0.00026086941103970347
      },
      {
        "epoch": 2871,
        "reward": 0.769562304019928,
        "val_loss": 0.00025940799969248474,
        "train_loss": 0.00030389208180937345
      },
      {
        "epoch": 2872,
        "reward": 0.7639551758766174,
        "val_loss": 0.00027619577096109945,
        "train_loss": 0.0002811072794989181
      },
      {
        "epoch": 2873,
        "reward": 0.765131413936615,
        "val_loss": 0.0002726096676529518,
        "train_loss": 0.0003290409938647197
      },
      {
        "epoch": 2874,
        "reward": 0.7746817469596863,
        "val_loss": 0.00024474286224826107,
        "train_loss": 0.0003289172594892219
      },
      {
        "epoch": 2875,
        "reward": 0.7543417811393738,
        "val_loss": 0.0003068242804147303,
        "train_loss": 0.0002760390583576876
      },
      {
        "epoch": 2876,
        "reward": 0.7746760249137878,
        "val_loss": 0.000244758790358901,
        "train_loss": 0.00028663894660824624
      },
      {
        "epoch": 2877,
        "reward": 0.773414134979248,
        "val_loss": 0.00024831623470942887,
        "train_loss": 0.0002516776565663839
      },
      {
        "epoch": 2878,
        "reward": 0.7733893394470215,
        "val_loss": 0.0002483865142234468,
        "train_loss": 0.00025319730215974583
      },
      {
        "epoch": 2879,
        "reward": 0.7743359804153442,
        "val_loss": 0.00024571387828992944,
        "train_loss": 0.00025168396408704354
      },
      {
        "epoch": 2880,
        "reward": 0.7726008296012878,
        "val_loss": 0.000250628827156366,
        "train_loss": 0.0002558957987555634
      },
      {
        "epoch": 2881,
        "reward": 0.7743610739707947,
        "val_loss": 0.0002456430416454428,
        "train_loss": 0.0002639181679674388
      },
      {
        "epoch": 2882,
        "reward": 0.7729786038398743,
        "val_loss": 0.0002495528377559302,
        "train_loss": 0.0002560634384980613
      },
      {
        "epoch": 2883,
        "reward": 0.773935079574585,
        "val_loss": 0.00024684299257517395,
        "train_loss": 0.00026984950090991333
      },
      {
        "epoch": 2884,
        "reward": 0.7722517251968384,
        "val_loss": 0.00025162635470873544,
        "train_loss": 0.0002514678264840488
      },
      {
        "epoch": 2885,
        "reward": 0.764798104763031,
        "val_loss": 0.00027362235414329916,
        "train_loss": 0.00028191459401009174
      },
      {
        "epoch": 2886,
        "reward": 0.7743375897407532,
        "val_loss": 0.000245709198809761,
        "train_loss": 0.00026706629656613444
      },
      {
        "epoch": 2887,
        "reward": 0.7717230319976807,
        "val_loss": 0.0002531425291506041,
        "train_loss": 0.00026858735509449616
      },
      {
        "epoch": 2888,
        "reward": 0.7664608359336853,
        "val_loss": 0.00026859828462225517,
        "train_loss": 0.00025459016100844915
      },
      {
        "epoch": 2889,
        "reward": 0.772980809211731,
        "val_loss": 0.0002495464182824695,
        "train_loss": 0.0002538905478454231
      },
      {
        "epoch": 2890,
        "reward": 0.7646205425262451,
        "val_loss": 0.00027416288919214694,
        "train_loss": 0.0002655757729931233
      },
      {
        "epoch": 2891,
        "reward": 0.7589421272277832,
        "val_loss": 0.0002918698301073164,
        "train_loss": 0.00027758368098427757
      },
      {
        "epoch": 2892,
        "reward": 0.7714146971702576,
        "val_loss": 0.00025402981762973856,
        "train_loss": 0.00027324505544339237
      },
      {
        "epoch": 2893,
        "reward": 0.7691845893859863,
        "val_loss": 0.00026051452524760473,
        "train_loss": 0.0002634331853746866
      },
      {
        "epoch": 2894,
        "reward": 0.7745997309684753,
        "val_loss": 0.0002449726931185329,
        "train_loss": 0.0002562122495314375
      },
      {
        "epoch": 2895,
        "reward": 0.7701751589775085,
        "val_loss": 0.0002576194965513423,
        "train_loss": 0.00026063396091138624
      },
      {
        "epoch": 2896,
        "reward": 0.7743363380432129,
        "val_loss": 0.00024571264761367014,
        "train_loss": 0.00026796584895167214
      },
      {
        "epoch": 2897,
        "reward": 0.7639840841293335,
        "val_loss": 0.00027610711861468317,
        "train_loss": 0.00026097157103558506
      },
      {
        "epoch": 2898,
        "reward": 0.7738515138626099,
        "val_loss": 0.000247079087005529,
        "train_loss": 0.0002781019334529097
      },
      {
        "epoch": 2899,
        "reward": 0.7742592692375183,
        "val_loss": 0.00024592971645428667,
        "train_loss": 0.0002528700880737653
      },
      {
        "epoch": 2900,
        "reward": 0.7676599621772766,
        "val_loss": 0.000265017307745958,
        "train_loss": 0.0002515210750201592
      },
      {
        "epoch": 2901,
        "reward": 0.7718672752380371,
        "val_loss": 0.0002527281820740817,
        "train_loss": 0.0002701543839975784
      },
      {
        "epoch": 2902,
        "reward": 0.7741361856460571,
        "val_loss": 0.00024627606243094694,
        "train_loss": 0.0002551423830692119
      },
      {
        "epoch": 2903,
        "reward": 0.7740703821182251,
        "val_loss": 0.00024646157232512323,
        "train_loss": 0.00025307081299475755
      },
      {
        "epoch": 2904,
        "reward": 0.7697178721427917,
        "val_loss": 0.00025895304237824997,
        "train_loss": 0.0002535770965131143
      },
      {
        "epoch": 2905,
        "reward": 0.7687636017799377,
        "val_loss": 0.00026175217395315746,
        "train_loss": 0.00025226263607272325
      },
      {
        "epoch": 2906,
        "reward": 0.7691733241081238,
        "val_loss": 0.00026054780339888694,
        "train_loss": 0.0002571968273584319
      },
      {
        "epoch": 2907,
        "reward": 0.7743369936943054,
        "val_loss": 0.0002457109762222639,
        "train_loss": 0.0002687404767829531
      },
      {
        "epoch": 2908,
        "reward": 0.7742855548858643,
        "val_loss": 0.0002458555848404233,
        "train_loss": 0.00026207301366062334
      },
      {
        "epoch": 2909,
        "reward": 0.7709819674491882,
        "val_loss": 0.0002552788854310555,
        "train_loss": 0.0002545762091848211
      },
      {
        "epoch": 2910,
        "reward": 0.7737485766410828,
        "val_loss": 0.0002473696804372594,
        "train_loss": 0.0002544780166838875
      },
      {
        "epoch": 2911,
        "reward": 0.7662713527679443,
        "val_loss": 0.00026916743081528693,
        "train_loss": 0.00026508604059927166
      },
      {
        "epoch": 2912,
        "reward": 0.7728144526481628,
        "val_loss": 0.0002500199438405356,
        "train_loss": 0.0002705987096235801
      },
      {
        "epoch": 2913,
        "reward": 0.7743748426437378,
        "val_loss": 0.0002456044270989618,
        "train_loss": 0.00025462150674334576
      },
      {
        "epoch": 2914,
        "reward": 0.772821307182312,
        "val_loss": 0.0002500004879298753,
        "train_loss": 0.0002586048627003598
      },
      {
        "epoch": 2915,
        "reward": 0.7712992429733276,
        "val_loss": 0.0002543624141253531,
        "train_loss": 0.0002806297270581126
      },
      {
        "epoch": 2916,
        "reward": 0.7745180130004883,
        "val_loss": 0.0002452022038466696,
        "train_loss": 0.0002597491130263034
      },
      {
        "epoch": 2917,
        "reward": 0.7741162180900574,
        "val_loss": 0.0002463322868736993,
        "train_loss": 0.00026455347184450005
      },
      {
        "epoch": 2918,
        "reward": 0.7712857723236084,
        "val_loss": 0.00025440142573123533,
        "train_loss": 0.0002808887992824356
      },
      {
        "epoch": 2919,
        "reward": 0.7750182151794434,
        "val_loss": 0.00024380054050457796,
        "train_loss": 0.0002794315453054598
      },
      {
        "epoch": 2920,
        "reward": 0.7739291191101074,
        "val_loss": 0.00024685974598729184,
        "train_loss": 0.000267608436563303
      },
      {
        "epoch": 2921,
        "reward": 0.7726501822471619,
        "val_loss": 0.0002504880082727011,
        "train_loss": 0.0002573440259976241
      },
      {
        "epoch": 2922,
        "reward": 0.7740932106971741,
        "val_loss": 0.0002463970782368311,
        "train_loss": 0.0002598809509296328
      },
      {
        "epoch": 2923,
        "reward": 0.7742629647254944,
        "val_loss": 0.0002459191081080852,
        "train_loss": 0.00026853639372767735
      },
      {
        "epoch": 2924,
        "reward": 0.7734794616699219,
        "val_loss": 0.00024813121542268036,
        "train_loss": 0.00025764588672945346
      },
      {
        "epoch": 2925,
        "reward": 0.7743567228317261,
        "val_loss": 0.00024565545235028755,
        "train_loss": 0.00025420934112984326
      },
      {
        "epoch": 2926,
        "reward": 0.7738159894943237,
        "val_loss": 0.0002471794099879584,
        "train_loss": 0.0002689955178469133
      },
      {
        "epoch": 2927,
        "reward": 0.7746438980102539,
        "val_loss": 0.0002448489415525858,
        "train_loss": 0.0002563023892714857
      },
      {
        "epoch": 2928,
        "reward": 0.7707008123397827,
        "val_loss": 0.0002560926805017516,
        "train_loss": 0.00025662469348529924
      },
      {
        "epoch": 2929,
        "reward": 0.7747043967247009,
        "val_loss": 0.0002446790042865489,
        "train_loss": 0.0002611555972534391
      },
      {
        "epoch": 2930,
        "reward": 0.7718200087547302,
        "val_loss": 0.00025286373524327895,
        "train_loss": 0.00026763582886465324
      },
      {
        "epoch": 2931,
        "reward": 0.7734918594360352,
        "val_loss": 0.00024809621183002103,
        "train_loss": 0.00026310576560298126
      },
      {
        "epoch": 2932,
        "reward": 0.7738003134727478,
        "val_loss": 0.0002472237663044195,
        "train_loss": 0.0002851353341471762
      },
      {
        "epoch": 2933,
        "reward": 0.771236777305603,
        "val_loss": 0.00025454275393193323,
        "train_loss": 0.0002500860092158501
      },
      {
        "epoch": 2934,
        "reward": 0.7660175561904907,
        "val_loss": 0.0002699311444303021,
        "train_loss": 0.00025961969647771464
      },
      {
        "epoch": 2935,
        "reward": 0.7746803164482117,
        "val_loss": 0.0002447468910499343,
        "train_loss": 0.00026635709666432097
      },
      {
        "epoch": 2936,
        "reward": 0.7749257683753967,
        "val_loss": 0.0002440592402958178,
        "train_loss": 0.00025171670970918896
      },
      {
        "epoch": 2937,
        "reward": 0.7737347483634949,
        "val_loss": 0.00024740865462393103,
        "train_loss": 0.0002490371200740181
      },
      {
        "epoch": 2938,
        "reward": 0.7725197076797485,
        "val_loss": 0.00025086030239305856,
        "train_loss": 0.00025431495361352485
      },
      {
        "epoch": 2939,
        "reward": 0.7743470668792725,
        "val_loss": 0.00024568262909139903,
        "train_loss": 0.00027001305324329925
      },
      {
        "epoch": 2940,
        "reward": 0.7720789313316345,
        "val_loss": 0.00025212137136674883,
        "train_loss": 0.0002537913012649649
      },
      {
        "epoch": 2941,
        "reward": 0.7734414339065552,
        "val_loss": 0.00024823884138770936,
        "train_loss": 0.00025372042308355536
      },
      {
        "epoch": 2942,
        "reward": 0.7721264958381653,
        "val_loss": 0.0002519846914635439,
        "train_loss": 0.0002542210338735738
      },
      {
        "epoch": 2943,
        "reward": 0.7719064354896545,
        "val_loss": 0.0002526156832962962,
        "train_loss": 0.00025571105694465444
      },
      {
        "epoch": 2944,
        "reward": 0.7713420391082764,
        "val_loss": 0.00025423906793418737,
        "train_loss": 0.00026917874213093176
      },
      {
        "epoch": 2945,
        "reward": 0.7740433812141418,
        "val_loss": 0.00024653756242644576,
        "train_loss": 0.0002594230693200818
      },
      {
        "epoch": 2946,
        "reward": 0.7714524269104004,
        "val_loss": 0.0002539208549673536,
        "train_loss": 0.0002659150939927293
      },
      {
        "epoch": 2947,
        "reward": 0.7726579308509827,
        "val_loss": 0.00025046601617110094,
        "train_loss": 0.0002776745145988221
      },
      {
        "epoch": 2948,
        "reward": 0.7727787494659424,
        "val_loss": 0.00025012154115497,
        "train_loss": 0.0002744005558689913
      },
      {
        "epoch": 2949,
        "reward": 0.774352490901947,
        "val_loss": 0.00024566722692855237,
        "train_loss": 0.000285500229578107
      },
      {
        "epoch": 2950,
        "reward": 0.7749783396720886,
        "val_loss": 0.00024391190007528557,
        "train_loss": 0.00024974302918132286
      },
      {
        "epoch": 2951,
        "reward": 0.7738025784492493,
        "val_loss": 0.0002472172532829323,
        "train_loss": 0.0002524544235292034
      },
      {
        "epoch": 2952,
        "reward": 0.774219274520874,
        "val_loss": 0.0002460420031898788,
        "train_loss": 0.0002512485296812464
      },
      {
        "epoch": 2953,
        "reward": 0.7747202515602112,
        "val_loss": 0.0002446347976469302,
        "train_loss": 0.00026808403568933357
      },
      {
        "epoch": 2954,
        "reward": 0.7725032567977905,
        "val_loss": 0.0002509073736811323,
        "train_loss": 0.0002845891011440052
      },
      {
        "epoch": 2955,
        "reward": 0.7750530242919922,
        "val_loss": 0.00024370310919558897,
        "train_loss": 0.00027142285062627006
      },
      {
        "epoch": 2956,
        "reward": 0.7706973552703857,
        "val_loss": 0.0002561026714309784,
        "train_loss": 0.0002533294783951043
      },
      {
        "epoch": 2957,
        "reward": 0.7747637629508972,
        "val_loss": 0.000244512887937682,
        "train_loss": 0.0002659812044629899
      },
      {
        "epoch": 2958,
        "reward": 0.7729887366294861,
        "val_loss": 0.0002495238836023158,
        "train_loss": 0.0002531981646405676
      },
      {
        "epoch": 2959,
        "reward": 0.7747704386711121,
        "val_loss": 0.00024449393926520964,
        "train_loss": 0.00025375109460303345
      },
      {
        "epoch": 2960,
        "reward": 0.7745594382286072,
        "val_loss": 0.00024508609619390754,
        "train_loss": 0.00024831773015858536
      },
      {
        "epoch": 2961,
        "reward": 0.7742713093757629,
        "val_loss": 0.0002458957605995238,
        "train_loss": 0.00024712026904056145
      },
      {
        "epoch": 2962,
        "reward": 0.7749038338661194,
        "val_loss": 0.000244120489307014,
        "train_loss": 0.0002591304426179984
      },
      {
        "epoch": 2963,
        "reward": 0.7735329866409302,
        "val_loss": 0.0002479796405948166,
        "train_loss": 0.00024661823586040574
      },
      {
        "epoch": 2964,
        "reward": 0.775022566318512,
        "val_loss": 0.0002437883023438709,
        "train_loss": 0.0002494947521059797
      },
      {
        "epoch": 2965,
        "reward": 0.7745711803436279,
        "val_loss": 0.0002450527182580637,
        "train_loss": 0.0002673263364928201
      },
      {
        "epoch": 2966,
        "reward": 0.7739378809928894,
        "val_loss": 0.0002468352655081877,
        "train_loss": 0.0002640972351610589
      },
      {
        "epoch": 2967,
        "reward": 0.7740320563316345,
        "val_loss": 0.0002465695828764832,
        "train_loss": 0.0002713094867291287
      },
      {
        "epoch": 2968,
        "reward": 0.7749724388122559,
        "val_loss": 0.00024392848717980087,
        "train_loss": 0.0002500385931993011
      },
      {
        "epoch": 2969,
        "reward": 0.7742332816123962,
        "val_loss": 0.0002460027899360284,
        "train_loss": 0.00030416507405999047
      },
      {
        "epoch": 2970,
        "reward": 0.7743750214576721,
        "val_loss": 0.0002456039988568851,
        "train_loss": 0.0002695249299554584
      },
      {
        "epoch": 2971,
        "reward": 0.7746584415435791,
        "val_loss": 0.0002448079238612471,
        "train_loss": 0.00025058637822020013
      },
      {
        "epoch": 2972,
        "reward": 0.7748427987098694,
        "val_loss": 0.0002442912892937394,
        "train_loss": 0.00024588045408353745
      },
      {
        "epoch": 2973,
        "reward": 0.7747888565063477,
        "val_loss": 0.0002444424483525966,
        "train_loss": 0.00025424122577533126
      },
      {
        "epoch": 2974,
        "reward": 0.7747468948364258,
        "val_loss": 0.00024456006732569743,
        "train_loss": 0.00024827160520474607
      },
      {
        "epoch": 2975,
        "reward": 0.7746607661247253,
        "val_loss": 0.00024480154804353205,
        "train_loss": 0.0002480734827678624
      },
      {
        "epoch": 2976,
        "reward": 0.7746800184249878,
        "val_loss": 0.00024474762903992087,
        "train_loss": 0.00025692705262022524
      },
      {
        "epoch": 2977,
        "reward": 0.7748317122459412,
        "val_loss": 0.0002443224179192579,
        "train_loss": 0.00024739293061989325
      },
      {
        "epoch": 2978,
        "reward": 0.774716854095459,
        "val_loss": 0.00024464421481492797,
        "train_loss": 0.000282441319051521
      },
      {
        "epoch": 2979,
        "reward": 0.7739278078079224,
        "val_loss": 0.000246863641742883,
        "train_loss": 0.00028118453617655457
      },
      {
        "epoch": 2980,
        "reward": 0.7748541831970215,
        "val_loss": 0.00024425946217628995,
        "train_loss": 0.00026685235878595937
      },
      {
        "epoch": 2981,
        "reward": 0.774873673915863,
        "val_loss": 0.0002442049527806895,
        "train_loss": 0.00025257172260003595
      },
      {
        "epoch": 2982,
        "reward": 0.7749428153038025,
        "val_loss": 0.00024401125639477477,
        "train_loss": 0.00026125359447458043
      },
      {
        "epoch": 2983,
        "reward": 0.774925172328949,
        "val_loss": 0.00024406096781603992,
        "train_loss": 0.0002471833836002938
      },
      {
        "epoch": 2984,
        "reward": 0.7749109864234924,
        "val_loss": 0.00024410056773506637,
        "train_loss": 0.0002790438363892743
      },
      {
        "epoch": 2985,
        "reward": 0.7748992443084717,
        "val_loss": 0.0002441333677519911,
        "train_loss": 0.0002592186440149537
      },
      {
        "epoch": 2986,
        "reward": 0.7747907042503357,
        "val_loss": 0.0002444374965437289,
        "train_loss": 0.0002483944540122488
      },
      {
        "epoch": 2987,
        "reward": 0.774880051612854,
        "val_loss": 0.0002441871162903096,
        "train_loss": 0.0002565281493634057
      },
      {
        "epoch": 2988,
        "reward": 0.7749488353729248,
        "val_loss": 0.00024399466305372437,
        "train_loss": 0.0002658786834217608
      },
      {
        "epoch": 2989,
        "reward": 0.7749466300010681,
        "val_loss": 0.00024400081643502096,
        "train_loss": 0.00025525683640108374
      },
      {
        "epoch": 2990,
        "reward": 0.774980366230011,
        "val_loss": 0.00024390648884166564,
        "train_loss": 0.000265431040203951
      },
      {
        "epoch": 2991,
        "reward": 0.7749919891357422,
        "val_loss": 0.00024387388423617397,
        "train_loss": 0.0002451116757242744
      },
      {
        "epoch": 2992,
        "reward": 0.7750145792961121,
        "val_loss": 0.0002438104898569041,
        "train_loss": 0.00024616317079142813
      },
      {
        "epoch": 2993,
        "reward": 0.7749723792076111,
        "val_loss": 0.0002439287761392604,
        "train_loss": 0.00025462894700467587
      },
      {
        "epoch": 2994,
        "reward": 0.7749420404434204,
        "val_loss": 0.00024401355351853584,
        "train_loss": 0.00025442324336976384
      },
      {
        "epoch": 2995,
        "reward": 0.7749138474464417,
        "val_loss": 0.00024409238955870803,
        "train_loss": 0.0002453678135120404
      },
      {
        "epoch": 2996,
        "reward": 0.7749181389808655,
        "val_loss": 0.0002440803946228698,
        "train_loss": 0.00024620201216188993
      },
      {
        "epoch": 2997,
        "reward": 0.7749192118644714,
        "val_loss": 0.00024407750502827445,
        "train_loss": 0.00024825956335497234
      },
      {
        "epoch": 2998,
        "reward": 0.7749174237251282,
        "val_loss": 0.00024408240486601635,
        "train_loss": 0.00026282572183005797
      },
      {
        "epoch": 2999,
        "reward": 0.7749187350273132,
        "val_loss": 0.0002440787253103086,
        "train_loss": 0.0002527244667782305
      }
    ]
  }
}