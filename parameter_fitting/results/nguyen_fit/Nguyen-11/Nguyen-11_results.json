{
  "experiment_info": {
    "experiment_name": "Nguyen-11",
    "dataset_name": "Nguyen-11",
    "timestamp": "2025-08-30T21:20:50.530919",
    "random_seed": 42
  },
  "model_config": {
    "input_size": 2,
    "output_size": 1,
    "num_layers": 2,
    "nonlinear_info": [
      [
        1,
        0
      ]
    ],
    "function_set": [
      "SafeIdentityFunction",
      "SafeExp",
      "SafeLog",
      "SafeSin",
      "SafePower",
      "SafeCos",
      "ExpSwitchActivation"
    ]
  },
  "training_config": {
    "num_epochs": 200,
    "batch_size": 32,
    "learning_rate": 0.01,
    "reg_strength": 0.0,
    "scheduler": "none"
  },
  "final_equation": {
    "equation_string": "Matrix([[0.984506781706273*Abs(x1)**(1.0*Abs(x2)) + 0.0180318694460198*Abs(x2)**(1.0*Abs(x1))]])",
    "equation_latex": "Matrix([[0.984506781706273*Abs(x1)**(1.0*Abs(x2)) + 0.0180318694460198*Abs(x2)**(1.0*Abs(x1))]])"
  },
  "evaluation_metrics": {
    "mse": "7.534837e-05",
    "rmse": "0.008680344",
    "mae": "0.00722497"
  },
  "data_info": {
    "train_ratio": 0.8,
    "uncertainty_value": 0.0,
    "path_to_data": "/Users/pablocornejo/Documents/Tesis/SRNetwork/data/raw/nguyen.txt"
  },
  "lbfgs_optimization": {
    "enabled": true,
    "success": true,
    "message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
    "function_evaluations": 13,
    "gradient_evaluations": 13,
    "final_loss": 0.031363365113660786,
    "max_iterations": 1000,
    "tolerance": "1e-8",
    "criterion": "nrmse"
  },
  "lbfgs_topk_optimization": {
    "enabled": true,
    "num_models_optimized": 5,
    "optimization_summary": [
      {
        "rank": 1,
        "original_epoch": 183,
        "original_val_loss": 7.85247705477689e-05,
        "optimized_val_loss": "7.534837e-05",
        "improvement_percent": "4.045092",
        "original_equation": "Matrix([[0.984506781706273*Abs(x1)**(1.0*Abs(x2)) + 0.0180318694460198*Abs(x2)**(1.0*Abs(x1))]])",
        "optimized_equation": "Matrix([[0.984506781706273*Abs(x1)**(1.0*Abs(x2)) + 0.0180318694460198*Abs(x2)**(1.0*Abs(x1))]])",
        "optimization_success": true,
        "function_evaluations": 13,
        "final_loss": 0.031363365113660786
      },
      {
        "rank": 2,
        "original_epoch": 26,
        "original_val_loss": 7.851779706210696e-05,
        "optimized_val_loss": "7.535276e-05",
        "improvement_percent": "4.0309863",
        "original_equation": "Matrix([[0.984546115601006*Abs(x1)**(1.0*Abs(x2)) + 0.0180325898713818*Abs(x2)**(1.0*Abs(x1))]])",
        "optimized_equation": "Matrix([[0.984546115601006*Abs(x1)**(1.0*Abs(x2)) + 0.0180325898713818*Abs(x2)**(1.0*Abs(x1))]])",
        "optimization_success": true,
        "function_evaluations": 8,
        "final_loss": 0.03143983227334517
      },
      {
        "rank": 3,
        "original_epoch": 83,
        "original_val_loss": 7.850555994082242e-05,
        "optimized_val_loss": "7.538083e-05",
        "improvement_percent": "3.9802692",
        "original_equation": "Matrix([[0.984685071949364*Abs(x1)**(1.0*Abs(x2)) + 0.018035134945503*Abs(x2)**(1.0*Abs(x1))]])",
        "optimized_equation": "Matrix([[0.984685071949364*Abs(x1)**(1.0*Abs(x2)) + 0.018035134945503*Abs(x2)**(1.0*Abs(x1))]])",
        "optimization_success": true,
        "function_evaluations": 13,
        "final_loss": 0.0312721718116646
      },
      {
        "rank": 4,
        "original_epoch": 31,
        "original_val_loss": 7.850536141112181e-05,
        "optimized_val_loss": "7.5384916e-05",
        "improvement_percent": "3.9748204",
        "original_equation": "Matrix([[0.984699705094727*Abs(x1)**(1.0*Abs(x2)) + 0.0180354029608907*Abs(x2)**(1.0*Abs(x1))]])",
        "optimized_equation": "Matrix([[0.984699705094727*Abs(x1)**(1.0*Abs(x2)) + 0.0180354029608907*Abs(x2)**(1.0*Abs(x1))]])",
        "optimization_success": true,
        "function_evaluations": 15,
        "final_loss": 0.03145756971523556
      },
      {
        "rank": 5,
        "original_epoch": 79,
        "original_val_loss": 7.850543209185292e-05,
        "optimized_val_loss": "7.538872e-05",
        "improvement_percent": "3.9700534",
        "original_equation": "Matrix([[0.984712582262645*Abs(x1)**(1.0*Abs(x2)) + 0.0180356388144318*Abs(x2)**(1.0*Abs(x1))]])",
        "optimized_equation": "Matrix([[0.984712582262645*Abs(x1)**(1.0*Abs(x2)) + 0.0180356388144318*Abs(x2)**(1.0*Abs(x1))]])",
        "optimization_success": true,
        "function_evaluations": 15,
        "final_loss": 0.03126595633455579
      }
    ],
    "best_model": {
      "original_val_loss": 7.85247705477689e-05,
      "optimized_val_loss": "7.534837e-05",
      "improvement_percent": "4.045092",
      "equation": "Matrix([[0.984506781706273*Abs(x1)**(1.0*Abs(x2)) + 0.0180318694460198*Abs(x2)**(1.0*Abs(x1))]])",
      "optimization_iterations": 1
    }
  },
  "reward_tracking": {
    "reward_type": "nrmse",
    "reward_interval": 1,
    "num_measurements": 200,
    "initial_reward": 0.7406077980995178,
    "final_reward": 0.7541958689689636,
    "best_reward": 0.7545328736305237,
    "worst_reward": 0.7041552066802979,
    "average_reward": 0.7494401985406876,
    "reward_history": [
      {
        "epoch": 0,
        "reward": 0.7406077980995178,
        "val_loss": 9.099264986746545e-05,
        "train_loss": 0.0001331729900602323
      },
      {
        "epoch": 1,
        "reward": 0.7428457140922546,
        "val_loss": 8.889137201809458e-05,
        "train_loss": 7.919858538885959e-05
      },
      {
        "epoch": 2,
        "reward": 0.7533879280090332,
        "val_loss": 7.948050863758129e-05,
        "train_loss": 7.224087175927707e-05
      },
      {
        "epoch": 3,
        "reward": 0.7540180087089539,
        "val_loss": 7.894274209060573e-05,
        "train_loss": 7.405310050391842e-05
      },
      {
        "epoch": 4,
        "reward": 0.7520827054977417,
        "val_loss": 8.060311249989484e-05,
        "train_loss": 7.000428407567282e-05
      },
      {
        "epoch": 5,
        "reward": 0.7519963979721069,
        "val_loss": 8.067776122646007e-05,
        "train_loss": 6.873303872313185e-05
      },
      {
        "epoch": 6,
        "reward": 0.7504950761795044,
        "val_loss": 8.198446136832769e-05,
        "train_loss": 7.13631959045485e-05
      },
      {
        "epoch": 7,
        "reward": 0.7501114010810852,
        "val_loss": 8.232098168394129e-05,
        "train_loss": 7.501702916320377e-05
      },
      {
        "epoch": 8,
        "reward": 0.751298725605011,
        "val_loss": 8.128303774615883e-05,
        "train_loss": 7.847777207923803e-05
      },
      {
        "epoch": 9,
        "reward": 0.7542887330055237,
        "val_loss": 7.871259523588898e-05,
        "train_loss": 8.192143300570584e-05
      },
      {
        "epoch": 10,
        "reward": 0.7539969682693481,
        "val_loss": 7.896073085638429e-05,
        "train_loss": 6.966403283023773e-05
      },
      {
        "epoch": 11,
        "reward": 0.7428110837936401,
        "val_loss": 8.892355877573468e-05,
        "train_loss": 7.831302159152423e-05
      },
      {
        "epoch": 12,
        "reward": 0.753244936466217,
        "val_loss": 7.96029380580876e-05,
        "train_loss": 8.987098366420608e-05
      },
      {
        "epoch": 13,
        "reward": 0.7509695291519165,
        "val_loss": 8.156981597754307e-05,
        "train_loss": 7.018090407375264e-05
      },
      {
        "epoch": 14,
        "reward": 0.7544017434120178,
        "val_loss": 7.861661184246518e-05,
        "train_loss": 6.989367258169156e-05
      },
      {
        "epoch": 15,
        "reward": 0.7485988736152649,
        "val_loss": 8.365758705102573e-05,
        "train_loss": 7.100762300419425e-05
      },
      {
        "epoch": 16,
        "reward": 0.7544889450073242,
        "val_loss": 7.854264549678192e-05,
        "train_loss": 8.313035826946501e-05
      },
      {
        "epoch": 17,
        "reward": 0.7539446949958801,
        "val_loss": 7.900519059538575e-05,
        "train_loss": 7.67800194388166e-05
      },
      {
        "epoch": 18,
        "reward": 0.7544011473655701,
        "val_loss": 7.861709517393527e-05,
        "train_loss": 6.975956287647023e-05
      },
      {
        "epoch": 19,
        "reward": 0.7538684606552124,
        "val_loss": 7.907018464590822e-05,
        "train_loss": 7.403251234231553e-05
      },
      {
        "epoch": 20,
        "reward": 0.7544330954551697,
        "val_loss": 7.859004472265951e-05,
        "train_loss": 7.14066576480176e-05
      },
      {
        "epoch": 21,
        "reward": 0.7418168783187866,
        "val_loss": 8.985279315051489e-05,
        "train_loss": 7.574748731433199e-05
      },
      {
        "epoch": 22,
        "reward": 0.7490440607070923,
        "val_loss": 8.326248020499147e-05,
        "train_loss": 8.109890502685e-05
      },
      {
        "epoch": 23,
        "reward": 0.7495008111000061,
        "val_loss": 8.28586183031023e-05,
        "train_loss": 7.851388825376768e-05
      },
      {
        "epoch": 24,
        "reward": 0.7484828233718872,
        "val_loss": 8.376078351700147e-05,
        "train_loss": 7.816928281009986e-05
      },
      {
        "epoch": 25,
        "reward": 0.7495788931846619,
        "val_loss": 8.278966405279269e-05,
        "train_loss": 7.546438847874434e-05
      },
      {
        "epoch": 26,
        "reward": 0.7545182108879089,
        "val_loss": 7.851779706210696e-05,
        "train_loss": 7.107458742001864e-05
      },
      {
        "epoch": 27,
        "reward": 0.7532091736793518,
        "val_loss": 7.963353086129896e-05,
        "train_loss": 6.978348031557638e-05
      },
      {
        "epoch": 28,
        "reward": 0.7505065202713013,
        "val_loss": 8.197446368285455e-05,
        "train_loss": 7.375777442156014e-05
      },
      {
        "epoch": 29,
        "reward": 0.7540599703788757,
        "val_loss": 7.890702857236777e-05,
        "train_loss": 7.507596469972319e-05
      },
      {
        "epoch": 30,
        "reward": 0.7538928985595703,
        "val_loss": 7.904930472640055e-05,
        "train_loss": 7.199914144761211e-05
      },
      {
        "epoch": 31,
        "reward": 0.7545328736305237,
        "val_loss": 7.850536141112181e-05,
        "train_loss": 7.289876828928335e-05
      },
      {
        "epoch": 32,
        "reward": 0.7476223707199097,
        "val_loss": 8.452907890646852e-05,
        "train_loss": 7.309632005322223e-05
      },
      {
        "epoch": 33,
        "reward": 0.7453603744506836,
        "val_loss": 8.65741863630579e-05,
        "train_loss": 7.152314861531732e-05
      },
      {
        "epoch": 34,
        "reward": 0.7536692023277283,
        "val_loss": 7.924014477924044e-05,
        "train_loss": 7.181294719115473e-05
      },
      {
        "epoch": 35,
        "reward": 0.7482225298881531,
        "val_loss": 8.399263190637742e-05,
        "train_loss": 7.062466766700918e-05
      },
      {
        "epoch": 36,
        "reward": 0.7544049024581909,
        "val_loss": 7.861395403909097e-05,
        "train_loss": 8.029240038572774e-05
      },
      {
        "epoch": 37,
        "reward": 0.7426289319992065,
        "val_loss": 8.909330686687358e-05,
        "train_loss": 7.367807050356462e-05
      },
      {
        "epoch": 38,
        "reward": 0.7515413165092468,
        "val_loss": 8.107221687428787e-05,
        "train_loss": 7.696163279783483e-05
      },
      {
        "epoch": 39,
        "reward": 0.7530741691589355,
        "val_loss": 7.974924353350486e-05,
        "train_loss": 7.576390999020077e-05
      },
      {
        "epoch": 40,
        "reward": 0.7544309496879578,
        "val_loss": 7.859187254715445e-05,
        "train_loss": 7.426395593658806e-05
      },
      {
        "epoch": 41,
        "reward": 0.7507817149162292,
        "val_loss": 8.173373290836545e-05,
        "train_loss": 7.811910486802495e-05
      },
      {
        "epoch": 42,
        "reward": 0.7539708614349365,
        "val_loss": 7.898292876364264e-05,
        "train_loss": 7.423372909005803e-05
      },
      {
        "epoch": 43,
        "reward": 0.7517363429069519,
        "val_loss": 8.090291937280978e-05,
        "train_loss": 7.849437329591288e-05
      },
      {
        "epoch": 44,
        "reward": 0.754166841506958,
        "val_loss": 7.881617265021694e-05,
        "train_loss": 7.525208988786639e-05
      },
      {
        "epoch": 45,
        "reward": 0.7542572617530823,
        "val_loss": 7.873929955946681e-05,
        "train_loss": 7.404172062636532e-05
      },
      {
        "epoch": 46,
        "reward": 0.7166827917098999,
        "val_loss": 0.00011592071470139282,
        "train_loss": 7.270554572012491e-05
      },
      {
        "epoch": 47,
        "reward": 0.7544791102409363,
        "val_loss": 7.855102532110842e-05,
        "train_loss": 8.122548395196925e-05
      },
      {
        "epoch": 48,
        "reward": 0.7529234290122986,
        "val_loss": 7.987865839303205e-05,
        "train_loss": 7.069095804231787e-05
      },
      {
        "epoch": 49,
        "reward": 0.7542981505393982,
        "val_loss": 7.870452463976108e-05,
        "train_loss": 7.004544578684054e-05
      },
      {
        "epoch": 50,
        "reward": 0.7506430745124817,
        "val_loss": 8.185499297854091e-05,
        "train_loss": 7.14394575949812e-05
      },
      {
        "epoch": 51,
        "reward": 0.7522732615470886,
        "val_loss": 8.043848512378255e-05,
        "train_loss": 7.462601059197246e-05
      },
      {
        "epoch": 52,
        "reward": 0.7480146288871765,
        "val_loss": 8.417818025918677e-05,
        "train_loss": 7.158271532366947e-05
      },
      {
        "epoch": 53,
        "reward": 0.7469884753227234,
        "val_loss": 8.509851821664987e-05,
        "train_loss": 7.543930139447114e-05
      },
      {
        "epoch": 54,
        "reward": 0.7500264048576355,
        "val_loss": 8.239570057152637e-05,
        "train_loss": 7.098874546220311e-05
      },
      {
        "epoch": 55,
        "reward": 0.7414252758026123,
        "val_loss": 9.022078717992242e-05,
        "train_loss": 7.796215490648487e-05
      },
      {
        "epoch": 56,
        "reward": 0.7536548972129822,
        "val_loss": 7.925233616593427e-05,
        "train_loss": 7.288935886698219e-05
      },
      {
        "epoch": 57,
        "reward": 0.7539168000221252,
        "val_loss": 7.902890917778547e-05,
        "train_loss": 6.893673717583554e-05
      },
      {
        "epoch": 58,
        "reward": 0.7530940175056458,
        "val_loss": 7.973222558835655e-05,
        "train_loss": 8.0597167862624e-05
      },
      {
        "epoch": 59,
        "reward": 0.737083375453949,
        "val_loss": 9.437820179820327e-05,
        "train_loss": 8.124663173265827e-05
      },
      {
        "epoch": 60,
        "reward": 0.7514287829399109,
        "val_loss": 8.116991999226489e-05,
        "train_loss": 7.544369110781609e-05
      },
      {
        "epoch": 61,
        "reward": 0.7538982033729553,
        "val_loss": 7.90448154605526e-05,
        "train_loss": 7.545349609035139e-05
      },
      {
        "epoch": 62,
        "reward": 0.7510223388671875,
        "val_loss": 8.152371758894463e-05,
        "train_loss": 7.020965547501243e-05
      },
      {
        "epoch": 63,
        "reward": 0.7525319457054138,
        "val_loss": 8.021534865422706e-05,
        "train_loss": 7.006027866597063e-05
      },
      {
        "epoch": 64,
        "reward": 0.7527556419372559,
        "val_loss": 8.002284656478358e-05,
        "train_loss": 6.961620794334941e-05
      },
      {
        "epoch": 65,
        "reward": 0.7542296648025513,
        "val_loss": 7.876273593865335e-05,
        "train_loss": 7.279786922691319e-05
      },
      {
        "epoch": 66,
        "reward": 0.7522243857383728,
        "val_loss": 8.04806113592349e-05,
        "train_loss": 7.518845953969643e-05
      },
      {
        "epoch": 67,
        "reward": 0.7507275938987732,
        "val_loss": 8.178106457177949e-05,
        "train_loss": 7.771136803897277e-05
      },
      {
        "epoch": 68,
        "reward": 0.7430185079574585,
        "val_loss": 8.873066898169262e-05,
        "train_loss": 7.476577131735842e-05
      },
      {
        "epoch": 69,
        "reward": 0.7489928603172302,
        "val_loss": 8.33078333276457e-05,
        "train_loss": 7.774253446349085e-05
      },
      {
        "epoch": 70,
        "reward": 0.7482046484947205,
        "val_loss": 8.400864369052994e-05,
        "train_loss": 7.28134705940857e-05
      },
      {
        "epoch": 71,
        "reward": 0.7460079789161682,
        "val_loss": 8.598489720108253e-05,
        "train_loss": 6.950238369650099e-05
      },
      {
        "epoch": 72,
        "reward": 0.7541518211364746,
        "val_loss": 7.88288754327888e-05,
        "train_loss": 7.158725398207585e-05
      },
      {
        "epoch": 73,
        "reward": 0.7515636086463928,
        "val_loss": 8.105280098139442e-05,
        "train_loss": 7.917055504199547e-05
      },
      {
        "epoch": 74,
        "reward": 0.7162184119224548,
        "val_loss": 0.00011645188767163615,
        "train_loss": 7.751071181981108e-05
      },
      {
        "epoch": 75,
        "reward": 0.7539512515068054,
        "val_loss": 7.899955848448112e-05,
        "train_loss": 8.97099766566848e-05
      },
      {
        "epoch": 76,
        "reward": 0.7529662847518921,
        "val_loss": 7.984184256721554e-05,
        "train_loss": 7.65121273546426e-05
      },
      {
        "epoch": 77,
        "reward": 0.7524736523628235,
        "val_loss": 8.026559433866558e-05,
        "train_loss": 7.818911525156672e-05
      },
      {
        "epoch": 78,
        "reward": 0.7531275749206543,
        "val_loss": 7.970345801108383e-05,
        "train_loss": 8.29968255577394e-05
      },
      {
        "epoch": 79,
        "reward": 0.7545328140258789,
        "val_loss": 7.850543209185292e-05,
        "train_loss": 8.940986103530471e-05
      },
      {
        "epoch": 80,
        "reward": 0.7545003294944763,
        "val_loss": 7.85329591183524e-05,
        "train_loss": 6.93226758218001e-05
      },
      {
        "epoch": 81,
        "reward": 0.7541511654853821,
        "val_loss": 7.882946478535555e-05,
        "train_loss": 7.103463574017391e-05
      },
      {
        "epoch": 82,
        "reward": 0.7545091509819031,
        "val_loss": 7.852549294641773e-05,
        "train_loss": 6.954258620121087e-05
      },
      {
        "epoch": 83,
        "reward": 0.7545327544212341,
        "val_loss": 7.850555994082242e-05,
        "train_loss": 8.011793117755308e-05
      },
      {
        "epoch": 84,
        "reward": 0.7544965744018555,
        "val_loss": 7.853612415991458e-05,
        "train_loss": 7.748944797360589e-05
      },
      {
        "epoch": 85,
        "reward": 0.7540358901023865,
        "val_loss": 7.8927561324755e-05,
        "train_loss": 6.986439796736914e-05
      },
      {
        "epoch": 86,
        "reward": 0.7412415146827698,
        "val_loss": 9.03938790932963e-05,
        "train_loss": 7.232764367542516e-05
      },
      {
        "epoch": 87,
        "reward": 0.7539464831352234,
        "val_loss": 7.90037021423424e-05,
        "train_loss": 7.356011169926765e-05
      },
      {
        "epoch": 88,
        "reward": 0.7457829117774963,
        "val_loss": 8.618937655618148e-05,
        "train_loss": 7.212070634593077e-05
      },
      {
        "epoch": 89,
        "reward": 0.7534744143486023,
        "val_loss": 7.940652566113775e-05,
        "train_loss": 8.149369191064929e-05
      },
      {
        "epoch": 90,
        "reward": 0.7528787851333618,
        "val_loss": 7.991698865745483e-05,
        "train_loss": 7.705500991925455e-05
      },
      {
        "epoch": 91,
        "reward": 0.7527015805244446,
        "val_loss": 8.00693326579806e-05,
        "train_loss": 7.434415130529278e-05
      },
      {
        "epoch": 92,
        "reward": 0.7490720748901367,
        "val_loss": 8.323768374144233e-05,
        "train_loss": 7.13694348982804e-05
      },
      {
        "epoch": 93,
        "reward": 0.7541642189025879,
        "val_loss": 7.881838610046543e-05,
        "train_loss": 7.625040878058196e-05
      },
      {
        "epoch": 94,
        "reward": 0.7322210669517517,
        "val_loss": 9.920593687898613e-05,
        "train_loss": 7.368772276095115e-05
      },
      {
        "epoch": 95,
        "reward": 0.7041552066802979,
        "val_loss": 0.00013093632878735662,
        "train_loss": 8.646545169400409e-05
      },
      {
        "epoch": 96,
        "reward": 0.7539567947387695,
        "val_loss": 7.899492525861465e-05,
        "train_loss": 9.276396303903311e-05
      },
      {
        "epoch": 97,
        "reward": 0.748254656791687,
        "val_loss": 8.396396567280005e-05,
        "train_loss": 7.677426604529431e-05
      },
      {
        "epoch": 98,
        "reward": 0.752471923828125,
        "val_loss": 8.026709162680033e-05,
        "train_loss": 7.5538040479072e-05
      },
      {
        "epoch": 99,
        "reward": 0.7518535852432251,
        "val_loss": 8.080135947758598e-05,
        "train_loss": 7.667323622557048e-05
      },
      {
        "epoch": 100,
        "reward": 0.7484669089317322,
        "val_loss": 8.377497839059547e-05,
        "train_loss": 6.956723154871725e-05
      },
      {
        "epoch": 101,
        "reward": 0.7506889700889587,
        "val_loss": 8.181485463865101e-05,
        "train_loss": 7.121144119537348e-05
      },
      {
        "epoch": 102,
        "reward": 0.7543227076530457,
        "val_loss": 7.86836608313024e-05,
        "train_loss": 7.0727646044151e-05
      },
      {
        "epoch": 103,
        "reward": 0.7378606200218201,
        "val_loss": 9.36235602629105e-05,
        "train_loss": 7.285570259577631e-05
      },
      {
        "epoch": 104,
        "reward": 0.747670590877533,
        "val_loss": 8.44858581591065e-05,
        "train_loss": 8.323516773928601e-05
      },
      {
        "epoch": 105,
        "reward": 0.7532137632369995,
        "val_loss": 7.962961015956742e-05,
        "train_loss": 7.61370679706138e-05
      },
      {
        "epoch": 106,
        "reward": 0.7536541223526001,
        "val_loss": 7.925302738190762e-05,
        "train_loss": 7.371321687689767e-05
      },
      {
        "epoch": 107,
        "reward": 0.7516701817512512,
        "val_loss": 8.09603464274135e-05,
        "train_loss": 7.087493409366849e-05
      },
      {
        "epoch": 108,
        "reward": 0.7502099871635437,
        "val_loss": 8.223440974169145e-05,
        "train_loss": 7.195026654909061e-05
      },
      {
        "epoch": 109,
        "reward": 0.7502620816230774,
        "val_loss": 8.218870633364921e-05,
        "train_loss": 7.358070552772215e-05
      },
      {
        "epoch": 110,
        "reward": 0.7533286213874817,
        "val_loss": 7.953126935587664e-05,
        "train_loss": 8.122494965881252e-05
      },
      {
        "epoch": 111,
        "reward": 0.7514855265617371,
        "val_loss": 8.112067059430826e-05,
        "train_loss": 7.113509160971122e-05
      },
      {
        "epoch": 112,
        "reward": 0.7543497681617737,
        "val_loss": 7.866071298069852e-05,
        "train_loss": 6.964479829408586e-05
      },
      {
        "epoch": 113,
        "reward": 0.7494038343429565,
        "val_loss": 8.294421110934178e-05,
        "train_loss": 7.251364107875046e-05
      },
      {
        "epoch": 114,
        "reward": 0.7544079422950745,
        "val_loss": 7.861133001694855e-05,
        "train_loss": 7.372444651292216e-05
      },
      {
        "epoch": 115,
        "reward": 0.75346440076828,
        "val_loss": 7.941510141660859e-05,
        "train_loss": 8.013878840966544e-05
      },
      {
        "epoch": 116,
        "reward": 0.7543407082557678,
        "val_loss": 7.866839795107288e-05,
        "train_loss": 7.110814840416424e-05
      },
      {
        "epoch": 117,
        "reward": 0.7413890957832336,
        "val_loss": 9.025486256827467e-05,
        "train_loss": 8.134620699050944e-05
      },
      {
        "epoch": 118,
        "reward": 0.7359175086021423,
        "val_loss": 9.551908650402246e-05,
        "train_loss": 8.577217844364126e-05
      },
      {
        "epoch": 119,
        "reward": 0.7533270716667175,
        "val_loss": 7.9532598777275e-05,
        "train_loss": 7.65096564761664e-05
      },
      {
        "epoch": 120,
        "reward": 0.7269319295883179,
        "val_loss": 0.00010467031721158751,
        "train_loss": 7.265754328937664e-05
      },
      {
        "epoch": 121,
        "reward": 0.7541035413742065,
        "val_loss": 7.88699762779288e-05,
        "train_loss": 7.892827278947852e-05
      },
      {
        "epoch": 122,
        "reward": 0.7542290091514587,
        "val_loss": 7.876331489699493e-05,
        "train_loss": 7.079130535622916e-05
      },
      {
        "epoch": 123,
        "reward": 0.7495009899139404,
        "val_loss": 8.285847122481625e-05,
        "train_loss": 8.540535488394268e-05
      },
      {
        "epoch": 124,
        "reward": 0.7543908357620239,
        "val_loss": 7.86259068783173e-05,
        "train_loss": 7.471817508093618e-05
      },
      {
        "epoch": 125,
        "reward": 0.7471966743469238,
        "val_loss": 8.491117166288729e-05,
        "train_loss": 7.839624483424884e-05
      },
      {
        "epoch": 126,
        "reward": 0.7427381873130798,
        "val_loss": 8.899148503717567e-05,
        "train_loss": 7.359097127426558e-05
      },
      {
        "epoch": 127,
        "reward": 0.7545077800750732,
        "val_loss": 7.852663839003071e-05,
        "train_loss": 7.933815896439437e-05
      },
      {
        "epoch": 128,
        "reward": 0.7524263262748718,
        "val_loss": 8.030639583012089e-05,
        "train_loss": 6.891984966618845e-05
      },
      {
        "epoch": 129,
        "reward": 0.7534914612770081,
        "val_loss": 7.939192853102992e-05,
        "train_loss": 7.05278332763835e-05
      },
      {
        "epoch": 130,
        "reward": 0.7500341534614563,
        "val_loss": 8.238883466609488e-05,
        "train_loss": 7.081389216741976e-05
      },
      {
        "epoch": 131,
        "reward": 0.7462663054466248,
        "val_loss": 8.575068828317203e-05,
        "train_loss": 7.254059108583114e-05
      },
      {
        "epoch": 132,
        "reward": 0.7431135177612305,
        "val_loss": 8.864239706391735e-05,
        "train_loss": 7.53562566947389e-05
      },
      {
        "epoch": 133,
        "reward": 0.7393065690994263,
        "val_loss": 9.22317402520483e-05,
        "train_loss": 7.011682788953085e-05
      },
      {
        "epoch": 134,
        "reward": 0.724502444267273,
        "val_loss": 0.00010725688376364165,
        "train_loss": 7.441437362733547e-05
      },
      {
        "epoch": 135,
        "reward": 0.7515877485275269,
        "val_loss": 8.103181763934637e-05,
        "train_loss": 9.076923966998808e-05
      },
      {
        "epoch": 136,
        "reward": 0.7540568709373474,
        "val_loss": 7.890971755841747e-05,
        "train_loss": 7.084684636118673e-05
      },
      {
        "epoch": 137,
        "reward": 0.7508391737937927,
        "val_loss": 8.168360623780504e-05,
        "train_loss": 6.934278509946195e-05
      },
      {
        "epoch": 138,
        "reward": 0.7505137920379639,
        "val_loss": 8.196807435264677e-05,
        "train_loss": 7.262905441726056e-05
      },
      {
        "epoch": 139,
        "reward": 0.7528205513954163,
        "val_loss": 7.996701398431989e-05,
        "train_loss": 7.172163255885467e-05
      },
      {
        "epoch": 140,
        "reward": 0.7538594603538513,
        "val_loss": 7.907782544082562e-05,
        "train_loss": 7.244691690944959e-05
      },
      {
        "epoch": 141,
        "reward": 0.7530389428138733,
        "val_loss": 7.977949384699709e-05,
        "train_loss": 7.168192748325125e-05
      },
      {
        "epoch": 142,
        "reward": 0.7521295547485352,
        "val_loss": 8.05625771006037e-05,
        "train_loss": 7.165010752666709e-05
      },
      {
        "epoch": 143,
        "reward": 0.7510737776756287,
        "val_loss": 8.147885351458431e-05,
        "train_loss": 7.309673184443874e-05
      },
      {
        "epoch": 144,
        "reward": 0.7544037699699402,
        "val_loss": 7.861489679531328e-05,
        "train_loss": 8.063514710206968e-05
      },
      {
        "epoch": 145,
        "reward": 0.7515384554862976,
        "val_loss": 8.10746943378555e-05,
        "train_loss": 7.535099659715063e-05
      },
      {
        "epoch": 146,
        "reward": 0.750823438167572,
        "val_loss": 8.16973099842601e-05,
        "train_loss": 8.229022904952917e-05
      },
      {
        "epoch": 147,
        "reward": 0.7350949645042419,
        "val_loss": 9.633028093958274e-05,
        "train_loss": 7.354266031493003e-05
      },
      {
        "epoch": 148,
        "reward": 0.7543296217918396,
        "val_loss": 7.867787748442165e-05,
        "train_loss": 7.723327325948048e-05
      },
      {
        "epoch": 149,
        "reward": 0.7506851553916931,
        "val_loss": 8.181821613106877e-05,
        "train_loss": 7.053154870216252e-05
      },
      {
        "epoch": 150,
        "reward": 0.7543758153915405,
        "val_loss": 7.863860602291035e-05,
        "train_loss": 7.639618035262593e-05
      },
      {
        "epoch": 151,
        "reward": 0.7328817844390869,
        "val_loss": 9.85390059733098e-05,
        "train_loss": 7.380738917653126e-05
      },
      {
        "epoch": 152,
        "reward": 0.7476624846458435,
        "val_loss": 8.449320271860675e-05,
        "train_loss": 8.181254760039828e-05
      },
      {
        "epoch": 153,
        "reward": 0.7427330613136292,
        "val_loss": 8.899622584327258e-05,
        "train_loss": 7.436817199609672e-05
      },
      {
        "epoch": 154,
        "reward": 0.7499291300773621,
        "val_loss": 8.248116604850761e-05,
        "train_loss": 8.032954330981459e-05
      },
      {
        "epoch": 155,
        "reward": 0.7543424367904663,
        "val_loss": 7.866696406771163e-05,
        "train_loss": 7.07561731675154e-05
      },
      {
        "epoch": 156,
        "reward": 0.7544047832489014,
        "val_loss": 7.861403147606845e-05,
        "train_loss": 7.218368773465045e-05
      },
      {
        "epoch": 157,
        "reward": 0.7542099356651306,
        "val_loss": 7.877944725415935e-05,
        "train_loss": 7.291072940391202e-05
      },
      {
        "epoch": 158,
        "reward": 0.7537433505058289,
        "val_loss": 7.917682887637056e-05,
        "train_loss": 7.591012441620338e-05
      },
      {
        "epoch": 159,
        "reward": 0.7527438998222351,
        "val_loss": 8.003293312088187e-05,
        "train_loss": 7.105808264476273e-05
      },
      {
        "epoch": 160,
        "reward": 0.7542270421981812,
        "val_loss": 7.876501123454156e-05,
        "train_loss": 7.673324734451644e-05
      },
      {
        "epoch": 161,
        "reward": 0.7545081377029419,
        "val_loss": 7.852639828342944e-05,
        "train_loss": 7.061879533956436e-05
      },
      {
        "epoch": 162,
        "reward": 0.7406401038169861,
        "val_loss": 9.096210851566866e-05,
        "train_loss": 7.424385638352341e-05
      },
      {
        "epoch": 163,
        "reward": 0.7538040280342102,
        "val_loss": 7.912504328747414e-05,
        "train_loss": 7.76691455170154e-05
      },
      {
        "epoch": 164,
        "reward": 0.7487050294876099,
        "val_loss": 8.356322879470619e-05,
        "train_loss": 8.31783657374147e-05
      },
      {
        "epoch": 165,
        "reward": 0.7498309016227722,
        "val_loss": 8.256756908459855e-05,
        "train_loss": 8.124059492659468e-05
      },
      {
        "epoch": 166,
        "reward": 0.7167059779167175,
        "val_loss": 0.00011589425100412752,
        "train_loss": 7.944310303943124e-05
      },
      {
        "epoch": 167,
        "reward": 0.7378231287002563,
        "val_loss": 9.365980908374436e-05,
        "train_loss": 8.435995005129371e-05
      },
      {
        "epoch": 168,
        "reward": 0.7472042441368103,
        "val_loss": 8.490433745984254e-05,
        "train_loss": 7.261541920273045e-05
      },
      {
        "epoch": 169,
        "reward": 0.7506173253059387,
        "val_loss": 8.18775468880111e-05,
        "train_loss": 7.171515937023706e-05
      },
      {
        "epoch": 170,
        "reward": 0.7544151544570923,
        "val_loss": 7.860522756735528e-05,
        "train_loss": 7.792225747275203e-05
      },
      {
        "epoch": 171,
        "reward": 0.7543439865112305,
        "val_loss": 7.866560658190533e-05,
        "train_loss": 7.224778468858298e-05
      },
      {
        "epoch": 172,
        "reward": 0.7424737811088562,
        "val_loss": 8.923796745615878e-05,
        "train_loss": 7.201317566796206e-05
      },
      {
        "epoch": 173,
        "reward": 0.7514603137969971,
        "val_loss": 8.114248443494685e-05,
        "train_loss": 7.69624644257979e-05
      },
      {
        "epoch": 174,
        "reward": 0.7484405636787415,
        "val_loss": 8.379843451880984e-05,
        "train_loss": 7.160803586605022e-05
      },
      {
        "epoch": 175,
        "reward": 0.75043785572052,
        "val_loss": 8.203458907831061e-05,
        "train_loss": 7.25054912716307e-05
      },
      {
        "epoch": 176,
        "reward": 0.7328957915306091,
        "val_loss": 9.852493842897405e-05,
        "train_loss": 7.583228370304614e-05
      },
      {
        "epoch": 177,
        "reward": 0.7506992220878601,
        "val_loss": 8.180580698535778e-05,
        "train_loss": 8.340631995032218e-05
      },
      {
        "epoch": 178,
        "reward": 0.7499399781227112,
        "val_loss": 8.247165325363832e-05,
        "train_loss": 7.219513988205178e-05
      },
      {
        "epoch": 179,
        "reward": 0.75264972448349,
        "val_loss": 8.011403302329459e-05,
        "train_loss": 7.653827480698265e-05
      },
      {
        "epoch": 180,
        "reward": 0.7522205710411072,
        "val_loss": 8.04839052891891e-05,
        "train_loss": 7.527730877672393e-05
      },
      {
        "epoch": 181,
        "reward": 0.7358811497688293,
        "val_loss": 9.555481561359816e-05,
        "train_loss": 7.783765753489346e-05
      },
      {
        "epoch": 182,
        "reward": 0.7539941668510437,
        "val_loss": 7.896306903733472e-05,
        "train_loss": 7.76556358477347e-05
      },
      {
        "epoch": 183,
        "reward": 0.7545099854469299,
        "val_loss": 7.85247705477689e-05,
        "train_loss": 6.944644825833935e-05
      },
      {
        "epoch": 184,
        "reward": 0.7526528835296631,
        "val_loss": 8.011124373297207e-05,
        "train_loss": 7.192495398227878e-05
      },
      {
        "epoch": 185,
        "reward": 0.7511850595474243,
        "val_loss": 8.13819736192402e-05,
        "train_loss": 7.186883548316613e-05
      },
      {
        "epoch": 186,
        "reward": 0.7432375550270081,
        "val_loss": 8.852722281257488e-05,
        "train_loss": 7.043025855707059e-05
      },
      {
        "epoch": 187,
        "reward": 0.7365238666534424,
        "val_loss": 9.492447549876357e-05,
        "train_loss": 7.512149386457168e-05
      },
      {
        "epoch": 188,
        "reward": 0.7538030743598938,
        "val_loss": 7.91258956139375e-05,
        "train_loss": 7.318272551296664e-05
      },
      {
        "epoch": 189,
        "reward": 0.7522347569465637,
        "val_loss": 8.047170350827011e-05,
        "train_loss": 7.20950837813479e-05
      },
      {
        "epoch": 190,
        "reward": 0.754176914691925,
        "val_loss": 7.880753348997262e-05,
        "train_loss": 7.213039806139513e-05
      },
      {
        "epoch": 191,
        "reward": 0.7469955682754517,
        "val_loss": 8.509209874318913e-05,
        "train_loss": 7.851572123539742e-05
      },
      {
        "epoch": 192,
        "reward": 0.7544695734977722,
        "val_loss": 7.855900600718866e-05,
        "train_loss": 7.452641637848082e-05
      },
      {
        "epoch": 193,
        "reward": 0.7530194520950317,
        "val_loss": 7.979627272496665e-05,
        "train_loss": 7.221878877317067e-05
      },
      {
        "epoch": 194,
        "reward": 0.7496871948242188,
        "val_loss": 8.269423571099261e-05,
        "train_loss": 7.633868251734664e-05
      },
      {
        "epoch": 195,
        "reward": 0.7529252171516418,
        "val_loss": 7.987712160684168e-05,
        "train_loss": 7.64323947525834e-05
      },
      {
        "epoch": 196,
        "reward": 0.7503876686096191,
        "val_loss": 8.207855613103934e-05,
        "train_loss": 7.038924426384395e-05
      },
      {
        "epoch": 197,
        "reward": 0.7512080073356628,
        "val_loss": 8.136201670692702e-05,
        "train_loss": 7.254375004077492e-05
      },
      {
        "epoch": 198,
        "reward": 0.7536771893501282,
        "val_loss": 7.923331629301953e-05,
        "train_loss": 7.144254840778348e-05
      },
      {
        "epoch": 199,
        "reward": 0.7541958689689636,
        "val_loss": 7.879141204674462e-05,
        "train_loss": 7.412365966257102e-05
      }
    ]
  }
}