{
  "experiment_info": {
    "experiment_name": "Nguyen-9",
    "dataset_name": "Nguyen-9",
    "timestamp": "2025-08-30T23:53:35.234624",
    "random_seed": null
  },
  "model_config": {
    "input_size": 2,
    "output_size": 1,
    "num_layers": 3,
    "nonlinear_info": [
      [
        2,
        0
      ],
      [
        2,
        0
      ],
      [
        0,
        0
      ]
    ],
    "function_set": [
      "SafeIdentityFunction",
      "SafeExp",
      "SafeLog",
      "SafeSin",
      "SafePower",
      "SafeCos",
      "ExpSwitchActivation"
    ]
  },
  "training_config": {
    "num_epochs": 2000,
    "batch_size": 32,
    "learning_rate": 0.01,
    "reg_strength": 0.0,
    "scheduler": "none"
  },
  "final_equation": {
    "equation_string": "Matrix([[-1.26607*sin(0.336664795875549*x1**0.798251 - 0.278476148843765*x1 - 0.278476148843765*x2 + 0.336664795875549*x2**4.81033) + 1.37491*sin(0.832497894763947*x1**0.798251 + 0.280080169439316*x1 + 0.280080169439316*x2 + 0.832497894763947*x2**4.81033)]])",
    "equation_latex": "Matrix([[-1.26607*sin(0.336664795875549*x1**0.798251 - 0.278476148843765*x1 - 0.278476148843765*x2 + 0.336664795875549*x2**4.81033) + 1.37491*sin(0.832497894763947*x1**0.798251 + 0.280080169439316*x1 + 0.280080169439316*x2 + 0.832497894763947*x2**4.81033)]])"
  },
  "evaluation_metrics": {
    "mse": "0.0017183869",
    "rmse": "0.04145343",
    "mae": "0.0287904"
  },
  "data_info": {
    "train_ratio": 0.8,
    "uncertainty_value": 0.0,
    "path_to_data": "/Users/pablocornejo/Documents/Tesis/SRNetwork/data/raw/nguyen.txt"
  },
  "lbfgs_optimization": {
    "enabled": true,
    "success": true,
    "message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
    "function_evaluations": 9,
    "gradient_evaluations": 9,
    "final_loss": 0.12237542324447155,
    "max_iterations": 1000,
    "tolerance": "1e-8",
    "criterion": "nrmse"
  },
  "lbfgs_topk_optimization": {
    "enabled": true,
    "num_models_optimized": 5,
    "optimization_summary": [
      {
        "rank": 1,
        "original_epoch": 865,
        "original_val_loss": 0.0015819765394553542,
        "optimized_val_loss": "0.0017183869",
        "improvement_percent": "-8.62278",
        "original_equation": "Matrix([[-1.26637*sin(0.336366981267929*x1**0.798209 - 0.280218362808228*x1 - 0.280218362808228*x2 + 0.336366981267929*x2**4.81032) + 1.37544*sin(0.832711756229401*x1**0.798209 + 0.281637668609619*x1 + 0.281637668609619*x2 + 0.832711756229401*x2**4.81032)]])",
        "optimized_equation": "Matrix([[-1.26607*sin(0.336664795875549*x1**0.798251 - 0.278476148843765*x1 - 0.278476148843765*x2 + 0.336664795875549*x2**4.81033) + 1.37491*sin(0.832497894763947*x1**0.798251 + 0.280080169439316*x1 + 0.280080169439316*x2 + 0.832497894763947*x2**4.81033)]])",
        "optimization_success": true,
        "function_evaluations": 9,
        "final_loss": 0.12237542324447155
      },
      {
        "rank": 2,
        "original_epoch": 931,
        "original_val_loss": 0.001586020749527961,
        "optimized_val_loss": "0.0017201027",
        "improvement_percent": "-8.453991",
        "original_equation": "Matrix([[-1.25422*sin(0.336223125457764*x1**0.769842 - 0.283220946788788*x1 - 0.283220946788788*x2 + 0.336223125457764*x2**4.73136) + 1.37977*sin(0.811624348163605*x1**0.769842 + 0.281662553548813*x1 + 0.281662553548813*x2 + 0.811624348163605*x2**4.73136)]])",
        "optimized_equation": "Matrix([[-1.25377*sin(0.336534768342972*x1**0.769907 - 0.2808698117733*x1 - 0.2808698117733*x2 + 0.336534768342972*x2**4.73138) + 1.37907*sin(0.811377942562103*x1**0.769907 + 0.279392123222351*x1 + 0.279392123222351*x2 + 0.811377942562103*x2**4.73138)]])",
        "optimization_success": true,
        "function_evaluations": 11,
        "final_loss": 0.1223590544398209
      },
      {
        "rank": 3,
        "original_epoch": 1017,
        "original_val_loss": 0.0015856218025354402,
        "optimized_val_loss": "0.0017218977",
        "improvement_percent": "-8.594477",
        "original_equation": "Matrix([[-1.23149*sin(0.329326301813126*x1**0.774522 - 0.286490023136139*x1 - 0.286490023136139*x2 + 0.329326301813126*x2**4.68081) + 1.38597*sin(0.78892308473587*x1**0.774522 + 0.282011806964874*x1 + 0.282011806964874*x2 + 0.78892308473587*x2**4.68081)]])",
        "optimized_equation": "Matrix([[-1.23107*sin(0.329659670591354*x1**0.774572 - 0.28425994515419*x1 - 0.28425994515419*x2 + 0.329659670591354*x2**4.68082) + 1.38531*sin(0.788688182830811*x1**0.774572 + 0.279883474111557*x1 + 0.279883474111557*x2 + 0.788688182830811*x2**4.68082)]])",
        "optimization_success": true,
        "function_evaluations": 9,
        "final_loss": 0.1220959953303343
      },
      {
        "rank": 4,
        "original_epoch": 701,
        "original_val_loss": 0.0015823130046815745,
        "optimized_val_loss": "0.0017220106",
        "improvement_percent": "-8.828694",
        "original_equation": "Matrix([[-1.23582*sin(0.310641825199127*x1**0.808919 - 0.288006037473679*x1 - 0.288006037473679*x2 + 0.310641825199127*x2**4.8089) + 1.3308*sin(0.833883106708527*x1**0.808919 + 0.290810227394104*x1 + 0.290810227394104*x2 + 0.833883106708527*x2**4.8089)]])",
        "optimized_equation": "Matrix([[-1.23553*sin(0.311107158660889*x1**0.808969 - 0.286136567592621*x1 - 0.286136567592621*x2 + 0.311107158660889*x2**4.80891) + 1.33015*sin(0.833589136600494*x1**0.808969 + 0.28936094045639*x1 + 0.28936094045639*x2 + 0.833589136600494*x2**4.80891)]])",
        "optimization_success": true,
        "function_evaluations": 11,
        "final_loss": 0.12172383192773169
      },
      {
        "rank": 5,
        "original_epoch": 1145,
        "original_val_loss": 0.0015845811909197696,
        "optimized_val_loss": "0.0017285264",
        "improvement_percent": "-9.084118",
        "original_equation": "Matrix([[-1.21157*sin(0.344364792108536*x1**0.802894 - 0.283346652984619*x1 - 0.283346652984619*x2 + 0.344364792108536*x2**4.80715) + 1.39516*sin(0.825693368911743*x1**0.802894 + 0.285212308168411*x1 + 0.285212308168411*x2 + 0.825693368911743*x2**4.80715)]])",
        "optimized_equation": "Matrix([[-1.21123*sin(0.344651132822037*x1**0.802944 - 0.281588494777679*x1 - 0.281588494777679*x2 + 0.344651132822037*x2**4.80716) + 1.39459*sin(0.825468838214874*x1**0.802944 + 0.283524006605148*x1 + 0.283524006605148*x2 + 0.825468838214874*x2**4.80716)]])",
        "optimization_success": true,
        "function_evaluations": 8,
        "final_loss": 0.12256862690088603
      }
    ],
    "best_model": {
      "original_val_loss": 0.0015819765394553542,
      "optimized_val_loss": "0.0017183869",
      "improvement_percent": "-8.62278",
      "equation": "Matrix([[-1.26607*sin(0.336664795875549*x1**0.798251 - 0.278476148843765*x1 - 0.278476148843765*x2 + 0.336664795875549*x2**4.81033) + 1.37491*sin(0.832497894763947*x1**0.798251 + 0.280080169439316*x1 + 0.280080169439316*x2 + 0.832497894763947*x2**4.81033)]])",
      "optimization_iterations": 3
    }
  },
  "reward_tracking": {
    "reward_type": "nrmse",
    "reward_interval": 1,
    "num_measurements": 2000,
    "initial_reward": 0.15980786085128784,
    "final_reward": 0.43107128143310547,
    "best_reward": 0.45707663893699646,
    "worst_reward": 0.15980786085128784,
    "average_reward": 0.44426425983011725,
    "reward_history": [
      {
        "epoch": 0,
        "reward": 0.15980786085128784,
        "val_loss": 0.030992882060153142,
        "train_loss": 0.20881200194931948
      },
      {
        "epoch": 1,
        "reward": 0.22493517398834229,
        "val_loss": 0.01331258418836764,
        "train_loss": 0.013798221862788732
      },
      {
        "epoch": 2,
        "reward": 0.2534540891647339,
        "val_loss": 0.009727819024452142,
        "train_loss": 0.010426024763056865
      },
      {
        "epoch": 3,
        "reward": 0.27006494998931885,
        "val_loss": 0.008190926763096027,
        "train_loss": 0.008408994207946727
      },
      {
        "epoch": 4,
        "reward": 0.28500574827194214,
        "val_loss": 0.007056656892278365,
        "train_loss": 0.007164137956194212
      },
      {
        "epoch": 5,
        "reward": 0.2980055809020996,
        "val_loss": 0.006221850602222341,
        "train_loss": 0.0064035395984179695
      },
      {
        "epoch": 6,
        "reward": 0.3120598793029785,
        "val_loss": 0.005449121485331229,
        "train_loss": 0.0056246014428325
      },
      {
        "epoch": 7,
        "reward": 0.3250479996204376,
        "val_loss": 0.004834502303440656,
        "train_loss": 0.005392163812827606
      },
      {
        "epoch": 8,
        "reward": 0.335957407951355,
        "val_loss": 0.004380508059901851,
        "train_loss": 0.004562198569496663
      },
      {
        "epoch": 9,
        "reward": 0.34584373235702515,
        "val_loss": 0.004011477576568723,
        "train_loss": 0.0045255364563602666
      },
      {
        "epoch": 10,
        "reward": 0.35691580176353455,
        "val_loss": 0.003640032173799617,
        "train_loss": 0.003729536151975201
      },
      {
        "epoch": 11,
        "reward": 0.36652451753616333,
        "val_loss": 0.00334930419921875,
        "train_loss": 0.0035070572048425674
      },
      {
        "epoch": 12,
        "reward": 0.3735416829586029,
        "val_loss": 0.003153604654861348,
        "train_loss": 0.0034308107972789844
      },
      {
        "epoch": 13,
        "reward": 0.3820313513278961,
        "val_loss": 0.0029338362427162273,
        "train_loss": 0.002951695724802378
      },
      {
        "epoch": 14,
        "reward": 0.39009496569633484,
        "val_loss": 0.0027408466641125934,
        "train_loss": 0.002735128191908678
      },
      {
        "epoch": 15,
        "reward": 0.3961680829524994,
        "val_loss": 0.0026047995779663324,
        "train_loss": 0.003003000129515735
      },
      {
        "epoch": 16,
        "reward": 0.39639270305633545,
        "val_loss": 0.002599912362971476,
        "train_loss": 0.002447242283079294
      },
      {
        "epoch": 17,
        "reward": 0.407379150390625,
        "val_loss": 0.00237277863613729,
        "train_loss": 0.00251470988867088
      },
      {
        "epoch": 18,
        "reward": 0.40794453024864197,
        "val_loss": 0.00236169363571597,
        "train_loss": 0.0023380623628886845
      },
      {
        "epoch": 19,
        "reward": 0.41498667001724243,
        "val_loss": 0.0022282521573028396,
        "train_loss": 0.0022996792417521086
      },
      {
        "epoch": 20,
        "reward": 0.41898971796035767,
        "val_loss": 0.0021560653944366743,
        "train_loss": 0.0022115897915612618
      },
      {
        "epoch": 21,
        "reward": 0.42026957869529724,
        "val_loss": 0.0021335231639178736,
        "train_loss": 0.002529972004525077
      },
      {
        "epoch": 22,
        "reward": 0.4213225543498993,
        "val_loss": 0.0021151668957567643,
        "train_loss": 0.0021380933491435337
      },
      {
        "epoch": 23,
        "reward": 0.42478060722351074,
        "val_loss": 0.0020560737965362413,
        "train_loss": 0.0021267315197082306
      },
      {
        "epoch": 24,
        "reward": 0.42770513892173767,
        "val_loss": 0.0020074824070824043,
        "train_loss": 0.002103150415278011
      },
      {
        "epoch": 25,
        "reward": 0.4287082850933075,
        "val_loss": 0.0019911002600565553,
        "train_loss": 0.0021023435944628613
      },
      {
        "epoch": 26,
        "reward": 0.43041935563087463,
        "val_loss": 0.001963487161057336,
        "train_loss": 0.002102972639617152
      },
      {
        "epoch": 27,
        "reward": 0.4302511215209961,
        "val_loss": 0.001966183040557163,
        "train_loss": 0.002086040407168464
      },
      {
        "epoch": 28,
        "reward": 0.43368497490882874,
        "val_loss": 0.001911914341949991,
        "train_loss": 0.0020604423335288838
      },
      {
        "epoch": 29,
        "reward": 0.4347052574157715,
        "val_loss": 0.0018960993703720824,
        "train_loss": 0.002063445980288984
      },
      {
        "epoch": 30,
        "reward": 0.4358690679073334,
        "val_loss": 0.001878229618471648,
        "train_loss": 0.002062200393643602
      },
      {
        "epoch": 31,
        "reward": 0.435378760099411,
        "val_loss": 0.0018857359620077269,
        "train_loss": 0.002196358236967801
      },
      {
        "epoch": 32,
        "reward": 0.43615418672561646,
        "val_loss": 0.0018738791945257357,
        "train_loss": 0.002056159061654538
      },
      {
        "epoch": 33,
        "reward": 0.4389001429080963,
        "val_loss": 0.0018325253622606397,
        "train_loss": 0.0021327949899177137
      },
      {
        "epoch": 34,
        "reward": 0.4370623230934143,
        "val_loss": 0.0018600943398528866,
        "train_loss": 0.0020797541678453293
      },
      {
        "epoch": 35,
        "reward": 0.4373847544193268,
        "val_loss": 0.0018552254353250777,
        "train_loss": 0.0020766998193441676
      },
      {
        "epoch": 36,
        "reward": 0.44082555174827576,
        "val_loss": 0.0018041071348956653,
        "train_loss": 0.0020775974665481886
      },
      {
        "epoch": 37,
        "reward": 0.4417175352573395,
        "val_loss": 0.0017910991861884082,
        "train_loss": 0.0020443860706179226
      },
      {
        "epoch": 38,
        "reward": 0.44130849838256836,
        "val_loss": 0.0017970515847472207,
        "train_loss": 0.002030931956351896
      },
      {
        "epoch": 39,
        "reward": 0.44151726365089417,
        "val_loss": 0.001794011240625488,
        "train_loss": 0.0023940788501372132
      },
      {
        "epoch": 40,
        "reward": 0.44361916184425354,
        "val_loss": 0.001763699875612344,
        "train_loss": 0.002083956983999367
      },
      {
        "epoch": 41,
        "reward": 0.44314733147621155,
        "val_loss": 0.0017704566208911793,
        "train_loss": 0.0020563264132271377
      },
      {
        "epoch": 42,
        "reward": 0.44296956062316895,
        "val_loss": 0.001773009608898844,
        "train_loss": 0.0021561295367204226
      },
      {
        "epoch": 43,
        "reward": 0.43140336871147156,
        "val_loss": 0.0019477925296606763,
        "train_loss": 0.0021227618227175507
      },
      {
        "epoch": 44,
        "reward": 0.4420136511325836,
        "val_loss": 0.0017868038017435797,
        "train_loss": 0.002172474064326917
      },
      {
        "epoch": 45,
        "reward": 0.4398825764656067,
        "val_loss": 0.001817965938244015,
        "train_loss": 0.002176177916296113
      },
      {
        "epoch": 46,
        "reward": 0.44500860571861267,
        "val_loss": 0.0017439605601664101,
        "train_loss": 0.0021406202073334358
      },
      {
        "epoch": 47,
        "reward": 0.4444803297519684,
        "val_loss": 0.0017514381241718574,
        "train_loss": 0.0020458418204305838
      },
      {
        "epoch": 48,
        "reward": 0.4447561204433441,
        "val_loss": 0.0017475295628953194,
        "train_loss": 0.0020346329733561454
      },
      {
        "epoch": 49,
        "reward": 0.44035908579826355,
        "val_loss": 0.0018109482313905443,
        "train_loss": 0.0020432337606997373
      },
      {
        "epoch": 50,
        "reward": 0.4441640079021454,
        "val_loss": 0.0017559313481407507,
        "train_loss": 0.002029978520742868
      },
      {
        "epoch": 51,
        "reward": 0.44378647208213806,
        "val_loss": 0.0017613106673317297,
        "train_loss": 0.0020155144593445584
      },
      {
        "epoch": 52,
        "reward": 0.4366447925567627,
        "val_loss": 0.0018664187851494976,
        "train_loss": 0.0021320623703874075
      },
      {
        "epoch": 53,
        "reward": 0.4454443156719208,
        "val_loss": 0.0017378190449172898,
        "train_loss": 0.0025147809736573924
      },
      {
        "epoch": 54,
        "reward": 0.4466382563114166,
        "val_loss": 0.001721105579885521,
        "train_loss": 0.0023842426016926765
      },
      {
        "epoch": 55,
        "reward": 0.44126254320144653,
        "val_loss": 0.001797721954062581,
        "train_loss": 0.002067733155294823
      },
      {
        "epoch": 56,
        "reward": 0.4460259974002838,
        "val_loss": 0.0017296551959589124,
        "train_loss": 0.0020312356493657436
      },
      {
        "epoch": 57,
        "reward": 0.43287020921707153,
        "val_loss": 0.001924644290868725,
        "train_loss": 0.002671762154652522
      },
      {
        "epoch": 58,
        "reward": 0.4461860656738281,
        "val_loss": 0.0017274154483207635,
        "train_loss": 0.00224766411478273
      },
      {
        "epoch": 59,
        "reward": 0.443695068359375,
        "val_loss": 0.0017626152506896428,
        "train_loss": 0.002082353950194934
      },
      {
        "epoch": 60,
        "reward": 0.4453885555267334,
        "val_loss": 0.0017386034763019,
        "train_loss": 0.002059483656641812
      },
      {
        "epoch": 61,
        "reward": 0.44378939270973206,
        "val_loss": 0.001761269082115697,
        "train_loss": 0.002080466215445015
      },
      {
        "epoch": 62,
        "reward": 0.4452939033508301,
        "val_loss": 0.0017399363652137773,
        "train_loss": 0.0020382947807845017
      },
      {
        "epoch": 63,
        "reward": 0.4382048547267914,
        "val_loss": 0.0018429038796706923,
        "train_loss": 0.0020605643244030383
      },
      {
        "epoch": 64,
        "reward": 0.4463961124420166,
        "val_loss": 0.0017244814911724202,
        "train_loss": 0.0020297011830664883
      },
      {
        "epoch": 65,
        "reward": 0.436233252286911,
        "val_loss": 0.0018726753603134836,
        "train_loss": 0.002034210815998869
      },
      {
        "epoch": 66,
        "reward": 0.4354550540447235,
        "val_loss": 0.0018845662790616708,
        "train_loss": 0.0020493173371785535
      },
      {
        "epoch": 67,
        "reward": 0.4457762837409973,
        "val_loss": 0.00173315463221765,
        "train_loss": 0.002234380616125866
      },
      {
        "epoch": 68,
        "reward": 0.4333363175392151,
        "val_loss": 0.001917350571602583,
        "train_loss": 0.002263474752768301
      },
      {
        "epoch": 69,
        "reward": 0.4440934360027313,
        "val_loss": 0.0017569366526523872,
        "train_loss": 0.00226783716173556
      },
      {
        "epoch": 70,
        "reward": 0.43981361389160156,
        "val_loss": 0.001818983707510467,
        "train_loss": 0.002026898550796502
      },
      {
        "epoch": 71,
        "reward": 0.4444630742073059,
        "val_loss": 0.001751683311470385,
        "train_loss": 0.002056813767502228
      },
      {
        "epoch": 72,
        "reward": 0.44624629616737366,
        "val_loss": 0.0017265732416750065,
        "train_loss": 0.0021427719531437526
      },
      {
        "epoch": 73,
        "reward": 0.4426921010017395,
        "val_loss": 0.0017770020141532378,
        "train_loss": 0.0020821092275582487
      },
      {
        "epoch": 74,
        "reward": 0.44638562202453613,
        "val_loss": 0.0017246276921858744,
        "train_loss": 0.0023403813471444524
      },
      {
        "epoch": 75,
        "reward": 0.4458042085170746,
        "val_loss": 0.0017327625370983566,
        "train_loss": 0.002077481697667211
      },
      {
        "epoch": 76,
        "reward": 0.444353312253952,
        "val_loss": 0.0017532413808761963,
        "train_loss": 0.002031550560017282
      },
      {
        "epoch": 77,
        "reward": 0.4464208781719208,
        "val_loss": 0.001724135920604957,
        "train_loss": 0.0020044604783694153
      },
      {
        "epoch": 78,
        "reward": 0.4458690583705902,
        "val_loss": 0.0017318533001733677,
        "train_loss": 0.002215417590028105
      },
      {
        "epoch": 79,
        "reward": 0.4428744912147522,
        "val_loss": 0.0017743770398997835,
        "train_loss": 0.0020563563523934977
      },
      {
        "epoch": 80,
        "reward": 0.4468483626842499,
        "val_loss": 0.001718182158323803,
        "train_loss": 0.0020132726271045753
      },
      {
        "epoch": 81,
        "reward": 0.4388778805732727,
        "val_loss": 0.0018328566220588982,
        "train_loss": 0.0020578394043975724
      },
      {
        "epoch": 82,
        "reward": 0.44623515009880066,
        "val_loss": 0.0017267298202828638,
        "train_loss": 0.0020325993962335186
      },
      {
        "epoch": 83,
        "reward": 0.44180989265441895,
        "val_loss": 0.0017897584142961673,
        "train_loss": 0.0020496157644979227
      },
      {
        "epoch": 84,
        "reward": 0.4351598918437958,
        "val_loss": 0.0018890982194404518,
        "train_loss": 0.0020779507780949082
      },
      {
        "epoch": 85,
        "reward": 0.44524145126342773,
        "val_loss": 0.0017406759101764432,
        "train_loss": 0.00222576308162668
      },
      {
        "epoch": 86,
        "reward": 0.44311752915382385,
        "val_loss": 0.0017708851041139237,
        "train_loss": 0.002051529405155004
      },
      {
        "epoch": 87,
        "reward": 0.4454196095466614,
        "val_loss": 0.001738166794114347,
        "train_loss": 0.00206789317595534
      },
      {
        "epoch": 88,
        "reward": 0.4455907940864563,
        "val_loss": 0.0017357592421051646,
        "train_loss": 0.002062116346608561
      },
      {
        "epoch": 89,
        "reward": 0.4358155429363251,
        "val_loss": 0.0018790473778998213,
        "train_loss": 0.002599597953331585
      },
      {
        "epoch": 90,
        "reward": 0.44491106271743774,
        "val_loss": 0.0017453387096923376,
        "train_loss": 0.0020553867234936593
      },
      {
        "epoch": 91,
        "reward": 0.44685861468315125,
        "val_loss": 0.0017180392502008804,
        "train_loss": 0.0022065867132578906
      },
      {
        "epoch": 92,
        "reward": 0.42895475029945374,
        "val_loss": 0.0019870970032310913,
        "train_loss": 0.00231602534544296
      },
      {
        "epoch": 93,
        "reward": 0.44602900743484497,
        "val_loss": 0.0017296129538278495,
        "train_loss": 0.002138768211387707
      },
      {
        "epoch": 94,
        "reward": 0.44708022475242615,
        "val_loss": 0.0017149610461534134,
        "train_loss": 0.0020084727884050854
      },
      {
        "epoch": 95,
        "reward": 0.4433634877204895,
        "val_loss": 0.0017673579194316907,
        "train_loss": 0.0020022130251723304
      },
      {
        "epoch": 96,
        "reward": 0.438443660736084,
        "val_loss": 0.0018393314676359296,
        "train_loss": 0.0021038918415657603
      },
      {
        "epoch": 97,
        "reward": 0.44564715027809143,
        "val_loss": 0.0017349676678090223,
        "train_loss": 0.002019633522790033
      },
      {
        "epoch": 98,
        "reward": 0.44588080048561096,
        "val_loss": 0.001731689362454095,
        "train_loss": 0.002035682839889957
      },
      {
        "epoch": 99,
        "reward": 0.4465959966182709,
        "val_loss": 0.0017216938597682332,
        "train_loss": 0.002016046450780078
      },
      {
        "epoch": 100,
        "reward": 0.42901870608329773,
        "val_loss": 0.0019860597593443735,
        "train_loss": 0.002059160022047133
      },
      {
        "epoch": 101,
        "reward": 0.4441283643245697,
        "val_loss": 0.001756438719374793,
        "train_loss": 0.0021483209163237075
      },
      {
        "epoch": 102,
        "reward": 0.43901410698890686,
        "val_loss": 0.0018308300391903945,
        "train_loss": 0.0020274338995267707
      },
      {
        "epoch": 103,
        "reward": 0.4462127685546875,
        "val_loss": 0.0017270422873220273,
        "train_loss": 0.0020357791083649946
      },
      {
        "epoch": 104,
        "reward": 0.43862205743789673,
        "val_loss": 0.0018366689827027066,
        "train_loss": 0.002049365936657593
      },
      {
        "epoch": 105,
        "reward": 0.4300256669521332,
        "val_loss": 0.001969802609112646,
        "train_loss": 0.0022106026164972438
      },
      {
        "epoch": 106,
        "reward": 0.4437258839607239,
        "val_loss": 0.0017621757329574653,
        "train_loss": 0.0024585360885024644
      },
      {
        "epoch": 107,
        "reward": 0.4462275505065918,
        "val_loss": 0.0017268355836027435,
        "train_loss": 0.002092315589624587
      },
      {
        "epoch": 108,
        "reward": 0.4459548890590668,
        "val_loss": 0.0017306506550604744,
        "train_loss": 0.0022399387447736585
      },
      {
        "epoch": 109,
        "reward": 0.4414350688457489,
        "val_loss": 0.0017952075743648624,
        "train_loss": 0.002154452824750199
      },
      {
        "epoch": 110,
        "reward": 0.4458240568637848,
        "val_loss": 0.0017324846454097756,
        "train_loss": 0.002037748615223861
      },
      {
        "epoch": 111,
        "reward": 0.4453248083591461,
        "val_loss": 0.001739501246317689,
        "train_loss": 0.0020073195639375065
      },
      {
        "epoch": 112,
        "reward": 0.44426852464675903,
        "val_loss": 0.0017544458636880986,
        "train_loss": 0.002027456632976492
      },
      {
        "epoch": 113,
        "reward": 0.43810954689979553,
        "val_loss": 0.001844331405923835,
        "train_loss": 0.0020070760501067317
      },
      {
        "epoch": 114,
        "reward": 0.43782663345336914,
        "val_loss": 0.0018485761829651892,
        "train_loss": 0.002020267474178511
      },
      {
        "epoch": 115,
        "reward": 0.43770167231559753,
        "val_loss": 0.001850453737590994,
        "train_loss": 0.0020015602167404722
      },
      {
        "epoch": 116,
        "reward": 0.44207000732421875,
        "val_loss": 0.0017859871732071042,
        "train_loss": 0.00200872293946584
      },
      {
        "epoch": 117,
        "reward": 0.4458331763744354,
        "val_loss": 0.001732356912855591,
        "train_loss": 0.0020178536427780413
      },
      {
        "epoch": 118,
        "reward": 0.44619742035865784,
        "val_loss": 0.001727256757606353,
        "train_loss": 0.0019983828740525776
      },
      {
        "epoch": 119,
        "reward": 0.4458354413509369,
        "val_loss": 0.0017323250233727907,
        "train_loss": 0.00202492630118146
      },
      {
        "epoch": 120,
        "reward": 0.4384821355342865,
        "val_loss": 0.001838757049491895,
        "train_loss": 0.002202932839281857
      },
      {
        "epoch": 121,
        "reward": 0.44596996903419495,
        "val_loss": 0.00173043945272054,
        "train_loss": 0.0021040053890409092
      },
      {
        "epoch": 122,
        "reward": 0.4468752443790436,
        "val_loss": 0.0017178082406254752,
        "train_loss": 0.001995202836741765
      },
      {
        "epoch": 123,
        "reward": 0.44341740012168884,
        "val_loss": 0.0017665862854171013,
        "train_loss": 0.0022941864803075218
      },
      {
        "epoch": 124,
        "reward": 0.447538822889328,
        "val_loss": 0.0017086105238247132,
        "train_loss": 0.002029878449460599
      },
      {
        "epoch": 125,
        "reward": 0.43860650062561035,
        "val_loss": 0.0018369005577239608,
        "train_loss": 0.00199935976591475
      },
      {
        "epoch": 126,
        "reward": 0.442770391702652,
        "val_loss": 0.0017758743820845016,
        "train_loss": 0.0019994688107264945
      },
      {
        "epoch": 127,
        "reward": 0.44632458686828613,
        "val_loss": 0.0017254802431645139,
        "train_loss": 0.0019966732066117963
      },
      {
        "epoch": 128,
        "reward": 0.4467332363128662,
        "val_loss": 0.001719782968783485,
        "train_loss": 0.002004784819011827
      },
      {
        "epoch": 129,
        "reward": 0.44731369614601135,
        "val_loss": 0.0017117250078756893,
        "train_loss": 0.001984533383969952
      },
      {
        "epoch": 130,
        "reward": 0.4283391535282135,
        "val_loss": 0.001997112113583301,
        "train_loss": 0.0020347511789833126
      },
      {
        "epoch": 131,
        "reward": 0.4454704821109772,
        "val_loss": 0.00173745074841593,
        "train_loss": 0.002068982047673601
      },
      {
        "epoch": 132,
        "reward": 0.435746431350708,
        "val_loss": 0.0018801041047221848,
        "train_loss": 0.00234991423964787
      },
      {
        "epoch": 133,
        "reward": 0.4454256594181061,
        "val_loss": 0.001738081220537424,
        "train_loss": 0.002067383278000097
      },
      {
        "epoch": 134,
        "reward": 0.4462890326976776,
        "val_loss": 0.0017259767877736262,
        "train_loss": 0.0019755942249993007
      },
      {
        "epoch": 135,
        "reward": 0.44710540771484375,
        "val_loss": 0.001714612531941384,
        "train_loss": 0.0020214854067979525
      },
      {
        "epoch": 136,
        "reward": 0.44825997948646545,
        "val_loss": 0.0016986741268608188,
        "train_loss": 0.0026964189735456156
      },
      {
        "epoch": 137,
        "reward": 0.43298035860061646,
        "val_loss": 0.0019229179181690728,
        "train_loss": 0.002178527466290129
      },
      {
        "epoch": 138,
        "reward": 0.4480784833431244,
        "val_loss": 0.0017011688406845288,
        "train_loss": 0.00219566513148423
      },
      {
        "epoch": 139,
        "reward": 0.4489321708679199,
        "val_loss": 0.0016894667392729648,
        "train_loss": 0.002054983181341623
      },
      {
        "epoch": 140,
        "reward": 0.43261194229125977,
        "val_loss": 0.0019286992194663202,
        "train_loss": 0.00205573168484709
      },
      {
        "epoch": 141,
        "reward": 0.4488042891025543,
        "val_loss": 0.001691214058415166,
        "train_loss": 0.00198507764770721
      },
      {
        "epoch": 142,
        "reward": 0.44860124588012695,
        "val_loss": 0.0016939926011088704,
        "train_loss": 0.002115159416392159
      },
      {
        "epoch": 143,
        "reward": 0.4493136405944824,
        "val_loss": 0.001684264886924731,
        "train_loss": 0.0020987739083536258
      },
      {
        "epoch": 144,
        "reward": 0.4306868016719818,
        "val_loss": 0.0019592067027198417,
        "train_loss": 0.002383188093797519
      },
      {
        "epoch": 145,
        "reward": 0.4326246380805969,
        "val_loss": 0.0019284991514203803,
        "train_loss": 0.0022625735045249504
      },
      {
        "epoch": 146,
        "reward": 0.44337525963783264,
        "val_loss": 0.0017671893749918257,
        "train_loss": 0.0020607354840299543
      },
      {
        "epoch": 147,
        "reward": 0.4360615909099579,
        "val_loss": 0.0018752913955332978,
        "train_loss": 0.0020073695696527674
      },
      {
        "epoch": 148,
        "reward": 0.43643125891685486,
        "val_loss": 0.0018696622490616782,
        "train_loss": 0.00229655560822441
      },
      {
        "epoch": 149,
        "reward": 0.4472220540046692,
        "val_loss": 0.0017129943257064692,
        "train_loss": 0.002089040487100227
      },
      {
        "epoch": 150,
        "reward": 0.43279120326042175,
        "val_loss": 0.0019258835818618536,
        "train_loss": 0.0020242123573552817
      },
      {
        "epoch": 151,
        "reward": 0.4481927454471588,
        "val_loss": 0.0016995980820086385,
        "train_loss": 0.00210409199532408
      },
      {
        "epoch": 152,
        "reward": 0.4476799964904785,
        "val_loss": 0.0017066601846766258,
        "train_loss": 0.0020104402543578404
      },
      {
        "epoch": 153,
        "reward": 0.4448578357696533,
        "val_loss": 0.0017460914262171303,
        "train_loss": 0.002307459801578751
      },
      {
        "epoch": 154,
        "reward": 0.4507249891757965,
        "val_loss": 0.0016651659389026463,
        "train_loss": 0.002234453271739767
      },
      {
        "epoch": 155,
        "reward": 0.45022469758987427,
        "val_loss": 0.0016719096622961973,
        "train_loss": 0.0021358577785297083
      },
      {
        "epoch": 156,
        "reward": 0.44522586464881897,
        "val_loss": 0.0017408958852424153,
        "train_loss": 0.001957453744790445
      },
      {
        "epoch": 157,
        "reward": 0.4463919699192047,
        "val_loss": 0.001724539399479649,
        "train_loss": 0.002013980451290711
      },
      {
        "epoch": 158,
        "reward": 0.4479884207248688,
        "val_loss": 0.0017024082480929792,
        "train_loss": 0.0020188581256661564
      },
      {
        "epoch": 159,
        "reward": 0.4376668632030487,
        "val_loss": 0.001850978155354304,
        "train_loss": 0.0019799343292386485
      },
      {
        "epoch": 160,
        "reward": 0.4410134255886078,
        "val_loss": 0.0018013585525165712,
        "train_loss": 0.0019795261435389807
      },
      {
        "epoch": 161,
        "reward": 0.43251320719718933,
        "val_loss": 0.0019302511354908347,
        "train_loss": 0.00194892570247108
      },
      {
        "epoch": 162,
        "reward": 0.43413034081459045,
        "val_loss": 0.0019049941162977899,
        "train_loss": 0.001987829055556526
      },
      {
        "epoch": 163,
        "reward": 0.44373828172683716,
        "val_loss": 0.0017619987068298673,
        "train_loss": 0.0022301684769515237
      },
      {
        "epoch": 164,
        "reward": 0.449423611164093,
        "val_loss": 0.0016827692660236998,
        "train_loss": 0.0021561012119771196
      },
      {
        "epoch": 165,
        "reward": 0.4504106640815735,
        "val_loss": 0.001669399265665561,
        "train_loss": 0.0021888895515495767
      },
      {
        "epoch": 166,
        "reward": 0.4500126540660858,
        "val_loss": 0.001674776921780514,
        "train_loss": 0.0019655075033929627
      },
      {
        "epoch": 167,
        "reward": 0.44840773940086365,
        "val_loss": 0.0016966458726009087,
        "train_loss": 0.0019494788743591367
      },
      {
        "epoch": 168,
        "reward": 0.4505336880683899,
        "val_loss": 0.0016677416611595877,
        "train_loss": 0.0019504895399922344
      },
      {
        "epoch": 169,
        "reward": 0.4514729976654053,
        "val_loss": 0.0016551354949894761,
        "train_loss": 0.001956058799246071
      },
      {
        "epoch": 170,
        "reward": 0.4410664737224579,
        "val_loss": 0.0018005831433194025,
        "train_loss": 0.002283249171271634
      },
      {
        "epoch": 171,
        "reward": 0.45159631967544556,
        "val_loss": 0.0016534877442089574,
        "train_loss": 0.0023117471204246753
      },
      {
        "epoch": 172,
        "reward": 0.44385644793510437,
        "val_loss": 0.0017603125805700465,
        "train_loss": 0.0019651161094840905
      },
      {
        "epoch": 173,
        "reward": 0.4516768455505371,
        "val_loss": 0.001652412731865687,
        "train_loss": 0.002258797744826342
      },
      {
        "epoch": 174,
        "reward": 0.4512026906013489,
        "val_loss": 0.001658752519038639,
        "train_loss": 0.0019969909514587084
      },
      {
        "epoch": 175,
        "reward": 0.4192633628845215,
        "val_loss": 0.002151224363063063,
        "train_loss": 0.0019495110631956218
      },
      {
        "epoch": 176,
        "reward": 0.45100918412208557,
        "val_loss": 0.0016613476078159042,
        "train_loss": 0.001969701152400096
      },
      {
        "epoch": 177,
        "reward": 0.4495273232460022,
        "val_loss": 0.0016813584536846196,
        "train_loss": 0.0019581928137575653
      },
      {
        "epoch": 178,
        "reward": 0.4481986463069916,
        "val_loss": 0.001699516932213945,
        "train_loss": 0.0019377539028937463
      },
      {
        "epoch": 179,
        "reward": 0.44765493273735046,
        "val_loss": 0.0017070066533051431,
        "train_loss": 0.0019491920465952717
      },
      {
        "epoch": 180,
        "reward": 0.43825802206993103,
        "val_loss": 0.0018421079564307416,
        "train_loss": 0.0019439555046399338
      },
      {
        "epoch": 181,
        "reward": 0.4490511417388916,
        "val_loss": 0.00168784217177225,
        "train_loss": 0.002002904083033522
      },
      {
        "epoch": 182,
        "reward": 0.4487214684486389,
        "val_loss": 0.0016923473033654904,
        "train_loss": 0.0019710037225964838
      },
      {
        "epoch": 183,
        "reward": 0.44800248742103577,
        "val_loss": 0.0017022151732817292,
        "train_loss": 0.001998084265953646
      },
      {
        "epoch": 184,
        "reward": 0.45103374123573303,
        "val_loss": 0.001661018210662795,
        "train_loss": 0.001955634656881627
      },
      {
        "epoch": 185,
        "reward": 0.45119795203208923,
        "val_loss": 0.0016588162813734794,
        "train_loss": 0.001947796883261897
      },
      {
        "epoch": 186,
        "reward": 0.4516483247280121,
        "val_loss": 0.0016527932852373592,
        "train_loss": 0.0024253520756386793
      },
      {
        "epoch": 187,
        "reward": 0.4516935348510742,
        "val_loss": 0.0016521905033316994,
        "train_loss": 0.0020285954126918046
      },
      {
        "epoch": 188,
        "reward": 0.44972720742225647,
        "val_loss": 0.0016786446628559912,
        "train_loss": 0.0020257678177306214
      },
      {
        "epoch": 189,
        "reward": 0.44269999861717224,
        "val_loss": 0.0017768884426914155,
        "train_loss": 0.0019515856057786061
      },
      {
        "epoch": 190,
        "reward": 0.4311981797218323,
        "val_loss": 0.0019510531232559256,
        "train_loss": 0.0019386857118381439
      },
      {
        "epoch": 191,
        "reward": 0.4146655201911926,
        "val_loss": 0.0022341553288112792,
        "train_loss": 0.002079092026598608
      },
      {
        "epoch": 192,
        "reward": 0.429915189743042,
        "val_loss": 0.0019715806203229086,
        "train_loss": 0.0022134251238849875
      },
      {
        "epoch": 193,
        "reward": 0.44998106360435486,
        "val_loss": 0.0016752041327500983,
        "train_loss": 0.0019867873925250024
      },
      {
        "epoch": 194,
        "reward": 0.4492623507976532,
        "val_loss": 0.0016849634536941136,
        "train_loss": 0.002066332620765584
      },
      {
        "epoch": 195,
        "reward": 0.4519721567630768,
        "val_loss": 0.0016484766799424375,
        "train_loss": 0.001976721477918685
      },
      {
        "epoch": 196,
        "reward": 0.427544504404068,
        "val_loss": 0.0020101194802139488,
        "train_loss": 0.00258421250887645
      },
      {
        "epoch": 197,
        "reward": 0.42810025811195374,
        "val_loss": 0.0020010131577562007,
        "train_loss": 0.0021558878294084794
      },
      {
        "epoch": 198,
        "reward": 0.4379289746284485,
        "val_loss": 0.0018470391431557281,
        "train_loss": 0.0020161473737691548
      },
      {
        "epoch": 199,
        "reward": 0.4417297840118408,
        "val_loss": 0.0017909211705305747,
        "train_loss": 0.001939059585520926
      },
      {
        "epoch": 200,
        "reward": 0.4517987370491028,
        "val_loss": 0.0016507873577730997,
        "train_loss": 0.0019486633035250213
      },
      {
        "epoch": 201,
        "reward": 0.4464242160320282,
        "val_loss": 0.001724088897130319,
        "train_loss": 0.0019212924381253498
      },
      {
        "epoch": 202,
        "reward": 0.45118021965026855,
        "val_loss": 0.0016590533279148595,
        "train_loss": 0.0019618728144380907
      },
      {
        "epoch": 203,
        "reward": 0.4135427176952362,
        "val_loss": 0.002254930757252233,
        "train_loss": 0.0022020885058177207
      },
      {
        "epoch": 204,
        "reward": 0.45008859038352966,
        "val_loss": 0.0016737491574271449,
        "train_loss": 0.002049700569701739
      },
      {
        "epoch": 205,
        "reward": 0.4419957101345062,
        "val_loss": 0.0017870635326419557,
        "train_loss": 0.002019975276198238
      },
      {
        "epoch": 206,
        "reward": 0.45080897212028503,
        "val_loss": 0.001664036460819521,
        "train_loss": 0.0020059062886642865
      },
      {
        "epoch": 207,
        "reward": 0.44968849420547485,
        "val_loss": 0.0016791698872111738,
        "train_loss": 0.0021056471719370726
      },
      {
        "epoch": 208,
        "reward": 0.4289466440677643,
        "val_loss": 0.001987228386237153,
        "train_loss": 0.0023583603682569587
      },
      {
        "epoch": 209,
        "reward": 0.44714903831481934,
        "val_loss": 0.00171400628252221,
        "train_loss": 0.0021361225539854225
      },
      {
        "epoch": 210,
        "reward": 0.44489747285842896,
        "val_loss": 0.0017455311608500779,
        "train_loss": 0.002217168498855944
      },
      {
        "epoch": 211,
        "reward": 0.43908196687698364,
        "val_loss": 0.001829821283796004,
        "train_loss": 0.0025172825172865908
      },
      {
        "epoch": 212,
        "reward": 0.4502873420715332,
        "val_loss": 0.0016710639798215457,
        "train_loss": 0.0022008540231931526
      },
      {
        "epoch": 213,
        "reward": 0.44389253854751587,
        "val_loss": 0.0017597972847787397,
        "train_loss": 0.002099863497558265
      },
      {
        "epoch": 214,
        "reward": 0.45229727029800415,
        "val_loss": 0.0016441553182500815,
        "train_loss": 0.0019323030422898368
      },
      {
        "epoch": 215,
        "reward": 0.44826242327690125,
        "val_loss": 0.0016986407406095947,
        "train_loss": 0.0019337127708310548
      },
      {
        "epoch": 216,
        "reward": 0.4515507221221924,
        "val_loss": 0.0016540968956957971,
        "train_loss": 0.0022434383953133454
      },
      {
        "epoch": 217,
        "reward": 0.4474460780620575,
        "val_loss": 0.0017098931961559824,
        "train_loss": 0.00199710144862855
      },
      {
        "epoch": 218,
        "reward": 0.45107704401016235,
        "val_loss": 0.0016604369240147726,
        "train_loss": 0.001973116183832574
      },
      {
        "epoch": 219,
        "reward": 0.45044636726379395,
        "val_loss": 0.0016689178883098066,
        "train_loss": 0.0019335726144792996
      },
      {
        "epoch": 220,
        "reward": 0.404215544462204,
        "val_loss": 0.0024358655625422087,
        "train_loss": 0.002298233909711528
      },
      {
        "epoch": 221,
        "reward": 0.4077473282814026,
        "val_loss": 0.002365554333664477,
        "train_loss": 0.0023790198834971166
      },
      {
        "epoch": 222,
        "reward": 0.42391619086265564,
        "val_loss": 0.002070677383536739,
        "train_loss": 0.0023423775385778686
      },
      {
        "epoch": 223,
        "reward": 0.4208359718322754,
        "val_loss": 0.0021236277285165022,
        "train_loss": 0.002105331207321097
      },
      {
        "epoch": 224,
        "reward": 0.4486735761165619,
        "val_loss": 0.001693002663419715,
        "train_loss": 0.002000522475170258
      },
      {
        "epoch": 225,
        "reward": 0.44938182830810547,
        "val_loss": 0.0016833372646942735,
        "train_loss": 0.0019043775796140276
      },
      {
        "epoch": 226,
        "reward": 0.4522199332714081,
        "val_loss": 0.0016451831491264915,
        "train_loss": 0.001922652818253622
      },
      {
        "epoch": 227,
        "reward": 0.45198607444763184,
        "val_loss": 0.0016482925358494477,
        "train_loss": 0.002020980858315642
      },
      {
        "epoch": 228,
        "reward": 0.43093934655189514,
        "val_loss": 0.0019551756725247416,
        "train_loss": 0.0019714615977696106
      },
      {
        "epoch": 229,
        "reward": 0.4380461275577545,
        "val_loss": 0.0018452816709343875,
        "train_loss": 0.0023916097259363877
      },
      {
        "epoch": 230,
        "reward": 0.45103365182876587,
        "val_loss": 0.0016610192251391709,
        "train_loss": 0.0027655537123791873
      },
      {
        "epoch": 231,
        "reward": 0.4500320553779602,
        "val_loss": 0.0016745143719682737,
        "train_loss": 0.001994144195542993
      },
      {
        "epoch": 232,
        "reward": 0.4525052607059479,
        "val_loss": 0.001641397480852902,
        "train_loss": 0.001935145828086276
      },
      {
        "epoch": 233,
        "reward": 0.45150110125541687,
        "val_loss": 0.0016547597063306188,
        "train_loss": 0.0019255052242302694
      },
      {
        "epoch": 234,
        "reward": 0.4438696503639221,
        "val_loss": 0.0017601244534099741,
        "train_loss": 0.0021650114414604525
      },
      {
        "epoch": 235,
        "reward": 0.44803586602211,
        "val_loss": 0.0017017557651602796,
        "train_loss": 0.0025976594859877457
      },
      {
        "epoch": 236,
        "reward": 0.45141011476516724,
        "val_loss": 0.0016559761549745286,
        "train_loss": 0.002123095947004353
      },
      {
        "epoch": 237,
        "reward": 0.43059393763542175,
        "val_loss": 0.0019606922952724354,
        "train_loss": 0.0021101973968772935
      },
      {
        "epoch": 238,
        "reward": 0.43470650911331177,
        "val_loss": 0.001896080860335912,
        "train_loss": 0.0019507434816869835
      },
      {
        "epoch": 239,
        "reward": 0.4392622113227844,
        "val_loss": 0.0018271446959780796,
        "train_loss": 0.001996673052557386
      },
      {
        "epoch": 240,
        "reward": 0.45282527804374695,
        "val_loss": 0.0016371626573215639,
        "train_loss": 0.0019310657859862728
      },
      {
        "epoch": 241,
        "reward": 0.4429343640804291,
        "val_loss": 0.001773515616410545,
        "train_loss": 0.0019469826365821064
      },
      {
        "epoch": 242,
        "reward": 0.4509144425392151,
        "val_loss": 0.0016626194368914834,
        "train_loss": 0.0019493836488646383
      },
      {
        "epoch": 243,
        "reward": 0.45164424180984497,
        "val_loss": 0.00165284814180008,
        "train_loss": 0.002119334616089383
      },
      {
        "epoch": 244,
        "reward": 0.44536304473876953,
        "val_loss": 0.0017389630000772221,
        "train_loss": 0.0020019845351970825
      },
      {
        "epoch": 245,
        "reward": 0.44061657786369324,
        "val_loss": 0.0018071682258908237,
        "train_loss": 0.0020110344250077526
      },
      {
        "epoch": 246,
        "reward": 0.4515160620212555,
        "val_loss": 0.0016545601704690074,
        "train_loss": 0.0019202779598904622
      },
      {
        "epoch": 247,
        "reward": 0.4316083490848541,
        "val_loss": 0.0019445397358919894,
        "train_loss": 0.0021878733017589324
      },
      {
        "epoch": 248,
        "reward": 0.4446602761745453,
        "val_loss": 0.0017488870902785233,
        "train_loss": 0.0020196976351703946
      },
      {
        "epoch": 249,
        "reward": 0.4526568353176117,
        "val_loss": 0.0016393896408512124,
        "train_loss": 0.0019067941710729358
      },
      {
        "epoch": 250,
        "reward": 0.4447301924228668,
        "val_loss": 0.0017478973105815904,
        "train_loss": 0.001907014928852172
      },
      {
        "epoch": 251,
        "reward": 0.4410548210144043,
        "val_loss": 0.0018007533258891531,
        "train_loss": 0.0019444669160293415
      },
      {
        "epoch": 252,
        "reward": 0.4476279318332672,
        "val_loss": 0.0017073791906503694,
        "train_loss": 0.0019795047292763437
      },
      {
        "epoch": 253,
        "reward": 0.45252856612205505,
        "val_loss": 0.0016410882318658488,
        "train_loss": 0.002088823360211861
      },
      {
        "epoch": 254,
        "reward": 0.451812744140625,
        "val_loss": 0.001650600610966129,
        "train_loss": 0.0019377350366154972
      },
      {
        "epoch": 255,
        "reward": 0.45354610681533813,
        "val_loss": 0.0016276656284130045,
        "train_loss": 0.0019338196426150927
      },
      {
        "epoch": 256,
        "reward": 0.43887075781822205,
        "val_loss": 0.0018329614207946829,
        "train_loss": 0.0021491238708572034
      },
      {
        "epoch": 257,
        "reward": 0.4508694112300873,
        "val_loss": 0.0016632239234500698,
        "train_loss": 0.0022063989597602184
      },
      {
        "epoch": 258,
        "reward": 0.4538698196411133,
        "val_loss": 0.0016234193961801274,
        "train_loss": 0.0019437573004971944
      },
      {
        "epoch": 259,
        "reward": 0.44110533595085144,
        "val_loss": 0.0018000161674405848,
        "train_loss": 0.002055080041128139
      },
      {
        "epoch": 260,
        "reward": 0.4538785517215729,
        "val_loss": 0.0016233055253646203,
        "train_loss": 0.00203689523822102
      },
      {
        "epoch": 261,
        "reward": 0.45341020822525024,
        "val_loss": 0.0016294513147191278,
        "train_loss": 0.0018927477222650151
      },
      {
        "epoch": 262,
        "reward": 0.45328330993652344,
        "val_loss": 0.0016311209682109101,
        "train_loss": 0.0018957815452197862
      },
      {
        "epoch": 263,
        "reward": 0.4370853900909424,
        "val_loss": 0.001859745559548693,
        "train_loss": 0.0018993501717676946
      },
      {
        "epoch": 264,
        "reward": 0.45232436060905457,
        "val_loss": 0.00164379647633593,
        "train_loss": 0.0019199915628772802
      },
      {
        "epoch": 265,
        "reward": 0.4525606334209442,
        "val_loss": 0.0016406635570872044,
        "train_loss": 0.0019046543581610492
      },
      {
        "epoch": 266,
        "reward": 0.4484446048736572,
        "val_loss": 0.0016961397736200265,
        "train_loss": 0.0019872354325623466
      },
      {
        "epoch": 267,
        "reward": 0.45160600543022156,
        "val_loss": 0.0016533590054937772,
        "train_loss": 0.0022559764463669406
      },
      {
        "epoch": 268,
        "reward": 0.45154404640197754,
        "val_loss": 0.0016541857039555907,
        "train_loss": 0.0019564391178881545
      },
      {
        "epoch": 269,
        "reward": 0.4461396634578705,
        "val_loss": 0.0017280641893324042,
        "train_loss": 0.002150835863386209
      },
      {
        "epoch": 270,
        "reward": 0.4190771281719208,
        "val_loss": 0.0021545178523021086,
        "train_loss": 0.0020373656790560256
      },
      {
        "epoch": 271,
        "reward": 0.450188547372818,
        "val_loss": 0.0016723982075096241,
        "train_loss": 0.0019865018167855362
      },
      {
        "epoch": 272,
        "reward": 0.4409261643886566,
        "val_loss": 0.0018026346141206367,
        "train_loss": 0.002084898869865216
      },
      {
        "epoch": 273,
        "reward": 0.3918747007846832,
        "val_loss": 0.0027001802809536457,
        "train_loss": 0.0024437811807729304
      },
      {
        "epoch": 274,
        "reward": 0.4270443916320801,
        "val_loss": 0.0020183517231738995,
        "train_loss": 0.002294462963618571
      },
      {
        "epoch": 275,
        "reward": 0.4529894292354584,
        "val_loss": 0.0016349941309142327,
        "train_loss": 0.0019218029555120736
      },
      {
        "epoch": 276,
        "reward": 0.453164666891098,
        "val_loss": 0.0016326837940141559,
        "train_loss": 0.001892068411577314
      },
      {
        "epoch": 277,
        "reward": 0.4431169927120209,
        "val_loss": 0.0017708923135484969,
        "train_loss": 0.0019760347861917512
      },
      {
        "epoch": 278,
        "reward": 0.4520174562931061,
        "val_loss": 0.001647873898036778,
        "train_loss": 0.001966156419187498
      },
      {
        "epoch": 279,
        "reward": 0.45144882798194885,
        "val_loss": 0.00165545818163082,
        "train_loss": 0.0018982640131770705
      },
      {
        "epoch": 280,
        "reward": 0.4528639018535614,
        "val_loss": 0.0016366523174968148,
        "train_loss": 0.0019080212980322987
      },
      {
        "epoch": 281,
        "reward": 0.4465441405773163,
        "val_loss": 0.0017224168488090591,
        "train_loss": 0.0019495033400464589
      },
      {
        "epoch": 282,
        "reward": 0.44906654953956604,
        "val_loss": 0.0016876326824006224,
        "train_loss": 0.0019515597109253018
      },
      {
        "epoch": 283,
        "reward": 0.4423552453517914,
        "val_loss": 0.0017818616470322013,
        "train_loss": 0.0024796945419019232
      },
      {
        "epoch": 284,
        "reward": 0.44674068689346313,
        "val_loss": 0.0017196799495390483,
        "train_loss": 0.00192105162680561
      },
      {
        "epoch": 285,
        "reward": 0.4533291757106781,
        "val_loss": 0.0016305176042286412,
        "train_loss": 0.0018983573003284759
      },
      {
        "epoch": 286,
        "reward": 0.43692252039909363,
        "val_loss": 0.0018622099721272076,
        "train_loss": 0.001993442840802555
      },
      {
        "epoch": 287,
        "reward": 0.453897088766098,
        "val_loss": 0.0016230626247956284,
        "train_loss": 0.002124346313604082
      },
      {
        "epoch": 288,
        "reward": 0.45272812247276306,
        "val_loss": 0.0016384466517982738,
        "train_loss": 0.0020758093227274143
      },
      {
        "epoch": 289,
        "reward": 0.45488157868385315,
        "val_loss": 0.0016102231706359557,
        "train_loss": 0.001905770233581559
      },
      {
        "epoch": 290,
        "reward": 0.4503392279148102,
        "val_loss": 0.0016703632676840893,
        "train_loss": 0.0019351736611077706
      },
      {
        "epoch": 291,
        "reward": 0.42232728004455566,
        "val_loss": 0.0020978108514100313,
        "train_loss": 0.0024183255781491217
      },
      {
        "epoch": 292,
        "reward": 0.45370182394981384,
        "val_loss": 0.0016256215832462268,
        "train_loss": 0.001949788922782038
      },
      {
        "epoch": 293,
        "reward": 0.4537040889263153,
        "val_loss": 0.001625592662354133,
        "train_loss": 0.0019061397304959917
      },
      {
        "epoch": 294,
        "reward": 0.45220136642456055,
        "val_loss": 0.001645429475632097,
        "train_loss": 0.001967395208059595
      },
      {
        "epoch": 295,
        "reward": 0.43483230471611023,
        "val_loss": 0.0018941406825823443,
        "train_loss": 0.002117668824771849
      },
      {
        "epoch": 296,
        "reward": 0.43563389778137207,
        "val_loss": 0.0018818261866856898,
        "train_loss": 0.0020107160875201
      },
      {
        "epoch": 297,
        "reward": 0.453829824924469,
        "val_loss": 0.0016239442297124437,
        "train_loss": 0.0019294092338756085
      },
      {
        "epoch": 298,
        "reward": 0.44842496514320374,
        "val_loss": 0.0016964097074898227,
        "train_loss": 0.0019121189991262956
      },
      {
        "epoch": 299,
        "reward": 0.4529999792575836,
        "val_loss": 0.0016348552973275737,
        "train_loss": 0.001913972147471773
      },
      {
        "epoch": 300,
        "reward": 0.4390752911567688,
        "val_loss": 0.0018299207191116043,
        "train_loss": 0.002021857039765634
      },
      {
        "epoch": 301,
        "reward": 0.43452832102775574,
        "val_loss": 0.001898831787652203,
        "train_loss": 0.001981303301783135
      },
      {
        "epoch": 302,
        "reward": 0.4472768306732178,
        "val_loss": 0.001712235322754298,
        "train_loss": 0.002006897581080781
      },
      {
        "epoch": 303,
        "reward": 0.43902307748794556,
        "val_loss": 0.0018306969265852655,
        "train_loss": 0.002097496677799007
      },
      {
        "epoch": 304,
        "reward": 0.4427858889102936,
        "val_loss": 0.0017756519706121513,
        "train_loss": 0.0020786910364362344
      },
      {
        "epoch": 305,
        "reward": 0.45423635840415955,
        "val_loss": 0.0016186257707886398,
        "train_loss": 0.0019357041730052936
      },
      {
        "epoch": 306,
        "reward": 0.44599443674087524,
        "val_loss": 0.0017300971334667078,
        "train_loss": 0.0019198974175826432
      },
      {
        "epoch": 307,
        "reward": 0.44963929057121277,
        "val_loss": 0.0016798379448508577,
        "train_loss": 0.0019140859546426397
      },
      {
        "epoch": 308,
        "reward": 0.4545268714427948,
        "val_loss": 0.001614837084032063,
        "train_loss": 0.0019108741723287564
      },
      {
        "epoch": 309,
        "reward": 0.45100894570350647,
        "val_loss": 0.0016613506928219327,
        "train_loss": 0.0019533538926715176
      },
      {
        "epoch": 310,
        "reward": 0.4548572599887848,
        "val_loss": 0.0016105388474118496,
        "train_loss": 0.0019392583666418572
      },
      {
        "epoch": 311,
        "reward": 0.4452633559703827,
        "val_loss": 0.0017403668524431331,
        "train_loss": 0.0018837517189660082
      },
      {
        "epoch": 312,
        "reward": 0.4448220431804657,
        "val_loss": 0.0017465975335133927,
        "train_loss": 0.0019287725892634345
      },
      {
        "epoch": 313,
        "reward": 0.44489166140556335,
        "val_loss": 0.0017456135745825513,
        "train_loss": 0.001894125958922534
      },
      {
        "epoch": 314,
        "reward": 0.45064783096313477,
        "val_loss": 0.0016662036733967917,
        "train_loss": 0.0018953809384793902
      },
      {
        "epoch": 315,
        "reward": 0.450609028339386,
        "val_loss": 0.0016667269270068832,
        "train_loss": 0.0018868030295449828
      },
      {
        "epoch": 316,
        "reward": 0.43530669808387756,
        "val_loss": 0.0018868424064878906,
        "train_loss": 0.0021212093460445222
      },
      {
        "epoch": 317,
        "reward": 0.44312533736228943,
        "val_loss": 0.0017707725554438575,
        "train_loss": 0.002014163037529215
      },
      {
        "epoch": 318,
        "reward": 0.453845739364624,
        "val_loss": 0.0016237349731714598,
        "train_loss": 0.0018737284840776387
      },
      {
        "epoch": 319,
        "reward": 0.45342111587524414,
        "val_loss": 0.0016293083068116435,
        "train_loss": 0.0019029513613741773
      },
      {
        "epoch": 320,
        "reward": 0.4356832504272461,
        "val_loss": 0.0018810714661542857,
        "train_loss": 0.0019291773608599145
      },
      {
        "epoch": 321,
        "reward": 0.43013879656791687,
        "val_loss": 0.001967986297261502,
        "train_loss": 0.001934086021859772
      },
      {
        "epoch": 322,
        "reward": 0.44911837577819824,
        "val_loss": 0.0016869260996047939,
        "train_loss": 0.0023084682321635997
      },
      {
        "epoch": 323,
        "reward": 0.44772869348526,
        "val_loss": 0.0017059882603851812,
        "train_loss": 0.0019383481498887424
      },
      {
        "epoch": 324,
        "reward": 0.4313846230506897,
        "val_loss": 0.0019480899209156632,
        "train_loss": 0.0020895329429409825
      },
      {
        "epoch": 325,
        "reward": 0.44938236474990845,
        "val_loss": 0.0016833297642213957,
        "train_loss": 0.0019475149993713086
      },
      {
        "epoch": 326,
        "reward": 0.4522852897644043,
        "val_loss": 0.0016443145660949604,
        "train_loss": 0.001883935546804703
      },
      {
        "epoch": 327,
        "reward": 0.45146456360816956,
        "val_loss": 0.0016552479106134602,
        "train_loss": 0.0020276165921061943
      },
      {
        "epoch": 328,
        "reward": 0.4502336084842682,
        "val_loss": 0.001671789463476411,
        "train_loss": 0.001969188676761965
      },
      {
        "epoch": 329,
        "reward": 0.4549565315246582,
        "val_loss": 0.0016092498637070613,
        "train_loss": 0.0020785108835508046
      },
      {
        "epoch": 330,
        "reward": 0.44230279326438904,
        "val_loss": 0.0017826186210316206,
        "train_loss": 0.001954186980863317
      },
      {
        "epoch": 331,
        "reward": 0.4292895495891571,
        "val_loss": 0.0019816740615559475,
        "train_loss": 0.0024197507076538526
      },
      {
        "epoch": 332,
        "reward": 0.42832574248313904,
        "val_loss": 0.001997330059696521,
        "train_loss": 0.001997726873154394
      },
      {
        "epoch": 333,
        "reward": 0.4475686252117157,
        "val_loss": 0.0017081987877775515,
        "train_loss": 0.0019162006395582955
      },
      {
        "epoch": 334,
        "reward": 0.43113085627555847,
        "val_loss": 0.0019521245932472603,
        "train_loss": 0.0019849063940525343
      },
      {
        "epoch": 335,
        "reward": 0.4535083770751953,
        "val_loss": 0.0016281609257150973,
        "train_loss": 0.0019816422371569877
      },
      {
        "epoch": 336,
        "reward": 0.44486093521118164,
        "val_loss": 0.0017460475210100412,
        "train_loss": 0.0019106309272711559
      },
      {
        "epoch": 337,
        "reward": 0.45117536187171936,
        "val_loss": 0.0016591187616411065,
        "train_loss": 0.0018854883419757802
      },
      {
        "epoch": 338,
        "reward": 0.45126327872276306,
        "val_loss": 0.0016579408464687212,
        "train_loss": 0.0019284199314335217
      },
      {
        "epoch": 339,
        "reward": 0.41196581721305847,
        "val_loss": 0.0022844617321555105,
        "train_loss": 0.0022192523028934374
      },
      {
        "epoch": 340,
        "reward": 0.45299845933914185,
        "val_loss": 0.0016348757864242153,
        "train_loss": 0.0022967016915432536
      },
      {
        "epoch": 341,
        "reward": 0.44040727615356445,
        "val_loss": 0.0018102404345492168,
        "train_loss": 0.0021677177865058184
      },
      {
        "epoch": 342,
        "reward": 0.4123609662055969,
        "val_loss": 0.00227702221101416,
        "train_loss": 0.002145801881292405
      },
      {
        "epoch": 343,
        "reward": 0.4524223804473877,
        "val_loss": 0.001642495160922408,
        "train_loss": 0.002023648949734007
      },
      {
        "epoch": 344,
        "reward": 0.4461762011051178,
        "val_loss": 0.0017275531593311047,
        "train_loss": 0.0020047523296223236
      },
      {
        "epoch": 345,
        "reward": 0.45351967215538025,
        "val_loss": 0.0016280127040642714,
        "train_loss": 0.001968464806045981
      },
      {
        "epoch": 346,
        "reward": 0.44599229097366333,
        "val_loss": 0.0017301269441044756,
        "train_loss": 0.0019012135974033019
      },
      {
        "epoch": 347,
        "reward": 0.4537449777126312,
        "val_loss": 0.0016250555885822646,
        "train_loss": 0.0018757581425374015
      },
      {
        "epoch": 348,
        "reward": 0.44887518882751465,
        "val_loss": 0.0016902450089608984,
        "train_loss": 0.0019333362982321817
      },
      {
        "epoch": 349,
        "reward": 0.4253329932689667,
        "val_loss": 0.0020468005843992743,
        "train_loss": 0.002028509470759533
      },
      {
        "epoch": 350,
        "reward": 0.45410236716270447,
        "val_loss": 0.001620375958736986,
        "train_loss": 0.0019616261512195566
      },
      {
        "epoch": 351,
        "reward": 0.45239636301994324,
        "val_loss": 0.0016428406732822104,
        "train_loss": 0.0019726166098665157
      },
      {
        "epoch": 352,
        "reward": 0.44942203164100647,
        "val_loss": 0.0016827906032891146,
        "train_loss": 0.001894177347332096
      },
      {
        "epoch": 353,
        "reward": 0.4546397626399994,
        "val_loss": 0.0016133668749327107,
        "train_loss": 0.0018965201687443857
      },
      {
        "epoch": 354,
        "reward": 0.455183744430542,
        "val_loss": 0.0016063036330576455,
        "train_loss": 0.0020509032272877027
      },
      {
        "epoch": 355,
        "reward": 0.45535778999328613,
        "val_loss": 0.0016040508718495922,
        "train_loss": 0.0021631258244339665
      },
      {
        "epoch": 356,
        "reward": 0.4512409269809723,
        "val_loss": 0.0016582407489685075,
        "train_loss": 0.001998433448674265
      },
      {
        "epoch": 357,
        "reward": 0.4456177353858948,
        "val_loss": 0.0017353803684402788,
        "train_loss": 0.0018736568098784818
      },
      {
        "epoch": 358,
        "reward": 0.3984714448451996,
        "val_loss": 0.0025551657558285762,
        "train_loss": 0.002169636281905696
      },
      {
        "epoch": 359,
        "reward": 0.4516693651676178,
        "val_loss": 0.001652512591265674,
        "train_loss": 0.0021562423655548347
      },
      {
        "epoch": 360,
        "reward": 0.4540286958217621,
        "val_loss": 0.001621339752871011,
        "train_loss": 0.0020233641732305
      },
      {
        "epoch": 361,
        "reward": 0.4508681893348694,
        "val_loss": 0.001663240695571793,
        "train_loss": 0.0018757359230396385
      },
      {
        "epoch": 362,
        "reward": 0.42121973633766174,
        "val_loss": 0.002116951725578734,
        "train_loss": 0.002397964117475427
      },
      {
        "epoch": 363,
        "reward": 0.4548780620098114,
        "val_loss": 0.001610269129741937,
        "train_loss": 0.002402967219425661
      },
      {
        "epoch": 364,
        "reward": 0.4064754545688629,
        "val_loss": 0.002390614610963634,
        "train_loss": 0.0020717695230044997
      },
      {
        "epoch": 365,
        "reward": 0.44073161482810974,
        "val_loss": 0.001805481584077435,
        "train_loss": 0.0020685373668899187
      },
      {
        "epoch": 366,
        "reward": 0.4473727345466614,
        "val_loss": 0.00171090813819319,
        "train_loss": 0.0020970134713794463
      },
      {
        "epoch": 367,
        "reward": 0.45299240946769714,
        "val_loss": 0.0016349556889118893,
        "train_loss": 0.0018799346500880066
      },
      {
        "epoch": 368,
        "reward": 0.44248294830322266,
        "val_loss": 0.001780017786326685,
        "train_loss": 0.0018652812107645262
      },
      {
        "epoch": 369,
        "reward": 0.4543776512145996,
        "val_loss": 0.001616781810298562,
        "train_loss": 0.0020590761873441246
      },
      {
        "epoch": 370,
        "reward": 0.4442347586154938,
        "val_loss": 0.0017549257525908096,
        "train_loss": 0.0021316878219994786
      },
      {
        "epoch": 371,
        "reward": 0.4540347754955292,
        "val_loss": 0.0016212601164755011,
        "train_loss": 0.0019204797520641337
      },
      {
        "epoch": 372,
        "reward": 0.42093953490257263,
        "val_loss": 0.002121824006150876,
        "train_loss": 0.002173961875646805
      },
      {
        "epoch": 373,
        "reward": 0.4491748809814453,
        "val_loss": 0.0016861556879510836,
        "train_loss": 0.002525522203471225
      },
      {
        "epoch": 374,
        "reward": 0.44897890090942383,
        "val_loss": 0.001688828957932336,
        "train_loss": 0.0020716512562313047
      },
      {
        "epoch": 375,
        "reward": 0.4532446563243866,
        "val_loss": 0.0016316305180745466,
        "train_loss": 0.0019383841804833186
      },
      {
        "epoch": 376,
        "reward": 0.4362330436706543,
        "val_loss": 0.0018726778715582831,
        "train_loss": 0.001892287691690014
      },
      {
        "epoch": 377,
        "reward": 0.45124122500419617,
        "val_loss": 0.0016582365164400212,
        "train_loss": 0.0019012521448670528
      },
      {
        "epoch": 378,
        "reward": 0.45344844460487366,
        "val_loss": 0.0016289491322822869,
        "train_loss": 0.0018688018973569763
      },
      {
        "epoch": 379,
        "reward": 0.4533655643463135,
        "val_loss": 0.001630039095679032,
        "train_loss": 0.001981815898593945
      },
      {
        "epoch": 380,
        "reward": 0.4491767883300781,
        "val_loss": 0.0016861296275497548,
        "train_loss": 0.002225273723105112
      },
      {
        "epoch": 381,
        "reward": 0.43390414118766785,
        "val_loss": 0.0019085052190348506,
        "train_loss": 0.00202664040595944
      },
      {
        "epoch": 382,
        "reward": 0.44100356101989746,
        "val_loss": 0.001801502175762185,
        "train_loss": 0.0019317509678120797
      },
      {
        "epoch": 383,
        "reward": 0.42978793382644653,
        "val_loss": 0.0019736288647566524,
        "train_loss": 0.001926880721629669
      },
      {
        "epoch": 384,
        "reward": 0.43670853972435,
        "val_loss": 0.0018654509913176298,
        "train_loss": 0.002206374344845804
      },
      {
        "epoch": 385,
        "reward": 0.45158058404922485,
        "val_loss": 0.0016536976992418723,
        "train_loss": 0.0018870130034674031
      },
      {
        "epoch": 386,
        "reward": 0.4546607434749603,
        "val_loss": 0.0016130935816493417,
        "train_loss": 0.0018770054371438723
      },
      {
        "epoch": 387,
        "reward": 0.4539957046508789,
        "val_loss": 0.001621771337730544,
        "train_loss": 0.001870342702414536
      },
      {
        "epoch": 388,
        "reward": 0.43987011909484863,
        "val_loss": 0.001818149333952793,
        "train_loss": 0.002043085298142754
      },
      {
        "epoch": 389,
        "reward": 0.4545222222805023,
        "val_loss": 0.001614897054553564,
        "train_loss": 0.001951045860411026
      },
      {
        "epoch": 390,
        "reward": 0.4517982006072998,
        "val_loss": 0.0016507944092154503,
        "train_loss": 0.0019164345378437876
      },
      {
        "epoch": 391,
        "reward": 0.4532376229763031,
        "val_loss": 0.001631722877001656,
        "train_loss": 0.001888117095798127
      },
      {
        "epoch": 392,
        "reward": 0.4254853427410126,
        "val_loss": 0.0020442507728668196,
        "train_loss": 0.0019543816272814115
      },
      {
        "epoch": 393,
        "reward": 0.45172205567359924,
        "val_loss": 0.001651809925013887,
        "train_loss": 0.0020643311038908837
      },
      {
        "epoch": 394,
        "reward": 0.44452062249183655,
        "val_loss": 0.0017508667494569505,
        "train_loss": 0.0019600412387472507
      },
      {
        "epoch": 395,
        "reward": 0.4526141583919525,
        "val_loss": 0.0016399548538694425,
        "train_loss": 0.0019338230041075104
      },
      {
        "epoch": 396,
        "reward": 0.44142699241638184,
        "val_loss": 0.0017953255280320133,
        "train_loss": 0.002078259717493963
      },
      {
        "epoch": 397,
        "reward": 0.44603878259658813,
        "val_loss": 0.0017294760327786207,
        "train_loss": 0.002008370189846923
      },
      {
        "epoch": 398,
        "reward": 0.4537137448787689,
        "val_loss": 0.0016254651792613523,
        "train_loss": 0.0018802973634312646
      },
      {
        "epoch": 399,
        "reward": 0.4488656520843506,
        "val_loss": 0.0016903757849442108,
        "train_loss": 0.0019496726070848615
      },
      {
        "epoch": 400,
        "reward": 0.45359736680984497,
        "val_loss": 0.0016269929224758276,
        "train_loss": 0.001915085985764073
      },
      {
        "epoch": 401,
        "reward": 0.43799206614494324,
        "val_loss": 0.0018460919880973442,
        "train_loss": 0.001906019615349718
      },
      {
        "epoch": 402,
        "reward": 0.4530735909938812,
        "val_loss": 0.0016338839029361094,
        "train_loss": 0.00198911862501588
      },
      {
        "epoch": 403,
        "reward": 0.4541366994380951,
        "val_loss": 0.001619927427132747,
        "train_loss": 0.0019831717094907966
      },
      {
        "epoch": 404,
        "reward": 0.45456987619400024,
        "val_loss": 0.0016142767355112092,
        "train_loss": 0.001875466106866952
      },
      {
        "epoch": 405,
        "reward": 0.45200738310813904,
        "val_loss": 0.0016480081165874644,
        "train_loss": 0.001950617159038232
      },
      {
        "epoch": 406,
        "reward": 0.45488840341567993,
        "val_loss": 0.001610134295853121,
        "train_loss": 0.001910134789516003
      },
      {
        "epoch": 407,
        "reward": 0.43815478682518005,
        "val_loss": 0.0018436532035203917,
        "train_loss": 0.00208355931009954
      },
      {
        "epoch": 408,
        "reward": 0.4547851085662842,
        "val_loss": 0.001611476140429399,
        "train_loss": 0.0019005818635028286
      },
      {
        "epoch": 409,
        "reward": 0.4554203450679779,
        "val_loss": 0.0016032414194861694,
        "train_loss": 0.0019226253878934165
      },
      {
        "epoch": 410,
        "reward": 0.4509066641330719,
        "val_loss": 0.001662723404089255,
        "train_loss": 0.0019274231744930148
      },
      {
        "epoch": 411,
        "reward": 0.4543910026550293,
        "val_loss": 0.001616607661292489,
        "train_loss": 0.001890284228675927
      },
      {
        "epoch": 412,
        "reward": 0.453402578830719,
        "val_loss": 0.0016295520555494086,
        "train_loss": 0.0018682298966898369
      },
      {
        "epoch": 413,
        "reward": 0.45404043793678284,
        "val_loss": 0.0016211864006306445,
        "train_loss": 0.0019064278435857536
      },
      {
        "epoch": 414,
        "reward": 0.4409491717815399,
        "val_loss": 0.0018022981738405569,
        "train_loss": 0.0019295562121372384
      },
      {
        "epoch": 415,
        "reward": 0.43602991104125977,
        "val_loss": 0.0018757744692265987,
        "train_loss": 0.002083435914335916
      },
      {
        "epoch": 416,
        "reward": 0.4428151249885559,
        "val_loss": 0.0017752304639933364,
        "train_loss": 0.0019439905165479733
      },
      {
        "epoch": 417,
        "reward": 0.4485364854335785,
        "val_loss": 0.0016948801099455782,
        "train_loss": 0.001925779050977256
      },
      {
        "epoch": 418,
        "reward": 0.4483523368835449,
        "val_loss": 0.001697405756983374,
        "train_loss": 0.001898340880870819
      },
      {
        "epoch": 419,
        "reward": 0.45340052247047424,
        "val_loss": 0.0016295791054809733,
        "train_loss": 0.0019385134737603948
      },
      {
        "epoch": 420,
        "reward": 0.45392081141471863,
        "val_loss": 0.0016227520952400351,
        "train_loss": 0.0019053530391269864
      },
      {
        "epoch": 421,
        "reward": 0.4442775249481201,
        "val_loss": 0.0017543177153649075,
        "train_loss": 0.0019208731649156946
      },
      {
        "epoch": 422,
        "reward": 0.45548897981643677,
        "val_loss": 0.0016023548170258956,
        "train_loss": 0.0019096246147595453
      },
      {
        "epoch": 423,
        "reward": 0.4551185667514801,
        "val_loss": 0.0016071487085095473,
        "train_loss": 0.0018877536259913961
      },
      {
        "epoch": 424,
        "reward": 0.4427200257778168,
        "val_loss": 0.0017765996744856238,
        "train_loss": 0.0018936940211740595
      },
      {
        "epoch": 425,
        "reward": 0.45395565032958984,
        "val_loss": 0.0016222952316249056,
        "train_loss": 0.0019286497308012957
      },
      {
        "epoch": 426,
        "reward": 0.4506320059299469,
        "val_loss": 0.0016664168049049164,
        "train_loss": 0.0018813655870662143
      },
      {
        "epoch": 427,
        "reward": 0.45224103331565857,
        "val_loss": 0.001644902105908841,
        "train_loss": 0.0018664978919192576
      },
      {
        "epoch": 428,
        "reward": 0.453752726316452,
        "val_loss": 0.001624954373775316,
        "train_loss": 0.0018758624836874122
      },
      {
        "epoch": 429,
        "reward": 0.4486810266971588,
        "val_loss": 0.0016929002179365074,
        "train_loss": 0.0019531655539489854
      },
      {
        "epoch": 430,
        "reward": 0.4281102120876312,
        "val_loss": 0.002000849910213479,
        "train_loss": 0.0020031334492019736
      },
      {
        "epoch": 431,
        "reward": 0.4287687838077545,
        "val_loss": 0.0019901168499408023,
        "train_loss": 0.0020352482052448276
      },
      {
        "epoch": 432,
        "reward": 0.45567813515663147,
        "val_loss": 0.0015999128393429732,
        "train_loss": 0.0021437753076987485
      },
      {
        "epoch": 433,
        "reward": 0.44380083680152893,
        "val_loss": 0.001761105709842273,
        "train_loss": 0.0018984588462514624
      },
      {
        "epoch": 434,
        "reward": 0.43540069460868835,
        "val_loss": 0.001885400153696537,
        "train_loss": 0.002087274698379378
      },
      {
        "epoch": 435,
        "reward": 0.4445217251777649,
        "val_loss": 0.001750851099911545,
        "train_loss": 0.0019030109951227831
      },
      {
        "epoch": 436,
        "reward": 0.4530796706676483,
        "val_loss": 0.0016338046157865652,
        "train_loss": 0.0018913944782420562
      },
      {
        "epoch": 437,
        "reward": 0.45213958621025085,
        "val_loss": 0.0016462502868047782,
        "train_loss": 0.0018650681752030952
      },
      {
        "epoch": 438,
        "reward": 0.4284655749797821,
        "val_loss": 0.0019950513628178407,
        "train_loss": 0.0022987316523750243
      },
      {
        "epoch": 439,
        "reward": 0.4420681595802307,
        "val_loss": 0.0017860136244312993,
        "train_loss": 0.0022018880660582977
      },
      {
        "epoch": 440,
        "reward": 0.45236024260520935,
        "val_loss": 0.0016433199801083123,
        "train_loss": 0.0019023333460119409
      },
      {
        "epoch": 441,
        "reward": 0.415905624628067,
        "val_loss": 0.0022114525781944394,
        "train_loss": 0.0021044799896816793
      },
      {
        "epoch": 442,
        "reward": 0.4209918677806854,
        "val_loss": 0.002120913871164833,
        "train_loss": 0.00206378919000809
      },
      {
        "epoch": 443,
        "reward": 0.42558392882347107,
        "val_loss": 0.0020426020491868258,
        "train_loss": 0.001986663475131186
      },
      {
        "epoch": 444,
        "reward": 0.42544689774513245,
        "val_loss": 0.0020448926703206132,
        "train_loss": 0.0019091002265598106
      },
      {
        "epoch": 445,
        "reward": 0.4287656247615814,
        "val_loss": 0.0019901677566979614,
        "train_loss": 0.0023296709360483172
      },
      {
        "epoch": 446,
        "reward": 0.4529036581516266,
        "val_loss": 0.0016361270099878311,
        "train_loss": 0.002059859664873679
      },
      {
        "epoch": 447,
        "reward": 0.4515753388404846,
        "val_loss": 0.0016537677978963725,
        "train_loss": 0.0019501350291718084
      },
      {
        "epoch": 448,
        "reward": 0.42249956727027893,
        "val_loss": 0.0020948508089142187,
        "train_loss": 0.001993816448912884
      },
      {
        "epoch": 449,
        "reward": 0.4272019565105438,
        "val_loss": 0.002015754663651543,
        "train_loss": 0.001975462415989918
      },
      {
        "epoch": 450,
        "reward": 0.45359906554222107,
        "val_loss": 0.0016269704127418144,
        "train_loss": 0.001945468268611596
      },
      {
        "epoch": 451,
        "reward": 0.4549029469490051,
        "val_loss": 0.0016099456281933402,
        "train_loss": 0.0019363490013907163
      },
      {
        "epoch": 452,
        "reward": 0.4366312623023987,
        "val_loss": 0.0018666238257927553,
        "train_loss": 0.0022158968002678682
      },
      {
        "epoch": 453,
        "reward": 0.4540596604347229,
        "val_loss": 0.0016209347689125156,
        "train_loss": 0.0020161372012807988
      },
      {
        "epoch": 454,
        "reward": 0.45199641585350037,
        "val_loss": 0.0016481542011855968,
        "train_loss": 0.0018935187119775666
      },
      {
        "epoch": 455,
        "reward": 0.41577550768852234,
        "val_loss": 0.0022138229105621576,
        "train_loss": 0.002092533740394104
      },
      {
        "epoch": 456,
        "reward": 0.45438241958618164,
        "val_loss": 0.001616719744301268,
        "train_loss": 0.0019089733429539662
      },
      {
        "epoch": 457,
        "reward": 0.4557492733001709,
        "val_loss": 0.001598994929476508,
        "train_loss": 0.0018918771926949446
      },
      {
        "epoch": 458,
        "reward": 0.45582038164138794,
        "val_loss": 0.0015980785163784666,
        "train_loss": 0.0019008872438392316
      },
      {
        "epoch": 459,
        "reward": 0.4535614550113678,
        "val_loss": 0.0016274639804448401,
        "train_loss": 0.0019510181692357247
      },
      {
        "epoch": 460,
        "reward": 0.4113948345184326,
        "val_loss": 0.0022952581223632607,
        "train_loss": 0.0021398359408172276
      },
      {
        "epoch": 461,
        "reward": 0.4442649483680725,
        "val_loss": 0.0017544967122375965,
        "train_loss": 0.0020428446566886404
      },
      {
        "epoch": 462,
        "reward": 0.4531726837158203,
        "val_loss": 0.0016325783633094812,
        "train_loss": 0.001932659222242924
      },
      {
        "epoch": 463,
        "reward": 0.4406033456325531,
        "val_loss": 0.0018073612092328922,
        "train_loss": 0.0018889084368800889
      },
      {
        "epoch": 464,
        "reward": 0.4540187418460846,
        "val_loss": 0.0016214701712929777,
        "train_loss": 0.0018870910386725042
      },
      {
        "epoch": 465,
        "reward": 0.44506940245628357,
        "val_loss": 0.0017431025626137853,
        "train_loss": 0.0019351361283602624
      },
      {
        "epoch": 466,
        "reward": 0.448984295129776,
        "val_loss": 0.001688754842949233,
        "train_loss": 0.0020771222189068794
      },
      {
        "epoch": 467,
        "reward": 0.4513706862926483,
        "val_loss": 0.0016565031255595386,
        "train_loss": 0.002050808324174096
      },
      {
        "epoch": 468,
        "reward": 0.45594993233680725,
        "val_loss": 0.0015964102765013064,
        "train_loss": 0.0019459597376855807
      },
      {
        "epoch": 469,
        "reward": 0.4562436044216156,
        "val_loss": 0.0015926347779376166,
        "train_loss": 0.001963855438589235
      },
      {
        "epoch": 470,
        "reward": 0.4560061991214752,
        "val_loss": 0.0015956855578614132,
        "train_loss": 0.0018876493738319438
      },
      {
        "epoch": 471,
        "reward": 0.45235005021095276,
        "val_loss": 0.0016434550301970116,
        "train_loss": 0.0019147541727831524
      },
      {
        "epoch": 472,
        "reward": 0.44782862067222595,
        "val_loss": 0.001704610202328435,
        "train_loss": 0.0018571471973700682
      },
      {
        "epoch": 473,
        "reward": 0.4540366232395172,
        "val_loss": 0.0016212366172112525,
        "train_loss": 0.0018780599370634614
      },
      {
        "epoch": 474,
        "reward": 0.44732123613357544,
        "val_loss": 0.0017116213150854623,
        "train_loss": 0.0018926920445385175
      },
      {
        "epoch": 475,
        "reward": 0.45451799035072327,
        "val_loss": 0.0016149524349852332,
        "train_loss": 0.0019007149740690903
      },
      {
        "epoch": 476,
        "reward": 0.4480670988559723,
        "val_loss": 0.0017013260678920364,
        "train_loss": 0.0018742661192775883
      },
      {
        "epoch": 477,
        "reward": 0.44994989037513733,
        "val_loss": 0.0016756267536298505,
        "train_loss": 0.0019638706759836236
      },
      {
        "epoch": 478,
        "reward": 0.4482421576976776,
        "val_loss": 0.0016989190896440829,
        "train_loss": 0.002438404015265405
      },
      {
        "epoch": 479,
        "reward": 0.45527753233909607,
        "val_loss": 0.0016050889223281825,
        "train_loss": 0.002061415707710414
      },
      {
        "epoch": 480,
        "reward": 0.44666194915771484,
        "val_loss": 0.0017207756339173233,
        "train_loss": 0.0021655116131744133
      },
      {
        "epoch": 481,
        "reward": 0.44514021277427673,
        "val_loss": 0.001742103145391281,
        "train_loss": 0.0020700986788142473
      },
      {
        "epoch": 482,
        "reward": 0.45607826113700867,
        "val_loss": 0.0015947591912533557,
        "train_loss": 0.0018769876867456613
      },
      {
        "epoch": 483,
        "reward": 0.45619770884513855,
        "val_loss": 0.0015932239475660026,
        "train_loss": 0.0018916549843897184
      },
      {
        "epoch": 484,
        "reward": 0.4447118937969208,
        "val_loss": 0.001748156692234001,
        "train_loss": 0.0019135938491672277
      },
      {
        "epoch": 485,
        "reward": 0.44113072752952576,
        "val_loss": 0.0017996447859331965,
        "train_loss": 0.001872166059911251
      },
      {
        "epoch": 486,
        "reward": 0.4478939473628998,
        "val_loss": 0.001703709937698607,
        "train_loss": 0.0019361793558625951
      },
      {
        "epoch": 487,
        "reward": 0.45240551233291626,
        "val_loss": 0.0016427196595551713,
        "train_loss": 0.0019039666927150951
      },
      {
        "epoch": 488,
        "reward": 0.45252203941345215,
        "val_loss": 0.0016411748947575688,
        "train_loss": 0.0019411595550276562
      },
      {
        "epoch": 489,
        "reward": 0.4549235999584198,
        "val_loss": 0.0016096776983301555,
        "train_loss": 0.0018934455734219786
      },
      {
        "epoch": 490,
        "reward": 0.42168399691581726,
        "val_loss": 0.00210890597996435,
        "train_loss": 0.0018912074939670185
      },
      {
        "epoch": 491,
        "reward": 0.4501773416996002,
        "val_loss": 0.0016725498135201633,
        "train_loss": 0.0019521440420843506
      },
      {
        "epoch": 492,
        "reward": 0.4383796155452728,
        "val_loss": 0.0018402885346274292,
        "train_loss": 0.001951538359627683
      },
      {
        "epoch": 493,
        "reward": 0.4501517713069916,
        "val_loss": 0.0016728953341953456,
        "train_loss": 0.001867767879118149
      },
      {
        "epoch": 494,
        "reward": 0.4519414007663727,
        "val_loss": 0.0016488865866059704,
        "train_loss": 0.001889171741472987
      },
      {
        "epoch": 495,
        "reward": 0.4402732849121094,
        "val_loss": 0.001812210156848388,
        "train_loss": 0.0019084584827606494
      },
      {
        "epoch": 496,
        "reward": 0.4477083384990692,
        "val_loss": 0.0017062691705567496,
        "train_loss": 0.002013846952580095
      },
      {
        "epoch": 497,
        "reward": 0.4215087890625,
        "val_loss": 0.0021119379006060107,
        "train_loss": 0.002198937541554467
      },
      {
        "epoch": 498,
        "reward": 0.42775437235832214,
        "val_loss": 0.002006675848471267,
        "train_loss": 0.0023554593745547417
      },
      {
        "epoch": 499,
        "reward": 0.4548494815826416,
        "val_loss": 0.001610639804442014,
        "train_loss": 0.0023708732915110886
      },
      {
        "epoch": 500,
        "reward": 0.43602386116981506,
        "val_loss": 0.001875867069299732,
        "train_loss": 0.00196154117405128
      },
      {
        "epoch": 501,
        "reward": 0.4419414699077606,
        "val_loss": 0.0017878501676023006,
        "train_loss": 0.0018973892247931173
      },
      {
        "epoch": 502,
        "reward": 0.4555806815624237,
        "val_loss": 0.0016011704408031488,
        "train_loss": 0.0019114237153329528
      },
      {
        "epoch": 503,
        "reward": 0.43630629777908325,
        "val_loss": 0.0018715634110516735,
        "train_loss": 0.002422136653107233
      },
      {
        "epoch": 504,
        "reward": 0.45002564787864685,
        "val_loss": 0.0016746003363680626,
        "train_loss": 0.003098907396913721
      },
      {
        "epoch": 505,
        "reward": 0.4439077079296112,
        "val_loss": 0.0017595817501257574,
        "train_loss": 0.0022014201072474513
      },
      {
        "epoch": 506,
        "reward": 0.4554397761821747,
        "val_loss": 0.0016029909269751183,
        "train_loss": 0.0018946118731177053
      },
      {
        "epoch": 507,
        "reward": 0.4483158588409424,
        "val_loss": 0.0016979070413591607,
        "train_loss": 0.002107460551017609
      },
      {
        "epoch": 508,
        "reward": 0.446867436170578,
        "val_loss": 0.0017179165401362947,
        "train_loss": 0.0019224318309100524
      },
      {
        "epoch": 509,
        "reward": 0.43774041533470154,
        "val_loss": 0.0018498708294438465,
        "train_loss": 0.002042218653234438
      },
      {
        "epoch": 510,
        "reward": 0.45363950729370117,
        "val_loss": 0.0016264396087665642,
        "train_loss": 0.001893618345583001
      },
      {
        "epoch": 511,
        "reward": 0.4488285481929779,
        "val_loss": 0.0016908826156785445,
        "train_loss": 0.001903237948471752
      },
      {
        "epoch": 512,
        "reward": 0.4520881772041321,
        "val_loss": 0.00164693349506706,
        "train_loss": 0.0019526990139498734
      },
      {
        "epoch": 513,
        "reward": 0.44454145431518555,
        "val_loss": 0.001750571304000914,
        "train_loss": 0.0019061193299701419
      },
      {
        "epoch": 514,
        "reward": 0.4545108377933502,
        "val_loss": 0.0016150452845197702,
        "train_loss": 0.0018746698378191257
      },
      {
        "epoch": 515,
        "reward": 0.45463553071022034,
        "val_loss": 0.0016134220724260168,
        "train_loss": 0.001859920958762674
      },
      {
        "epoch": 516,
        "reward": 0.43925562500953674,
        "val_loss": 0.001827242734309818,
        "train_loss": 0.0019205733697162941
      },
      {
        "epoch": 517,
        "reward": 0.43091893196105957,
        "val_loss": 0.0019555017684719394,
        "train_loss": 0.00235063927874972
      },
      {
        "epoch": 518,
        "reward": 0.4126353859901428,
        "val_loss": 0.002271871265423085,
        "train_loss": 0.002242520420203129
      },
      {
        "epoch": 519,
        "reward": 0.4543825089931488,
        "val_loss": 0.0016167180147022009,
        "train_loss": 0.0020868599128264645
      },
      {
        "epoch": 520,
        "reward": 0.4547578990459442,
        "val_loss": 0.0016118302592076361,
        "train_loss": 0.0018723565444815904
      },
      {
        "epoch": 521,
        "reward": 0.4527294635772705,
        "val_loss": 0.0016384294722229242,
        "train_loss": 0.0019205158459953964
      },
      {
        "epoch": 522,
        "reward": 0.45298752188682556,
        "val_loss": 0.0016350193431467883,
        "train_loss": 0.0018669715507257933
      },
      {
        "epoch": 523,
        "reward": 0.44659239053726196,
        "val_loss": 0.0017217447249484913,
        "train_loss": 0.0018619357100620759
      },
      {
        "epoch": 524,
        "reward": 0.4316630959510803,
        "val_loss": 0.001943672009344612,
        "train_loss": 0.001870391272859706
      },
      {
        "epoch": 525,
        "reward": 0.45449453592300415,
        "val_loss": 0.0016152576011206423,
        "train_loss": 0.0019124153821814195
      },
      {
        "epoch": 526,
        "reward": 0.4520040452480316,
        "val_loss": 0.0016480525955557823,
        "train_loss": 0.0018549199222049468
      },
      {
        "epoch": 527,
        "reward": 0.43771180510520935,
        "val_loss": 0.001850301433088524,
        "train_loss": 0.001865220539492349
      },
      {
        "epoch": 528,
        "reward": 0.40722140669822693,
        "val_loss": 0.002375881586756025,
        "train_loss": 0.002110617651711576
      },
      {
        "epoch": 529,
        "reward": 0.4540879428386688,
        "val_loss": 0.0016205651003734342,
        "train_loss": 0.002399009233788372
      },
      {
        "epoch": 530,
        "reward": 0.4531393051147461,
        "val_loss": 0.001633017390434231,
        "train_loss": 0.0018798247916632905
      },
      {
        "epoch": 531,
        "reward": 0.4462895095348358,
        "val_loss": 0.0017259696864389948,
        "train_loss": 0.0018569037550220785
      },
      {
        "epoch": 532,
        "reward": 0.45601698756217957,
        "val_loss": 0.0015955472814052232,
        "train_loss": 0.0019473337317601992
      },
      {
        "epoch": 533,
        "reward": 0.42924728989601135,
        "val_loss": 0.0019823574028643115,
        "train_loss": 0.0019267084672509765
      },
      {
        "epoch": 534,
        "reward": 0.4524483382701874,
        "val_loss": 0.0016421517689845391,
        "train_loss": 0.0019301093505838742
      },
      {
        "epoch": 535,
        "reward": 0.4325428605079651,
        "val_loss": 0.0019297852580036437,
        "train_loss": 0.001918809298121442
      },
      {
        "epoch": 536,
        "reward": 0.45620962977409363,
        "val_loss": 0.001593071609802012,
        "train_loss": 0.0019452725285261225
      },
      {
        "epoch": 537,
        "reward": 0.4560302197933197,
        "val_loss": 0.001595376616543425,
        "train_loss": 0.0018879090092433705
      },
      {
        "epoch": 538,
        "reward": 0.4356614053249359,
        "val_loss": 0.001881405511604888,
        "train_loss": 0.0020256756912343777
      },
      {
        "epoch": 539,
        "reward": 0.45136889815330505,
        "val_loss": 0.0016565265666161264,
        "train_loss": 0.001914975905002883
      },
      {
        "epoch": 540,
        "reward": 0.45257630944252014,
        "val_loss": 0.0016404561715067498,
        "train_loss": 0.0018808373267977284
      },
      {
        "epoch": 541,
        "reward": 0.41329675912857056,
        "val_loss": 0.002259508224337229,
        "train_loss": 0.0022359768224235336
      },
      {
        "epoch": 542,
        "reward": 0.45494651794433594,
        "val_loss": 0.0016093798829907818,
        "train_loss": 0.0023729821326784217
      },
      {
        "epoch": 543,
        "reward": 0.45366016030311584,
        "val_loss": 0.0016261688683048955,
        "train_loss": 0.0018746952103426268
      },
      {
        "epoch": 544,
        "reward": 0.4555025100708008,
        "val_loss": 0.0016021793126128614,
        "train_loss": 0.0018525971265542186
      },
      {
        "epoch": 545,
        "reward": 0.45202261209487915,
        "val_loss": 0.0016478061193733343,
        "train_loss": 0.00193854710400606
      },
      {
        "epoch": 546,
        "reward": 0.4536839425563812,
        "val_loss": 0.0016258563929503517,
        "train_loss": 0.0019195595836768357
      },
      {
        "epoch": 547,
        "reward": 0.4246094226837158,
        "val_loss": 0.0020589569051350865,
        "train_loss": 0.0019408775865136145
      },
      {
        "epoch": 548,
        "reward": 0.44379326701164246,
        "val_loss": 0.001761214092506894,
        "train_loss": 0.0019150547152373921
      },
      {
        "epoch": 549,
        "reward": 0.45007139444351196,
        "val_loss": 0.001673982195955302,
        "train_loss": 0.0018719197060608377
      },
      {
        "epoch": 550,
        "reward": 0.4098723530769348,
        "val_loss": 0.0023243192450276445,
        "train_loss": 0.002126912868474252
      },
      {
        "epoch": 551,
        "reward": 0.4449465870857239,
        "val_loss": 0.001744836602093918,
        "train_loss": 0.003325804996375854
      },
      {
        "epoch": 552,
        "reward": 0.44109413027763367,
        "val_loss": 0.0018001792320449436,
        "train_loss": 0.002128752673832843
      },
      {
        "epoch": 553,
        "reward": 0.4534929394721985,
        "val_loss": 0.0016283645111668324,
        "train_loss": 0.0019306113412872388
      },
      {
        "epoch": 554,
        "reward": 0.4557258188724518,
        "val_loss": 0.001599297667520919,
        "train_loss": 0.0018891704944857897
      },
      {
        "epoch": 555,
        "reward": 0.4562329351902008,
        "val_loss": 0.0015927719733943896,
        "train_loss": 0.001910741005723629
      },
      {
        "epoch": 556,
        "reward": 0.4523143470287323,
        "val_loss": 0.0016439291066490114,
        "train_loss": 0.0018736685854561913
      },
      {
        "epoch": 557,
        "reward": 0.44860193133354187,
        "val_loss": 0.0016939834458753467,
        "train_loss": 0.0018954026588919358
      },
      {
        "epoch": 558,
        "reward": 0.45622286200523376,
        "val_loss": 0.0015929011278785765,
        "train_loss": 0.0018714246005209554
      },
      {
        "epoch": 559,
        "reward": 0.42760106921195984,
        "val_loss": 0.0020091903528996874,
        "train_loss": 0.0019642823160840915
      },
      {
        "epoch": 560,
        "reward": 0.44144439697265625,
        "val_loss": 0.0017950714931690267,
        "train_loss": 0.0020226226489862362
      },
      {
        "epoch": 561,
        "reward": 0.40797755122184753,
        "val_loss": 0.0023610482291717616,
        "train_loss": 0.0020076412407573885
      },
      {
        "epoch": 562,
        "reward": 0.44407764077186584,
        "val_loss": 0.0017571602948009968,
        "train_loss": 0.0021304712600585143
      },
      {
        "epoch": 563,
        "reward": 0.44532299041748047,
        "val_loss": 0.0017395267745346896,
        "train_loss": 0.0020394146939417203
      },
      {
        "epoch": 564,
        "reward": 0.44373393058776855,
        "val_loss": 0.0017620607977733016,
        "train_loss": 0.002055256954358461
      },
      {
        "epoch": 565,
        "reward": 0.44372883439064026,
        "val_loss": 0.0017621337735493267,
        "train_loss": 0.0019426497450555102
      },
      {
        "epoch": 566,
        "reward": 0.45509472489356995,
        "val_loss": 0.0016074573172123305,
        "train_loss": 0.0018668266736942595
      },
      {
        "epoch": 567,
        "reward": 0.4509292542934418,
        "val_loss": 0.0016624201089143753,
        "train_loss": 0.002069347712676972
      },
      {
        "epoch": 568,
        "reward": 0.4390740394592285,
        "val_loss": 0.0018299390628401721,
        "train_loss": 0.0021296458390469733
      },
      {
        "epoch": 569,
        "reward": 0.446717232465744,
        "val_loss": 0.00172000567129414,
        "train_loss": 0.0020125901960105132
      },
      {
        "epoch": 570,
        "reward": 0.4309369623661041,
        "val_loss": 0.001955213723704219,
        "train_loss": 0.002068013834874504
      },
      {
        "epoch": 571,
        "reward": 0.4547472596168518,
        "val_loss": 0.0016119683277793229,
        "train_loss": 0.002049789639741015
      },
      {
        "epoch": 572,
        "reward": 0.4471403658390045,
        "val_loss": 0.0017141268638494825,
        "train_loss": 0.0019312802469357848
      },
      {
        "epoch": 573,
        "reward": 0.4538581371307373,
        "val_loss": 0.0016235725571667509,
        "train_loss": 0.0019786536778645734
      },
      {
        "epoch": 574,
        "reward": 0.4365096688270569,
        "val_loss": 0.0018684706384582178,
        "train_loss": 0.0022683457041589115
      },
      {
        "epoch": 575,
        "reward": 0.45575353503227234,
        "val_loss": 0.0015989407381441975,
        "train_loss": 0.002504981957967035
      },
      {
        "epoch": 576,
        "reward": 0.4548645615577698,
        "val_loss": 0.0016104441019706428,
        "train_loss": 0.001942100773493831
      },
      {
        "epoch": 577,
        "reward": 0.4508368968963623,
        "val_loss": 0.0016636615369601973,
        "train_loss": 0.0018608444194814393
      },
      {
        "epoch": 578,
        "reward": 0.45573121309280396,
        "val_loss": 0.001599227502343378,
        "train_loss": 0.0018880355883783733
      },
      {
        "epoch": 579,
        "reward": 0.4556658864021301,
        "val_loss": 0.001600070415796446,
        "train_loss": 0.0019010802282607004
      },
      {
        "epoch": 580,
        "reward": 0.4532753527164459,
        "val_loss": 0.0016312263323925436,
        "train_loss": 0.0019241442250159497
      },
      {
        "epoch": 581,
        "reward": 0.447150856256485,
        "val_loss": 0.001713981552581702,
        "train_loss": 0.0018740191399746647
      },
      {
        "epoch": 582,
        "reward": 0.4469050467014313,
        "val_loss": 0.0017173932865262032,
        "train_loss": 0.0019929474510718137
      },
      {
        "epoch": 583,
        "reward": 0.45497122406959534,
        "val_loss": 0.0016090593001406109,
        "train_loss": 0.0018684846323395732
      },
      {
        "epoch": 584,
        "reward": 0.45460811257362366,
        "val_loss": 0.0016137792263180017,
        "train_loss": 0.0019033637531370355
      },
      {
        "epoch": 585,
        "reward": 0.4529430866241455,
        "val_loss": 0.001635605885115053,
        "train_loss": 0.0018801869188721937
      },
      {
        "epoch": 586,
        "reward": 0.4297947883605957,
        "val_loss": 0.0019735178876934306,
        "train_loss": 0.002043396176304668
      },
      {
        "epoch": 587,
        "reward": 0.44840317964553833,
        "val_loss": 0.0016967083127903087,
        "train_loss": 0.0019646335788890542
      },
      {
        "epoch": 588,
        "reward": 0.43904373049736023,
        "val_loss": 0.0018303901722122515,
        "train_loss": 0.0018663377167845634
      },
      {
        "epoch": 589,
        "reward": 0.45520472526550293,
        "val_loss": 0.0016060323770424084,
        "train_loss": 0.0018712114900923693
      },
      {
        "epoch": 590,
        "reward": 0.44660791754722595,
        "val_loss": 0.0017215271363966167,
        "train_loss": 0.0019158622263393437
      },
      {
        "epoch": 591,
        "reward": 0.42704328894615173,
        "val_loss": 0.002018370416148433,
        "train_loss": 0.002368236265073602
      },
      {
        "epoch": 592,
        "reward": 0.4335549473762512,
        "val_loss": 0.0019139402679034642,
        "train_loss": 0.0024181080964178992
      },
      {
        "epoch": 593,
        "reward": 0.4545784592628479,
        "val_loss": 0.0016141644030410265,
        "train_loss": 0.0020766999245657083
      },
      {
        "epoch": 594,
        "reward": 0.4532959461212158,
        "val_loss": 0.0016309549849081253,
        "train_loss": 0.0018931449200093853
      },
      {
        "epoch": 595,
        "reward": 0.43925008177757263,
        "val_loss": 0.0018273253226652741,
        "train_loss": 0.0019411319875731491
      },
      {
        "epoch": 596,
        "reward": 0.4470461905002594,
        "val_loss": 0.001715433584260089,
        "train_loss": 0.0018682588568201307
      },
      {
        "epoch": 597,
        "reward": 0.4342007339000702,
        "val_loss": 0.0019039023401481764,
        "train_loss": 0.002066900187995858
      },
      {
        "epoch": 598,
        "reward": 0.44843798875808716,
        "val_loss": 0.0016962307605094143,
        "train_loss": 0.00187099364780908
      },
      {
        "epoch": 599,
        "reward": 0.4362439811229706,
        "val_loss": 0.0018725125618012889,
        "train_loss": 0.002078096449482613
      },
      {
        "epoch": 600,
        "reward": 0.4247857630252838,
        "val_loss": 0.0020559870837522404,
        "train_loss": 0.0020480503906303337
      },
      {
        "epoch": 601,
        "reward": 0.4547392427921295,
        "val_loss": 0.0016120729518921248,
        "train_loss": 0.0019449306880862703
      },
      {
        "epoch": 602,
        "reward": 0.44653111696243286,
        "val_loss": 0.0017225979827344418,
        "train_loss": 0.0018696448049433036
      },
      {
        "epoch": 603,
        "reward": 0.4495978057384491,
        "val_loss": 0.001680401079024055,
        "train_loss": 0.0018822515748280028
      },
      {
        "epoch": 604,
        "reward": 0.4361381232738495,
        "val_loss": 0.0018741250803161944,
        "train_loss": 0.00200667976661442
      },
      {
        "epoch": 605,
        "reward": 0.44985562562942505,
        "val_loss": 0.0016769039128640933,
        "train_loss": 0.0020616990928269494
      },
      {
        "epoch": 606,
        "reward": 0.4539463222026825,
        "val_loss": 0.001622418116312474,
        "train_loss": 0.0018753409430456276
      },
      {
        "epoch": 607,
        "reward": 0.4493497908115387,
        "val_loss": 0.0016837731153438134,
        "train_loss": 0.002298377973672289
      },
      {
        "epoch": 608,
        "reward": 0.44616079330444336,
        "val_loss": 0.0017277685526226247,
        "train_loss": 0.002036447390519942
      },
      {
        "epoch": 609,
        "reward": 0.4473094046115875,
        "val_loss": 0.001711784679043506,
        "train_loss": 0.0019476250073729227
      },
      {
        "epoch": 610,
        "reward": 0.44706302881240845,
        "val_loss": 0.0017152000301783638,
        "train_loss": 0.0019831946634580023
      },
      {
        "epoch": 611,
        "reward": 0.42605289816856384,
        "val_loss": 0.002034780552743801,
        "train_loss": 0.002138401882033437
      },
      {
        "epoch": 612,
        "reward": 0.4201347529888153,
        "val_loss": 0.002135885330582304,
        "train_loss": 0.0023162900738847945
      },
      {
        "epoch": 613,
        "reward": 0.4527417719364166,
        "val_loss": 0.0016382666321338288,
        "train_loss": 0.002080045931506902
      },
      {
        "epoch": 614,
        "reward": 0.44113633036613464,
        "val_loss": 0.001799564010330609,
        "train_loss": 0.0022766200977807436
      },
      {
        "epoch": 615,
        "reward": 0.4308905303478241,
        "val_loss": 0.0019559545908123255,
        "train_loss": 0.0020218343460538355
      },
      {
        "epoch": 616,
        "reward": 0.4467957019805908,
        "val_loss": 0.0017189137205215438,
        "train_loss": 0.0018920358066907284
      },
      {
        "epoch": 617,
        "reward": 0.4485839307308197,
        "val_loss": 0.0016942305041344038,
        "train_loss": 0.001882811715544309
      },
      {
        "epoch": 618,
        "reward": 0.43672677874565125,
        "val_loss": 0.0018651759019121528,
        "train_loss": 0.0019404356358931041
      },
      {
        "epoch": 619,
        "reward": 0.44424518942832947,
        "val_loss": 0.0017547767243481108,
        "train_loss": 0.0019770581604042
      },
      {
        "epoch": 620,
        "reward": 0.4498843252658844,
        "val_loss": 0.0016765145535048629,
        "train_loss": 0.0018833006408665543
      },
      {
        "epoch": 621,
        "reward": 0.38034242391586304,
        "val_loss": 0.002976151615647333,
        "train_loss": 0.002337007205754232
      },
      {
        "epoch": 622,
        "reward": 0.42843928933143616,
        "val_loss": 0.0019954792223870754,
        "train_loss": 0.002335623421598799
      },
      {
        "epoch": 623,
        "reward": 0.4540031850337982,
        "val_loss": 0.0016216733492910862,
        "train_loss": 0.0019500166750871218
      },
      {
        "epoch": 624,
        "reward": 0.44626808166503906,
        "val_loss": 0.0017262690567544528,
        "train_loss": 0.002030734751875011
      },
      {
        "epoch": 625,
        "reward": 0.4381983280181885,
        "val_loss": 0.0018430011446720787,
        "train_loss": 0.0025115756994077507
      },
      {
        "epoch": 626,
        "reward": 0.45100051164627075,
        "val_loss": 0.001661463441061122,
        "train_loss": 0.002005992701295047
      },
      {
        "epoch": 627,
        "reward": 0.4487144947052002,
        "val_loss": 0.001692442738983248,
        "train_loss": 0.002002214853116759
      },
      {
        "epoch": 628,
        "reward": 0.45173054933547974,
        "val_loss": 0.0016516964699673866,
        "train_loss": 0.0019300080289562733
      },
      {
        "epoch": 629,
        "reward": 0.4190339148044586,
        "val_loss": 0.002155282734228032,
        "train_loss": 0.002033691965222645
      },
      {
        "epoch": 630,
        "reward": 0.4554501175880432,
        "val_loss": 0.001602856641901391,
        "train_loss": 0.001974485543681882
      },
      {
        "epoch": 631,
        "reward": 0.44418516755104065,
        "val_loss": 0.0017556310963949987,
        "train_loss": 0.002100549862146951
      },
      {
        "epoch": 632,
        "reward": 0.4529716968536377,
        "val_loss": 0.0016352281257111048,
        "train_loss": 0.0019516552162643236
      },
      {
        "epoch": 633,
        "reward": 0.4452340602874756,
        "val_loss": 0.001740780085258718,
        "train_loss": 0.0018841834333635722
      },
      {
        "epoch": 634,
        "reward": 0.44601795077323914,
        "val_loss": 0.0017297682019748858,
        "train_loss": 0.0018627457180767893
      },
      {
        "epoch": 635,
        "reward": 0.4524296820163727,
        "val_loss": 0.0016423992097510823,
        "train_loss": 0.0018729202112388941
      },
      {
        "epoch": 636,
        "reward": 0.4549522399902344,
        "val_loss": 0.0016093056266462164,
        "train_loss": 0.0018808675623194387
      },
      {
        "epoch": 637,
        "reward": 0.4449957311153412,
        "val_loss": 0.001744142617098987,
        "train_loss": 0.002304138275436484
      },
      {
        "epoch": 638,
        "reward": 0.44356438517570496,
        "val_loss": 0.0017644841739508723,
        "train_loss": 0.002223740566897994
      },
      {
        "epoch": 639,
        "reward": 0.4542410969734192,
        "val_loss": 0.0016185639293066093,
        "train_loss": 0.0018998086931018266
      },
      {
        "epoch": 640,
        "reward": 0.4316270351409912,
        "val_loss": 0.0019442432260672962,
        "train_loss": 0.002259921282529831
      },
      {
        "epoch": 641,
        "reward": 0.455304354429245,
        "val_loss": 0.0016047420129845186,
        "train_loss": 0.002141971893322009
      },
      {
        "epoch": 642,
        "reward": 0.45606112480163574,
        "val_loss": 0.0015949790997962867,
        "train_loss": 0.001872042274151489
      },
      {
        "epoch": 643,
        "reward": 0.439251184463501,
        "val_loss": 0.0018273086420127324,
        "train_loss": 0.0018720327328852504
      },
      {
        "epoch": 644,
        "reward": 0.4456918239593506,
        "val_loss": 0.0017343400229167724,
        "train_loss": 0.0020592475462203417
      },
      {
        "epoch": 645,
        "reward": 0.45284897089004517,
        "val_loss": 0.001636849092652223,
        "train_loss": 0.002064517764945497
      },
      {
        "epoch": 646,
        "reward": 0.45596715807914734,
        "val_loss": 0.001596188804666911,
        "train_loss": 0.0018755540720751295
      },
      {
        "epoch": 647,
        "reward": 0.4562574326992035,
        "val_loss": 0.0015924568038566836,
        "train_loss": 0.0018769392501711152
      },
      {
        "epoch": 648,
        "reward": 0.4084678590297699,
        "val_loss": 0.002351482764684728,
        "train_loss": 0.0019305551921626409
      },
      {
        "epoch": 649,
        "reward": 0.45132842659950256,
        "val_loss": 0.0016570685880391725,
        "train_loss": 0.001965924550649316
      },
      {
        "epoch": 650,
        "reward": 0.41673406958580017,
        "val_loss": 0.002196424042007753,
        "train_loss": 0.002074047260416242
      },
      {
        "epoch": 651,
        "reward": 0.45463284850120544,
        "val_loss": 0.0016134570469148457,
        "train_loss": 0.002260066308596064
      },
      {
        "epoch": 652,
        "reward": 0.4422791600227356,
        "val_loss": 0.001782960890393172,
        "train_loss": 0.0018908908330978681
      },
      {
        "epoch": 653,
        "reward": 0.4505598545074463,
        "val_loss": 0.001667388215927141,
        "train_loss": 0.0019952852386408127
      },
      {
        "epoch": 654,
        "reward": 0.4436035752296448,
        "val_loss": 0.0017639227277998412,
        "train_loss": 0.0018818943166339663
      },
      {
        "epoch": 655,
        "reward": 0.45572900772094727,
        "val_loss": 0.0015992567309045366,
        "train_loss": 0.001872283150777758
      },
      {
        "epoch": 656,
        "reward": 0.4085548520088196,
        "val_loss": 0.0023497911003817406,
        "train_loss": 0.0021210402639833493
      },
      {
        "epoch": 657,
        "reward": 0.43428951501846313,
        "val_loss": 0.001902527192474476,
        "train_loss": 0.0021453624313625577
      },
      {
        "epoch": 658,
        "reward": 0.45146021246910095,
        "val_loss": 0.001655305627666946,
        "train_loss": 0.0019013360055956023
      },
      {
        "epoch": 659,
        "reward": 0.4550878703594208,
        "val_loss": 0.0016075460423183227,
        "train_loss": 0.0018612535374743927
      },
      {
        "epoch": 660,
        "reward": 0.43305903673171997,
        "val_loss": 0.0019216865434178285,
        "train_loss": 0.0018602202802027862
      },
      {
        "epoch": 661,
        "reward": 0.45403560996055603,
        "val_loss": 0.0016212492565890507,
        "train_loss": 0.001985638308374641
      },
      {
        "epoch": 662,
        "reward": 0.44568106532096863,
        "val_loss": 0.0017344909969584218,
        "train_loss": 0.0019321167548276628
      },
      {
        "epoch": 663,
        "reward": 0.4556009769439697,
        "val_loss": 0.0016009083150752953,
        "train_loss": 0.0018910442360300715
      },
      {
        "epoch": 664,
        "reward": 0.4441958963871002,
        "val_loss": 0.0017554786754772067,
        "train_loss": 0.0018944911571452394
      },
      {
        "epoch": 665,
        "reward": 0.44911623001098633,
        "val_loss": 0.001686955220066011,
        "train_loss": 0.0019027992530158582
      },
      {
        "epoch": 666,
        "reward": 0.44255518913269043,
        "val_loss": 0.0017789754700580879,
        "train_loss": 0.0018585195945119127
      },
      {
        "epoch": 667,
        "reward": 0.4538799226284027,
        "val_loss": 0.0016232866660824844,
        "train_loss": 0.0018619913935253862
      },
      {
        "epoch": 668,
        "reward": 0.4558473527431488,
        "val_loss": 0.0015977307838121696,
        "train_loss": 0.0018638554202670304
      },
      {
        "epoch": 669,
        "reward": 0.455879271030426,
        "val_loss": 0.0015973195965800966,
        "train_loss": 0.0018645445721071714
      },
      {
        "epoch": 670,
        "reward": 0.45536404848098755,
        "val_loss": 0.0016039700130932033,
        "train_loss": 0.0018829888704063025
      },
      {
        "epoch": 671,
        "reward": 0.45339474081993103,
        "val_loss": 0.0016296547504940204,
        "train_loss": 0.0020407478217608654
      },
      {
        "epoch": 672,
        "reward": 0.4527158737182617,
        "val_loss": 0.0016386085023571337,
        "train_loss": 0.0019968359623677456
      },
      {
        "epoch": 673,
        "reward": 0.4520131051540375,
        "val_loss": 0.0016479319227593286,
        "train_loss": 0.0020067709713028027
      },
      {
        "epoch": 674,
        "reward": 0.45453205704689026,
        "val_loss": 0.0016147692055840576,
        "train_loss": 0.0020371316038038526
      },
      {
        "epoch": 675,
        "reward": 0.4546128809452057,
        "val_loss": 0.0016137165532979583,
        "train_loss": 0.0019437297887634486
      },
      {
        "epoch": 676,
        "reward": 0.4558280408382416,
        "val_loss": 0.0015979795966164342,
        "train_loss": 0.0020006514387205243
      },
      {
        "epoch": 677,
        "reward": 0.4512154161930084,
        "val_loss": 0.0016585817211307585,
        "train_loss": 0.0019312222894733657
      },
      {
        "epoch": 678,
        "reward": 0.43218645453453064,
        "val_loss": 0.0019353981894840086,
        "train_loss": 0.0019614347682083743
      },
      {
        "epoch": 679,
        "reward": 0.4463368058204651,
        "val_loss": 0.0017253091625337089,
        "train_loss": 0.0019878192419687715
      },
      {
        "epoch": 680,
        "reward": 0.45523786544799805,
        "val_loss": 0.001605602222428258,
        "train_loss": 0.0019120721755406032
      },
      {
        "epoch": 681,
        "reward": 0.45097532868385315,
        "val_loss": 0.0016618012533789234,
        "train_loss": 0.0019247728555455978
      },
      {
        "epoch": 682,
        "reward": 0.4531765580177307,
        "val_loss": 0.0016325273235062404,
        "train_loss": 0.0018715473746012251
      },
      {
        "epoch": 683,
        "reward": 0.4427051246166229,
        "val_loss": 0.0017768143443390727,
        "train_loss": 0.001903903729411328
      },
      {
        "epoch": 684,
        "reward": 0.4554482400417328,
        "val_loss": 0.0016028810225959336,
        "train_loss": 0.0018874770942672442
      },
      {
        "epoch": 685,
        "reward": 0.43864068388938904,
        "val_loss": 0.0018363904507298554,
        "train_loss": 0.0018964770536583203
      },
      {
        "epoch": 686,
        "reward": 0.44376659393310547,
        "val_loss": 0.0017615941053788578,
        "train_loss": 0.002004678164107295
      },
      {
        "epoch": 687,
        "reward": 0.45283427834510803,
        "val_loss": 0.0016370430488937668,
        "train_loss": 0.001956225667807023
      },
      {
        "epoch": 688,
        "reward": 0.44060060381889343,
        "val_loss": 0.0018074023703645384,
        "train_loss": 0.00196699856986435
      },
      {
        "epoch": 689,
        "reward": 0.44984927773475647,
        "val_loss": 0.0016769890789873898,
        "train_loss": 0.0018635425859918962
      },
      {
        "epoch": 690,
        "reward": 0.416372150182724,
        "val_loss": 0.0022029754971819265,
        "train_loss": 0.00229384369091489
      },
      {
        "epoch": 691,
        "reward": 0.45208749175071716,
        "val_loss": 0.0016469425089391215,
        "train_loss": 0.0025660850179310027
      },
      {
        "epoch": 692,
        "reward": 0.4401702582836151,
        "val_loss": 0.0018137255849848901,
        "train_loss": 0.00197482278991419
      },
      {
        "epoch": 693,
        "reward": 0.45401763916015625,
        "val_loss": 0.001621484523639083,
        "train_loss": 0.0018929755405084647
      },
      {
        "epoch": 694,
        "reward": 0.4123268127441406,
        "val_loss": 0.0022776634099760224,
        "train_loss": 0.0020148770686668847
      },
      {
        "epoch": 695,
        "reward": 0.45094844698905945,
        "val_loss": 0.0016621629557838397,
        "train_loss": 0.002077625809201541
      },
      {
        "epoch": 696,
        "reward": 0.43836912512779236,
        "val_loss": 0.001840445096604526,
        "train_loss": 0.0021369394425374386
      },
      {
        "epoch": 697,
        "reward": 0.43308210372924805,
        "val_loss": 0.0019213246580745494,
        "train_loss": 0.0020788997700527455
      },
      {
        "epoch": 698,
        "reward": 0.4523361623287201,
        "val_loss": 0.0016436390412439192,
        "train_loss": 0.0023819175951827606
      },
      {
        "epoch": 699,
        "reward": 0.4387664496898651,
        "val_loss": 0.0018345160975254007,
        "train_loss": 0.002408747037407011
      },
      {
        "epoch": 700,
        "reward": 0.45116931200027466,
        "val_loss": 0.001659199977958841,
        "train_loss": 0.0022362972264930317
      },
      {
        "epoch": 701,
        "reward": 0.45705023407936096,
        "val_loss": 0.0015823130046815745,
        "train_loss": 0.00190097379926066
      },
      {
        "epoch": 702,
        "reward": 0.4535050392150879,
        "val_loss": 0.00162820506375283,
        "train_loss": 0.0018564861035726538
      },
      {
        "epoch": 703,
        "reward": 0.451805979013443,
        "val_loss": 0.0016506908245251647,
        "train_loss": 0.0019150727804606925
      },
      {
        "epoch": 704,
        "reward": 0.45631924271583557,
        "val_loss": 0.0015916642067687853,
        "train_loss": 0.0018871012251530862
      },
      {
        "epoch": 705,
        "reward": 0.4480891227722168,
        "val_loss": 0.001701023121963122,
        "train_loss": 0.001871528827905422
      },
      {
        "epoch": 706,
        "reward": 0.4516037404537201,
        "val_loss": 0.0016533882257395557,
        "train_loss": 0.0018555909840730377
      },
      {
        "epoch": 707,
        "reward": 0.4295605719089508,
        "val_loss": 0.0019772942177951336,
        "train_loss": 0.002237633159473682
      },
      {
        "epoch": 708,
        "reward": 0.3837577998638153,
        "val_loss": 0.0028912758820557167,
        "train_loss": 0.002466484107292042
      },
      {
        "epoch": 709,
        "reward": 0.4489670395851135,
        "val_loss": 0.00168899042598371,
        "train_loss": 0.0021832072240893187
      },
      {
        "epoch": 710,
        "reward": 0.45414552092552185,
        "val_loss": 0.0016198123256409807,
        "train_loss": 0.001977814459958329
      },
      {
        "epoch": 711,
        "reward": 0.4236050248146057,
        "val_loss": 0.0020759609760716558,
        "train_loss": 0.0019180525732735987
      },
      {
        "epoch": 712,
        "reward": 0.45514827966690063,
        "val_loss": 0.0016067633155866393,
        "train_loss": 0.0019038470505060663
      },
      {
        "epoch": 713,
        "reward": 0.44480395317077637,
        "val_loss": 0.0017468532231370254,
        "train_loss": 0.002190491728610001
      },
      {
        "epoch": 714,
        "reward": 0.42744001746177673,
        "val_loss": 0.0020118357414113624,
        "train_loss": 0.002119425608095928
      },
      {
        "epoch": 715,
        "reward": 0.45089322328567505,
        "val_loss": 0.0016629045213838772,
        "train_loss": 0.002153609886031168
      },
      {
        "epoch": 716,
        "reward": 0.45038270950317383,
        "val_loss": 0.0016697767839234854,
        "train_loss": 0.0022411560639739037
      },
      {
        "epoch": 717,
        "reward": 0.44765064120292664,
        "val_loss": 0.0017070666487727845,
        "train_loss": 0.001910020332825997
      },
      {
        "epoch": 718,
        "reward": 0.44510385394096375,
        "val_loss": 0.00174261666169124,
        "train_loss": 0.0019739338223679135
      },
      {
        "epoch": 719,
        "reward": 0.43636569380760193,
        "val_loss": 0.0018706586810627154,
        "train_loss": 0.0020719516637305226
      },
      {
        "epoch": 720,
        "reward": 0.4537475109100342,
        "val_loss": 0.001625022742830749,
        "train_loss": 0.0020195407269056886
      },
      {
        "epoch": 721,
        "reward": 0.4556193947792053,
        "val_loss": 0.0016006702374267792,
        "train_loss": 0.0019813895847934104
      },
      {
        "epoch": 722,
        "reward": 0.45576348900794983,
        "val_loss": 0.0015988115587138704,
        "train_loss": 0.0018754095069128268
      },
      {
        "epoch": 723,
        "reward": 0.4320397973060608,
        "val_loss": 0.0019377118608515178,
        "train_loss": 0.002102198323252826
      },
      {
        "epoch": 724,
        "reward": 0.44822755455970764,
        "val_loss": 0.001699119357259146,
        "train_loss": 0.0022853345637066434
      },
      {
        "epoch": 725,
        "reward": 0.43786484003067017,
        "val_loss": 0.0018480013656829084,
        "train_loss": 0.0023529135117034737
      },
      {
        "epoch": 726,
        "reward": 0.45395737886428833,
        "val_loss": 0.0016222726803139917,
        "train_loss": 0.002041360155159894
      },
      {
        "epoch": 727,
        "reward": 0.4526151120662689,
        "val_loss": 0.0016399423142762057,
        "train_loss": 0.0018758354977203102
      },
      {
        "epoch": 728,
        "reward": 0.4366694390773773,
        "val_loss": 0.0018660439610747354,
        "train_loss": 0.0019410876982594626
      },
      {
        "epoch": 729,
        "reward": 0.4503011405467987,
        "val_loss": 0.001670878064552588,
        "train_loss": 0.0020874941793198767
      },
      {
        "epoch": 730,
        "reward": 0.42350348830223083,
        "val_loss": 0.0020776884630322456,
        "train_loss": 0.0019540876674000174
      },
      {
        "epoch": 731,
        "reward": 0.44694310426712036,
        "val_loss": 0.0017168651102110744,
        "train_loss": 0.0020296635562912202
      },
      {
        "epoch": 732,
        "reward": 0.4551568925380707,
        "val_loss": 0.0016066509249087954,
        "train_loss": 0.0018845094388010553
      },
      {
        "epoch": 733,
        "reward": 0.4519304931163788,
        "val_loss": 0.0016490320059736924,
        "train_loss": 0.0019066527579875232
      },
      {
        "epoch": 734,
        "reward": 0.4456731379032135,
        "val_loss": 0.0017346022484291876,
        "train_loss": 0.0018649212743184762
      },
      {
        "epoch": 735,
        "reward": 0.44908711314201355,
        "val_loss": 0.0016873520466365985,
        "train_loss": 0.001875843428094343
      },
      {
        "epoch": 736,
        "reward": 0.45317527651786804,
        "val_loss": 0.0016325441538356245,
        "train_loss": 0.0018864494209782816
      },
      {
        "epoch": 737,
        "reward": 0.44959139823913574,
        "val_loss": 0.0016804880163233196,
        "train_loss": 0.001913659767104456
      },
      {
        "epoch": 738,
        "reward": 0.44024378061294556,
        "val_loss": 0.0018126440533835972,
        "train_loss": 0.0020892874006396877
      },
      {
        "epoch": 739,
        "reward": 0.4375418722629547,
        "val_loss": 0.001852858212909528,
        "train_loss": 0.002075677088354356
      },
      {
        "epoch": 740,
        "reward": 0.4066241681575775,
        "val_loss": 0.0023876700683363845,
        "train_loss": 0.0024113280770297232
      },
      {
        "epoch": 741,
        "reward": 0.4548341929912567,
        "val_loss": 0.001610838558657893,
        "train_loss": 0.002164877465335079
      },
      {
        "epoch": 742,
        "reward": 0.4522099196910858,
        "val_loss": 0.0016453154468243675,
        "train_loss": 0.0019718404778709207
      },
      {
        "epoch": 743,
        "reward": 0.4536079466342926,
        "val_loss": 0.0016268537645893438,
        "train_loss": 0.0019609467641343004
      },
      {
        "epoch": 744,
        "reward": 0.4494296610355377,
        "val_loss": 0.0016826864697837404,
        "train_loss": 0.0019204550771974027
      },
      {
        "epoch": 745,
        "reward": 0.4551963806152344,
        "val_loss": 0.0016061400279535779,
        "train_loss": 0.001980370532972022
      },
      {
        "epoch": 746,
        "reward": 0.4551212787628174,
        "val_loss": 0.0016071127278597227,
        "train_loss": 0.0018737676996701898
      },
      {
        "epoch": 747,
        "reward": 0.4450650215148926,
        "val_loss": 0.0017431641047421312,
        "train_loss": 0.002385227291737325
      },
      {
        "epoch": 748,
        "reward": 0.45482268929481506,
        "val_loss": 0.0016109879278311773,
        "train_loss": 0.002220118836983322
      },
      {
        "epoch": 749,
        "reward": 0.4532795548439026,
        "val_loss": 0.0016311708854378334,
        "train_loss": 0.0019133461789281752
      },
      {
        "epoch": 750,
        "reward": 0.4550328850746155,
        "val_loss": 0.0016082597597103035,
        "train_loss": 0.0019123423833382102
      },
      {
        "epoch": 751,
        "reward": 0.44751793146133423,
        "val_loss": 0.001708899308661265,
        "train_loss": 0.002160758724830185
      },
      {
        "epoch": 752,
        "reward": 0.4499780833721161,
        "val_loss": 0.0016752449778972992,
        "train_loss": 0.002011812424265932
      },
      {
        "epoch": 753,
        "reward": 0.45195674896240234,
        "val_loss": 0.0016486822610854038,
        "train_loss": 0.0018895540740161848
      },
      {
        "epoch": 754,
        "reward": 0.4496931731700897,
        "val_loss": 0.0016791066487452813,
        "train_loss": 0.001910679588595835
      },
      {
        "epoch": 755,
        "reward": 0.4479811191558838,
        "val_loss": 0.0017025089473463595,
        "train_loss": 0.00224639478032119
      },
      {
        "epoch": 756,
        "reward": 0.4506964683532715,
        "val_loss": 0.0016655491033036793,
        "train_loss": 0.002015794768969779
      },
      {
        "epoch": 757,
        "reward": 0.4532594382762909,
        "val_loss": 0.0016314357053488493,
        "train_loss": 0.0018820090870296834
      },
      {
        "epoch": 758,
        "reward": 0.4533960521221161,
        "val_loss": 0.0016296379534261568,
        "train_loss": 0.0018639092282123433
      },
      {
        "epoch": 759,
        "reward": 0.41111287474632263,
        "val_loss": 0.002300610100584371,
        "train_loss": 0.002302698401483492
      },
      {
        "epoch": 760,
        "reward": 0.45481330156326294,
        "val_loss": 0.001611109939403832,
        "train_loss": 0.0021690383616190115
      },
      {
        "epoch": 761,
        "reward": 0.45553693175315857,
        "val_loss": 0.001601735021852489,
        "train_loss": 0.0020318530517285513
      },
      {
        "epoch": 762,
        "reward": 0.40919503569602966,
        "val_loss": 0.0023373759717547466,
        "train_loss": 0.0019967031862156894
      },
      {
        "epoch": 763,
        "reward": 0.4550725519657135,
        "val_loss": 0.001607744863057243,
        "train_loss": 0.001975531008890987
      },
      {
        "epoch": 764,
        "reward": 0.45552942156791687,
        "val_loss": 0.0016018321704385535,
        "train_loss": 0.0019250894256401807
      },
      {
        "epoch": 765,
        "reward": 0.4535139203071594,
        "val_loss": 0.0016280882659235171,
        "train_loss": 0.0019188346020830348
      },
      {
        "epoch": 766,
        "reward": 0.45083919167518616,
        "val_loss": 0.001663629971777222,
        "train_loss": 0.0018879364527562687
      },
      {
        "epoch": 767,
        "reward": 0.45615872740745544,
        "val_loss": 0.0015937248494343034,
        "train_loss": 0.0019480661229373743
      },
      {
        "epoch": 768,
        "reward": 0.45509204268455505,
        "val_loss": 0.0016074922002319778,
        "train_loss": 0.0018932220924538202
      },
      {
        "epoch": 769,
        "reward": 0.4474731981754303,
        "val_loss": 0.0017095174324432655,
        "train_loss": 0.0020314410996014397
      },
      {
        "epoch": 770,
        "reward": 0.4489738643169403,
        "val_loss": 0.0016888981252642615,
        "train_loss": 0.0019712813798553096
      },
      {
        "epoch": 771,
        "reward": 0.44660255312919617,
        "val_loss": 0.0017216029560326465,
        "train_loss": 0.0019259662613666689
      },
      {
        "epoch": 772,
        "reward": 0.4524456560611725,
        "val_loss": 0.0016421869846193918,
        "train_loss": 0.0019202061151960292
      },
      {
        "epoch": 773,
        "reward": 0.4478786885738373,
        "val_loss": 0.0017039205579619323,
        "train_loss": 0.0019373745744815096
      },
      {
        "epoch": 774,
        "reward": 0.45297595858573914,
        "val_loss": 0.001635172770225576,
        "train_loss": 0.0022760837567217937
      },
      {
        "epoch": 775,
        "reward": 0.42765411734580994,
        "val_loss": 0.0020083194665078607,
        "train_loss": 0.0020065897596605983
      },
      {
        "epoch": 776,
        "reward": 0.4452873766422272,
        "val_loss": 0.0017400282751103596,
        "train_loss": 0.0020533596935610357
      },
      {
        "epoch": 777,
        "reward": 0.4523552358150482,
        "val_loss": 0.0016433863118956132,
        "train_loss": 0.002077876583196205
      },
      {
        "epoch": 778,
        "reward": 0.4558468461036682,
        "val_loss": 0.0015977375359008355,
        "train_loss": 0.001902998202170308
      },
      {
        "epoch": 779,
        "reward": 0.4240729510784149,
        "val_loss": 0.0020680209854617715,
        "train_loss": 0.0019281807561548282
      },
      {
        "epoch": 780,
        "reward": 0.4522877633571625,
        "val_loss": 0.001644282161058592,
        "train_loss": 0.0019315949578482944
      },
      {
        "epoch": 781,
        "reward": 0.4469238221645355,
        "val_loss": 0.0017171330899665399,
        "train_loss": 0.0018674898351666623
      },
      {
        "epoch": 782,
        "reward": 0.45420995354652405,
        "val_loss": 0.0016189704266642885,
        "train_loss": 0.0019020298943639947
      },
      {
        "epoch": 783,
        "reward": 0.45033499598503113,
        "val_loss": 0.001670420602230089,
        "train_loss": 0.001868449046241949
      },
      {
        "epoch": 784,
        "reward": 0.44755658507347107,
        "val_loss": 0.001708365062118641,
        "train_loss": 0.0018611364489887505
      },
      {
        "epoch": 785,
        "reward": 0.4089474380016327,
        "val_loss": 0.0023421686242467593,
        "train_loss": 0.0021865529438050892
      },
      {
        "epoch": 786,
        "reward": 0.44478318095207214,
        "val_loss": 0.0017471473630783813,
        "train_loss": 0.0019771529034467395
      },
      {
        "epoch": 787,
        "reward": 0.45494768023490906,
        "val_loss": 0.0016093645743759616,
        "train_loss": 0.0018920615607035311
      },
      {
        "epoch": 788,
        "reward": 0.4376440942287445,
        "val_loss": 0.0018513196347547428,
        "train_loss": 0.0019020123973649999
      },
      {
        "epoch": 789,
        "reward": 0.45091381669044495,
        "val_loss": 0.001662627694063953,
        "train_loss": 0.0019317887943963376
      },
      {
        "epoch": 790,
        "reward": 0.45459938049316406,
        "val_loss": 0.0016138925067415194,
        "train_loss": 0.0020395626053449144
      },
      {
        "epoch": 791,
        "reward": 0.4535604417324066,
        "val_loss": 0.0016274772767376686,
        "train_loss": 0.0019120556883605716
      },
      {
        "epoch": 792,
        "reward": 0.454332172870636,
        "val_loss": 0.0016173757695859031,
        "train_loss": 0.0018513244541771621
      },
      {
        "epoch": 793,
        "reward": 0.4365210235118866,
        "val_loss": 0.0018682983604126743,
        "train_loss": 0.0018786973759530995
      },
      {
        "epoch": 794,
        "reward": 0.4314071238040924,
        "val_loss": 0.0019477318772780044,
        "train_loss": 0.001993056765059009
      },
      {
        "epoch": 795,
        "reward": 0.45235857367515564,
        "val_loss": 0.0016433412674814463,
        "train_loss": 0.0019482839675744729
      },
      {
        "epoch": 796,
        "reward": 0.4506240785121918,
        "val_loss": 0.0016665236492242133,
        "train_loss": 0.0018737006276541462
      },
      {
        "epoch": 797,
        "reward": 0.4559091627597809,
        "val_loss": 0.0015969345612185343,
        "train_loss": 0.001880754660025839
      },
      {
        "epoch": 798,
        "reward": 0.45534202456474304,
        "val_loss": 0.0016042549978010356,
        "train_loss": 0.0019105111143569676
      },
      {
        "epoch": 799,
        "reward": 0.45390191674232483,
        "val_loss": 0.0016229991618144726,
        "train_loss": 0.001930634706066205
      },
      {
        "epoch": 800,
        "reward": 0.45452195405960083,
        "val_loss": 0.0016149008297361434,
        "train_loss": 0.0018890149429073343
      },
      {
        "epoch": 801,
        "reward": 0.44296273589134216,
        "val_loss": 0.0017731075807075416,
        "train_loss": 0.00207057428241779
      },
      {
        "epoch": 802,
        "reward": 0.43372002243995667,
        "val_loss": 0.0019113690359517932,
        "train_loss": 0.002103620186412277
      },
      {
        "epoch": 803,
        "reward": 0.45404598116874695,
        "val_loss": 0.0016211144227002347,
        "train_loss": 0.0020257112785027577
      },
      {
        "epoch": 804,
        "reward": 0.4440394341945648,
        "val_loss": 0.0017577047027381404,
        "train_loss": 0.0018994170599258863
      },
      {
        "epoch": 805,
        "reward": 0.4546429216861725,
        "val_loss": 0.0016133255225473217,
        "train_loss": 0.001963975969164704
      },
      {
        "epoch": 806,
        "reward": 0.4493332803249359,
        "val_loss": 0.0016839978218610799,
        "train_loss": 0.001888700444571721
      },
      {
        "epoch": 807,
        "reward": 0.45487284660339355,
        "val_loss": 0.0016103369499822812,
        "train_loss": 0.0018615544149025271
      },
      {
        "epoch": 808,
        "reward": 0.43769001960754395,
        "val_loss": 0.0018506290756964258,
        "train_loss": 0.0019815029495825563
      },
      {
        "epoch": 809,
        "reward": 0.4542956054210663,
        "val_loss": 0.0016178525319056852,
        "train_loss": 0.0019780066133814845
      },
      {
        "epoch": 810,
        "reward": 0.4518015384674072,
        "val_loss": 0.0016507499718240329,
        "train_loss": 0.0019578786864608098
      },
      {
        "epoch": 811,
        "reward": 0.45104169845581055,
        "val_loss": 0.0016609111168820942,
        "train_loss": 0.0018837691459339112
      },
      {
        "epoch": 812,
        "reward": 0.4559013843536377,
        "val_loss": 0.0015970352438411542,
        "train_loss": 0.0019286318957501163
      },
      {
        "epoch": 813,
        "reward": 0.4495261609554291,
        "val_loss": 0.0016813746520451137,
        "train_loss": 0.0018590979125292506
      },
      {
        "epoch": 814,
        "reward": 0.45357733964920044,
        "val_loss": 0.0016272552145112837,
        "train_loss": 0.0018520328404310232
      },
      {
        "epoch": 815,
        "reward": 0.43960103392601013,
        "val_loss": 0.001822124800777861,
        "train_loss": 0.0018615587869053212
      },
      {
        "epoch": 816,
        "reward": 0.45478230714797974,
        "val_loss": 0.0016115134764861847,
        "train_loss": 0.0020114219962404324
      },
      {
        "epoch": 817,
        "reward": 0.43126893043518066,
        "val_loss": 0.001949927570032222,
        "train_loss": 0.0019274496701725114
      },
      {
        "epoch": 818,
        "reward": 0.4454009532928467,
        "val_loss": 0.001738428687011557,
        "train_loss": 0.002345620672433422
      },
      {
        "epoch": 819,
        "reward": 0.42264047265052795,
        "val_loss": 0.0020924324302801062,
        "train_loss": 0.0021647257190824556
      },
      {
        "epoch": 820,
        "reward": 0.4503866732120514,
        "val_loss": 0.0016697233742369072,
        "train_loss": 0.001881158021275881
      },
      {
        "epoch": 821,
        "reward": 0.42656493186950684,
        "val_loss": 0.0020262795400672723,
        "train_loss": 0.0018832699108595708
      },
      {
        "epoch": 822,
        "reward": 0.4541114866733551,
        "val_loss": 0.0016202576142469688,
        "train_loss": 0.0019739736364079784
      },
      {
        "epoch": 823,
        "reward": 0.44058582186698914,
        "val_loss": 0.0018076197510319097,
        "train_loss": 0.0018667015752166312
      },
      {
        "epoch": 824,
        "reward": 0.4487445056438446,
        "val_loss": 0.0016920322336123458,
        "train_loss": 0.0019025350442321864
      },
      {
        "epoch": 825,
        "reward": 0.41036278009414673,
        "val_loss": 0.002314913901500404,
        "train_loss": 0.0021209329850255297
      },
      {
        "epoch": 826,
        "reward": 0.44600731134414673,
        "val_loss": 0.0017299164153103317,
        "train_loss": 0.0019468868452419813
      },
      {
        "epoch": 827,
        "reward": 0.44433432817459106,
        "val_loss": 0.0017535103085849965,
        "train_loss": 0.0018690539285531626
      },
      {
        "epoch": 828,
        "reward": 0.4512060582637787,
        "val_loss": 0.0016587070754862257,
        "train_loss": 0.0019447294012374745
      },
      {
        "epoch": 829,
        "reward": 0.45395922660827637,
        "val_loss": 0.0016222490147421403,
        "train_loss": 0.001954854730194291
      },
      {
        "epoch": 830,
        "reward": 0.45328935980796814,
        "val_loss": 0.0016310415563306638,
        "train_loss": 0.0020918699133639727
      },
      {
        "epoch": 831,
        "reward": 0.45498576760292053,
        "val_loss": 0.0016088704911193677,
        "train_loss": 0.0019625853069905694
      },
      {
        "epoch": 832,
        "reward": 0.44855785369873047,
        "val_loss": 0.0016945877245494298,
        "train_loss": 0.0019180701268711486
      },
      {
        "epoch": 833,
        "reward": 0.44914814829826355,
        "val_loss": 0.0016865203423159464,
        "train_loss": 0.001846218087271504
      },
      {
        "epoch": 834,
        "reward": 0.4550619125366211,
        "val_loss": 0.0016078826738521457,
        "train_loss": 0.0018853198495120383
      },
      {
        "epoch": 835,
        "reward": 0.44610533118247986,
        "val_loss": 0.001728544178019677,
        "train_loss": 0.0019394232428147427
      },
      {
        "epoch": 836,
        "reward": 0.45545244216918945,
        "val_loss": 0.0016028268395790032,
        "train_loss": 0.0018749995609911052
      },
      {
        "epoch": 837,
        "reward": 0.41601940989494324,
        "val_loss": 0.0022093813001577344,
        "train_loss": 0.001940396386019599
      },
      {
        "epoch": 838,
        "reward": 0.4524095058441162,
        "val_loss": 0.0016426665492222778,
        "train_loss": 0.002017488015833526
      },
      {
        "epoch": 839,
        "reward": 0.43730732798576355,
        "val_loss": 0.0018563934635104878,
        "train_loss": 0.0022115898497689227
      },
      {
        "epoch": 840,
        "reward": 0.44966164231300354,
        "val_loss": 0.001679534391899194,
        "train_loss": 0.00195456160872709
      },
      {
        "epoch": 841,
        "reward": 0.4193533957004547,
        "val_loss": 0.002149633980090065,
        "train_loss": 0.0019262905832594978
      },
      {
        "epoch": 842,
        "reward": 0.4516567885875702,
        "val_loss": 0.0016526805286827897,
        "train_loss": 0.0019196717699882216
      },
      {
        "epoch": 843,
        "reward": 0.4541521668434143,
        "val_loss": 0.001619725554649319,
        "train_loss": 0.001931941462456822
      },
      {
        "epoch": 844,
        "reward": 0.4352186620235443,
        "val_loss": 0.001888194221204945,
        "train_loss": 0.0018966794159496203
      },
      {
        "epoch": 845,
        "reward": 0.4539424479007721,
        "val_loss": 0.0016224683079469418,
        "train_loss": 0.0019056448735345665
      },
      {
        "epoch": 846,
        "reward": 0.45498496294021606,
        "val_loss": 0.001608880893659911,
        "train_loss": 0.0019088857851994152
      },
      {
        "epoch": 847,
        "reward": 0.45209380984306335,
        "val_loss": 0.0016468589809457107,
        "train_loss": 0.001890037102244745
      },
      {
        "epoch": 848,
        "reward": 0.44470128417015076,
        "val_loss": 0.0017483063857071102,
        "train_loss": 0.0020255160679181036
      },
      {
        "epoch": 849,
        "reward": 0.45287439227104187,
        "val_loss": 0.0016365136419023787,
        "train_loss": 0.0022225280901273857
      },
      {
        "epoch": 850,
        "reward": 0.44746899604797363,
        "val_loss": 0.0017095759477732436,
        "train_loss": 0.0018936283170030667
      },
      {
        "epoch": 851,
        "reward": 0.4563257694244385,
        "val_loss": 0.001591580587306193,
        "train_loss": 0.0018810093115462223
      },
      {
        "epoch": 852,
        "reward": 0.45218729972839355,
        "val_loss": 0.001645616106023746,
        "train_loss": 0.0018874258866372446
      },
      {
        "epoch": 853,
        "reward": 0.44545862078666687,
        "val_loss": 0.0017376178542950324,
        "train_loss": 0.001880931976931886
      },
      {
        "epoch": 854,
        "reward": 0.4509529769420624,
        "val_loss": 0.0016621019874167229,
        "train_loss": 0.0018834021646818235
      },
      {
        "epoch": 855,
        "reward": 0.45582571625709534,
        "val_loss": 0.0015980100974307529,
        "train_loss": 0.001864905153454926
      },
      {
        "epoch": 856,
        "reward": 0.42901739478111267,
        "val_loss": 0.0019860814791172743,
        "train_loss": 0.0019080679832348744
      },
      {
        "epoch": 857,
        "reward": 0.44788026809692383,
        "val_loss": 0.0017038985804122473,
        "train_loss": 0.001941158082515288
      },
      {
        "epoch": 858,
        "reward": 0.4196772575378418,
        "val_loss": 0.0021439232264778446,
        "train_loss": 0.0020212281043103966
      },
      {
        "epoch": 859,
        "reward": 0.44758573174476624,
        "val_loss": 0.001707962589404945,
        "train_loss": 0.002156170364917041
      },
      {
        "epoch": 860,
        "reward": 0.45449694991111755,
        "val_loss": 0.0016152269672602415,
        "train_loss": 0.0018686339742718982
      },
      {
        "epoch": 861,
        "reward": 0.4459277093410492,
        "val_loss": 0.001731031690724194,
        "train_loss": 0.0018897945328017857
      },
      {
        "epoch": 862,
        "reward": 0.44756850600242615,
        "val_loss": 0.0017081997523616468,
        "train_loss": 0.002220835281500163
      },
      {
        "epoch": 863,
        "reward": 0.44992515444755554,
        "val_loss": 0.0016759616056723253,
        "train_loss": 0.002130235207285016
      },
      {
        "epoch": 864,
        "reward": 0.44862261414527893,
        "val_loss": 0.0016937003238126636,
        "train_loss": 0.0023470830727511873
      },
      {
        "epoch": 865,
        "reward": 0.45707663893699646,
        "val_loss": 0.0015819765394553542,
        "train_loss": 0.0021359122541840547
      },
      {
        "epoch": 866,
        "reward": 0.4461330473423004,
        "val_loss": 0.0017281567311978766,
        "train_loss": 0.0020534050574602027
      },
      {
        "epoch": 867,
        "reward": 0.4563466012477875,
        "val_loss": 0.0015913127322814294,
        "train_loss": 0.0019290023035584735
      },
      {
        "epoch": 868,
        "reward": 0.43459293246269226,
        "val_loss": 0.0018978343744363105,
        "train_loss": 0.0018631182616410604
      },
      {
        "epoch": 869,
        "reward": 0.4542299807071686,
        "val_loss": 0.0016187089744822256,
        "train_loss": 0.0019039713011947102
      },
      {
        "epoch": 870,
        "reward": 0.4414726793766022,
        "val_loss": 0.0017946598652218068,
        "train_loss": 0.0018929622019641101
      },
      {
        "epoch": 871,
        "reward": 0.4483650326728821,
        "val_loss": 0.0016972316661849618,
        "train_loss": 0.002149584949410592
      },
      {
        "epoch": 872,
        "reward": 0.45504507422447205,
        "val_loss": 0.0016081009110036706,
        "train_loss": 0.001961436678706937
      },
      {
        "epoch": 873,
        "reward": 0.44197559356689453,
        "val_loss": 0.0017873556103690394,
        "train_loss": 0.002017192990304186
      },
      {
        "epoch": 874,
        "reward": 0.4558229148387909,
        "val_loss": 0.0015980461861805192,
        "train_loss": 0.002028569776537272
      },
      {
        "epoch": 875,
        "reward": 0.4545113742351532,
        "val_loss": 0.0016150385989541455,
        "train_loss": 0.001876814942359208
      },
      {
        "epoch": 876,
        "reward": 0.45474353432655334,
        "val_loss": 0.0016120171556914492,
        "train_loss": 0.0018788126827670427
      },
      {
        "epoch": 877,
        "reward": 0.4416866898536682,
        "val_loss": 0.0017915483497615372,
        "train_loss": 0.0018929086251703736
      },
      {
        "epoch": 878,
        "reward": 0.4503394663333893,
        "val_loss": 0.0016703600246858383,
        "train_loss": 0.001865134145191405
      },
      {
        "epoch": 879,
        "reward": 0.4562145173549652,
        "val_loss": 0.001593008138505476,
        "train_loss": 0.0018666103356876052
      },
      {
        "epoch": 880,
        "reward": 0.45516878366470337,
        "val_loss": 0.0016064973564685456,
        "train_loss": 0.0018694174110490936
      },
      {
        "epoch": 881,
        "reward": 0.44174647331237793,
        "val_loss": 0.0017906785609998874,
        "train_loss": 0.0021552473369341055
      },
      {
        "epoch": 882,
        "reward": 0.4441213607788086,
        "val_loss": 0.001756538320997996,
        "train_loss": 0.0019427928894471664
      },
      {
        "epoch": 883,
        "reward": 0.4441239833831787,
        "val_loss": 0.0017565014672332577,
        "train_loss": 0.0019250623568390997
      },
      {
        "epoch": 884,
        "reward": 0.4548998475074768,
        "val_loss": 0.0016099857499024697,
        "train_loss": 0.001934097366406954
      },
      {
        "epoch": 885,
        "reward": 0.4533526599407196,
        "val_loss": 0.0016302087128029338,
        "train_loss": 0.001956217640187018
      },
      {
        "epoch": 886,
        "reward": 0.4484681785106659,
        "val_loss": 0.0016958166462635355,
        "train_loss": 0.002031202669828557
      },
      {
        "epoch": 887,
        "reward": 0.4556550979614258,
        "val_loss": 0.0016002094240060874,
        "train_loss": 0.0019745743909599977
      },
      {
        "epoch": 888,
        "reward": 0.4316720962524414,
        "val_loss": 0.0019435296999290586,
        "train_loss": 0.002112957615351591
      },
      {
        "epoch": 889,
        "reward": 0.43680259585380554,
        "val_loss": 0.0018640256852709822,
        "train_loss": 0.002044059514166572
      },
      {
        "epoch": 890,
        "reward": 0.45514607429504395,
        "val_loss": 0.0016067917708174459,
        "train_loss": 0.0019006088035754287
      },
      {
        "epoch": 891,
        "reward": 0.4536057412624359,
        "val_loss": 0.0016268827270583383,
        "train_loss": 0.0018734693798111179
      },
      {
        "epoch": 892,
        "reward": 0.4546377658843994,
        "val_loss": 0.001613392902072519,
        "train_loss": 0.0019321608336982676
      },
      {
        "epoch": 893,
        "reward": 0.43035411834716797,
        "val_loss": 0.0019645310572481583,
        "train_loss": 0.0019922164322521826
      },
      {
        "epoch": 894,
        "reward": 0.4416458308696747,
        "val_loss": 0.0017921421344258956,
        "train_loss": 0.0021500410019563367
      },
      {
        "epoch": 895,
        "reward": 0.450779527425766,
        "val_loss": 0.0016644322479675924,
        "train_loss": 0.0018929613982506383
      },
      {
        "epoch": 896,
        "reward": 0.4488413333892822,
        "val_loss": 0.0016907077681805407,
        "train_loss": 0.001889332428198451
      },
      {
        "epoch": 897,
        "reward": 0.4554288983345032,
        "val_loss": 0.001603131348799382,
        "train_loss": 0.0019776925529675702
      },
      {
        "epoch": 898,
        "reward": 0.4534749984741211,
        "val_loss": 0.001628600202301251,
        "train_loss": 0.001970949370073728
      },
      {
        "epoch": 899,
        "reward": 0.4518272578716278,
        "val_loss": 0.0016504069707090302,
        "train_loss": 0.0019001332805671084
      },
      {
        "epoch": 900,
        "reward": 0.42528364062309265,
        "val_loss": 0.002047626966876643,
        "train_loss": 0.0023827027269782354
      },
      {
        "epoch": 901,
        "reward": 0.4525845944881439,
        "val_loss": 0.0016403463502813662,
        "train_loss": 0.002087962106228448
      },
      {
        "epoch": 902,
        "reward": 0.44742894172668457,
        "val_loss": 0.0017101303840588247,
        "train_loss": 0.0019568668347066985
      },
      {
        "epoch": 903,
        "reward": 0.44379615783691406,
        "val_loss": 0.0017611727484368853,
        "train_loss": 0.0018675052135502202
      },
      {
        "epoch": 904,
        "reward": 0.4554250240325928,
        "val_loss": 0.0016031812078186444,
        "train_loss": 0.001966296936958455
      },
      {
        "epoch": 905,
        "reward": 0.455108642578125,
        "val_loss": 0.001607276831886598,
        "train_loss": 0.0020429943812744636
      },
      {
        "epoch": 906,
        "reward": 0.4465359151363373,
        "val_loss": 0.0017225309441398298,
        "train_loss": 0.002201782882016582
      },
      {
        "epoch": 907,
        "reward": 0.45157885551452637,
        "val_loss": 0.0016537208159986352,
        "train_loss": 0.0019298252356328214
      },
      {
        "epoch": 908,
        "reward": 0.3922352194786072,
        "val_loss": 0.0026920235250145197,
        "train_loss": 0.00259070574807433
      },
      {
        "epoch": 909,
        "reward": 0.44912371039390564,
        "val_loss": 0.0016868532818209911,
        "train_loss": 0.0022077109042584198
      },
      {
        "epoch": 910,
        "reward": 0.4432072639465332,
        "val_loss": 0.00176959769201598,
        "train_loss": 0.0019744132094694157
      },
      {
        "epoch": 911,
        "reward": 0.4526897370815277,
        "val_loss": 0.0016389542392321996,
        "train_loss": 0.0023239602652700762
      },
      {
        "epoch": 912,
        "reward": 0.44916826486587524,
        "val_loss": 0.0016862454358488321,
        "train_loss": 0.0019771407197157922
      },
      {
        "epoch": 913,
        "reward": 0.4535128176212311,
        "val_loss": 0.001628103483069156,
        "train_loss": 0.0020009044271249036
      },
      {
        "epoch": 914,
        "reward": 0.4539617598056793,
        "val_loss": 0.0016222158197446593,
        "train_loss": 0.0020463467615741138
      },
      {
        "epoch": 915,
        "reward": 0.4292217791080475,
        "val_loss": 0.001982770161703229,
        "train_loss": 0.00221997831025734
      },
      {
        "epoch": 916,
        "reward": 0.39461979269981384,
        "val_loss": 0.0026387589750811458,
        "train_loss": 0.0022337422258435534
      },
      {
        "epoch": 917,
        "reward": 0.4463028609752655,
        "val_loss": 0.0017257829562627844,
        "train_loss": 0.002052494157772764
      },
      {
        "epoch": 918,
        "reward": 0.45015451312065125,
        "val_loss": 0.0016728583224383847,
        "train_loss": 0.0018995536195759017
      },
      {
        "epoch": 919,
        "reward": 0.45051369071006775,
        "val_loss": 0.0016680107385452305,
        "train_loss": 0.0019064562757893538
      },
      {
        "epoch": 920,
        "reward": 0.4325350224971771,
        "val_loss": 0.001929907693660685,
        "train_loss": 0.0019276588091787954
      },
      {
        "epoch": 921,
        "reward": 0.452887624502182,
        "val_loss": 0.0016363386364121521,
        "train_loss": 0.0018581277187107704
      },
      {
        "epoch": 922,
        "reward": 0.4544602036476135,
        "val_loss": 0.0016157057834789157,
        "train_loss": 0.0018612770358091579
      },
      {
        "epoch": 923,
        "reward": 0.42967483401298523,
        "val_loss": 0.001975451596081257,
        "train_loss": 0.002126475899086262
      },
      {
        "epoch": 924,
        "reward": 0.4536356031894684,
        "val_loss": 0.0016264907150928462,
        "train_loss": 0.002254420159330878
      },
      {
        "epoch": 925,
        "reward": 0.4524095952510834,
        "val_loss": 0.0016426653767536794,
        "train_loss": 0.0024626192305451976
      },
      {
        "epoch": 926,
        "reward": 0.4543939232826233,
        "val_loss": 0.001616569551905351,
        "train_loss": 0.0020212395812939997
      },
      {
        "epoch": 927,
        "reward": 0.45273956656455994,
        "val_loss": 0.0016382949460031731,
        "train_loss": 0.0019397023417975735
      },
      {
        "epoch": 928,
        "reward": 0.4560624063014984,
        "val_loss": 0.0015949632257356175,
        "train_loss": 0.002030375212108573
      },
      {
        "epoch": 929,
        "reward": 0.45358553528785706,
        "val_loss": 0.0016271477714846177,
        "train_loss": 0.0020103771284294245
      },
      {
        "epoch": 930,
        "reward": 0.44627436995506287,
        "val_loss": 0.0017261810467711516,
        "train_loss": 0.0018907863973604085
      },
      {
        "epoch": 931,
        "reward": 0.45675984025001526,
        "val_loss": 0.001586020749527961,
        "train_loss": 0.0018472555961203886
      },
      {
        "epoch": 932,
        "reward": 0.43606123328208923,
        "val_loss": 0.0018752967506381018,
        "train_loss": 0.0018522987562531712
      },
      {
        "epoch": 933,
        "reward": 0.45407286286354065,
        "val_loss": 0.0016207620168903045,
        "train_loss": 0.0018877568115315696
      },
      {
        "epoch": 934,
        "reward": 0.4537665843963623,
        "val_loss": 0.0016247721671658968,
        "train_loss": 0.0019552980912312004
      },
      {
        "epoch": 935,
        "reward": 0.45569688081741333,
        "val_loss": 0.001599670953250357,
        "train_loss": 0.001957421530208264
      },
      {
        "epoch": 936,
        "reward": 0.4523446559906006,
        "val_loss": 0.001643526675512216,
        "train_loss": 0.0018984262675915558
      },
      {
        "epoch": 937,
        "reward": 0.43355289101600647,
        "val_loss": 0.0019139714672097138,
        "train_loss": 0.002181750050602624
      },
      {
        "epoch": 938,
        "reward": 0.4098696708679199,
        "val_loss": 0.0023243706673383713,
        "train_loss": 0.0021017506929078642
      },
      {
        "epoch": 939,
        "reward": 0.4503970742225647,
        "val_loss": 0.0016695826364281987,
        "train_loss": 0.0030153883271850646
      },
      {
        "epoch": 940,
        "reward": 0.41762763261795044,
        "val_loss": 0.002180339984728822,
        "train_loss": 0.0021018874518071804
      },
      {
        "epoch": 941,
        "reward": 0.4522736668586731,
        "val_loss": 0.0016444694733114115,
        "train_loss": 0.0022255365083065745
      },
      {
        "epoch": 942,
        "reward": 0.4548531174659729,
        "val_loss": 0.0016105930137980198,
        "train_loss": 0.0019353087484082958
      },
      {
        "epoch": 943,
        "reward": 0.45350852608680725,
        "val_loss": 0.0016281592293775507,
        "train_loss": 0.00188936378645639
      },
      {
        "epoch": 944,
        "reward": 0.4547095000743866,
        "val_loss": 0.0016124597334835147,
        "train_loss": 0.0018755393246688247
      },
      {
        "epoch": 945,
        "reward": 0.4474000036716461,
        "val_loss": 0.001710530578358365,
        "train_loss": 0.002018208136388029
      },
      {
        "epoch": 946,
        "reward": 0.43155527114868164,
        "val_loss": 0.001945380653653826,
        "train_loss": 0.0019297423466643803
      },
      {
        "epoch": 947,
        "reward": 0.44781121611595154,
        "val_loss": 0.001704850367137364,
        "train_loss": 0.0019342341357304787
      },
      {
        "epoch": 948,
        "reward": 0.45188090205192566,
        "val_loss": 0.0016496928209172828,
        "train_loss": 0.0018782161115758265
      },
      {
        "epoch": 949,
        "reward": 0.45577913522720337,
        "val_loss": 0.0015986100271610276,
        "train_loss": 0.0018787507679707443
      },
      {
        "epoch": 950,
        "reward": 0.4377521574497223,
        "val_loss": 0.001849694992415607,
        "train_loss": 0.0019360388530633198
      },
      {
        "epoch": 951,
        "reward": 0.45107609033584595,
        "val_loss": 0.0016604493139311671,
        "train_loss": 0.0019531988095527943
      },
      {
        "epoch": 952,
        "reward": 0.45480188727378845,
        "val_loss": 0.0016112583107315004,
        "train_loss": 0.0018596303960014037
      },
      {
        "epoch": 953,
        "reward": 0.45074158906936646,
        "val_loss": 0.0016649429952459677,
        "train_loss": 0.0019264177625210811
      },
      {
        "epoch": 954,
        "reward": 0.4441889822483063,
        "val_loss": 0.0017555763978245004,
        "train_loss": 0.0019212108426682579
      },
      {
        "epoch": 955,
        "reward": 0.44512349367141724,
        "val_loss": 0.0017423391275640046,
        "train_loss": 0.0025040945284462604
      },
      {
        "epoch": 956,
        "reward": 0.45543161034584045,
        "val_loss": 0.001603096440833594,
        "train_loss": 0.002308252740914003
      },
      {
        "epoch": 957,
        "reward": 0.45657578110694885,
        "val_loss": 0.001588375715073198,
        "train_loss": 0.0018831785947930678
      },
      {
        "epoch": 958,
        "reward": 0.4563123881816864,
        "val_loss": 0.001591752316536648,
        "train_loss": 0.001869803354006413
      },
      {
        "epoch": 959,
        "reward": 0.4469430148601532,
        "val_loss": 0.0017168668564409018,
        "train_loss": 0.0019122927484344333
      },
      {
        "epoch": 960,
        "reward": 0.4446432292461395,
        "val_loss": 0.0017491292674094439,
        "train_loss": 0.0019489511189301712
      },
      {
        "epoch": 961,
        "reward": 0.45533743500709534,
        "val_loss": 0.0016043140619461025,
        "train_loss": 0.0019167300186102064
      },
      {
        "epoch": 962,
        "reward": 0.4516194462776184,
        "val_loss": 0.0016531790024600923,
        "train_loss": 0.0018752309123853522
      },
      {
        "epoch": 963,
        "reward": 0.44367504119873047,
        "val_loss": 0.001762902330873268,
        "train_loss": 0.0019142212079784188
      },
      {
        "epoch": 964,
        "reward": 0.45507070422172546,
        "val_loss": 0.0016077691605979843,
        "train_loss": 0.0018645666903833393
      },
      {
        "epoch": 965,
        "reward": 0.45602163672447205,
        "val_loss": 0.001595487502137465,
        "train_loss": 0.0018881249228658047
      },
      {
        "epoch": 966,
        "reward": 0.4418230950832367,
        "val_loss": 0.0017895666117380773,
        "train_loss": 0.0019237981648005259
      },
      {
        "epoch": 967,
        "reward": 0.4549766480922699,
        "val_loss": 0.0016089884198403784,
        "train_loss": 0.0019994207048931946
      },
      {
        "epoch": 968,
        "reward": 0.45402559638023376,
        "val_loss": 0.0016213802986645273,
        "train_loss": 0.002007334701304969
      },
      {
        "epoch": 969,
        "reward": 0.44574999809265137,
        "val_loss": 0.0017335237602570228,
        "train_loss": 0.0019070971197484492
      },
      {
        "epoch": 970,
        "reward": 0.45019659399986267,
        "val_loss": 0.001672289043199271,
        "train_loss": 0.0019082532783683676
      },
      {
        "epoch": 971,
        "reward": 0.4497712254524231,
        "val_loss": 0.0016780475603549608,
        "train_loss": 0.0019515981481303102
      },
      {
        "epoch": 972,
        "reward": 0.4546411633491516,
        "val_loss": 0.0016133490134961903,
        "train_loss": 0.002004142146408692
      },
      {
        "epoch": 973,
        "reward": 0.45455679297447205,
        "val_loss": 0.0016144465605196143,
        "train_loss": 0.0018538335906878973
      },
      {
        "epoch": 974,
        "reward": 0.44685664772987366,
        "val_loss": 0.0017180664830708078,
        "train_loss": 0.0019222315668929906
      },
      {
        "epoch": 975,
        "reward": 0.44087186455726624,
        "val_loss": 0.0018034290156460234,
        "train_loss": 0.001885797109235472
      },
      {
        "epoch": 976,
        "reward": 0.4480741024017334,
        "val_loss": 0.0017012292768673173,
        "train_loss": 0.0018901147928912765
      },
      {
        "epoch": 977,
        "reward": 0.45262083411216736,
        "val_loss": 0.0016398660456096487,
        "train_loss": 0.0019476118546803123
      },
      {
        "epoch": 978,
        "reward": 0.40981537103652954,
        "val_loss": 0.0023254136987296598,
        "train_loss": 0.0020784755291130682
      },
      {
        "epoch": 979,
        "reward": 0.44613805413246155,
        "val_loss": 0.0017280869152663009,
        "train_loss": 0.0022321772233296474
      },
      {
        "epoch": 980,
        "reward": 0.4554060399532318,
        "val_loss": 0.001603426636263196,
        "train_loss": 0.0019433953274039175
      },
      {
        "epoch": 981,
        "reward": 0.441195547580719,
        "val_loss": 0.0017986996099352837,
        "train_loss": 0.001963776675088761
      },
      {
        "epoch": 982,
        "reward": 0.4326140880584717,
        "val_loss": 0.001928664677377258,
        "train_loss": 0.001872090455190818
      },
      {
        "epoch": 983,
        "reward": 0.44991251826286316,
        "val_loss": 0.0016761328858722533,
        "train_loss": 0.0018774017914368485
      },
      {
        "epoch": 984,
        "reward": 0.4539984166622162,
        "val_loss": 0.0016217362717725337,
        "train_loss": 0.001905444402906981
      },
      {
        "epoch": 985,
        "reward": 0.453280508518219,
        "val_loss": 0.0016311580298601516,
        "train_loss": 0.0018667822128708605
      },
      {
        "epoch": 986,
        "reward": 0.4555181562900543,
        "val_loss": 0.001601977348660252,
        "train_loss": 0.001854991636579283
      },
      {
        "epoch": 987,
        "reward": 0.4539518356323242,
        "val_loss": 0.0016223450407518872,
        "train_loss": 0.0018901757754904863
      },
      {
        "epoch": 988,
        "reward": 0.4462392032146454,
        "val_loss": 0.0017266730096058122,
        "train_loss": 0.0019965773246720065
      },
      {
        "epoch": 989,
        "reward": 0.4551986753940582,
        "val_loss": 0.001606110275523471,
        "train_loss": 0.001880799261785936
      },
      {
        "epoch": 990,
        "reward": 0.45587536692619324,
        "val_loss": 0.0015973703869219338,
        "train_loss": 0.0018699773094200422
      },
      {
        "epoch": 991,
        "reward": 0.45236149430274963,
        "val_loss": 0.0016433033659788115,
        "train_loss": 0.002031269129544783
      },
      {
        "epoch": 992,
        "reward": 0.4520637094974518,
        "val_loss": 0.0016472585183302207,
        "train_loss": 0.001885969438052808
      },
      {
        "epoch": 993,
        "reward": 0.4539349675178528,
        "val_loss": 0.0016225666456323648,
        "train_loss": 0.00215805506405349
      },
      {
        "epoch": 994,
        "reward": 0.43757888674736023,
        "val_loss": 0.001852301198856107,
        "train_loss": 0.0020569655288664554
      },
      {
        "epoch": 995,
        "reward": 0.4399220943450928,
        "val_loss": 0.001817383271242891,
        "train_loss": 0.0020182476504347646
      },
      {
        "epoch": 996,
        "reward": 0.4536229074001312,
        "val_loss": 0.0016266573968875622,
        "train_loss": 0.0020763655372250537
      },
      {
        "epoch": 997,
        "reward": 0.4284486770629883,
        "val_loss": 0.001995326385700277,
        "train_loss": 0.002096285748008925
      },
      {
        "epoch": 998,
        "reward": 0.4552431106567383,
        "val_loss": 0.0016055346017570368,
        "train_loss": 0.0019340823416244418
      },
      {
        "epoch": 999,
        "reward": 0.4453217089176178,
        "val_loss": 0.0017395450683709765,
        "train_loss": 0.001890344397487262
      },
      {
        "epoch": 1000,
        "reward": 0.4528901278972626,
        "val_loss": 0.0016363060900143214,
        "train_loss": 0.002208217432220968
      },
      {
        "epoch": 1001,
        "reward": 0.4529685974121094,
        "val_loss": 0.0016352696028271957,
        "train_loss": 0.001972307072719559
      },
      {
        "epoch": 1002,
        "reward": 0.4555760324001312,
        "val_loss": 0.001601230078709445,
        "train_loss": 0.0019458041458095137
      },
      {
        "epoch": 1003,
        "reward": 0.45345211029052734,
        "val_loss": 0.0016289005954084651,
        "train_loss": 0.0018804601456325215
      },
      {
        "epoch": 1004,
        "reward": 0.426514208316803,
        "val_loss": 0.0020271191938913296,
        "train_loss": 0.0019449640710193377
      },
      {
        "epoch": 1005,
        "reward": 0.411456435918808,
        "val_loss": 0.0022940906596236993,
        "train_loss": 0.0023192239571541836
      },
      {
        "epoch": 1006,
        "reward": 0.4174882471561432,
        "val_loss": 0.0021828402864879797,
        "train_loss": 0.002650159915132323
      },
      {
        "epoch": 1007,
        "reward": 0.45340561866760254,
        "val_loss": 0.0016295116594327347,
        "train_loss": 0.002030688589212122
      },
      {
        "epoch": 1008,
        "reward": 0.45493578910827637,
        "val_loss": 0.0016095191905541079,
        "train_loss": 0.0018867547534262906
      },
      {
        "epoch": 1009,
        "reward": 0.4545225203037262,
        "val_loss": 0.0016148932377940842,
        "train_loss": 0.0019803351102522216
      },
      {
        "epoch": 1010,
        "reward": 0.42301222681999207,
        "val_loss": 0.002086068353881793,
        "train_loss": 0.0022883390976438443
      },
      {
        "epoch": 1011,
        "reward": 0.4542745053768158,
        "val_loss": 0.0016181272970113372,
        "train_loss": 0.0020664500591989895
      },
      {
        "epoch": 1012,
        "reward": 0.45352086424827576,
        "val_loss": 0.0016279971127265266,
        "train_loss": 0.002120748466740434
      },
      {
        "epoch": 1013,
        "reward": 0.4334309697151184,
        "val_loss": 0.001915873128122517,
        "train_loss": 0.0019276764472194302
      },
      {
        "epoch": 1014,
        "reward": 0.4313535690307617,
        "val_loss": 0.001948582540665354,
        "train_loss": 0.0023920397775677536
      },
      {
        "epoch": 1015,
        "reward": 0.4451468586921692,
        "val_loss": 0.0017420094310572104,
        "train_loss": 0.0020394877633057498
      },
      {
        "epoch": 1016,
        "reward": 0.43759775161743164,
        "val_loss": 0.001852016762963363,
        "train_loss": 0.0018995814684435923
      },
      {
        "epoch": 1017,
        "reward": 0.45679107308387756,
        "val_loss": 0.0015856218025354402,
        "train_loss": 0.001935898533422285
      },
      {
        "epoch": 1018,
        "reward": 0.45650649070739746,
        "val_loss": 0.001589263340325228,
        "train_loss": 0.0018943538587056817
      },
      {
        "epoch": 1019,
        "reward": 0.45259761810302734,
        "val_loss": 0.001640174088866583,
        "train_loss": 0.0018753492006978306
      },
      {
        "epoch": 1020,
        "reward": 0.45424720644950867,
        "val_loss": 0.0016184846587878252,
        "train_loss": 0.0018789673609337964
      },
      {
        "epoch": 1021,
        "reward": 0.4537738263607025,
        "val_loss": 0.0016246773967785494,
        "train_loss": 0.001866942476996113
      },
      {
        "epoch": 1022,
        "reward": 0.4410918653011322,
        "val_loss": 0.0018002120944272196,
        "train_loss": 0.001923658970134476
      },
      {
        "epoch": 1023,
        "reward": 0.45177537202835083,
        "val_loss": 0.0016510989433819695,
        "train_loss": 0.0018575918911665212
      },
      {
        "epoch": 1024,
        "reward": 0.4502902626991272,
        "val_loss": 0.0016710243902967445,
        "train_loss": 0.001907097840627942
      },
      {
        "epoch": 1025,
        "reward": 0.43937596678733826,
        "val_loss": 0.0018254579710108893,
        "train_loss": 0.0019207554197726916
      },
      {
        "epoch": 1026,
        "reward": 0.4555209279060364,
        "val_loss": 0.0016019419667177967,
        "train_loss": 0.0018934200340411805
      },
      {
        "epoch": 1027,
        "reward": 0.4203818738460541,
        "val_loss": 0.0021315567760861348,
        "train_loss": 0.0023340384896772984
      },
      {
        "epoch": 1028,
        "reward": 0.45340728759765625,
        "val_loss": 0.0016294900311290153,
        "train_loss": 0.002219872405546014
      },
      {
        "epoch": 1029,
        "reward": 0.4485648274421692,
        "val_loss": 0.0016944922639855317,
        "train_loss": 0.0018634837794637021
      },
      {
        "epoch": 1030,
        "reward": 0.4552747905254364,
        "val_loss": 0.0016051250692856098,
        "train_loss": 0.0019062375358771533
      },
      {
        "epoch": 1031,
        "reward": 0.45602211356163025,
        "val_loss": 0.0015954810494024838,
        "train_loss": 0.001867460381897847
      },
      {
        "epoch": 1032,
        "reward": 0.44488558173179626,
        "val_loss": 0.0017456988072288887,
        "train_loss": 0.0018465583045606483
      },
      {
        "epoch": 1033,
        "reward": 0.4136755168437958,
        "val_loss": 0.0022524618709992084,
        "train_loss": 0.002279669608329781
      },
      {
        "epoch": 1034,
        "reward": 0.4493318200111389,
        "val_loss": 0.0016840178868733346,
        "train_loss": 0.002400782375703924
      },
      {
        "epoch": 1035,
        "reward": 0.44126731157302856,
        "val_loss": 0.0017976527950460358,
        "train_loss": 0.0024756425140927043
      },
      {
        "epoch": 1036,
        "reward": 0.41430002450942993,
        "val_loss": 0.0022408951107146485,
        "train_loss": 0.0022195382804896394
      },
      {
        "epoch": 1037,
        "reward": 0.4251699149608612,
        "val_loss": 0.0020495341658326133,
        "train_loss": 0.0020021184486372825
      },
      {
        "epoch": 1038,
        "reward": 0.4542914927005768,
        "val_loss": 0.0016179061577921467,
        "train_loss": 0.0020605215238622175
      },
      {
        "epoch": 1039,
        "reward": 0.4543893337249756,
        "val_loss": 0.001616629572319133,
        "train_loss": 0.0019710092689750195
      },
      {
        "epoch": 1040,
        "reward": 0.4491618573665619,
        "val_loss": 0.0016863326891325414,
        "train_loss": 0.0023812943702348722
      },
      {
        "epoch": 1041,
        "reward": 0.43474894762039185,
        "val_loss": 0.0018954250595665403,
        "train_loss": 0.0024337403931265445
      },
      {
        "epoch": 1042,
        "reward": 0.4565499722957611,
        "val_loss": 0.0015887065507870699,
        "train_loss": 0.002185439776020268
      },
      {
        "epoch": 1043,
        "reward": 0.4555390477180481,
        "val_loss": 0.0016017080800208663,
        "train_loss": 0.0018807162179235513
      },
      {
        "epoch": 1044,
        "reward": 0.4537380635738373,
        "val_loss": 0.0016251461430718856,
        "train_loss": 0.0019362821291836624
      },
      {
        "epoch": 1045,
        "reward": 0.45584598183631897,
        "val_loss": 0.001597748595356409,
        "train_loss": 0.0018531123939213173
      },
      {
        "epoch": 1046,
        "reward": 0.44490718841552734,
        "val_loss": 0.0017453941150701471,
        "train_loss": 0.001878021786419245
      },
      {
        "epoch": 1047,
        "reward": 0.4347858130931854,
        "val_loss": 0.0018948571024728672,
        "train_loss": 0.0019164215742561142
      },
      {
        "epoch": 1048,
        "reward": 0.4383552670478821,
        "val_loss": 0.001840653280461473,
        "train_loss": 0.0019626372892302102
      },
      {
        "epoch": 1049,
        "reward": 0.45617610216140747,
        "val_loss": 0.001593501855885344,
        "train_loss": 0.0019067892124159979
      },
      {
        "epoch": 1050,
        "reward": 0.4544440805912018,
        "val_loss": 0.0016159156220965087,
        "train_loss": 0.0019296836023316316
      },
      {
        "epoch": 1051,
        "reward": 0.45536860823631287,
        "val_loss": 0.0016039104417099484,
        "train_loss": 0.0021562946628994094
      },
      {
        "epoch": 1052,
        "reward": 0.44046837091445923,
        "val_loss": 0.0018093425314873457,
        "train_loss": 0.0019191583672251839
      },
      {
        "epoch": 1053,
        "reward": 0.4325430989265442,
        "val_loss": 0.0019297812167289002,
        "train_loss": 0.0019091163754078129
      },
      {
        "epoch": 1054,
        "reward": 0.4521004855632782,
        "val_loss": 0.0016467696405015886,
        "train_loss": 0.001886828032953557
      },
      {
        "epoch": 1055,
        "reward": 0.4521213173866272,
        "val_loss": 0.0016464927383432431,
        "train_loss": 0.0018964638074976392
      },
      {
        "epoch": 1056,
        "reward": 0.4492357671260834,
        "val_loss": 0.0016853252725143517,
        "train_loss": 0.0019067341988742415
      },
      {
        "epoch": 1057,
        "reward": 0.45026278495788574,
        "val_loss": 0.0016713958300117935,
        "train_loss": 0.0019747918816462448
      },
      {
        "epoch": 1058,
        "reward": 0.44730526208877563,
        "val_loss": 0.0017118419636972249,
        "train_loss": 0.0020479109706894425
      },
      {
        "epoch": 1059,
        "reward": 0.4514493942260742,
        "val_loss": 0.001655450913988586,
        "train_loss": 0.002364139014389366
      },
      {
        "epoch": 1060,
        "reward": 0.4407115578651428,
        "val_loss": 0.001805775857064873,
        "train_loss": 0.0023722036589438524
      },
      {
        "epoch": 1061,
        "reward": 0.45294904708862305,
        "val_loss": 0.0016355279034801892,
        "train_loss": 0.0020025537344806185
      },
      {
        "epoch": 1062,
        "reward": 0.45064231753349304,
        "val_loss": 0.0016662782956180827,
        "train_loss": 0.0018996837013848843
      },
      {
        "epoch": 1063,
        "reward": 0.4551451802253723,
        "val_loss": 0.0016068031545728445,
        "train_loss": 0.0018802491032287295
      },
      {
        "epoch": 1064,
        "reward": 0.44712454080581665,
        "val_loss": 0.001714346481354109,
        "train_loss": 0.001861407034014589
      },
      {
        "epoch": 1065,
        "reward": 0.38470378518104553,
        "val_loss": 0.0028682475011529668,
        "train_loss": 0.00222444344455233
      },
      {
        "epoch": 1066,
        "reward": 0.43843069672584534,
        "val_loss": 0.0018395259477464215,
        "train_loss": 0.002101148381790643
      },
      {
        "epoch": 1067,
        "reward": 0.45495015382766724,
        "val_loss": 0.0016093325767932193,
        "train_loss": 0.0018843921186019613
      },
      {
        "epoch": 1068,
        "reward": 0.4538823664188385,
        "val_loss": 0.0016232553669916733,
        "train_loss": 0.0018806102385636992
      },
      {
        "epoch": 1069,
        "reward": 0.45552849769592285,
        "val_loss": 0.0016018441529013216,
        "train_loss": 0.002124460727477876
      },
      {
        "epoch": 1070,
        "reward": 0.4521457850933075,
        "val_loss": 0.0016461677816031234,
        "train_loss": 0.002014122209332597
      },
      {
        "epoch": 1071,
        "reward": 0.4083004891872406,
        "val_loss": 0.002354743890464306,
        "train_loss": 0.0021151280290303896
      },
      {
        "epoch": 1072,
        "reward": 0.4530612528324127,
        "val_loss": 0.0016340470839557903,
        "train_loss": 0.0020626829949693414
      },
      {
        "epoch": 1073,
        "reward": 0.4453616738319397,
        "val_loss": 0.0017389821587130427,
        "train_loss": 0.00192305969987781
      },
      {
        "epoch": 1074,
        "reward": 0.4462891221046448,
        "val_loss": 0.0017259753242667233,
        "train_loss": 0.0019993738796284352
      },
      {
        "epoch": 1075,
        "reward": 0.4502159655094147,
        "val_loss": 0.0016720281148861562,
        "train_loss": 0.0018821193482905913
      },
      {
        "epoch": 1076,
        "reward": 0.4461054801940918,
        "val_loss": 0.0017285423153745277,
        "train_loss": 0.0019139268666689391
      },
      {
        "epoch": 1077,
        "reward": 0.45101091265678406,
        "val_loss": 0.001661324457797621,
        "train_loss": 0.0019311164975918543
      },
      {
        "epoch": 1078,
        "reward": 0.44766226410865784,
        "val_loss": 0.001706905579859657,
        "train_loss": 0.0019059416344344544
      },
      {
        "epoch": 1079,
        "reward": 0.4536591172218323,
        "val_loss": 0.001626181956713221,
        "train_loss": 0.0018737980706366496
      },
      {
        "epoch": 1080,
        "reward": 0.4509514272212982,
        "val_loss": 0.0016621220191674574,
        "train_loss": 0.0019256653792511385
      },
      {
        "epoch": 1081,
        "reward": 0.4394240081310272,
        "val_loss": 0.0018247470226404922,
        "train_loss": 0.0022783127317849835
      },
      {
        "epoch": 1082,
        "reward": 0.4549223482608795,
        "val_loss": 0.0016096937636445677,
        "train_loss": 0.0023324700764183384
      },
      {
        "epoch": 1083,
        "reward": 0.449786514043808,
        "val_loss": 0.0016778400833053248,
        "train_loss": 0.0019050091577810235
      },
      {
        "epoch": 1084,
        "reward": 0.45187005400657654,
        "val_loss": 0.0016498370012933655,
        "train_loss": 0.0018780884644141994
      },
      {
        "epoch": 1085,
        "reward": 0.45629802346229553,
        "val_loss": 0.0015919361945374735,
        "train_loss": 0.0018546022693525488
      },
      {
        "epoch": 1086,
        "reward": 0.4538348615169525,
        "val_loss": 0.0016238774488946156,
        "train_loss": 0.001896123573085508
      },
      {
        "epoch": 1087,
        "reward": 0.4383425712585449,
        "val_loss": 0.0018408432203744138,
        "train_loss": 0.0020049924362235917
      },
      {
        "epoch": 1088,
        "reward": 0.45549827814102173,
        "val_loss": 0.00160223466809839,
        "train_loss": 0.001966310517183536
      },
      {
        "epoch": 1089,
        "reward": 0.4480530917644501,
        "val_loss": 0.0017015183028498931,
        "train_loss": 0.0018838410156044678
      },
      {
        "epoch": 1090,
        "reward": 0.4527585208415985,
        "val_loss": 0.0016380454347069775,
        "train_loss": 0.0018865981278045534
      },
      {
        "epoch": 1091,
        "reward": 0.4268867075443268,
        "val_loss": 0.0020209548362929907,
        "train_loss": 0.0019378633833884334
      },
      {
        "epoch": 1092,
        "reward": 0.4480019211769104,
        "val_loss": 0.00170222350529262,
        "train_loss": 0.0020458166120358957
      },
      {
        "epoch": 1093,
        "reward": 0.4536714255809784,
        "val_loss": 0.0016260204304541861,
        "train_loss": 0.0020515188852396724
      },
      {
        "epoch": 1094,
        "reward": 0.4125541150569916,
        "val_loss": 0.0022733950588319984,
        "train_loss": 0.002052321049492233
      },
      {
        "epoch": 1095,
        "reward": 0.44602036476135254,
        "val_loss": 0.0017297339259779879,
        "train_loss": 0.002119270423708468
      },
      {
        "epoch": 1096,
        "reward": 0.4545775353908539,
        "val_loss": 0.0016141766931728593,
        "train_loss": 0.0018585223017278342
      },
      {
        "epoch": 1097,
        "reward": 0.45588698983192444,
        "val_loss": 0.0015972202610490577,
        "train_loss": 0.0018986350937316625
      },
      {
        "epoch": 1098,
        "reward": 0.4558332562446594,
        "val_loss": 0.0015979127742217056,
        "train_loss": 0.0018819534900383307
      },
      {
        "epoch": 1099,
        "reward": 0.45397114753723145,
        "val_loss": 0.0016220927271725877,
        "train_loss": 0.0018753826390401139
      },
      {
        "epoch": 1100,
        "reward": 0.45125460624694824,
        "val_loss": 0.0016580570871675654,
        "train_loss": 0.0018586164300918777
      },
      {
        "epoch": 1101,
        "reward": 0.4548928439617157,
        "val_loss": 0.0016100768282610392,
        "train_loss": 0.0018539180029900027
      },
      {
        "epoch": 1102,
        "reward": 0.45161929726600647,
        "val_loss": 0.001653181272558868,
        "train_loss": 0.0018666148122904885
      },
      {
        "epoch": 1103,
        "reward": 0.43840834498405457,
        "val_loss": 0.0018398598435201816,
        "train_loss": 0.0019393408617291313
      },
      {
        "epoch": 1104,
        "reward": 0.453996479511261,
        "val_loss": 0.0016217616253665515,
        "train_loss": 0.00240573722224396
      },
      {
        "epoch": 1105,
        "reward": 0.45434150099754333,
        "val_loss": 0.001617253101098218,
        "train_loss": 0.0019522128921363009
      },
      {
        "epoch": 1106,
        "reward": 0.45639491081237793,
        "val_loss": 0.0015906933528770293,
        "train_loss": 0.0018881942837302072
      },
      {
        "epoch": 1107,
        "reward": 0.43619757890701294,
        "val_loss": 0.001873218554205128,
        "train_loss": 0.002211958246054844
      },
      {
        "epoch": 1108,
        "reward": 0.42353254556655884,
        "val_loss": 0.002077194013898926,
        "train_loss": 0.002452011108219337
      },
      {
        "epoch": 1109,
        "reward": 0.4032255709171295,
        "val_loss": 0.0024559826124459505,
        "train_loss": 0.0021294087547665606
      },
      {
        "epoch": 1110,
        "reward": 0.4474429786205292,
        "val_loss": 0.001709936502655702,
        "train_loss": 0.002013919067394454
      },
      {
        "epoch": 1111,
        "reward": 0.45239946246147156,
        "val_loss": 0.0016427994289967632,
        "train_loss": 0.0018896495345800829
      },
      {
        "epoch": 1112,
        "reward": 0.45048943161964417,
        "val_loss": 0.0016683376327689206,
        "train_loss": 0.0020921567965370533
      },
      {
        "epoch": 1113,
        "reward": 0.4439428746700287,
        "val_loss": 0.001759080249550087,
        "train_loss": 0.0020062402674319367
      },
      {
        "epoch": 1114,
        "reward": 0.43447351455688477,
        "val_loss": 0.0018996794408719455,
        "train_loss": 0.0019239257176545484
      },
      {
        "epoch": 1115,
        "reward": 0.4385121464729309,
        "val_loss": 0.0018383088754490018,
        "train_loss": 0.0019509241146107132
      },
      {
        "epoch": 1116,
        "reward": 0.4280589520931244,
        "val_loss": 0.0020016884497765985,
        "train_loss": 0.00219161621778487
      },
      {
        "epoch": 1117,
        "reward": 0.44967302680015564,
        "val_loss": 0.001679379418159702,
        "train_loss": 0.002415171878685494
      },
      {
        "epoch": 1118,
        "reward": 0.4243687093257904,
        "val_loss": 0.002063017837437136,
        "train_loss": 0.0021885331997719523
      },
      {
        "epoch": 1119,
        "reward": 0.4556247889995575,
        "val_loss": 0.00160060083726421,
        "train_loss": 0.002376248625716051
      },
      {
        "epoch": 1120,
        "reward": 0.4501152038574219,
        "val_loss": 0.001673389833220946,
        "train_loss": 0.0019809377800601605
      },
      {
        "epoch": 1121,
        "reward": 0.45647260546684265,
        "val_loss": 0.0015896975944217826,
        "train_loss": 0.0019192264925760145
      },
      {
        "epoch": 1122,
        "reward": 0.45321351289749146,
        "val_loss": 0.0016320406741994833,
        "train_loss": 0.0019088891518536527
      },
      {
        "epoch": 1123,
        "reward": 0.45644956827163696,
        "val_loss": 0.001589992516008871,
        "train_loss": 0.0018625050622806437
      },
      {
        "epoch": 1124,
        "reward": 0.4534723460674286,
        "val_loss": 0.0016286349106979156,
        "train_loss": 0.0019711872535901
      },
      {
        "epoch": 1125,
        "reward": 0.45060235261917114,
        "val_loss": 0.0016668160346203617,
        "train_loss": 0.002050527537134118
      },
      {
        "epoch": 1126,
        "reward": 0.4565044939517975,
        "val_loss": 0.001589289226103574,
        "train_loss": 0.001956151786054341
      },
      {
        "epoch": 1127,
        "reward": 0.45406991243362427,
        "val_loss": 0.00162080060025411,
        "train_loss": 0.0018935094516424355
      },
      {
        "epoch": 1128,
        "reward": 0.45055174827575684,
        "val_loss": 0.001667497496652816,
        "train_loss": 0.001846881277882718
      },
      {
        "epoch": 1129,
        "reward": 0.44365301728248596,
        "val_loss": 0.001763216552457639,
        "train_loss": 0.0018553239885582466
      },
      {
        "epoch": 1130,
        "reward": 0.45228347182273865,
        "val_loss": 0.0016443389218433627,
        "train_loss": 0.0018912809061405894
      },
      {
        "epoch": 1131,
        "reward": 0.43808871507644653,
        "val_loss": 0.0018446430331096053,
        "train_loss": 0.0019400948501872616
      },
      {
        "epoch": 1132,
        "reward": 0.4551651179790497,
        "val_loss": 0.0016065451449581555,
        "train_loss": 0.0020920676089679967
      },
      {
        "epoch": 1133,
        "reward": 0.43449899554252625,
        "val_loss": 0.001899285358376801,
        "train_loss": 0.0019769937028356185
      },
      {
        "epoch": 1134,
        "reward": 0.44955703616142273,
        "val_loss": 0.001680955573517297,
        "train_loss": 0.0019717397623865577
      },
      {
        "epoch": 1135,
        "reward": 0.45532694458961487,
        "val_loss": 0.0016044498022113527,
        "train_loss": 0.0019211452541080338
      },
      {
        "epoch": 1136,
        "reward": 0.45194196701049805,
        "val_loss": 0.001648879111079233,
        "train_loss": 0.0018777718281713673
      },
      {
        "epoch": 1137,
        "reward": 0.45114070177078247,
        "val_loss": 0.001659583333613617,
        "train_loss": 0.0019126270915596532
      },
      {
        "epoch": 1138,
        "reward": 0.4521911144256592,
        "val_loss": 0.0016455653156819089,
        "train_loss": 0.0018649664886057648
      },
      {
        "epoch": 1139,
        "reward": 0.44329768419265747,
        "val_loss": 0.0017683016402380808,
        "train_loss": 0.002120159329094279
      },
      {
        "epoch": 1140,
        "reward": 0.4395844042301178,
        "val_loss": 0.001822371019183525,
        "train_loss": 0.0020250769493241724
      },
      {
        "epoch": 1141,
        "reward": 0.4403328001499176,
        "val_loss": 0.001811334680366729,
        "train_loss": 0.0022370332466939893
      },
      {
        "epoch": 1142,
        "reward": 0.4292457103729248,
        "val_loss": 0.0019823829144505517,
        "train_loss": 0.0026529372642891337
      },
      {
        "epoch": 1143,
        "reward": 0.42382317781448364,
        "val_loss": 0.002072255326701062,
        "train_loss": 0.002377896941302774
      },
      {
        "epoch": 1144,
        "reward": 0.4459475576877594,
        "val_loss": 0.0017307529508668398,
        "train_loss": 0.002142405089321423
      },
      {
        "epoch": 1145,
        "reward": 0.45687252283096313,
        "val_loss": 0.0015845811909197696,
        "train_loss": 0.002021774232092027
      },
      {
        "epoch": 1146,
        "reward": 0.4365510642528534,
        "val_loss": 0.001867841895935791,
        "train_loss": 0.0020530919685440427
      },
      {
        "epoch": 1147,
        "reward": 0.4395197927951813,
        "val_loss": 0.0018233274375753744,
        "train_loss": 0.0019391229375637171
      },
      {
        "epoch": 1148,
        "reward": 0.42217570543289185,
        "val_loss": 0.00210041951920305,
        "train_loss": 0.0020037900674371766
      },
      {
        "epoch": 1149,
        "reward": 0.4546572268009186,
        "val_loss": 0.0016131397819013468,
        "train_loss": 0.0019443387259693386
      },
      {
        "epoch": 1150,
        "reward": 0.4553080201148987,
        "val_loss": 0.0016046952472866646,
        "train_loss": 0.002329139576221888
      },
      {
        "epoch": 1151,
        "reward": 0.44946447014808655,
        "val_loss": 0.0016822132331851339,
        "train_loss": 0.0020670309559836122
      },
      {
        "epoch": 1152,
        "reward": 0.43863674998283386,
        "val_loss": 0.001836450121897672,
        "train_loss": 0.0018674896709154171
      },
      {
        "epoch": 1153,
        "reward": 0.4372617304325104,
        "val_loss": 0.0018570818938314915,
        "train_loss": 0.0019388930455674059
      },
      {
        "epoch": 1154,
        "reward": 0.4506860375404358,
        "val_loss": 0.0016656899907892303,
        "train_loss": 0.001992748844294021
      },
      {
        "epoch": 1155,
        "reward": 0.45428362488746643,
        "val_loss": 0.001618008836105998,
        "train_loss": 0.0020354227604702127
      },
      {
        "epoch": 1156,
        "reward": 0.4551587700843811,
        "val_loss": 0.0016066274090137864,
        "train_loss": 0.0018742386696081108
      },
      {
        "epoch": 1157,
        "reward": 0.45292574167251587,
        "val_loss": 0.0016358357554833805,
        "train_loss": 0.001857824507134445
      },
      {
        "epoch": 1158,
        "reward": 0.44940462708473206,
        "val_loss": 0.0016830271924845874,
        "train_loss": 0.0018520263852923773
      },
      {
        "epoch": 1159,
        "reward": 0.4468873143196106,
        "val_loss": 0.0017176401867930377,
        "train_loss": 0.001858826071506533
      },
      {
        "epoch": 1160,
        "reward": 0.4533841609954834,
        "val_loss": 0.0016297941578419081,
        "train_loss": 0.0018809999679573453
      },
      {
        "epoch": 1161,
        "reward": 0.44950491189956665,
        "val_loss": 0.0016816634535124259,
        "train_loss": 0.0018641160389121908
      },
      {
        "epoch": 1162,
        "reward": 0.4532397389411926,
        "val_loss": 0.0016316947377552943,
        "train_loss": 0.0019722414391043666
      },
      {
        "epoch": 1163,
        "reward": 0.454637736082077,
        "val_loss": 0.001613393292895385,
        "train_loss": 0.0019019342433658983
      },
      {
        "epoch": 1164,
        "reward": 0.4515070617198944,
        "val_loss": 0.001654680011727448,
        "train_loss": 0.0018786732958128245
      },
      {
        "epoch": 1165,
        "reward": 0.4547230303287506,
        "val_loss": 0.0016122832229094847,
        "train_loss": 0.0024291861336678267
      },
      {
        "epoch": 1166,
        "reward": 0.4526258111000061,
        "val_loss": 0.0016398010110216482,
        "train_loss": 0.0018716146075628505
      },
      {
        "epoch": 1167,
        "reward": 0.4413747489452362,
        "val_loss": 0.001796087050544364,
        "train_loss": 0.0018686906920405678
      },
      {
        "epoch": 1168,
        "reward": 0.45242515206336975,
        "val_loss": 0.00164245895575732,
        "train_loss": 0.0019420592736703558
      },
      {
        "epoch": 1169,
        "reward": 0.4135700762271881,
        "val_loss": 0.002254421456850001,
        "train_loss": 0.002125306063904785
      },
      {
        "epoch": 1170,
        "reward": 0.4523804187774658,
        "val_loss": 0.0016430521583450691,
        "train_loss": 0.002275309518713934
      },
      {
        "epoch": 1171,
        "reward": 0.4547788202762604,
        "val_loss": 0.0016115584626926907,
        "train_loss": 0.001865551989702943
      },
      {
        "epoch": 1172,
        "reward": 0.45517268776893616,
        "val_loss": 0.0016064472147263587,
        "train_loss": 0.0018671945017646207
      },
      {
        "epoch": 1173,
        "reward": 0.45050016045570374,
        "val_loss": 0.0016681931197776326,
        "train_loss": 0.0018622875821279194
      },
      {
        "epoch": 1174,
        "reward": 0.4392697811126709,
        "val_loss": 0.0018270326711769616,
        "train_loss": 0.0018830878364567
      },
      {
        "epoch": 1175,
        "reward": 0.4280402660369873,
        "val_loss": 0.00200199379053499,
        "train_loss": 0.002055405970447912
      },
      {
        "epoch": 1176,
        "reward": 0.44301486015319824,
        "val_loss": 0.001772359129972756,
        "train_loss": 0.0020486686441402594
      },
      {
        "epoch": 1177,
        "reward": 0.45566630363464355,
        "val_loss": 0.0016000651687915837,
        "train_loss": 0.0019131449688967012
      },
      {
        "epoch": 1178,
        "reward": 0.4330216944217682,
        "val_loss": 0.0019222711811640433,
        "train_loss": 0.0019018226019648172
      },
      {
        "epoch": 1179,
        "reward": 0.44956275820732117,
        "val_loss": 0.0016808774754671113,
        "train_loss": 0.0019050610963649189
      },
      {
        "epoch": 1180,
        "reward": 0.4548884928226471,
        "val_loss": 0.0016101333894766867,
        "train_loss": 0.001855825778525636
      },
      {
        "epoch": 1181,
        "reward": 0.4497024118900299,
        "val_loss": 0.001678980970089989,
        "train_loss": 0.001958012809224713
      },
      {
        "epoch": 1182,
        "reward": 0.452427476644516,
        "val_loss": 0.001642427864551012,
        "train_loss": 0.001928815112198488
      },
      {
        "epoch": 1183,
        "reward": 0.4165688455104828,
        "val_loss": 0.002199412922241858,
        "train_loss": 0.002056743578018191
      },
      {
        "epoch": 1184,
        "reward": 0.4518004059791565,
        "val_loss": 0.0016507656296848186,
        "train_loss": 0.0021968914460068424
      },
      {
        "epoch": 1185,
        "reward": 0.4499562680721283,
        "val_loss": 0.0016755400824227504,
        "train_loss": 0.001984012075878966
      },
      {
        "epoch": 1186,
        "reward": 0.43211469054222107,
        "val_loss": 0.0019365298794582486,
        "train_loss": 0.002050426188641443
      },
      {
        "epoch": 1187,
        "reward": 0.42406320571899414,
        "val_loss": 0.0020681860124958412,
        "train_loss": 0.0020317141339686574
      },
      {
        "epoch": 1188,
        "reward": 0.4552764594554901,
        "val_loss": 0.0016051031333128257,
        "train_loss": 0.001891126951451182
      },
      {
        "epoch": 1189,
        "reward": 0.4559086859226227,
        "val_loss": 0.0015969412550995393,
        "train_loss": 0.0018845456853831331
      },
      {
        "epoch": 1190,
        "reward": 0.44792914390563965,
        "val_loss": 0.0017032251260908587,
        "train_loss": 0.001999908610461996
      },
      {
        "epoch": 1191,
        "reward": 0.44564422965049744,
        "val_loss": 0.0017350084630639426,
        "train_loss": 0.0019098830243120363
      },
      {
        "epoch": 1192,
        "reward": 0.4532630443572998,
        "val_loss": 0.0016313879750669003,
        "train_loss": 0.0018505125311863734
      },
      {
        "epoch": 1193,
        "reward": 0.44750353693962097,
        "val_loss": 0.0017090986532691335,
        "train_loss": 0.0018552322773687663
      },
      {
        "epoch": 1194,
        "reward": 0.4490947425365448,
        "val_loss": 0.001687248087754207,
        "train_loss": 0.001849738132967524
      },
      {
        "epoch": 1195,
        "reward": 0.4560825824737549,
        "val_loss": 0.0015947038025063062,
        "train_loss": 0.001873453850678813
      },
      {
        "epoch": 1196,
        "reward": 0.45127081871032715,
        "val_loss": 0.001657839648292533,
        "train_loss": 0.001925776457378211
      },
      {
        "epoch": 1197,
        "reward": 0.4491223990917206,
        "val_loss": 0.001686870860534587,
        "train_loss": 0.001879074211711458
      },
      {
        "epoch": 1198,
        "reward": 0.4543519914150238,
        "val_loss": 0.001617116088579808,
        "train_loss": 0.0018569621676691056
      },
      {
        "epoch": 1199,
        "reward": 0.45480844378471375,
        "val_loss": 0.0016111730115621217,
        "train_loss": 0.0018601309588680474
      },
      {
        "epoch": 1200,
        "reward": 0.45516878366470337,
        "val_loss": 0.001606497705714511,
        "train_loss": 0.0018608526630452195
      },
      {
        "epoch": 1201,
        "reward": 0.45155954360961914,
        "val_loss": 0.0016539784846827388,
        "train_loss": 0.00185771566458033
      },
      {
        "epoch": 1202,
        "reward": 0.45451781153678894,
        "val_loss": 0.0016149547133993889,
        "train_loss": 0.0018650061226883107
      },
      {
        "epoch": 1203,
        "reward": 0.4391382336616516,
        "val_loss": 0.0018289856712466904,
        "train_loss": 0.001977033142303788
      },
      {
        "epoch": 1204,
        "reward": 0.4515988826751709,
        "val_loss": 0.0016534534515812993,
        "train_loss": 0.0018551200695443326
      },
      {
        "epoch": 1205,
        "reward": 0.4555666148662567,
        "val_loss": 0.0016013519655513977,
        "train_loss": 0.0018960576131716012
      },
      {
        "epoch": 1206,
        "reward": 0.42691612243652344,
        "val_loss": 0.00202046986669302,
        "train_loss": 0.0019251234659280342
      },
      {
        "epoch": 1207,
        "reward": 0.44905921816825867,
        "val_loss": 0.0016877330407234175,
        "train_loss": 0.002066072020590162
      },
      {
        "epoch": 1208,
        "reward": 0.45591649413108826,
        "val_loss": 0.0015968407886768027,
        "train_loss": 0.0020860178808036903
      },
      {
        "epoch": 1209,
        "reward": 0.4552510380744934,
        "val_loss": 0.0016054321729045893,
        "train_loss": 0.001907408692554432
      },
      {
        "epoch": 1210,
        "reward": 0.4527188241481781,
        "val_loss": 0.0016385699522548489,
        "train_loss": 0.0020745347092787805
      },
      {
        "epoch": 1211,
        "reward": 0.43775221705436707,
        "val_loss": 0.0018496941608775938,
        "train_loss": 0.001961859986365128
      },
      {
        "epoch": 1212,
        "reward": 0.43874117732048035,
        "val_loss": 0.00183489263456847,
        "train_loss": 0.0020251325678635533
      },
      {
        "epoch": 1213,
        "reward": 0.44501668214797974,
        "val_loss": 0.001743846622827862,
        "train_loss": 0.002449861179159668
      },
      {
        "epoch": 1214,
        "reward": 0.4543413817882538,
        "val_loss": 0.0016172548390126654,
        "train_loss": 0.0019002004434101904
      },
      {
        "epoch": 1215,
        "reward": 0.44256076216697693,
        "val_loss": 0.001778894370155675,
        "train_loss": 0.002031885266590577
      },
      {
        "epoch": 1216,
        "reward": 0.4463414251804352,
        "val_loss": 0.0017252444439301534,
        "train_loss": 0.002280009522040088
      },
      {
        "epoch": 1217,
        "reward": 0.4531262516975403,
        "val_loss": 0.001633190325394805,
        "train_loss": 0.0019555196917141215
      },
      {
        "epoch": 1218,
        "reward": 0.4241185784339905,
        "val_loss": 0.002067248203924724,
        "train_loss": 0.0019364187453622715
      },
      {
        "epoch": 1219,
        "reward": 0.45492884516716003,
        "val_loss": 0.0016096093874823833,
        "train_loss": 0.002022830227570711
      },
      {
        "epoch": 1220,
        "reward": 0.4448559284210205,
        "val_loss": 0.001746118110271969,
        "train_loss": 0.0018946990861038032
      },
      {
        "epoch": 1221,
        "reward": 0.4167514443397522,
        "val_loss": 0.002196110801638237,
        "train_loss": 0.0020450952579267323
      },
      {
        "epoch": 1222,
        "reward": 0.4549817144870758,
        "val_loss": 0.0016089233187293367,
        "train_loss": 0.002057731403440882
      },
      {
        "epoch": 1223,
        "reward": 0.4527762830257416,
        "val_loss": 0.0016378097352571785,
        "train_loss": 0.001898813008440269
      },
      {
        "epoch": 1224,
        "reward": 0.45309025049209595,
        "val_loss": 0.0016336649922387941,
        "train_loss": 0.0019043136226872986
      },
      {
        "epoch": 1225,
        "reward": 0.45365339517593384,
        "val_loss": 0.001626257027965039,
        "train_loss": 0.0018660908356720868
      },
      {
        "epoch": 1226,
        "reward": 0.45553699135780334,
        "val_loss": 0.001601734065583774,
        "train_loss": 0.001860132674175055
      },
      {
        "epoch": 1227,
        "reward": 0.4432985484600067,
        "val_loss": 0.001768288402152913,
        "train_loss": 0.0022254975718589355
      },
      {
        "epoch": 1228,
        "reward": 0.4241405129432678,
        "val_loss": 0.0020668775708015475,
        "train_loss": 0.002077738624603416
      },
      {
        "epoch": 1229,
        "reward": 0.44821688532829285,
        "val_loss": 0.0016992665311720753,
        "train_loss": 0.002152646947741652
      },
      {
        "epoch": 1230,
        "reward": 0.45549091696739197,
        "val_loss": 0.0016023296297394804,
        "train_loss": 0.002010666277223768
      },
      {
        "epoch": 1231,
        "reward": 0.4545512795448303,
        "val_loss": 0.001614519245257335,
        "train_loss": 0.001982429478980171
      },
      {
        "epoch": 1232,
        "reward": 0.4160420000553131,
        "val_loss": 0.0022089708197329727,
        "train_loss": 0.0019425661818016893
      },
      {
        "epoch": 1233,
        "reward": 0.45584502816200256,
        "val_loss": 0.0015977612929418683,
        "train_loss": 0.001982085206096739
      },
      {
        "epoch": 1234,
        "reward": 0.4551771283149719,
        "val_loss": 0.0016063895226190133,
        "train_loss": 0.0019141730825560023
      },
      {
        "epoch": 1235,
        "reward": 0.4011386036872864,
        "val_loss": 0.002498992086787309,
        "train_loss": 0.00208544203465303
      },
      {
        "epoch": 1236,
        "reward": 0.4432712495326996,
        "val_loss": 0.0017686797572033747,
        "train_loss": 0.002573466904533024
      },
      {
        "epoch": 1237,
        "reward": 0.42778506875038147,
        "val_loss": 0.0020061728677579333,
        "train_loss": 0.0019399314411342717
      },
      {
        "epoch": 1238,
        "reward": 0.4370702803134918,
        "val_loss": 0.0018599739830408777,
        "train_loss": 0.0019093981917159488
      },
      {
        "epoch": 1239,
        "reward": 0.45423269271850586,
        "val_loss": 0.0016186737422166125,
        "train_loss": 0.0018698655599459575
      },
      {
        "epoch": 1240,
        "reward": 0.3856979310512543,
        "val_loss": 0.002844266643348549,
        "train_loss": 0.0020447982869182643
      },
      {
        "epoch": 1241,
        "reward": 0.45049571990966797,
        "val_loss": 0.001668252724422408,
        "train_loss": 0.002102029391468162
      },
      {
        "epoch": 1242,
        "reward": 0.440316766500473,
        "val_loss": 0.0018115698892091,
        "train_loss": 0.001955018789745876
      },
      {
        "epoch": 1243,
        "reward": 0.45344892144203186,
        "val_loss": 0.001628942388509001,
        "train_loss": 0.001929408671388116
      },
      {
        "epoch": 1244,
        "reward": 0.45476895570755005,
        "val_loss": 0.0016116861453545944,
        "train_loss": 0.0019208709373532867
      },
      {
        "epoch": 1245,
        "reward": 0.42294809222221375,
        "val_loss": 0.0020871644041367938,
        "train_loss": 0.001908819879575346
      },
      {
        "epoch": 1246,
        "reward": 0.43964454531669617,
        "val_loss": 0.0018214817724323698,
        "train_loss": 0.0019450629412089116
      },
      {
        "epoch": 1247,
        "reward": 0.45495089888572693,
        "val_loss": 0.0016093224070833198,
        "train_loss": 0.0018596814714748268
      },
      {
        "epoch": 1248,
        "reward": 0.4493284821510315,
        "val_loss": 0.001684062698456858,
        "train_loss": 0.0018771937197575776
      },
      {
        "epoch": 1249,
        "reward": 0.44879063963890076,
        "val_loss": 0.0016914010047912598,
        "train_loss": 0.0019278103539433617
      },
      {
        "epoch": 1250,
        "reward": 0.4554555118083954,
        "val_loss": 0.001602787449623325,
        "train_loss": 0.0018506196842141575
      },
      {
        "epoch": 1251,
        "reward": 0.4479043185710907,
        "val_loss": 0.001703566946421883,
        "train_loss": 0.0019062685135465402
      },
      {
        "epoch": 1252,
        "reward": 0.45272570848464966,
        "val_loss": 0.0016384785495964544,
        "train_loss": 0.001976594496227335
      },
      {
        "epoch": 1253,
        "reward": 0.45354586839675903,
        "val_loss": 0.001627668655211372,
        "train_loss": 0.0019283704302954273
      },
      {
        "epoch": 1254,
        "reward": 0.4428321421146393,
        "val_loss": 0.0017749853099563292,
        "train_loss": 0.0018795158930515754
      },
      {
        "epoch": 1255,
        "reward": 0.41178664565086365,
        "val_loss": 0.0022878432147470967,
        "train_loss": 0.002162980856015705
      },
      {
        "epoch": 1256,
        "reward": 0.41290560364723206,
        "val_loss": 0.002266811339982918,
        "train_loss": 0.002412153349723667
      },
      {
        "epoch": 1257,
        "reward": 0.45102691650390625,
        "val_loss": 0.0016611095551135285,
        "train_loss": 0.00222157959069591
      },
      {
        "epoch": 1258,
        "reward": 0.45561695098876953,
        "val_loss": 0.0016007017527174736,
        "train_loss": 0.0019050408560500587
      },
      {
        "epoch": 1259,
        "reward": 0.4533604085445404,
        "val_loss": 0.0016301066248810717,
        "train_loss": 0.0019077797500918119
      },
      {
        "epoch": 1260,
        "reward": 0.45661887526512146,
        "val_loss": 0.0015878240145476802,
        "train_loss": 0.0018866898507649938
      },
      {
        "epoch": 1261,
        "reward": 0.4562531113624573,
        "val_loss": 0.001592512965934085,
        "train_loss": 0.0019002855036748
      },
      {
        "epoch": 1262,
        "reward": 0.45301347970962524,
        "val_loss": 0.0016346773398774011,
        "train_loss": 0.0019250312547657044
      },
      {
        "epoch": 1263,
        "reward": 0.45581936836242676,
        "val_loss": 0.001598091804355915,
        "train_loss": 0.001868299295892939
      },
      {
        "epoch": 1264,
        "reward": 0.455312579870224,
        "val_loss": 0.0016046354597035264,
        "train_loss": 0.001887094779634096
      },
      {
        "epoch": 1265,
        "reward": 0.45481210947036743,
        "val_loss": 0.0016111253976954945,
        "train_loss": 0.0018810741110848119
      },
      {
        "epoch": 1266,
        "reward": 0.45539242029190063,
        "val_loss": 0.0016036030886295652,
        "train_loss": 0.0018686211372439105
      },
      {
        "epoch": 1267,
        "reward": 0.4536242187023163,
        "val_loss": 0.0016266402921506337,
        "train_loss": 0.0019003223547210486
      },
      {
        "epoch": 1268,
        "reward": 0.4559120833873749,
        "val_loss": 0.0015968969258080637,
        "train_loss": 0.0018665280315067671
      },
      {
        "epoch": 1269,
        "reward": 0.44522520899772644,
        "val_loss": 0.001740905040475939,
        "train_loss": 0.001900575114772297
      },
      {
        "epoch": 1270,
        "reward": 0.4550948143005371,
        "val_loss": 0.0016074559368592287,
        "train_loss": 0.0019164619348325336
      },
      {
        "epoch": 1271,
        "reward": 0.4556725025177002,
        "val_loss": 0.0015999850085271256,
        "train_loss": 0.001896219968330115
      },
      {
        "epoch": 1272,
        "reward": 0.424489825963974,
        "val_loss": 0.0020609735511243343,
        "train_loss": 0.0020058693603809494
      },
      {
        "epoch": 1273,
        "reward": 0.4547610282897949,
        "val_loss": 0.0016117893142758735,
        "train_loss": 0.001882390358682292
      },
      {
        "epoch": 1274,
        "reward": 0.4427514672279358,
        "val_loss": 0.0017761473094911448,
        "train_loss": 0.0020015503709705975
      },
      {
        "epoch": 1275,
        "reward": 0.4263720214366913,
        "val_loss": 0.0020294776685269816,
        "train_loss": 0.0018952629197052863
      },
      {
        "epoch": 1276,
        "reward": 0.44531702995300293,
        "val_loss": 0.0017396106185125454,
        "train_loss": 0.0020224402766101635
      },
      {
        "epoch": 1277,
        "reward": 0.4237240254878998,
        "val_loss": 0.002073937943870468,
        "train_loss": 0.0020403187484659543
      },
      {
        "epoch": 1278,
        "reward": 0.4548817276954651,
        "val_loss": 0.001610221016952502,
        "train_loss": 0.0020046659645126617
      },
      {
        "epoch": 1279,
        "reward": 0.45524224638938904,
        "val_loss": 0.001605546210027699,
        "train_loss": 0.001906403159060014
      },
      {
        "epoch": 1280,
        "reward": 0.4485323429107666,
        "val_loss": 0.0016949374777530985,
        "train_loss": 0.0018799140424772094
      },
      {
        "epoch": 1281,
        "reward": 0.4446875751018524,
        "val_loss": 0.0017485013397942697,
        "train_loss": 0.0018869143420418438
      },
      {
        "epoch": 1282,
        "reward": 0.4545125961303711,
        "val_loss": 0.001615022583532014,
        "train_loss": 0.0018635761673347307
      },
      {
        "epoch": 1283,
        "reward": 0.4472711980342865,
        "val_loss": 0.0017123134873275245,
        "train_loss": 0.0019107541033568291
      },
      {
        "epoch": 1284,
        "reward": 0.42245563864707947,
        "val_loss": 0.0020956051801996572,
        "train_loss": 0.002123990454352819
      },
      {
        "epoch": 1285,
        "reward": 0.43026208877563477,
        "val_loss": 0.0019660075527748893,
        "train_loss": 0.0020361695966969887
      },
      {
        "epoch": 1286,
        "reward": 0.4530642032623291,
        "val_loss": 0.001634008259445961,
        "train_loss": 0.002204829923217543
      },
      {
        "epoch": 1287,
        "reward": 0.44462838768959045,
        "val_loss": 0.0017493389397194342,
        "train_loss": 0.001968673103524802
      },
      {
        "epoch": 1288,
        "reward": 0.4429526925086975,
        "val_loss": 0.0017732524179986545,
        "train_loss": 0.0019549235249332222
      },
      {
        "epoch": 1289,
        "reward": 0.4564228951931,
        "val_loss": 0.0015903342199245734,
        "train_loss": 0.0019286577388321837
      },
      {
        "epoch": 1290,
        "reward": 0.4541361927986145,
        "val_loss": 0.001619934312267495,
        "train_loss": 0.0018516070501321407
      },
      {
        "epoch": 1291,
        "reward": 0.4544324576854706,
        "val_loss": 0.0016160672031609075,
        "train_loss": 0.001890564361999098
      },
      {
        "epoch": 1292,
        "reward": 0.441152423620224,
        "val_loss": 0.0017993281362578273,
        "train_loss": 0.002061369246803224
      },
      {
        "epoch": 1293,
        "reward": 0.44311484694480896,
        "val_loss": 0.0017709234130701848,
        "train_loss": 0.002128541509871586
      },
      {
        "epoch": 1294,
        "reward": 0.4554212689399719,
        "val_loss": 0.0016032297862693667,
        "train_loss": 0.0018554611530047483
      },
      {
        "epoch": 1295,
        "reward": 0.44664403796195984,
        "val_loss": 0.0017210254944594844,
        "train_loss": 0.0018624179602528994
      },
      {
        "epoch": 1296,
        "reward": 0.44886118173599243,
        "val_loss": 0.0016904367117344268,
        "train_loss": 0.001840543524189378
      },
      {
        "epoch": 1297,
        "reward": 0.45394816994667053,
        "val_loss": 0.0016223934445796268,
        "train_loss": 0.0018926627691633678
      },
      {
        "epoch": 1298,
        "reward": 0.37513574957847595,
        "val_loss": 0.003110968241734164,
        "train_loss": 0.0021563330933881495
      },
      {
        "epoch": 1299,
        "reward": 0.44077157974243164,
        "val_loss": 0.00180489694633122,
        "train_loss": 0.0024660547407200704
      },
      {
        "epoch": 1300,
        "reward": 0.4554911255836487,
        "val_loss": 0.001602327251540763,
        "train_loss": 0.001900129690651735
      },
      {
        "epoch": 1301,
        "reward": 0.4559343755245209,
        "val_loss": 0.0015966098373090582,
        "train_loss": 0.0020046201153980712
      },
      {
        "epoch": 1302,
        "reward": 0.45621490478515625,
        "val_loss": 0.0015930030079159354,
        "train_loss": 0.0018897863690374205
      },
      {
        "epoch": 1303,
        "reward": 0.4544947147369385,
        "val_loss": 0.0016152557467908732,
        "train_loss": 0.0018954788132969742
      },
      {
        "epoch": 1304,
        "reward": 0.4513716399669647,
        "val_loss": 0.0016564913177197532,
        "train_loss": 0.0018950889352709055
      },
      {
        "epoch": 1305,
        "reward": 0.4274764657020569,
        "val_loss": 0.002011237483072494,
        "train_loss": 0.002049742208328098
      },
      {
        "epoch": 1306,
        "reward": 0.4263565242290497,
        "val_loss": 0.0020297348632344176,
        "train_loss": 0.0025867595731352386
      },
      {
        "epoch": 1307,
        "reward": 0.4487677216529846,
        "val_loss": 0.0016917144613606589,
        "train_loss": 0.0019766973631563955
      },
      {
        "epoch": 1308,
        "reward": 0.4550148546695709,
        "val_loss": 0.001608492898023022,
        "train_loss": 0.0018835126563946968
      },
      {
        "epoch": 1309,
        "reward": 0.42099952697753906,
        "val_loss": 0.002120780775190464,
        "train_loss": 0.002004540364186351
      },
      {
        "epoch": 1310,
        "reward": 0.45548173785209656,
        "val_loss": 0.001602448381683124,
        "train_loss": 0.0019226791118853725
      },
      {
        "epoch": 1311,
        "reward": 0.45485517382621765,
        "val_loss": 0.0016105661883817188,
        "train_loss": 0.0018591745100156214
      },
      {
        "epoch": 1312,
        "reward": 0.4403434693813324,
        "val_loss": 0.0018111780684973513,
        "train_loss": 0.0018834417614226157
      },
      {
        "epoch": 1313,
        "reward": 0.4488177001476288,
        "val_loss": 0.0016910309537446924,
        "train_loss": 0.0018954649934025487
      },
      {
        "epoch": 1314,
        "reward": 0.4369677007198334,
        "val_loss": 0.001861525433404105,
        "train_loss": 0.0018658764243949777
      },
      {
        "epoch": 1315,
        "reward": 0.4544755518436432,
        "val_loss": 0.0016155052165101682,
        "train_loss": 0.0018974902945606469
      },
      {
        "epoch": 1316,
        "reward": 0.44987568259239197,
        "val_loss": 0.001676631733841662,
        "train_loss": 0.002067813913946828
      },
      {
        "epoch": 1317,
        "reward": 0.43982043862342834,
        "val_loss": 0.0018188831828800695,
        "train_loss": 0.0018767375429608645
      },
      {
        "epoch": 1318,
        "reward": 0.4556766450405121,
        "val_loss": 0.001599931249594582,
        "train_loss": 0.0018732431796817212
      },
      {
        "epoch": 1319,
        "reward": 0.4413037896156311,
        "val_loss": 0.0017971206855561053,
        "train_loss": 0.0019727192926578796
      },
      {
        "epoch": 1320,
        "reward": 0.4537464678287506,
        "val_loss": 0.0016250364632079644,
        "train_loss": 0.001915243056377956
      },
      {
        "epoch": 1321,
        "reward": 0.4558827877044678,
        "val_loss": 0.0015972742777583854,
        "train_loss": 0.0019678147711182157
      },
      {
        "epoch": 1322,
        "reward": 0.44895440340042114,
        "val_loss": 0.0016891633775750442,
        "train_loss": 0.0018636363893165253
      },
      {
        "epoch": 1323,
        "reward": 0.4547634720802307,
        "val_loss": 0.0016117578322466994,
        "train_loss": 0.0018839838113098477
      },
      {
        "epoch": 1324,
        "reward": 0.4389919936656952,
        "val_loss": 0.0018311584468132683,
        "train_loss": 0.0022518833463366786
      },
      {
        "epoch": 1325,
        "reward": 0.45560169219970703,
        "val_loss": 0.0016008990434264497,
        "train_loss": 0.0019475855330641095
      },
      {
        "epoch": 1326,
        "reward": 0.45005059242248535,
        "val_loss": 0.0016742634803189763,
        "train_loss": 0.001959146192977921
      },
      {
        "epoch": 1327,
        "reward": 0.429034560918808,
        "val_loss": 0.001985802481483136,
        "train_loss": 0.002167259607141694
      },
      {
        "epoch": 1328,
        "reward": 0.44466015696525574,
        "val_loss": 0.0017488892273312168,
        "train_loss": 0.002176109831242894
      },
      {
        "epoch": 1329,
        "reward": 0.4381493031978607,
        "val_loss": 0.0018437354592606425,
        "train_loss": 0.001998181797367019
      },
      {
        "epoch": 1330,
        "reward": 0.4529513418674469,
        "val_loss": 0.0016354969453199633,
        "train_loss": 0.0019709555870996644
      },
      {
        "epoch": 1331,
        "reward": 0.4562794268131256,
        "val_loss": 0.001592175361500787,
        "train_loss": 0.0019334999946854974
      },
      {
        "epoch": 1332,
        "reward": 0.4390772879123688,
        "val_loss": 0.0018298904677586897,
        "train_loss": 0.001888118429073634
      },
      {
        "epoch": 1333,
        "reward": 0.4521493911743164,
        "val_loss": 0.0016461200679519347,
        "train_loss": 0.001884161869104271
      },
      {
        "epoch": 1334,
        "reward": 0.4302375316619873,
        "val_loss": 0.0019664007704705,
        "train_loss": 0.00206745702934523
      },
      {
        "epoch": 1335,
        "reward": 0.4115312695503235,
        "val_loss": 0.0022926736855879426,
        "train_loss": 0.002442660065403638
      },
      {
        "epoch": 1336,
        "reward": 0.44866880774497986,
        "val_loss": 0.0016930683382919856,
        "train_loss": 0.001951697667148704
      },
      {
        "epoch": 1337,
        "reward": 0.44924527406692505,
        "val_loss": 0.001685196176237826,
        "train_loss": 0.0018623017282292354
      },
      {
        "epoch": 1338,
        "reward": 0.45568713545799255,
        "val_loss": 0.0015997959916213794,
        "train_loss": 0.0018584375634418393
      },
      {
        "epoch": 1339,
        "reward": 0.4524523913860321,
        "val_loss": 0.0016420977356444513,
        "train_loss": 0.0018512048713651334
      },
      {
        "epoch": 1340,
        "reward": 0.4151417315006256,
        "val_loss": 0.0022254071664065123,
        "train_loss": 0.002297224544096165
      },
      {
        "epoch": 1341,
        "reward": 0.4550003707408905,
        "val_loss": 0.0016086814575828612,
        "train_loss": 0.0019505775109372246
      },
      {
        "epoch": 1342,
        "reward": 0.44539234042167664,
        "val_loss": 0.001738550773422633,
        "train_loss": 0.0018764735589885417
      },
      {
        "epoch": 1343,
        "reward": 0.43633314967155457,
        "val_loss": 0.0018711546103336982,
        "train_loss": 0.0019376034615561366
      },
      {
        "epoch": 1344,
        "reward": 0.4489903151988983,
        "val_loss": 0.0016886734270623752,
        "train_loss": 0.0019023713729648779
      },
      {
        "epoch": 1345,
        "reward": 0.4556310176849365,
        "val_loss": 0.0016005199369309203,
        "train_loss": 0.0018631546073055898
      },
      {
        "epoch": 1346,
        "reward": 0.45552292466163635,
        "val_loss": 0.0016019157815857657,
        "train_loss": 0.0018629539543046402
      },
      {
        "epoch": 1347,
        "reward": 0.4552834928035736,
        "val_loss": 0.0016050118803312735,
        "train_loss": 0.0019367001335082862
      },
      {
        "epoch": 1348,
        "reward": 0.4510268270969391,
        "val_loss": 0.0016611109105204897,
        "train_loss": 0.0019491013640967698
      },
      {
        "epoch": 1349,
        "reward": 0.4462917447090149,
        "val_loss": 0.0017259382709328616,
        "train_loss": 0.002168395722177453
      },
      {
        "epoch": 1350,
        "reward": 0.4492833614349365,
        "val_loss": 0.0016846768308563956,
        "train_loss": 0.0018847331235659882
      },
      {
        "epoch": 1351,
        "reward": 0.4454041123390198,
        "val_loss": 0.0017383845656045846,
        "train_loss": 0.002163754243296213
      },
      {
        "epoch": 1352,
        "reward": 0.45203137397766113,
        "val_loss": 0.001647689562690045,
        "train_loss": 0.00189468231362228
      },
      {
        "epoch": 1353,
        "reward": 0.4495658874511719,
        "val_loss": 0.0016808352499668086,
        "train_loss": 0.001913655485011007
      },
      {
        "epoch": 1354,
        "reward": 0.4433479309082031,
        "val_loss": 0.001767581095919013,
        "train_loss": 0.0022807104754834794
      },
      {
        "epoch": 1355,
        "reward": 0.4376732409000397,
        "val_loss": 0.001850881813360112,
        "train_loss": 0.002238336583384528
      },
      {
        "epoch": 1356,
        "reward": 0.4557464122772217,
        "val_loss": 0.001599031883025808,
        "train_loss": 0.002013381099389405
      },
      {
        "epoch": 1357,
        "reward": 0.45530906319618225,
        "val_loss": 0.0016046810113558812,
        "train_loss": 0.0023562215904418668
      },
      {
        "epoch": 1358,
        "reward": 0.4551207721233368,
        "val_loss": 0.0016071201534941792,
        "train_loss": 0.002070365982945077
      },
      {
        "epoch": 1359,
        "reward": 0.4561340808868408,
        "val_loss": 0.0015940414991096727,
        "train_loss": 0.0018989257972809636
      },
      {
        "epoch": 1360,
        "reward": 0.4541536867618561,
        "val_loss": 0.001619705680890807,
        "train_loss": 0.0018787652460070183
      },
      {
        "epoch": 1361,
        "reward": 0.45608922839164734,
        "val_loss": 0.0015946186446983898,
        "train_loss": 0.0018977988158719828
      },
      {
        "epoch": 1362,
        "reward": 0.40132513642311096,
        "val_loss": 0.0024951136937098844,
        "train_loss": 0.002279317055721409
      },
      {
        "epoch": 1363,
        "reward": 0.45561090111732483,
        "val_loss": 0.0016007802499059056,
        "train_loss": 0.002161106314116086
      },
      {
        "epoch": 1364,
        "reward": 0.4016875922679901,
        "val_loss": 0.002487598253147943,
        "train_loss": 0.0020414074936595103
      },
      {
        "epoch": 1365,
        "reward": 0.44708648324012756,
        "val_loss": 0.0017148740090695874,
        "train_loss": 0.0021050690903183958
      },
      {
        "epoch": 1366,
        "reward": 0.4500494599342346,
        "val_loss": 0.0016742791049182415,
        "train_loss": 0.0019302094095529844
      },
      {
        "epoch": 1367,
        "reward": 0.4381754398345947,
        "val_loss": 0.0018433438381180167,
        "train_loss": 0.0022751166028543734
      },
      {
        "epoch": 1368,
        "reward": 0.4513011872768402,
        "val_loss": 0.0016574333837654973,
        "train_loss": 0.002226278097869392
      },
      {
        "epoch": 1369,
        "reward": 0.44796428084373474,
        "val_loss": 0.0017027410711827023,
        "train_loss": 0.0019636825935986754
      },
      {
        "epoch": 1370,
        "reward": 0.4360324442386627,
        "val_loss": 0.0018757357029244304,
        "train_loss": 0.0020500210789927784
      },
      {
        "epoch": 1371,
        "reward": 0.4560754895210266,
        "val_loss": 0.0015947948974956358,
        "train_loss": 0.0019040390190919144
      },
      {
        "epoch": 1372,
        "reward": 0.442078560590744,
        "val_loss": 0.001785863731389067,
        "train_loss": 0.002093364041334448
      },
      {
        "epoch": 1373,
        "reward": 0.453630656003952,
        "val_loss": 0.0016265558577807887,
        "train_loss": 0.0019196921963996899
      },
      {
        "epoch": 1374,
        "reward": 0.4483863413333893,
        "val_loss": 0.0016969393639426147,
        "train_loss": 0.0019483241731694972
      },
      {
        "epoch": 1375,
        "reward": 0.44943198561668396,
        "val_loss": 0.0016826543391549162,
        "train_loss": 0.00224670577825656
      },
      {
        "epoch": 1376,
        "reward": 0.44241705536842346,
        "val_loss": 0.0017809685918369464,
        "train_loss": 0.001893030367227766
      },
      {
        "epoch": 1377,
        "reward": 0.44999605417251587,
        "val_loss": 0.0016750015784054995,
        "train_loss": 0.0018565139546178845
      },
      {
        "epoch": 1378,
        "reward": 0.4442528188228607,
        "val_loss": 0.00175466899028314,
        "train_loss": 0.0018576501651505868
      },
      {
        "epoch": 1379,
        "reward": 0.44661298394203186,
        "val_loss": 0.0017214568464883737,
        "train_loss": 0.0018682164472221092
      },
      {
        "epoch": 1380,
        "reward": 0.44292545318603516,
        "val_loss": 0.0017736441721873625,
        "train_loss": 0.001881580363820271
      },
      {
        "epoch": 1381,
        "reward": 0.4528006613254547,
        "val_loss": 0.0016374872398695775,
        "train_loss": 0.0019317648391454266
      },
      {
        "epoch": 1382,
        "reward": 0.44976386427879333,
        "val_loss": 0.0016781472617627255,
        "train_loss": 0.0018992113203484433
      },
      {
        "epoch": 1383,
        "reward": 0.4559743106365204,
        "val_loss": 0.0015960968365626676,
        "train_loss": 0.0018923610981661254
      },
      {
        "epoch": 1384,
        "reward": 0.42324042320251465,
        "val_loss": 0.0020821712013067944,
        "train_loss": 0.00234058652467166
      },
      {
        "epoch": 1385,
        "reward": 0.44437023997306824,
        "val_loss": 0.0017530005092599563,
        "train_loss": 0.0019129858488808027
      },
      {
        "epoch": 1386,
        "reward": 0.4555278420448303,
        "val_loss": 0.0016018519859894045,
        "train_loss": 0.0018713734119116382
      },
      {
        "epoch": 1387,
        "reward": 0.45595094561576843,
        "val_loss": 0.0015963971132545599,
        "train_loss": 0.001908346443647483
      },
      {
        "epoch": 1388,
        "reward": 0.4237762987613678,
        "val_loss": 0.002073051524348557,
        "train_loss": 0.002360388703751736
      },
      {
        "epoch": 1389,
        "reward": 0.43385764956474304,
        "val_loss": 0.001909228357752519,
        "train_loss": 0.0023883486506887353
      },
      {
        "epoch": 1390,
        "reward": 0.4535678029060364,
        "val_loss": 0.0016273805272898503,
        "train_loss": 0.0018833300133477538
      },
      {
        "epoch": 1391,
        "reward": 0.43867096304893494,
        "val_loss": 0.0018359394411423377,
        "train_loss": 0.0019276743618180403
      },
      {
        "epoch": 1392,
        "reward": 0.4180573523044586,
        "val_loss": 0.002172649821399578,
        "train_loss": 0.0020580507474593245
      },
      {
        "epoch": 1393,
        "reward": 0.45568084716796875,
        "val_loss": 0.0015998778482233839,
        "train_loss": 0.0019718418096510083
      },
      {
        "epoch": 1394,
        "reward": 0.44204989075660706,
        "val_loss": 0.0017862788268498012,
        "train_loss": 0.0019666282057117382
      },
      {
        "epoch": 1395,
        "reward": 0.450061559677124,
        "val_loss": 0.0016741150092067464,
        "train_loss": 0.0019559403987771543
      },
      {
        "epoch": 1396,
        "reward": 0.4549596905708313,
        "val_loss": 0.0016092093594904458,
        "train_loss": 0.001868482705993721
      },
      {
        "epoch": 1397,
        "reward": 0.4477919042110443,
        "val_loss": 0.001705116858439786,
        "train_loss": 0.001884559524499379
      },
      {
        "epoch": 1398,
        "reward": 0.4379267692565918,
        "val_loss": 0.0018470716895535588,
        "train_loss": 0.0019212127842295628
      },
      {
        "epoch": 1399,
        "reward": 0.43503937125205994,
        "val_loss": 0.0018909501044877938,
        "train_loss": 0.0023078252113639163
      },
      {
        "epoch": 1400,
        "reward": 0.45579439401626587,
        "val_loss": 0.0015984134848362633,
        "train_loss": 0.002509141412491982
      },
      {
        "epoch": 1401,
        "reward": 0.4497033655643463,
        "val_loss": 0.001678967964835465,
        "train_loss": 0.0018693240182563807
      },
      {
        "epoch": 1402,
        "reward": 0.39500564336776733,
        "val_loss": 0.0026302505617163013,
        "train_loss": 0.0019730419063797365
      },
      {
        "epoch": 1403,
        "reward": 0.45518437027931213,
        "val_loss": 0.0016062956752388605,
        "train_loss": 0.002154388523194939
      },
      {
        "epoch": 1404,
        "reward": 0.4539624750614166,
        "val_loss": 0.0016222063485266907,
        "train_loss": 0.0019524985976973907
      },
      {
        "epoch": 1405,
        "reward": 0.4302736818790436,
        "val_loss": 0.0019658213048907264,
        "train_loss": 0.0018754375156417014
      },
      {
        "epoch": 1406,
        "reward": 0.4351343810558319,
        "val_loss": 0.0018894906721210905,
        "train_loss": 0.0020238192026646664
      },
      {
        "epoch": 1407,
        "reward": 0.44711223244667053,
        "val_loss": 0.001714517645138715,
        "train_loss": 0.002015344623941928
      },
      {
        "epoch": 1408,
        "reward": 0.4513741433620453,
        "val_loss": 0.0016564569336229137,
        "train_loss": 0.001880903259846561
      },
      {
        "epoch": 1409,
        "reward": 0.4554164409637451,
        "val_loss": 0.001603292567389352,
        "train_loss": 0.0018586125731347308
      },
      {
        "epoch": 1410,
        "reward": 0.438100665807724,
        "val_loss": 0.0018444645684212446,
        "train_loss": 0.002507405577209563
      },
      {
        "epoch": 1411,
        "reward": 0.442198246717453,
        "val_loss": 0.0017841312468850187,
        "train_loss": 0.0019786037827053894
      },
      {
        "epoch": 1412,
        "reward": 0.4542042315006256,
        "val_loss": 0.0016190453149777437,
        "train_loss": 0.0018738288083393574
      },
      {
        "epoch": 1413,
        "reward": 0.4555329978466034,
        "val_loss": 0.0016017858288250864,
        "train_loss": 0.0018732900856635892
      },
      {
        "epoch": 1414,
        "reward": 0.455146849155426,
        "val_loss": 0.001606781576161406,
        "train_loss": 0.0018805700103537394
      },
      {
        "epoch": 1415,
        "reward": 0.45582208037376404,
        "val_loss": 0.0015980565471441618,
        "train_loss": 0.0018687613874835034
      },
      {
        "epoch": 1416,
        "reward": 0.4524085223674774,
        "val_loss": 0.0016426798039382057,
        "train_loss": 0.00186439925661174
      },
      {
        "epoch": 1417,
        "reward": 0.4148036539554596,
        "val_loss": 0.002231614464627845,
        "train_loss": 0.0020061664063877496
      },
      {
        "epoch": 1418,
        "reward": 0.4559716284275055,
        "val_loss": 0.001596130705105939,
        "train_loss": 0.002155534629799569
      },
      {
        "epoch": 1419,
        "reward": 0.4202077090740204,
        "val_loss": 0.0021346069905640824,
        "train_loss": 0.002320008795672598
      },
      {
        "epoch": 1420,
        "reward": 0.4523645341396332,
        "val_loss": 0.0016432629449159972,
        "train_loss": 0.002264204590783965
      },
      {
        "epoch": 1421,
        "reward": 0.44525980949401855,
        "val_loss": 0.0017404165867316937,
        "train_loss": 0.0019127772527728947
      },
      {
        "epoch": 1422,
        "reward": 0.404584139585495,
        "val_loss": 0.0024284221664337175,
        "train_loss": 0.002538387596499748
      },
      {
        "epoch": 1423,
        "reward": 0.4526252746582031,
        "val_loss": 0.0016398079959409578,
        "train_loss": 0.0021744406370159527
      },
      {
        "epoch": 1424,
        "reward": 0.4364262521266937,
        "val_loss": 0.0018697384179436735,
        "train_loss": 0.0022763206104103187
      },
      {
        "epoch": 1425,
        "reward": 0.4524289071559906,
        "val_loss": 0.001642408880538174,
        "train_loss": 0.0019516129586218784
      },
      {
        "epoch": 1426,
        "reward": 0.43786191940307617,
        "val_loss": 0.0018480452043669565,
        "train_loss": 0.0021569856997722616
      },
      {
        "epoch": 1427,
        "reward": 0.4538477063179016,
        "val_loss": 0.0016237091622315347,
        "train_loss": 0.0019549357149606715
      },
      {
        "epoch": 1428,
        "reward": 0.434643030166626,
        "val_loss": 0.0018970607613612498,
        "train_loss": 0.002075969850501189
      },
      {
        "epoch": 1429,
        "reward": 0.4487583637237549,
        "val_loss": 0.001691842035922621,
        "train_loss": 0.0020034360081458893
      },
      {
        "epoch": 1430,
        "reward": 0.437615305185318,
        "val_loss": 0.0018517528161672609,
        "train_loss": 0.0019133063122773399
      },
      {
        "epoch": 1431,
        "reward": 0.44942742586135864,
        "val_loss": 0.0016827162554753678,
        "train_loss": 0.002476361071995388
      },
      {
        "epoch": 1432,
        "reward": 0.4544169008731842,
        "val_loss": 0.0016162697824516467,
        "train_loss": 0.0022111527305241907
      },
      {
        "epoch": 1433,
        "reward": 0.4206005036830902,
        "val_loss": 0.002127735975331494,
        "train_loss": 0.0023394256310824016
      },
      {
        "epoch": 1434,
        "reward": 0.4381945729255676,
        "val_loss": 0.0018430579054568494,
        "train_loss": 0.002472567040688143
      },
      {
        "epoch": 1435,
        "reward": 0.4563969075679779,
        "val_loss": 0.0015906676583524262,
        "train_loss": 0.002061678901484881
      },
      {
        "epoch": 1436,
        "reward": 0.45660218596458435,
        "val_loss": 0.0015880377115016536,
        "train_loss": 0.0018762996965401375
      },
      {
        "epoch": 1437,
        "reward": 0.45603320002555847,
        "val_loss": 0.0015953392638558789,
        "train_loss": 0.0019640559588039582
      },
      {
        "epoch": 1438,
        "reward": 0.4150862395763397,
        "val_loss": 0.0022264248691499233,
        "train_loss": 0.00212997937342152
      },
      {
        "epoch": 1439,
        "reward": 0.4543766975402832,
        "val_loss": 0.0016167940588534943,
        "train_loss": 0.0019250691273975042
      },
      {
        "epoch": 1440,
        "reward": 0.45555979013442993,
        "val_loss": 0.0016014404079344655,
        "train_loss": 0.0018788701496445215
      },
      {
        "epoch": 1441,
        "reward": 0.4514218270778656,
        "val_loss": 0.001655819360166788,
        "train_loss": 0.001938335167673918
      },
      {
        "epoch": 1442,
        "reward": 0.43907448649406433,
        "val_loss": 0.0018299323939053075,
        "train_loss": 0.0024467746440607766
      },
      {
        "epoch": 1443,
        "reward": 0.4528060555458069,
        "val_loss": 0.0016374166755537903,
        "train_loss": 0.001971496470594922
      },
      {
        "epoch": 1444,
        "reward": 0.45563364028930664,
        "val_loss": 0.0016004865091027959,
        "train_loss": 0.0018802504835968227
      },
      {
        "epoch": 1445,
        "reward": 0.4551808536052704,
        "val_loss": 0.0016063418754908656,
        "train_loss": 0.001858898352461088
      },
      {
        "epoch": 1446,
        "reward": 0.4560433328151703,
        "val_loss": 0.0015952084878725664,
        "train_loss": 0.0019300264404871715
      },
      {
        "epoch": 1447,
        "reward": 0.4541642367839813,
        "val_loss": 0.0016195685270109347,
        "train_loss": 0.00205902104677919
      },
      {
        "epoch": 1448,
        "reward": 0.44530248641967773,
        "val_loss": 0.0017398158171480255,
        "train_loss": 0.001905448018358304
      },
      {
        "epoch": 1449,
        "reward": 0.4536351263523102,
        "val_loss": 0.0016264969266818038,
        "train_loss": 0.001919506941563808
      },
      {
        "epoch": 1450,
        "reward": 0.4561014771461487,
        "val_loss": 0.0015944606108990098,
        "train_loss": 0.0018662556546517478
      },
      {
        "epoch": 1451,
        "reward": 0.4540286660194397,
        "val_loss": 0.001621340201901538,
        "train_loss": 0.00189167291794617
      },
      {
        "epoch": 1452,
        "reward": 0.452028751373291,
        "val_loss": 0.0016477243209789907,
        "train_loss": 0.0018469442167175797
      },
      {
        "epoch": 1453,
        "reward": 0.4535948932170868,
        "val_loss": 0.0016270249200585698,
        "train_loss": 0.00191193104435045
      },
      {
        "epoch": 1454,
        "reward": 0.436631977558136,
        "val_loss": 0.001866613348413791,
        "train_loss": 0.0023149479708920876
      },
      {
        "epoch": 1455,
        "reward": 0.44640597701072693,
        "val_loss": 0.0017243430567240076,
        "train_loss": 0.0027140823994369176
      },
      {
        "epoch": 1456,
        "reward": 0.39346548914909363,
        "val_loss": 0.002664396439545921,
        "train_loss": 0.0023640912348547806
      },
      {
        "epoch": 1457,
        "reward": 0.44576141238212585,
        "val_loss": 0.001733363140374422,
        "train_loss": 0.002093571036731681
      },
      {
        "epoch": 1458,
        "reward": 0.40070730447769165,
        "val_loss": 0.002507982276646154,
        "train_loss": 0.002321832719294784
      },
      {
        "epoch": 1459,
        "reward": 0.4510824382305145,
        "val_loss": 0.001660364613469158,
        "train_loss": 0.002559893715302818
      },
      {
        "epoch": 1460,
        "reward": 0.45516976714134216,
        "val_loss": 0.0016064849332906306,
        "train_loss": 0.0020413591275708033
      },
      {
        "epoch": 1461,
        "reward": 0.45432743430137634,
        "val_loss": 0.0016174364968069962,
        "train_loss": 0.0018962847937543232
      },
      {
        "epoch": 1462,
        "reward": 0.40759068727493286,
        "val_loss": 0.0023686254363773124,
        "train_loss": 0.0020615132587129036
      },
      {
        "epoch": 1463,
        "reward": 0.42777809500694275,
        "val_loss": 0.002006285857143147,
        "train_loss": 0.0021722510886880066
      },
      {
        "epoch": 1464,
        "reward": 0.45292678475379944,
        "val_loss": 0.0016358215611294977,
        "train_loss": 0.001950237617935412
      },
      {
        "epoch": 1465,
        "reward": 0.4340992569923401,
        "val_loss": 0.0019054755102843046,
        "train_loss": 0.0020522897561582234
      },
      {
        "epoch": 1466,
        "reward": 0.4463105797767639,
        "val_loss": 0.001725675255459334,
        "train_loss": 0.0020186018619614723
      },
      {
        "epoch": 1467,
        "reward": 0.43954750895500183,
        "val_loss": 0.001822917688904064,
        "train_loss": 0.0019171853222920059
      },
      {
        "epoch": 1468,
        "reward": 0.4543059766292572,
        "val_loss": 0.0016177168831096164,
        "train_loss": 0.0019023122541301956
      },
      {
        "epoch": 1469,
        "reward": 0.45534011721611023,
        "val_loss": 0.0016042797526876842,
        "train_loss": 0.001863241488116238
      },
      {
        "epoch": 1470,
        "reward": 0.4538976848125458,
        "val_loss": 0.0016230548083383059,
        "train_loss": 0.0019194576816516928
      },
      {
        "epoch": 1471,
        "reward": 0.4480660855770111,
        "val_loss": 0.0017013395970155085,
        "train_loss": 0.0018573679329235277
      },
      {
        "epoch": 1472,
        "reward": 0.4557774066925049,
        "val_loss": 0.0015986323872181987,
        "train_loss": 0.001906640906012259
      },
      {
        "epoch": 1473,
        "reward": 0.4537619650363922,
        "val_loss": 0.0016248325700871646,
        "train_loss": 0.001872599206623048
      },
      {
        "epoch": 1474,
        "reward": 0.4534253776073456,
        "val_loss": 0.0016292522278880434,
        "train_loss": 0.0018647768152522286
      },
      {
        "epoch": 1475,
        "reward": 0.44703933596611023,
        "val_loss": 0.0017155291945008294,
        "train_loss": 0.0018776628992502363
      },
      {
        "epoch": 1476,
        "reward": 0.4514199197292328,
        "val_loss": 0.0016558447553377067,
        "train_loss": 0.0019388512463102904
      },
      {
        "epoch": 1477,
        "reward": 0.43385234475135803,
        "val_loss": 0.0019093101478314825,
        "train_loss": 0.002021570280283833
      },
      {
        "epoch": 1478,
        "reward": 0.45580002665519714,
        "val_loss": 0.0015983405755832791,
        "train_loss": 0.0019737164369032075
      },
      {
        "epoch": 1479,
        "reward": 0.45536699891090393,
        "val_loss": 0.0016039314879370587,
        "train_loss": 0.001964265815051756
      },
      {
        "epoch": 1480,
        "reward": 0.4390685558319092,
        "val_loss": 0.0018300202043194855,
        "train_loss": 0.001933887558362375
      },
      {
        "epoch": 1481,
        "reward": 0.42228132486343384,
        "val_loss": 0.0020986019600448863,
        "train_loss": 0.0019477422992377586
      },
      {
        "epoch": 1482,
        "reward": 0.45635104179382324,
        "val_loss": 0.0015912559132889978,
        "train_loss": 0.002024669391035926
      },
      {
        "epoch": 1483,
        "reward": 0.4125854969024658,
        "val_loss": 0.00227280637981104,
        "train_loss": 0.002203670285570507
      },
      {
        "epoch": 1484,
        "reward": 0.42591673135757446,
        "val_loss": 0.002037048223428428,
        "train_loss": 0.002389459214800109
      },
      {
        "epoch": 1485,
        "reward": 0.4396696984767914,
        "val_loss": 0.0018211095094946878,
        "train_loss": 0.002158057875931263
      },
      {
        "epoch": 1486,
        "reward": 0.44894471764564514,
        "val_loss": 0.001689295716849821,
        "train_loss": 0.0019004348289924494
      },
      {
        "epoch": 1487,
        "reward": 0.43843331933021545,
        "val_loss": 0.0018394867656752467,
        "train_loss": 0.001881251335502244
      },
      {
        "epoch": 1488,
        "reward": 0.452566921710968,
        "val_loss": 0.0016405806693780636,
        "train_loss": 0.0019279085614611036
      },
      {
        "epoch": 1489,
        "reward": 0.4544220566749573,
        "val_loss": 0.0016162025276571512,
        "train_loss": 0.0019038110378740104
      },
      {
        "epoch": 1490,
        "reward": 0.4553479254245758,
        "val_loss": 0.0016041786044037768,
        "train_loss": 0.0018845371949002864
      },
      {
        "epoch": 1491,
        "reward": 0.4528738558292389,
        "val_loss": 0.0016365207266062498,
        "train_loss": 0.0020123142122219387
      },
      {
        "epoch": 1492,
        "reward": 0.4547305703163147,
        "val_loss": 0.0016121857749697352,
        "train_loss": 0.0018834211077074332
      },
      {
        "epoch": 1493,
        "reward": 0.45508629083633423,
        "val_loss": 0.0016075667392994677,
        "train_loss": 0.0018570414865210366
      },
      {
        "epoch": 1494,
        "reward": 0.45540520548820496,
        "val_loss": 0.0016034375793034478,
        "train_loss": 0.0018906256585838632
      },
      {
        "epoch": 1495,
        "reward": 0.431263267993927,
        "val_loss": 0.0019500184903985687,
        "train_loss": 0.0019048209427497708
      },
      {
        "epoch": 1496,
        "reward": 0.4545029103755951,
        "val_loss": 0.0016151488525792956,
        "train_loss": 0.002064977745668819
      },
      {
        "epoch": 1497,
        "reward": 0.45484670996665955,
        "val_loss": 0.0016106760761301433,
        "train_loss": 0.0019838867861276064
      },
      {
        "epoch": 1498,
        "reward": 0.4428512752056122,
        "val_loss": 0.001774711035458105,
        "train_loss": 0.0019244699293407253
      },
      {
        "epoch": 1499,
        "reward": 0.45331570506095886,
        "val_loss": 0.0016306953205327903,
        "train_loss": 0.0018856906703709124
      },
      {
        "epoch": 1500,
        "reward": 0.4518471658229828,
        "val_loss": 0.0016501415354598845,
        "train_loss": 0.001857090145886804
      },
      {
        "epoch": 1501,
        "reward": 0.44640421867370605,
        "val_loss": 0.0017243684020026454,
        "train_loss": 0.0023497675518648555
      },
      {
        "epoch": 1502,
        "reward": 0.41527459025382996,
        "val_loss": 0.0022229732546423164,
        "train_loss": 0.002439361464124746
      },
      {
        "epoch": 1503,
        "reward": 0.45504650473594666,
        "val_loss": 0.0016080828915749276,
        "train_loss": 0.0021794069483663547
      },
      {
        "epoch": 1504,
        "reward": 0.4540059268474579,
        "val_loss": 0.0016216380006101514,
        "train_loss": 0.0019140817961530187
      },
      {
        "epoch": 1505,
        "reward": 0.45520639419555664,
        "val_loss": 0.0016060101500313198,
        "train_loss": 0.0018593432347328276
      },
      {
        "epoch": 1506,
        "reward": 0.4492242932319641,
        "val_loss": 0.0016854819259606302,
        "train_loss": 0.002069029782433063
      },
      {
        "epoch": 1507,
        "reward": 0.4542500078678131,
        "val_loss": 0.001618447688607765,
        "train_loss": 0.001924782335733583
      },
      {
        "epoch": 1508,
        "reward": 0.45560622215270996,
        "val_loss": 0.0016008406029348926,
        "train_loss": 0.001875770469128978
      },
      {
        "epoch": 1509,
        "reward": 0.4553475081920624,
        "val_loss": 0.0016041842671776457,
        "train_loss": 0.0018907898920588195
      },
      {
        "epoch": 1510,
        "reward": 0.4560520350933075,
        "val_loss": 0.001595096695902092,
        "train_loss": 0.0019415946265396017
      },
      {
        "epoch": 1511,
        "reward": 0.443890243768692,
        "val_loss": 0.001759830371676279,
        "train_loss": 0.002006290395421764
      },
      {
        "epoch": 1512,
        "reward": 0.43954023718833923,
        "val_loss": 0.0018230245914310217,
        "train_loss": 0.0019076605939727204
      },
      {
        "epoch": 1513,
        "reward": 0.451666921377182,
        "val_loss": 0.001652545337232628,
        "train_loss": 0.0018899154697115032
      },
      {
        "epoch": 1514,
        "reward": 0.44544854760169983,
        "val_loss": 0.0017377597146800586,
        "train_loss": 0.0018522296640276236
      },
      {
        "epoch": 1515,
        "reward": 0.4536265432834625,
        "val_loss": 0.001626609225890466,
        "train_loss": 0.001874428253638773
      },
      {
        "epoch": 1516,
        "reward": 0.4326132833957672,
        "val_loss": 0.0019286781649238297,
        "train_loss": 0.0019457955674554866
      },
      {
        "epoch": 1517,
        "reward": 0.45386964082717896,
        "val_loss": 0.0016234219323710672,
        "train_loss": 0.001921492163091898
      },
      {
        "epoch": 1518,
        "reward": 0.4506302773952484,
        "val_loss": 0.0016664400214462408,
        "train_loss": 0.0024324190789439645
      },
      {
        "epoch": 1519,
        "reward": 0.4547414779663086,
        "val_loss": 0.0016120437649078667,
        "train_loss": 0.0019640562576779094
      },
      {
        "epoch": 1520,
        "reward": 0.44753319025039673,
        "val_loss": 0.0017086886800825596,
        "train_loss": 0.0018786929957479094
      },
      {
        "epoch": 1521,
        "reward": 0.4545188546180725,
        "val_loss": 0.001614941076175975,
        "train_loss": 0.001987544004805386
      },
      {
        "epoch": 1522,
        "reward": 0.40654411911964417,
        "val_loss": 0.0023892552126199007,
        "train_loss": 0.0023880997681632065
      },
      {
        "epoch": 1523,
        "reward": 0.43630272150039673,
        "val_loss": 0.0018716170286227549,
        "train_loss": 0.0022064224857345494
      },
      {
        "epoch": 1524,
        "reward": 0.45310384035110474,
        "val_loss": 0.001633485795796982,
        "train_loss": 0.001973962353076786
      },
      {
        "epoch": 1525,
        "reward": 0.43373188376426697,
        "val_loss": 0.0019111844012513757,
        "train_loss": 0.0022854739620995065
      },
      {
        "epoch": 1526,
        "reward": 0.45492443442344666,
        "val_loss": 0.0016096666222438216,
        "train_loss": 0.00213920852715651
      },
      {
        "epoch": 1527,
        "reward": 0.45005807280540466,
        "val_loss": 0.0016741623736119696,
        "train_loss": 0.0018587597654774212
      },
      {
        "epoch": 1528,
        "reward": 0.45455947518348694,
        "val_loss": 0.001614412251261196,
        "train_loss": 0.0018789818870852916
      },
      {
        "epoch": 1529,
        "reward": 0.4525277316570282,
        "val_loss": 0.0016410997569827096,
        "train_loss": 0.0019351157959065929
      },
      {
        "epoch": 1530,
        "reward": 0.4553552567958832,
        "val_loss": 0.0016040836510780667,
        "train_loss": 0.0018454890026847492
      },
      {
        "epoch": 1531,
        "reward": 0.4530760943889618,
        "val_loss": 0.0016338516143150628,
        "train_loss": 0.0019093696363807584
      },
      {
        "epoch": 1532,
        "reward": 0.45583200454711914,
        "val_loss": 0.0015979284403978714,
        "train_loss": 0.0019034264349521925
      },
      {
        "epoch": 1533,
        "reward": 0.4456096291542053,
        "val_loss": 0.001735494571870991,
        "train_loss": 0.00186850266786328
      },
      {
        "epoch": 1534,
        "reward": 0.45458269119262695,
        "val_loss": 0.0016141092304938606,
        "train_loss": 0.00187120185560511
      },
      {
        "epoch": 1535,
        "reward": 0.45125094056129456,
        "val_loss": 0.0016581066800946636,
        "train_loss": 0.0018901300164333617
      },
      {
        "epoch": 1536,
        "reward": 0.43944334983825684,
        "val_loss": 0.0018244593936417783,
        "train_loss": 0.0020679859534049262
      },
      {
        "epoch": 1537,
        "reward": 0.45387670397758484,
        "val_loss": 0.00162332971480542,
        "train_loss": 0.0019205465449396377
      },
      {
        "epoch": 1538,
        "reward": 0.4539449214935303,
        "val_loss": 0.001622435578610748,
        "train_loss": 0.0019476566141327987
      },
      {
        "epoch": 1539,
        "reward": 0.45449739694595337,
        "val_loss": 0.001615220564417541,
        "train_loss": 0.0018540254323992345
      },
      {
        "epoch": 1540,
        "reward": 0.45129290223121643,
        "val_loss": 0.0016575443525133388,
        "train_loss": 0.0018963531608908223
      },
      {
        "epoch": 1541,
        "reward": 0.40589234232902527,
        "val_loss": 0.0024022026087290476,
        "train_loss": 0.002055259293858678
      },
      {
        "epoch": 1542,
        "reward": 0.41666609048843384,
        "val_loss": 0.002197653770313731,
        "train_loss": 0.002099487585767817
      },
      {
        "epoch": 1543,
        "reward": 0.4497220516204834,
        "val_loss": 0.0016787144621568067,
        "train_loss": 0.0020060382846098105
      },
      {
        "epoch": 1544,
        "reward": 0.4301007390022278,
        "val_loss": 0.0019685971617166486,
        "train_loss": 0.0022632248314599004
      },
      {
        "epoch": 1545,
        "reward": 0.4545014798641205,
        "val_loss": 0.0016151673127231853,
        "train_loss": 0.002081799438411298
      },
      {
        "epoch": 1546,
        "reward": 0.4120713174343109,
        "val_loss": 0.002282472427136132,
        "train_loss": 0.002169973825892577
      },
      {
        "epoch": 1547,
        "reward": 0.44998106360435486,
        "val_loss": 0.001675204822926649,
        "train_loss": 0.0024870394711167766
      },
      {
        "epoch": 1548,
        "reward": 0.440171480178833,
        "val_loss": 0.0018137069585333978,
        "train_loss": 0.0019460770664199328
      },
      {
        "epoch": 1549,
        "reward": 0.45376187562942505,
        "val_loss": 0.0016248344244169338,
        "train_loss": 0.0019347131064233298
      },
      {
        "epoch": 1550,
        "reward": 0.4543019235134125,
        "val_loss": 0.0016177694529428013,
        "train_loss": 0.002126750925806566
      },
      {
        "epoch": 1551,
        "reward": 0.4545113146305084,
        "val_loss": 0.0016150396217459015,
        "train_loss": 0.0020174235530878203
      },
      {
        "epoch": 1552,
        "reward": 0.4289768636226654,
        "val_loss": 0.001986738244470741,
        "train_loss": 0.001954270302891158
      },
      {
        "epoch": 1553,
        "reward": 0.44974151253700256,
        "val_loss": 0.0016784508479759097,
        "train_loss": 0.0020895698555530263
      },
      {
        "epoch": 1554,
        "reward": 0.45327019691467285,
        "val_loss": 0.0016312940861098468,
        "train_loss": 0.0019653924816968637
      },
      {
        "epoch": 1555,
        "reward": 0.4474361836910248,
        "val_loss": 0.0017100296515439237,
        "train_loss": 0.0019383871286453751
      },
      {
        "epoch": 1556,
        "reward": 0.4554193615913391,
        "val_loss": 0.001603254524525255,
        "train_loss": 0.001927970523516146
      },
      {
        "epoch": 1557,
        "reward": 0.4493752419948578,
        "val_loss": 0.001683426754815238,
        "train_loss": 0.002387666047210447
      },
      {
        "epoch": 1558,
        "reward": 0.45208483934402466,
        "val_loss": 0.0016469784064351448,
        "train_loss": 0.0019134079652408569
      },
      {
        "epoch": 1559,
        "reward": 0.45384684205055237,
        "val_loss": 0.0016237208869175187,
        "train_loss": 0.0019598060439770613
      },
      {
        "epoch": 1560,
        "reward": 0.4541318416595459,
        "val_loss": 0.0016199910397907452,
        "train_loss": 0.0020093978964723647
      },
      {
        "epoch": 1561,
        "reward": 0.451102077960968,
        "val_loss": 0.0016601009909728809,
        "train_loss": 0.0019477692337834295
      },
      {
        "epoch": 1562,
        "reward": 0.4465663433074951,
        "val_loss": 0.0017221070426915372,
        "train_loss": 0.0018984595327100789
      },
      {
        "epoch": 1563,
        "reward": 0.45352640748023987,
        "val_loss": 0.0016279245277733675,
        "train_loss": 0.001944854126822275
      },
      {
        "epoch": 1564,
        "reward": 0.45636874437332153,
        "val_loss": 0.0015910291695035994,
        "train_loss": 0.001879083628479678
      },
      {
        "epoch": 1565,
        "reward": 0.450160950422287,
        "val_loss": 0.0016727715847082436,
        "train_loss": 0.0018605443205720244
      },
      {
        "epoch": 1566,
        "reward": 0.45078855752944946,
        "val_loss": 0.0016643110429868102,
        "train_loss": 0.001867724288156471
      },
      {
        "epoch": 1567,
        "reward": 0.4412784278392792,
        "val_loss": 0.0017974900381107415,
        "train_loss": 0.0020469267373510566
      },
      {
        "epoch": 1568,
        "reward": 0.45425722002983093,
        "val_loss": 0.0016183534587201262,
        "train_loss": 0.0018913464115869899
      },
      {
        "epoch": 1569,
        "reward": 0.448141485452652,
        "val_loss": 0.0017003029102592596,
        "train_loss": 0.001905639828272307
      },
      {
        "epoch": 1570,
        "reward": 0.45412617921829224,
        "val_loss": 0.0016200655954889953,
        "train_loss": 0.0019154928497930367
      },
      {
        "epoch": 1571,
        "reward": 0.44713807106018066,
        "val_loss": 0.0017141589362706458,
        "train_loss": 0.001956582687293681
      },
      {
        "epoch": 1572,
        "reward": 0.4548969864845276,
        "val_loss": 0.0016100235682513034,
        "train_loss": 0.0018747138128674123
      },
      {
        "epoch": 1573,
        "reward": 0.4173808693885803,
        "val_loss": 0.002184768722924803,
        "train_loss": 0.001981767221318128
      },
      {
        "epoch": 1574,
        "reward": 0.45364075899124146,
        "val_loss": 0.0016264229197986424,
        "train_loss": 0.0020103675521498257
      },
      {
        "epoch": 1575,
        "reward": 0.45307666063308716,
        "val_loss": 0.0016338442552036472,
        "train_loss": 0.001968710397285087
      },
      {
        "epoch": 1576,
        "reward": 0.4444925785064697,
        "val_loss": 0.0017512643576732703,
        "train_loss": 0.001936567143485053
      },
      {
        "epoch": 1577,
        "reward": 0.4357403814792633,
        "val_loss": 0.001880197403287249,
        "train_loss": 0.0018698220441225343
      },
      {
        "epoch": 1578,
        "reward": 0.4507308900356293,
        "val_loss": 0.0016650856539074863,
        "train_loss": 0.001979285130241456
      },
      {
        "epoch": 1579,
        "reward": 0.42258238792419434,
        "val_loss": 0.0020934296938191566,
        "train_loss": 0.0022728659006623696
      },
      {
        "epoch": 1580,
        "reward": 0.3954578936100006,
        "val_loss": 0.0026203159276129945,
        "train_loss": 0.0021661491392968367
      },
      {
        "epoch": 1581,
        "reward": 0.4522477090358734,
        "val_loss": 0.0016448139046717966,
        "train_loss": 0.0022832805989310145
      },
      {
        "epoch": 1582,
        "reward": 0.4438495635986328,
        "val_loss": 0.0017604109598323703,
        "train_loss": 0.0019148950545618741
      },
      {
        "epoch": 1583,
        "reward": 0.45144444704055786,
        "val_loss": 0.0016555169547375823,
        "train_loss": 0.0019762033379475516
      },
      {
        "epoch": 1584,
        "reward": 0.45393672585487366,
        "val_loss": 0.0016225433791987598,
        "train_loss": 0.001897223228857351
      },
      {
        "epoch": 1585,
        "reward": 0.4545222222805023,
        "val_loss": 0.0016148971044458449,
        "train_loss": 0.0018851516058650585
      },
      {
        "epoch": 1586,
        "reward": 0.4561648368835449,
        "val_loss": 0.0015936461110998476,
        "train_loss": 0.001870193564312873
      },
      {
        "epoch": 1587,
        "reward": 0.4454779624938965,
        "val_loss": 0.0017373453093958752,
        "train_loss": 0.002062449357114159
      },
      {
        "epoch": 1588,
        "reward": 0.4509633481502533,
        "val_loss": 0.001661962945945561,
        "train_loss": 0.001994950379005681
      },
      {
        "epoch": 1589,
        "reward": 0.4472886025905609,
        "val_loss": 0.0017120728485419282,
        "train_loss": 0.0018538179247116204
      },
      {
        "epoch": 1590,
        "reward": 0.4475092589855194,
        "val_loss": 0.0017090194575887705,
        "train_loss": 0.0018523905988471457
      },
      {
        "epoch": 1591,
        "reward": 0.45239949226379395,
        "val_loss": 0.0016427994040506227,
        "train_loss": 0.0018961171646459172
      },
      {
        "epoch": 1592,
        "reward": 0.454007625579834,
        "val_loss": 0.0016216155075068986,
        "train_loss": 0.001994779664808168
      },
      {
        "epoch": 1593,
        "reward": 0.4530065059661865,
        "val_loss": 0.0016347693162970245,
        "train_loss": 0.001985321694519371
      },
      {
        "epoch": 1594,
        "reward": 0.45536503195762634,
        "val_loss": 0.001603957115938621,
        "train_loss": 0.0018846659189036402
      },
      {
        "epoch": 1595,
        "reward": 0.4515987038612366,
        "val_loss": 0.0016534557798877358,
        "train_loss": 0.0019528676012459283
      },
      {
        "epoch": 1596,
        "reward": 0.43887344002723694,
        "val_loss": 0.0018329228873231582,
        "train_loss": 0.002037225739443854
      },
      {
        "epoch": 1597,
        "reward": 0.45538997650146484,
        "val_loss": 0.0016036339636359895,
        "train_loss": 0.0018964840341001176
      },
      {
        "epoch": 1598,
        "reward": 0.4525815546512604,
        "val_loss": 0.001640386405467455,
        "train_loss": 0.0018893933744178726
      },
      {
        "epoch": 1599,
        "reward": 0.4480251967906952,
        "val_loss": 0.0017019030388577708,
        "train_loss": 0.0018530908326003835
      },
      {
        "epoch": 1600,
        "reward": 0.45592108368873596,
        "val_loss": 0.0015967814584395715,
        "train_loss": 0.0018566945850929746
      },
      {
        "epoch": 1601,
        "reward": 0.454255074262619,
        "val_loss": 0.0016183815064973065,
        "train_loss": 0.001911174360359907
      },
      {
        "epoch": 1602,
        "reward": 0.4034554958343506,
        "val_loss": 0.002451295099620308,
        "train_loss": 0.0019940782882398567
      },
      {
        "epoch": 1603,
        "reward": 0.45455804467201233,
        "val_loss": 0.0016144307030897056,
        "train_loss": 0.0020692596095754057
      },
      {
        "epoch": 1604,
        "reward": 0.4542170464992523,
        "val_loss": 0.0016188776602835528,
        "train_loss": 0.0018861884374858234
      },
      {
        "epoch": 1605,
        "reward": 0.4528161585330963,
        "val_loss": 0.0016372834964256202,
        "train_loss": 0.0018426802198519
      },
      {
        "epoch": 1606,
        "reward": 0.45521464943885803,
        "val_loss": 0.0016059035801195673,
        "train_loss": 0.0019251855578309356
      },
      {
        "epoch": 1607,
        "reward": 0.4420604705810547,
        "val_loss": 0.0017861257490169788,
        "train_loss": 0.0018894901609375946
      },
      {
        "epoch": 1608,
        "reward": 0.45292744040489197,
        "val_loss": 0.0016358128632418811,
        "train_loss": 0.0019303890070519769
      },
      {
        "epoch": 1609,
        "reward": 0.45447254180908203,
        "val_loss": 0.0016155444318428636,
        "train_loss": 0.002321931412622619
      },
      {
        "epoch": 1610,
        "reward": 0.4430278241634369,
        "val_loss": 0.0017721725328426277,
        "train_loss": 0.0019409260522269716
      },
      {
        "epoch": 1611,
        "reward": 0.4564337432384491,
        "val_loss": 0.001590195918522243,
        "train_loss": 0.0018956050737940061
      },
      {
        "epoch": 1612,
        "reward": 0.45539870858192444,
        "val_loss": 0.0016035213151813618,
        "train_loss": 0.0018699013817240484
      },
      {
        "epoch": 1613,
        "reward": 0.4529755115509033,
        "val_loss": 0.0016351781502765203,
        "train_loss": 0.0018891481580479963
      },
      {
        "epoch": 1614,
        "reward": 0.44419151544570923,
        "val_loss": 0.0017555402758132135,
        "train_loss": 0.0019317265496983265
      },
      {
        "epoch": 1615,
        "reward": 0.43313559889793396,
        "val_loss": 0.0019204878314797366,
        "train_loss": 0.002056145928830889
      },
      {
        "epoch": 1616,
        "reward": 0.45604777336120605,
        "val_loss": 0.0015951512198496079,
        "train_loss": 0.0019522327571534193
      },
      {
        "epoch": 1617,
        "reward": 0.45061835646629333,
        "val_loss": 0.0016666000592522323,
        "train_loss": 0.002148479744881535
      },
      {
        "epoch": 1618,
        "reward": 0.4553181231021881,
        "val_loss": 0.0016045639973266848,
        "train_loss": 0.0020390046047396027
      },
      {
        "epoch": 1619,
        "reward": 0.45615965127944946,
        "val_loss": 0.0015937131746406002,
        "train_loss": 0.0018538698314981817
      },
      {
        "epoch": 1620,
        "reward": 0.41834792494773865,
        "val_loss": 0.0021674662961491515,
        "train_loss": 0.0018689292085652526
      },
      {
        "epoch": 1621,
        "reward": 0.4511077404022217,
        "val_loss": 0.0016600250133446284,
        "train_loss": 0.001888651203234286
      },
      {
        "epoch": 1622,
        "reward": 0.4390124976634979,
        "val_loss": 0.0018308534719316022,
        "train_loss": 0.002194729373933604
      },
      {
        "epoch": 1623,
        "reward": 0.4548799693584442,
        "val_loss": 0.0016102443998014288,
        "train_loss": 0.0018814257749069768
      },
      {
        "epoch": 1624,
        "reward": 0.45134028792381287,
        "val_loss": 0.0016569099305862828,
        "train_loss": 0.0018873269800503923
      },
      {
        "epoch": 1625,
        "reward": 0.455670028924942,
        "val_loss": 0.001600017213994371,
        "train_loss": 0.0018567957672880415
      },
      {
        "epoch": 1626,
        "reward": 0.45514819025993347,
        "val_loss": 0.0016067651283395077,
        "train_loss": 0.001864100817608862
      },
      {
        "epoch": 1627,
        "reward": 0.455170214176178,
        "val_loss": 0.0016064790792630187,
        "train_loss": 0.0018656510868682885
      },
      {
        "epoch": 1628,
        "reward": 0.45474910736083984,
        "val_loss": 0.0016119446705228516,
        "train_loss": 0.0019043100753781171
      },
      {
        "epoch": 1629,
        "reward": 0.4498293101787567,
        "val_loss": 0.0016772601853257843,
        "train_loss": 0.0019773151009128643
      },
      {
        "epoch": 1630,
        "reward": 0.37954118847846985,
        "val_loss": 0.002996464359707066,
        "train_loss": 0.002030600417548647
      },
      {
        "epoch": 1631,
        "reward": 0.4551311433315277,
        "val_loss": 0.0016069852031900414,
        "train_loss": 0.002144202695490094
      },
      {
        "epoch": 1632,
        "reward": 0.4515100121498108,
        "val_loss": 0.0016546407215563314,
        "train_loss": 0.0019004466622181309
      },
      {
        "epoch": 1633,
        "reward": 0.44391995668411255,
        "val_loss": 0.0017594068943123733,
        "train_loss": 0.0019143038662150502
      },
      {
        "epoch": 1634,
        "reward": 0.45529705286026,
        "val_loss": 0.001604836608748883,
        "train_loss": 0.0018856184749613302
      },
      {
        "epoch": 1635,
        "reward": 0.44928011298179626,
        "val_loss": 0.0016847213514016143,
        "train_loss": 0.0018971053054533864
      },
      {
        "epoch": 1636,
        "reward": 0.41566333174705505,
        "val_loss": 0.0022158677789515684,
        "train_loss": 0.002257788768754556
      },
      {
        "epoch": 1637,
        "reward": 0.44373035430908203,
        "val_loss": 0.001762112369760871,
        "train_loss": 0.002041731016596224
      },
      {
        "epoch": 1638,
        "reward": 0.43698644638061523,
        "val_loss": 0.0018612418290493743,
        "train_loss": 0.0020047254197729323
      },
      {
        "epoch": 1639,
        "reward": 0.4467092454433441,
        "val_loss": 0.001720116606780461,
        "train_loss": 0.0018832512701360078
      },
      {
        "epoch": 1640,
        "reward": 0.4478609561920166,
        "val_loss": 0.0017041649303532072,
        "train_loss": 0.0019041704363189638
      },
      {
        "epoch": 1641,
        "reward": 0.4421277940273285,
        "val_loss": 0.0017851502634584904,
        "train_loss": 0.0018973761997096096
      },
      {
        "epoch": 1642,
        "reward": 0.4514341354370117,
        "val_loss": 0.00165565444123266,
        "train_loss": 0.0019519477030441451
      },
      {
        "epoch": 1643,
        "reward": 0.4413875639438629,
        "val_loss": 0.0017958996218762227,
        "train_loss": 0.0018524389758497889
      },
      {
        "epoch": 1644,
        "reward": 0.44102367758750916,
        "val_loss": 0.0018012085763205374,
        "train_loss": 0.002347227172532047
      },
      {
        "epoch": 1645,
        "reward": 0.4565899074077606,
        "val_loss": 0.0015881949387091612,
        "train_loss": 0.002260564359648225
      },
      {
        "epoch": 1646,
        "reward": 0.4538450837135315,
        "val_loss": 0.0016237434798053332,
        "train_loss": 0.0018962912879662607
      },
      {
        "epoch": 1647,
        "reward": 0.43538233637809753,
        "val_loss": 0.0018856814297448312,
        "train_loss": 0.0021185999592909445
      },
      {
        "epoch": 1648,
        "reward": 0.45132341980934143,
        "val_loss": 0.0016571361089258321,
        "train_loss": 0.0022083407384343445
      },
      {
        "epoch": 1649,
        "reward": 0.42757993936538696,
        "val_loss": 0.0020095380854659845,
        "train_loss": 0.001853583907807031
      },
      {
        "epoch": 1650,
        "reward": 0.45250606536865234,
        "val_loss": 0.0016413869452662766,
        "train_loss": 0.001963358559665861
      },
      {
        "epoch": 1651,
        "reward": 0.44881224632263184,
        "val_loss": 0.0016911056757505452,
        "train_loss": 0.0018528402148289247
      },
      {
        "epoch": 1652,
        "reward": 0.39196327328681946,
        "val_loss": 0.002698173430482192,
        "train_loss": 0.0021651134145661043
      },
      {
        "epoch": 1653,
        "reward": 0.4555811583995819,
        "val_loss": 0.0016011640961681093,
        "train_loss": 0.0022286105729738036
      },
      {
        "epoch": 1654,
        "reward": 0.4208998382091522,
        "val_loss": 0.002122516028716096,
        "train_loss": 0.002106304804328829
      },
      {
        "epoch": 1655,
        "reward": 0.4476580321788788,
        "val_loss": 0.0017069643612817994,
        "train_loss": 0.0023978843461149014
      },
      {
        "epoch": 1656,
        "reward": 0.44548001885414124,
        "val_loss": 0.0017373166545959456,
        "train_loss": 0.0018705464485370053
      },
      {
        "epoch": 1657,
        "reward": 0.45110008120536804,
        "val_loss": 0.0016601278662814625,
        "train_loss": 0.0019276388137278934
      },
      {
        "epoch": 1658,
        "reward": 0.4442562162876129,
        "val_loss": 0.0017546209440167462,
        "train_loss": 0.0019226339377033024
      },
      {
        "epoch": 1659,
        "reward": 0.44882893562316895,
        "val_loss": 0.0016908776597119868,
        "train_loss": 0.0019341856599427187
      },
      {
        "epoch": 1660,
        "reward": 0.45304441452026367,
        "val_loss": 0.0016342686722055078,
        "train_loss": 0.0019005238259873854
      },
      {
        "epoch": 1661,
        "reward": 0.434451162815094,
        "val_loss": 0.001900025294162333,
        "train_loss": 0.0018548104719509585
      },
      {
        "epoch": 1662,
        "reward": 0.45084911584854126,
        "val_loss": 0.0016634966180260693,
        "train_loss": 0.0019188934171464867
      },
      {
        "epoch": 1663,
        "reward": 0.4535338580608368,
        "val_loss": 0.0016278270465720976,
        "train_loss": 0.0018895483067003975
      },
      {
        "epoch": 1664,
        "reward": 0.4555835425853729,
        "val_loss": 0.0016011337200844927,
        "train_loss": 0.0018876911199185997
      },
      {
        "epoch": 1665,
        "reward": 0.455360472202301,
        "val_loss": 0.0016040161468221673,
        "train_loss": 0.0019178981976717925
      },
      {
        "epoch": 1666,
        "reward": 0.4525063633918762,
        "val_loss": 0.0016413823967533453,
        "train_loss": 0.0018944885389198763
      },
      {
        "epoch": 1667,
        "reward": 0.4547930657863617,
        "val_loss": 0.0016113732126541436,
        "train_loss": 0.0018636744921073283
      },
      {
        "epoch": 1668,
        "reward": 0.42669305205345154,
        "val_loss": 0.002024157637996333,
        "train_loss": 0.0018980289415384715
      },
      {
        "epoch": 1669,
        "reward": 0.4547633230686188,
        "val_loss": 0.0016117596616303282,
        "train_loss": 0.002119201663075588
      },
      {
        "epoch": 1670,
        "reward": 0.43956151604652405,
        "val_loss": 0.0018227103864774108,
        "train_loss": 0.002539145361739569
      },
      {
        "epoch": 1671,
        "reward": 0.42298823595046997,
        "val_loss": 0.002086478451799069,
        "train_loss": 0.002431580429681792
      },
      {
        "epoch": 1672,
        "reward": 0.4523611068725586,
        "val_loss": 0.0016433086212990539,
        "train_loss": 0.0021216246666601645
      },
      {
        "epoch": 1673,
        "reward": 0.4133799970149994,
        "val_loss": 0.002257957655404295,
        "train_loss": 0.0021533407270908356
      },
      {
        "epoch": 1674,
        "reward": 0.42964527010917664,
        "val_loss": 0.0019759279010551317,
        "train_loss": 0.0020092670411731186
      },
      {
        "epoch": 1675,
        "reward": 0.4545760154724121,
        "val_loss": 0.001614196558615991,
        "train_loss": 0.001931723713194235
      },
      {
        "epoch": 1676,
        "reward": 0.44131141901016235,
        "val_loss": 0.001797009226200836,
        "train_loss": 0.0019240482428218597
      },
      {
        "epoch": 1677,
        "reward": 0.45423999428749084,
        "val_loss": 0.0016185779822990298,
        "train_loss": 0.0019098557589201776
      },
      {
        "epoch": 1678,
        "reward": 0.4338064193725586,
        "val_loss": 0.0019100247882306576,
        "train_loss": 0.001933317087465324
      },
      {
        "epoch": 1679,
        "reward": 0.45489025115966797,
        "val_loss": 0.0016101102893506841,
        "train_loss": 0.0020207044032688895
      },
      {
        "epoch": 1680,
        "reward": 0.4558691084384918,
        "val_loss": 0.0015974509712707783,
        "train_loss": 0.0018877212082420906
      },
      {
        "epoch": 1681,
        "reward": 0.3975779414176941,
        "val_loss": 0.0025742947057421717,
        "train_loss": 0.002108506618801934
      },
      {
        "epoch": 1682,
        "reward": 0.4545936584472656,
        "val_loss": 0.0016139669044475471,
        "train_loss": 0.0020937845413125334
      },
      {
        "epoch": 1683,
        "reward": 0.4325507581233978,
        "val_loss": 0.0019296612590551376,
        "train_loss": 0.0018828507465793965
      },
      {
        "epoch": 1684,
        "reward": 0.4515341818332672,
        "val_loss": 0.0016543178852381451,
        "train_loss": 0.0020980380829244564
      },
      {
        "epoch": 1685,
        "reward": 0.4535098075866699,
        "val_loss": 0.0016281423158943653,
        "train_loss": 0.0019201705760609072
      },
      {
        "epoch": 1686,
        "reward": 0.45488592982292175,
        "val_loss": 0.0016101670002431742,
        "train_loss": 0.0018910616015021403
      },
      {
        "epoch": 1687,
        "reward": 0.45186883211135864,
        "val_loss": 0.0016498534407998835,
        "train_loss": 0.0019089899089102312
      },
      {
        "epoch": 1688,
        "reward": 0.45469769835472107,
        "val_loss": 0.0016126127032163953,
        "train_loss": 0.0019040757585501594
      },
      {
        "epoch": 1689,
        "reward": 0.43753156065940857,
        "val_loss": 0.0018530130286567978,
        "train_loss": 0.0019442925919205523
      },
      {
        "epoch": 1690,
        "reward": 0.43847790360450745,
        "val_loss": 0.0018388207369883145,
        "train_loss": 0.0019238582893964262
      },
      {
        "epoch": 1691,
        "reward": 0.4554736614227295,
        "val_loss": 0.0016025518915349884,
        "train_loss": 0.0018916104510516073
      },
      {
        "epoch": 1692,
        "reward": 0.45498090982437134,
        "val_loss": 0.0016089335466468973,
        "train_loss": 0.0018524341657421945
      },
      {
        "epoch": 1693,
        "reward": 0.4318370819091797,
        "val_loss": 0.0019409172902149813,
        "train_loss": 0.001878714726234858
      },
      {
        "epoch": 1694,
        "reward": 0.4546022415161133,
        "val_loss": 0.0016138553536230965,
        "train_loss": 0.0018970445977839307
      },
      {
        "epoch": 1695,
        "reward": 0.44851669669151306,
        "val_loss": 0.0016951513742761953,
        "train_loss": 0.0019061290723374651
      },
      {
        "epoch": 1696,
        "reward": 0.4537835717201233,
        "val_loss": 0.0016245497058012656,
        "train_loss": 0.0018642268539854111
      },
      {
        "epoch": 1697,
        "reward": 0.4558844268321991,
        "val_loss": 0.001597253281423556,
        "train_loss": 0.001917382035082063
      },
      {
        "epoch": 1698,
        "reward": 0.4556107521057129,
        "val_loss": 0.0016007819212973118,
        "train_loss": 0.002137386611698625
      },
      {
        "epoch": 1699,
        "reward": 0.41821905970573425,
        "val_loss": 0.0021697638855714884,
        "train_loss": 0.0024528802963546836
      },
      {
        "epoch": 1700,
        "reward": 0.45162686705589294,
        "val_loss": 0.0016530795421983515,
        "train_loss": 0.002125058161954467
      },
      {
        "epoch": 1701,
        "reward": 0.4290308952331543,
        "val_loss": 0.0019858627014660408,
        "train_loss": 0.0021462037201182772
      },
      {
        "epoch": 1702,
        "reward": 0.4319467544555664,
        "val_loss": 0.001939182884858123,
        "train_loss": 0.002231494727311656
      },
      {
        "epoch": 1703,
        "reward": 0.44223251938819885,
        "val_loss": 0.0017836347687989473,
        "train_loss": 0.002804726973408833
      },
      {
        "epoch": 1704,
        "reward": 0.4452917277812958,
        "val_loss": 0.0017399671736971609,
        "train_loss": 0.0020270178434797204
      },
      {
        "epoch": 1705,
        "reward": 0.4566897451877594,
        "val_loss": 0.001586917189082929,
        "train_loss": 0.0019327137337173694
      },
      {
        "epoch": 1706,
        "reward": 0.43544769287109375,
        "val_loss": 0.0018846788693086378,
        "train_loss": 0.0021193481963844253
      },
      {
        "epoch": 1707,
        "reward": 0.4540540277957916,
        "val_loss": 0.0016210085679111736,
        "train_loss": 0.0019917332865588833
      },
      {
        "epoch": 1708,
        "reward": 0.4302859902381897,
        "val_loss": 0.0019656239809202297,
        "train_loss": 0.002036491433570448
      },
      {
        "epoch": 1709,
        "reward": 0.455827921628952,
        "val_loss": 0.0015979819249228708,
        "train_loss": 0.002107964642513812
      },
      {
        "epoch": 1710,
        "reward": 0.4528772830963135,
        "val_loss": 0.0016364751416923745,
        "train_loss": 0.0023123709834180772
      },
      {
        "epoch": 1711,
        "reward": 0.45575961470603943,
        "val_loss": 0.0015988613761562323,
        "train_loss": 0.002042652978651369
      },
      {
        "epoch": 1712,
        "reward": 0.45247817039489746,
        "val_loss": 0.0016417563892900944,
        "train_loss": 0.0020300563668430326
      },
      {
        "epoch": 1713,
        "reward": 0.45402511954307556,
        "val_loss": 0.001621386460361204,
        "train_loss": 0.002021013006854516
      },
      {
        "epoch": 1714,
        "reward": 0.4555053412914276,
        "val_loss": 0.0016021430575554924,
        "train_loss": 0.0019297280141472584
      },
      {
        "epoch": 1715,
        "reward": 0.45508286356925964,
        "val_loss": 0.0016076115009907102,
        "train_loss": 0.0019454919540574057
      },
      {
        "epoch": 1716,
        "reward": 0.453336626291275,
        "val_loss": 0.001630419707258365,
        "train_loss": 0.0020109373014677726
      },
      {
        "epoch": 1717,
        "reward": 0.4507083594799042,
        "val_loss": 0.0016653901714432453,
        "train_loss": 0.0019525259266139562
      },
      {
        "epoch": 1718,
        "reward": 0.4510936439037323,
        "val_loss": 0.00166021437118096,
        "train_loss": 0.0019140224103466608
      },
      {
        "epoch": 1719,
        "reward": 0.4564131796360016,
        "val_loss": 0.0015904591335648938,
        "train_loss": 0.0018715291237010835
      },
      {
        "epoch": 1720,
        "reward": 0.4377022385597229,
        "val_loss": 0.0018504450895956584,
        "train_loss": 0.0018521071586012393
      },
      {
        "epoch": 1721,
        "reward": 0.43462929129600525,
        "val_loss": 0.0018972722381087287,
        "train_loss": 0.002009114472177596
      },
      {
        "epoch": 1722,
        "reward": 0.4554014801979065,
        "val_loss": 0.0016034861743849302,
        "train_loss": 0.002144322220164423
      },
      {
        "epoch": 1723,
        "reward": 0.4483707547187805,
        "val_loss": 0.0016971532604657114,
        "train_loss": 0.0021304545315125813
      },
      {
        "epoch": 1724,
        "reward": 0.42932209372520447,
        "val_loss": 0.001981147099286318,
        "train_loss": 0.0022182771756958505
      },
      {
        "epoch": 1725,
        "reward": 0.44718480110168457,
        "val_loss": 0.0017135113095199423,
        "train_loss": 0.002373385981907352
      },
      {
        "epoch": 1726,
        "reward": 0.44845515489578247,
        "val_loss": 0.0016959951857903174,
        "train_loss": 0.0019353324745539934
      },
      {
        "epoch": 1727,
        "reward": 0.4533897340297699,
        "val_loss": 0.0016297205168354725,
        "train_loss": 0.0018444272706163317
      },
      {
        "epoch": 1728,
        "reward": 0.4488855004310608,
        "val_loss": 0.001690104412513652,
        "train_loss": 0.0019040462525131612
      },
      {
        "epoch": 1729,
        "reward": 0.45597726106643677,
        "val_loss": 0.001596057862375996,
        "train_loss": 0.0020857708794717556
      },
      {
        "epoch": 1730,
        "reward": 0.45186206698417664,
        "val_loss": 0.0016499428061901458,
        "train_loss": 0.0020523237942073206
      },
      {
        "epoch": 1731,
        "reward": 0.44769287109375,
        "val_loss": 0.0017064826513108397,
        "train_loss": 0.0019525091786188288
      },
      {
        "epoch": 1732,
        "reward": 0.4036136567592621,
        "val_loss": 0.0024480754675875816,
        "train_loss": 0.0022006327904259358
      },
      {
        "epoch": 1733,
        "reward": 0.4381876587867737,
        "val_loss": 0.0018431618643392409,
        "train_loss": 0.002176855243026064
      },
      {
        "epoch": 1734,
        "reward": 0.4552799165248871,
        "val_loss": 0.0016050577479680733,
        "train_loss": 0.0019317042942230518
      },
      {
        "epoch": 1735,
        "reward": 0.4486088752746582,
        "val_loss": 0.0016938884093958353,
        "train_loss": 0.001851451126485087
      },
      {
        "epoch": 1736,
        "reward": 0.42153969407081604,
        "val_loss": 0.0021114033048174213,
        "train_loss": 0.0022628055348132667
      },
      {
        "epoch": 1737,
        "reward": 0.44072994589805603,
        "val_loss": 0.0018055062807564224,
        "train_loss": 0.001971287390076143
      },
      {
        "epoch": 1738,
        "reward": 0.45264798402786255,
        "val_loss": 0.0016395072951646788,
        "train_loss": 0.001915293991435017
      },
      {
        "epoch": 1739,
        "reward": 0.4499576985836029,
        "val_loss": 0.0016755204747564026,
        "train_loss": 0.001921718388055993
      },
      {
        "epoch": 1740,
        "reward": 0.43728262186050415,
        "val_loss": 0.0018567665413554227,
        "train_loss": 0.0022556169692856762
      },
      {
        "epoch": 1741,
        "reward": 0.4518207609653473,
        "val_loss": 0.0016504935421315686,
        "train_loss": 0.002185986305658634
      },
      {
        "epoch": 1742,
        "reward": 0.4530504643917084,
        "val_loss": 0.0016341895181020455,
        "train_loss": 0.0018848755381231268
      },
      {
        "epoch": 1743,
        "reward": 0.4502698481082916,
        "val_loss": 0.0016713003445017552,
        "train_loss": 0.001879182929629818
      },
      {
        "epoch": 1744,
        "reward": 0.453535795211792,
        "val_loss": 0.0016278013769936348,
        "train_loss": 0.0019134665064764423
      },
      {
        "epoch": 1745,
        "reward": 0.4450438618659973,
        "val_loss": 0.0017434631673885243,
        "train_loss": 0.0018656466178911685
      },
      {
        "epoch": 1746,
        "reward": 0.4556376039981842,
        "val_loss": 0.001600435344568853,
        "train_loss": 0.0019028340018569278
      },
      {
        "epoch": 1747,
        "reward": 0.43763765692710876,
        "val_loss": 0.0018514164590409824,
        "train_loss": 0.0019361024029736795
      },
      {
        "epoch": 1748,
        "reward": 0.45173850655555725,
        "val_loss": 0.0016515899998401956,
        "train_loss": 0.0018855759676975699
      },
      {
        "epoch": 1749,
        "reward": 0.4559233784675598,
        "val_loss": 0.001596752121778471,
        "train_loss": 0.001870660474266445
      },
      {
        "epoch": 1750,
        "reward": 0.4361574649810791,
        "val_loss": 0.0018738291525681103,
        "train_loss": 0.0018806241932907142
      },
      {
        "epoch": 1751,
        "reward": 0.4311201274394989,
        "val_loss": 0.0019522960397547909,
        "train_loss": 0.0019166920078882517
      },
      {
        "epoch": 1752,
        "reward": 0.44927117228507996,
        "val_loss": 0.0016848436373818134,
        "train_loss": 0.0021794904918911364
      },
      {
        "epoch": 1753,
        "reward": 0.4359624981880188,
        "val_loss": 0.0018768030651179807,
        "train_loss": 0.002208529743186843
      },
      {
        "epoch": 1754,
        "reward": 0.4558776915073395,
        "val_loss": 0.001597340002522937,
        "train_loss": 0.0019752624709956134
      },
      {
        "epoch": 1755,
        "reward": 0.4561805725097656,
        "val_loss": 0.0015934444381855428,
        "train_loss": 0.0019170707584215472
      },
      {
        "epoch": 1756,
        "reward": 0.45010730624198914,
        "val_loss": 0.0016734966858556227,
        "train_loss": 0.0019938870816706466
      },
      {
        "epoch": 1757,
        "reward": 0.4460098445415497,
        "val_loss": 0.0017298812495677599,
        "train_loss": 0.0019286178674239917
      },
      {
        "epoch": 1758,
        "reward": 0.4542543888092041,
        "val_loss": 0.0016183905453155084,
        "train_loss": 0.0018492109060249417
      },
      {
        "epoch": 1759,
        "reward": 0.4542100429534912,
        "val_loss": 0.0016189689382112452,
        "train_loss": 0.0023605853113202522
      },
      {
        "epoch": 1760,
        "reward": 0.43987950682640076,
        "val_loss": 0.0018180111988580652,
        "train_loss": 0.002050431678071618
      },
      {
        "epoch": 1761,
        "reward": 0.4476088583469391,
        "val_loss": 0.0017076428131466465,
        "train_loss": 0.001987045879314582
      },
      {
        "epoch": 1762,
        "reward": 0.4431684911251068,
        "val_loss": 0.0017701532093009778,
        "train_loss": 0.0018734202298779006
      },
      {
        "epoch": 1763,
        "reward": 0.4479794502258301,
        "val_loss": 0.0017025324133490877,
        "train_loss": 0.001871331534717823
      },
      {
        "epoch": 1764,
        "reward": 0.4416520595550537,
        "val_loss": 0.001792050149690892,
        "train_loss": 0.0018868402145856705
      },
      {
        "epoch": 1765,
        "reward": 0.43573108315467834,
        "val_loss": 0.001880339064103152,
        "train_loss": 0.0019500057701057254
      },
      {
        "epoch": 1766,
        "reward": 0.4514637887477875,
        "val_loss": 0.0016552582715771028,
        "train_loss": 0.0019320516294101253
      },
      {
        "epoch": 1767,
        "reward": 0.4555600583553314,
        "val_loss": 0.0016014363333982015,
        "train_loss": 0.0019227257054388667
      },
      {
        "epoch": 1768,
        "reward": 0.4551100730895996,
        "val_loss": 0.0016072583135350474,
        "train_loss": 0.0018862871153172678
      },
      {
        "epoch": 1769,
        "reward": 0.43213945627212524,
        "val_loss": 0.0019361393226842796,
        "train_loss": 0.0022114058061001394
      },
      {
        "epoch": 1770,
        "reward": 0.4245464503765106,
        "val_loss": 0.0020600184465625455,
        "train_loss": 0.0022188105593578746
      },
      {
        "epoch": 1771,
        "reward": 0.4351944625377655,
        "val_loss": 0.0018885663843580655,
        "train_loss": 0.0020255431693910328
      },
      {
        "epoch": 1772,
        "reward": 0.4531056880950928,
        "val_loss": 0.0016334611822717956,
        "train_loss": 0.0019024051314492961
      },
      {
        "epoch": 1773,
        "reward": 0.433925598859787,
        "val_loss": 0.0019081725705681102,
        "train_loss": 0.0020155814395715985
      },
      {
        "epoch": 1774,
        "reward": 0.45259609818458557,
        "val_loss": 0.0016401941871403583,
        "train_loss": 0.0021162089811136518
      },
      {
        "epoch": 1775,
        "reward": 0.45561671257019043,
        "val_loss": 0.001600705020661865,
        "train_loss": 0.0019330861382164026
      },
      {
        "epoch": 1776,
        "reward": 0.45030084252357483,
        "val_loss": 0.001670881307550839,
        "train_loss": 0.0019106725868858541
      },
      {
        "epoch": 1777,
        "reward": 0.4550916850566864,
        "val_loss": 0.0016074971894600562,
        "train_loss": 0.0018968784103120784
      },
      {
        "epoch": 1778,
        "reward": 0.44928836822509766,
        "val_loss": 0.0016846090771390923,
        "train_loss": 0.0018730964791477444
      },
      {
        "epoch": 1779,
        "reward": 0.4545721113681793,
        "val_loss": 0.0016142470911810441,
        "train_loss": 0.0018697735560216154
      },
      {
        "epoch": 1780,
        "reward": 0.4527212679386139,
        "val_loss": 0.0016385378299414047,
        "train_loss": 0.001873695335094593
      },
      {
        "epoch": 1781,
        "reward": 0.4366123676300049,
        "val_loss": 0.0018669108228225792,
        "train_loss": 0.0018989971123608905
      },
      {
        "epoch": 1782,
        "reward": 0.44558462500572205,
        "val_loss": 0.0017358458218430834,
        "train_loss": 0.0020853223445905875
      },
      {
        "epoch": 1783,
        "reward": 0.45630794763565063,
        "val_loss": 0.001591808719760073,
        "train_loss": 0.0022371876178882443
      },
      {
        "epoch": 1784,
        "reward": 0.4004131257534027,
        "val_loss": 0.0025141347266201463,
        "train_loss": 0.00223374730334259
      },
      {
        "epoch": 1785,
        "reward": 0.45403018593788147,
        "val_loss": 0.0016213205360275293,
        "train_loss": 0.0021722930692843734
      },
      {
        "epoch": 1786,
        "reward": 0.4497087001800537,
        "val_loss": 0.0016788957208128913,
        "train_loss": 0.0019041869001319776
      },
      {
        "epoch": 1787,
        "reward": 0.45548558235168457,
        "val_loss": 0.001602398481086961,
        "train_loss": 0.002071954542770982
      },
      {
        "epoch": 1788,
        "reward": 0.45526495575904846,
        "val_loss": 0.0016052517956787987,
        "train_loss": 0.002016990716443755
      },
      {
        "epoch": 1789,
        "reward": 0.41209253668785095,
        "val_loss": 0.0022820725238748957,
        "train_loss": 0.002080134174320847
      },
      {
        "epoch": 1790,
        "reward": 0.4502750337123871,
        "val_loss": 0.0016712300047012313,
        "train_loss": 0.002088866057769897
      },
      {
        "epoch": 1791,
        "reward": 0.4545154571533203,
        "val_loss": 0.0016149852142137075,
        "train_loss": 0.0022853388262984273
      },
      {
        "epoch": 1792,
        "reward": 0.43503737449645996,
        "val_loss": 0.0018909814202093653,
        "train_loss": 0.0018809389400233228
      },
      {
        "epoch": 1793,
        "reward": 0.45547977089881897,
        "val_loss": 0.0016024741011538676,
        "train_loss": 0.001977690112723324
      },
      {
        "epoch": 1794,
        "reward": 0.44475647807121277,
        "val_loss": 0.0017475256130897573,
        "train_loss": 0.001953428082812864
      },
      {
        "epoch": 1795,
        "reward": 0.43373337388038635,
        "val_loss": 0.001911161351017654,
        "train_loss": 0.00189336910597586
      },
      {
        "epoch": 1796,
        "reward": 0.45486685633659363,
        "val_loss": 0.0016104142830174948,
        "train_loss": 0.0019039673968738778
      },
      {
        "epoch": 1797,
        "reward": 0.4454713761806488,
        "val_loss": 0.0017374382171380734,
        "train_loss": 0.0018941721522283982
      },
      {
        "epoch": 1798,
        "reward": 0.4543778598308563,
        "val_loss": 0.001616778800130955,
        "train_loss": 0.0018827726733154403
      },
      {
        "epoch": 1799,
        "reward": 0.44549256563186646,
        "val_loss": 0.0017371401190757751,
        "train_loss": 0.0018559031428034918
      },
      {
        "epoch": 1800,
        "reward": 0.4521941840648651,
        "val_loss": 0.0016455243208578654,
        "train_loss": 0.0019612135264861327
      },
      {
        "epoch": 1801,
        "reward": 0.4548143446445465,
        "val_loss": 0.001611096493434161,
        "train_loss": 0.001950962420988407
      },
      {
        "epoch": 1802,
        "reward": 0.43932580947875977,
        "val_loss": 0.0018262011497946723,
        "train_loss": 0.0018508967286834377
      },
      {
        "epoch": 1803,
        "reward": 0.45534202456474304,
        "val_loss": 0.001604254773285772,
        "train_loss": 0.0019106697686416178
      },
      {
        "epoch": 1804,
        "reward": 0.4469590187072754,
        "val_loss": 0.0017166442370840482,
        "train_loss": 0.001941560807888611
      },
      {
        "epoch": 1805,
        "reward": 0.45489755272865295,
        "val_loss": 0.0016100152362404124,
        "train_loss": 0.0018575266647251109
      },
      {
        "epoch": 1806,
        "reward": 0.4537544846534729,
        "val_loss": 0.001624930724834225,
        "train_loss": 0.0019629612484445367
      },
      {
        "epoch": 1807,
        "reward": 0.44579336047172546,
        "val_loss": 0.0017329150744314706,
        "train_loss": 0.0018608198973617198
      },
      {
        "epoch": 1808,
        "reward": 0.454439640045166,
        "val_loss": 0.0016159736634498195,
        "train_loss": 0.001847700339873462
      },
      {
        "epoch": 1809,
        "reward": 0.45587649941444397,
        "val_loss": 0.0015973557102760033,
        "train_loss": 0.0018517282492911573
      },
      {
        "epoch": 1810,
        "reward": 0.45350170135498047,
        "val_loss": 0.001628249284944364,
        "train_loss": 0.001897387634156845
      },
      {
        "epoch": 1811,
        "reward": 0.44435450434684753,
        "val_loss": 0.001753224725169795,
        "train_loss": 0.0018590651634440292
      },
      {
        "epoch": 1812,
        "reward": 0.4456702768802643,
        "val_loss": 0.001734642910638026,
        "train_loss": 0.0018901571557552626
      },
      {
        "epoch": 1813,
        "reward": 0.43395206332206726,
        "val_loss": 0.0019077611089284932,
        "train_loss": 0.00188574390575433
      },
      {
        "epoch": 1814,
        "reward": 0.4548530578613281,
        "val_loss": 0.0016105935127208276,
        "train_loss": 0.0018921740635190732
      },
      {
        "epoch": 1815,
        "reward": 0.45529618859291077,
        "val_loss": 0.0016048478178812989,
        "train_loss": 0.0019181895179197174
      },
      {
        "epoch": 1816,
        "reward": 0.4532988667488098,
        "val_loss": 0.0016309165262750217,
        "train_loss": 0.0018611020439913352
      },
      {
        "epoch": 1817,
        "reward": 0.4478122293949127,
        "val_loss": 0.0017048362642526627,
        "train_loss": 0.0018801548374960055
      },
      {
        "epoch": 1818,
        "reward": 0.4447891414165497,
        "val_loss": 0.001747063726985029,
        "train_loss": 0.001878327274775634
      },
      {
        "epoch": 1819,
        "reward": 0.44791480898857117,
        "val_loss": 0.0017034230155072042,
        "train_loss": 0.001854860827646777
      },
      {
        "epoch": 1820,
        "reward": 0.45308443903923035,
        "val_loss": 0.0016337416184666967,
        "train_loss": 0.0018811806758794074
      },
      {
        "epoch": 1821,
        "reward": 0.45306435227394104,
        "val_loss": 0.0016340058646164834,
        "train_loss": 0.0018656065689915873
      },
      {
        "epoch": 1822,
        "reward": 0.43776312470436096,
        "val_loss": 0.0018495304310428245,
        "train_loss": 0.001998944311008717
      },
      {
        "epoch": 1823,
        "reward": 0.44894590973854065,
        "val_loss": 0.0016892791276664606,
        "train_loss": 0.0019636808398130457
      },
      {
        "epoch": 1824,
        "reward": 0.4017994999885559,
        "val_loss": 0.0024852831847965717,
        "train_loss": 0.0024195039183653603
      },
      {
        "epoch": 1825,
        "reward": 0.4362405240535736,
        "val_loss": 0.0018725638178044132,
        "train_loss": 0.002346900679045715
      },
      {
        "epoch": 1826,
        "reward": 0.45256590843200684,
        "val_loss": 0.0016405936746325875,
        "train_loss": 0.0019297979757329114
      },
      {
        "epoch": 1827,
        "reward": 0.45475244522094727,
        "val_loss": 0.0016119010813002075,
        "train_loss": 0.0020461052593488535
      },
      {
        "epoch": 1828,
        "reward": 0.4491528570652008,
        "val_loss": 0.0016864554657201683,
        "train_loss": 0.0018763753614621237
      },
      {
        "epoch": 1829,
        "reward": 0.4555714726448059,
        "val_loss": 0.0016012895336773778,
        "train_loss": 0.0019131798359851998
      },
      {
        "epoch": 1830,
        "reward": 0.43323007225990295,
        "val_loss": 0.0019190110033378005,
        "train_loss": 0.002034564556267399
      },
      {
        "epoch": 1831,
        "reward": 0.45279285311698914,
        "val_loss": 0.001637590491944658,
        "train_loss": 0.002037520234947666
      },
      {
        "epoch": 1832,
        "reward": 0.4546181857585907,
        "val_loss": 0.0016136478017350392,
        "train_loss": 0.0021763265114994003
      },
      {
        "epoch": 1833,
        "reward": 0.4469461441040039,
        "val_loss": 0.0017168231175414153,
        "train_loss": 0.0023343170625874056
      },
      {
        "epoch": 1834,
        "reward": 0.4545780122280121,
        "val_loss": 0.0016141701323379362,
        "train_loss": 0.0019556794465573216
      },
      {
        "epoch": 1835,
        "reward": 0.43019381165504456,
        "val_loss": 0.001967102921168719,
        "train_loss": 0.001960992235511255
      },
      {
        "epoch": 1836,
        "reward": 0.4476564824581146,
        "val_loss": 0.0017069853493012488,
        "train_loss": 0.002673392797497889
      },
      {
        "epoch": 1837,
        "reward": 0.4433571994304657,
        "val_loss": 0.0017674486984365753,
        "train_loss": 0.0025431890479432275
      },
      {
        "epoch": 1838,
        "reward": 0.4358823895454407,
        "val_loss": 0.0018780261910121357,
        "train_loss": 0.002074868868266304
      },
      {
        "epoch": 1839,
        "reward": 0.45538225769996643,
        "val_loss": 0.0016037341889127024,
        "train_loss": 0.0019035329549716641
      },
      {
        "epoch": 1840,
        "reward": 0.44429680705070496,
        "val_loss": 0.0017540440146279121,
        "train_loss": 0.00230386059355134
      },
      {
        "epoch": 1841,
        "reward": 0.4501058757305145,
        "val_loss": 0.0016735156781838409,
        "train_loss": 0.0018721434470745197
      },
      {
        "epoch": 1842,
        "reward": 0.4291205108165741,
        "val_loss": 0.0019844104203262498,
        "train_loss": 0.0020257573341950774
      },
      {
        "epoch": 1843,
        "reward": 0.45568403601646423,
        "val_loss": 0.001599836246376591,
        "train_loss": 0.0020304297983015063
      },
      {
        "epoch": 1844,
        "reward": 0.45626020431518555,
        "val_loss": 0.001592421588221831,
        "train_loss": 0.001880108831056322
      },
      {
        "epoch": 1845,
        "reward": 0.4471468925476074,
        "val_loss": 0.0017140367168134876,
        "train_loss": 0.0019157418797616488
      },
      {
        "epoch": 1846,
        "reward": 0.4519568383693695,
        "val_loss": 0.0016486806312708982,
        "train_loss": 0.001958206992220277
      },
      {
        "epoch": 1847,
        "reward": 0.4344537854194641,
        "val_loss": 0.0018999846652150154,
        "train_loss": 0.0024368257145397365
      },
      {
        "epoch": 1848,
        "reward": 0.4427083134651184,
        "val_loss": 0.0017767686596406357,
        "train_loss": 0.0020020436252427597
      },
      {
        "epoch": 1849,
        "reward": 0.45342573523521423,
        "val_loss": 0.0016292473800214274,
        "train_loss": 0.001890951690431673
      },
      {
        "epoch": 1850,
        "reward": 0.4163076877593994,
        "val_loss": 0.002204145271597164,
        "train_loss": 0.002141165435135078
      },
      {
        "epoch": 1851,
        "reward": 0.4552103579044342,
        "val_loss": 0.001605958619620651,
        "train_loss": 0.0019586866334206066
      },
      {
        "epoch": 1852,
        "reward": 0.44380292296409607,
        "val_loss": 0.001761075358704797,
        "train_loss": 0.0020647326555962744
      },
      {
        "epoch": 1853,
        "reward": 0.44020533561706543,
        "val_loss": 0.0018132092747172074,
        "train_loss": 0.0022853149589186963
      },
      {
        "epoch": 1854,
        "reward": 0.4545685350894928,
        "val_loss": 0.0016142941229710622,
        "train_loss": 0.001970855742841265
      },
      {
        "epoch": 1855,
        "reward": 0.44644036889076233,
        "val_loss": 0.0017238639660977892,
        "train_loss": 0.0018669435439033594
      },
      {
        "epoch": 1856,
        "reward": 0.42035460472106934,
        "val_loss": 0.002132034511305392,
        "train_loss": 0.0022411603713408113
      },
      {
        "epoch": 1857,
        "reward": 0.45224300026893616,
        "val_loss": 0.001644875787730728,
        "train_loss": 0.002571255823848053
      },
      {
        "epoch": 1858,
        "reward": 0.4398687779903412,
        "val_loss": 0.001818169024772942,
        "train_loss": 0.0020973748625972522
      },
      {
        "epoch": 1859,
        "reward": 0.4559330642223358,
        "val_loss": 0.0015966276488532977,
        "train_loss": 0.002157270113597266
      },
      {
        "epoch": 1860,
        "reward": 0.4559648931026459,
        "val_loss": 0.0015962172515823372,
        "train_loss": 0.0019415838357347709
      },
      {
        "epoch": 1861,
        "reward": 0.45491090416908264,
        "val_loss": 0.0016098423761182598,
        "train_loss": 0.0018908583965989796
      },
      {
        "epoch": 1862,
        "reward": 0.45288166403770447,
        "val_loss": 0.0016364175077926899,
        "train_loss": 0.0018632122031564135
      },
      {
        "epoch": 1863,
        "reward": 0.4533785283565521,
        "val_loss": 0.0016298682811403914,
        "train_loss": 0.0018868207944951092
      },
      {
        "epoch": 1864,
        "reward": 0.4548804759979248,
        "val_loss": 0.0016102371155284345,
        "train_loss": 0.0018532035313770534
      },
      {
        "epoch": 1865,
        "reward": 0.4500001072883606,
        "val_loss": 0.001674947129296405,
        "train_loss": 0.0018696725640508633
      },
      {
        "epoch": 1866,
        "reward": 0.44750767946243286,
        "val_loss": 0.0017090419922689243,
        "train_loss": 0.0018759751970859584
      },
      {
        "epoch": 1867,
        "reward": 0.4503598213195801,
        "val_loss": 0.0016700852512648062,
        "train_loss": 0.001859746264542012
      },
      {
        "epoch": 1868,
        "reward": 0.44329753518104553,
        "val_loss": 0.0017683026879759772,
        "train_loss": 0.0018702644693593567
      },
      {
        "epoch": 1869,
        "reward": 0.4074919819831848,
        "val_loss": 0.002370562986470759,
        "train_loss": 0.0021204957290767478
      },
      {
        "epoch": 1870,
        "reward": 0.45517125725746155,
        "val_loss": 0.0016064654170934642,
        "train_loss": 0.001985937990516854
      },
      {
        "epoch": 1871,
        "reward": 0.44453945755958557,
        "val_loss": 0.0017505996927086795,
        "train_loss": 0.0019802608563063238
      },
      {
        "epoch": 1872,
        "reward": 0.42751237750053406,
        "val_loss": 0.002010646874883345,
        "train_loss": 0.0021325585593541083
      },
      {
        "epoch": 1873,
        "reward": 0.45022010803222656,
        "val_loss": 0.0016719720692240766,
        "train_loss": 0.0019415688209567005
      },
      {
        "epoch": 1874,
        "reward": 0.4530624449253082,
        "val_loss": 0.0016340314676719053,
        "train_loss": 0.0018787004659176231
      },
      {
        "epoch": 1875,
        "reward": 0.4539305865764618,
        "val_loss": 0.0016226239136553236,
        "train_loss": 0.001875213526843184
      },
      {
        "epoch": 1876,
        "reward": 0.4540455937385559,
        "val_loss": 0.0016211190626823477,
        "train_loss": 0.0019029465595219964
      },
      {
        "epoch": 1877,
        "reward": 0.44495058059692383,
        "val_loss": 0.0017447804732780372,
        "train_loss": 0.0019218982141375397
      },
      {
        "epoch": 1878,
        "reward": 0.45461583137512207,
        "val_loss": 0.0016136779366726322,
        "train_loss": 0.001860188173080902
      },
      {
        "epoch": 1879,
        "reward": 0.4436469078063965,
        "val_loss": 0.0017633032818724001,
        "train_loss": 0.0020309427099374053
      },
      {
        "epoch": 1880,
        "reward": 0.4500238001346588,
        "val_loss": 0.0016746261140464672,
        "train_loss": 0.0019869877634426723
      },
      {
        "epoch": 1881,
        "reward": 0.4536658823490143,
        "val_loss": 0.0016260933397071703,
        "train_loss": 0.002468603795233111
      },
      {
        "epoch": 1882,
        "reward": 0.4235686957836151,
        "val_loss": 0.002076579008384475,
        "train_loss": 0.0019608970503143678
      },
      {
        "epoch": 1883,
        "reward": 0.45495516061782837,
        "val_loss": 0.001609267883135804,
        "train_loss": 0.0019318616661901334
      },
      {
        "epoch": 1884,
        "reward": 0.4546906054019928,
        "val_loss": 0.0016127052866587682,
        "train_loss": 0.0018678801593173726
      },
      {
        "epoch": 1885,
        "reward": 0.45262280106544495,
        "val_loss": 0.0016398400517313608,
        "train_loss": 0.0019942399544211533
      },
      {
        "epoch": 1886,
        "reward": 0.45497727394104004,
        "val_loss": 0.0016089809692597815,
        "train_loss": 0.001893340330682874
      },
      {
        "epoch": 1887,
        "reward": 0.45556971430778503,
        "val_loss": 0.001601312234665134,
        "train_loss": 0.001881953066913411
      },
      {
        "epoch": 1888,
        "reward": 0.4325530529022217,
        "val_loss": 0.0019296248875824468,
        "train_loss": 0.0020705449636667394
      },
      {
        "epoch": 1889,
        "reward": 0.45408010482788086,
        "val_loss": 0.0016206676290104432,
        "train_loss": 0.0022311876126737983
      },
      {
        "epoch": 1890,
        "reward": 0.44570255279541016,
        "val_loss": 0.0017341899386207973,
        "train_loss": 0.0018824421167757612
      },
      {
        "epoch": 1891,
        "reward": 0.4551585614681244,
        "val_loss": 0.0016066300200431474,
        "train_loss": 0.001959432670936132
      },
      {
        "epoch": 1892,
        "reward": 0.4540284276008606,
        "val_loss": 0.0016213436943611928,
        "train_loss": 0.001985111681278795
      },
      {
        "epoch": 1893,
        "reward": 0.4270295202732086,
        "val_loss": 0.002018597808533481,
        "train_loss": 0.0019316336720993814
      },
      {
        "epoch": 1894,
        "reward": 0.45564505457878113,
        "val_loss": 0.0016003395430743694,
        "train_loss": 0.0018901403572481985
      },
      {
        "epoch": 1895,
        "reward": 0.45609626173973083,
        "val_loss": 0.0015945278324319848,
        "train_loss": 0.001868223987492876
      },
      {
        "epoch": 1896,
        "reward": 0.456416517496109,
        "val_loss": 0.0015904160432650574,
        "train_loss": 0.002017426857491955
      },
      {
        "epoch": 1897,
        "reward": 0.3927342891693115,
        "val_loss": 0.002680778137541243,
        "train_loss": 0.0022383457846724642
      },
      {
        "epoch": 1898,
        "reward": 0.44938549399375916,
        "val_loss": 0.0016832878214440175,
        "train_loss": 0.0022756932952548736
      },
      {
        "epoch": 1899,
        "reward": 0.4553258419036865,
        "val_loss": 0.0016044640797190368,
        "train_loss": 0.0020861363599788793
      },
      {
        "epoch": 1900,
        "reward": 0.4419781267642975,
        "val_loss": 0.0017873180664277502,
        "train_loss": 0.0020431325829122216
      },
      {
        "epoch": 1901,
        "reward": 0.44579219818115234,
        "val_loss": 0.00173293097343828,
        "train_loss": 0.0018515321705938103
      },
      {
        "epoch": 1902,
        "reward": 0.45400214195251465,
        "val_loss": 0.001621687302498945,
        "train_loss": 0.0018547851930354508
      },
      {
        "epoch": 1903,
        "reward": 0.4558071792125702,
        "val_loss": 0.0015982483995945326,
        "train_loss": 0.0018671638233802067
      },
      {
        "epoch": 1904,
        "reward": 0.4551205635070801,
        "val_loss": 0.00160712211592389,
        "train_loss": 0.0019105501694586845
      },
      {
        "epoch": 1905,
        "reward": 0.42401453852653503,
        "val_loss": 0.002069010099928294,
        "train_loss": 0.0021083039553979267
      },
      {
        "epoch": 1906,
        "reward": 0.4506107270717621,
        "val_loss": 0.0016667033695349736,
        "train_loss": 0.002031624984318534
      },
      {
        "epoch": 1907,
        "reward": 0.45478078722953796,
        "val_loss": 0.001611532984367971,
        "train_loss": 0.0018749584476329172
      },
      {
        "epoch": 1908,
        "reward": 0.4544566571712494,
        "val_loss": 0.0016157515097542533,
        "train_loss": 0.0019370042472683752
      },
      {
        "epoch": 1909,
        "reward": 0.44224581122398376,
        "val_loss": 0.001783443199071501,
        "train_loss": 0.0018822911039863427
      },
      {
        "epoch": 1910,
        "reward": 0.44799309968948364,
        "val_loss": 0.0017023445273350393,
        "train_loss": 0.0018667604434505426
      },
      {
        "epoch": 1911,
        "reward": 0.4532186686992645,
        "val_loss": 0.0016319725712362146,
        "train_loss": 0.001865548325720458
      },
      {
        "epoch": 1912,
        "reward": 0.44600746035575867,
        "val_loss": 0.0017299150515879904,
        "train_loss": 0.0019503254958320982
      },
      {
        "epoch": 1913,
        "reward": 0.4556102454662323,
        "val_loss": 0.0016007890642088438,
        "train_loss": 0.001977571563910575
      },
      {
        "epoch": 1914,
        "reward": 0.4496763348579407,
        "val_loss": 0.0016793356210525548,
        "train_loss": 0.0018991890487646183
      },
      {
        "epoch": 1915,
        "reward": 0.45624127984046936,
        "val_loss": 0.0015926645553138638,
        "train_loss": 0.0018903271389158012
      },
      {
        "epoch": 1916,
        "reward": 0.45628467202186584,
        "val_loss": 0.0015921077325141855,
        "train_loss": 0.0018838954571177824
      },
      {
        "epoch": 1917,
        "reward": 0.4559800624847412,
        "val_loss": 0.001596022297495178,
        "train_loss": 0.0018935197904983608
      },
      {
        "epoch": 1918,
        "reward": 0.4319879710674286,
        "val_loss": 0.0019385309756866523,
        "train_loss": 0.001938635763228656
      },
      {
        "epoch": 1919,
        "reward": 0.45621180534362793,
        "val_loss": 0.0015930430132097431,
        "train_loss": 0.002013659946477184
      },
      {
        "epoch": 1920,
        "reward": 0.45458313822746277,
        "val_loss": 0.0016141041747427412,
        "train_loss": 0.0018556532585744907
      },
      {
        "epoch": 1921,
        "reward": 0.4559784531593323,
        "val_loss": 0.0015960427200687782,
        "train_loss": 0.0020183666134611345
      },
      {
        "epoch": 1922,
        "reward": 0.4106498658657074,
        "val_loss": 0.0023094280789207134,
        "train_loss": 0.0019852817685414967
      },
      {
        "epoch": 1923,
        "reward": 0.4502125680446625,
        "val_loss": 0.001672073400446347,
        "train_loss": 0.002067922857979563
      },
      {
        "epoch": 1924,
        "reward": 0.4478413760662079,
        "val_loss": 0.0017044351136844074,
        "train_loss": 0.0018937525864412936
      },
      {
        "epoch": 1925,
        "reward": 0.453718900680542,
        "val_loss": 0.0016253977914207748,
        "train_loss": 0.0018855565196225564
      },
      {
        "epoch": 1926,
        "reward": 0.4256163239479065,
        "val_loss": 0.0020420608343556523,
        "train_loss": 0.0024628905140651534
      },
      {
        "epoch": 1927,
        "reward": 0.45396628975868225,
        "val_loss": 0.0016221562733075448,
        "train_loss": 0.001990022966100906
      },
      {
        "epoch": 1928,
        "reward": 0.4134626090526581,
        "val_loss": 0.002256420756956296,
        "train_loss": 0.0019911522484527757
      },
      {
        "epoch": 1929,
        "reward": 0.45292025804519653,
        "val_loss": 0.0016359077167830297,
        "train_loss": 0.002004337579609665
      },
      {
        "epoch": 1930,
        "reward": 0.44217419624328613,
        "val_loss": 0.0017844792621742403,
        "train_loss": 0.001850259806255613
      },
      {
        "epoch": 1931,
        "reward": 0.4548524022102356,
        "val_loss": 0.0016106019777778005,
        "train_loss": 0.0019342314906400414
      },
      {
        "epoch": 1932,
        "reward": 0.4479342997074127,
        "val_loss": 0.001703153713606298,
        "train_loss": 0.0019424791042603408
      },
      {
        "epoch": 1933,
        "reward": 0.4278506934642792,
        "val_loss": 0.002005096441800041,
        "train_loss": 0.0019399914062187935
      },
      {
        "epoch": 1934,
        "reward": 0.4470749497413635,
        "val_loss": 0.0017150345956906676,
        "train_loss": 0.002016213516561458
      },
      {
        "epoch": 1935,
        "reward": 0.45565205812454224,
        "val_loss": 0.0016002489969001285,
        "train_loss": 0.001923320605223685
      },
      {
        "epoch": 1936,
        "reward": 0.4335927665233612,
        "val_loss": 0.0019133507407137326,
        "train_loss": 0.0019044321323655401
      },
      {
        "epoch": 1937,
        "reward": 0.4511256217956543,
        "val_loss": 0.001659785389035408,
        "train_loss": 0.0019223185196586621
      },
      {
        "epoch": 1938,
        "reward": 0.4499852657318115,
        "val_loss": 0.001675147480065269,
        "train_loss": 0.0018750377964282122
      },
      {
        "epoch": 1939,
        "reward": 0.38507187366485596,
        "val_loss": 0.0028593418121870074,
        "train_loss": 0.002233821916608856
      },
      {
        "epoch": 1940,
        "reward": 0.45391106605529785,
        "val_loss": 0.0016228794868636345,
        "train_loss": 0.002534389348091701
      },
      {
        "epoch": 1941,
        "reward": 0.4555113911628723,
        "val_loss": 0.0016020650010822074,
        "train_loss": 0.00206895703517008
      },
      {
        "epoch": 1942,
        "reward": 0.4561256468296051,
        "val_loss": 0.0015941497320974512,
        "train_loss": 0.0018539662294362923
      },
      {
        "epoch": 1943,
        "reward": 0.4476326107978821,
        "val_loss": 0.0017073153451617276,
        "train_loss": 0.002096703293948219
      },
      {
        "epoch": 1944,
        "reward": 0.45393043756484985,
        "val_loss": 0.0016226260839695378,
        "train_loss": 0.0019718755759710735
      },
      {
        "epoch": 1945,
        "reward": 0.45249372720718384,
        "val_loss": 0.0016415498269322728,
        "train_loss": 0.0019095057941740379
      },
      {
        "epoch": 1946,
        "reward": 0.4547952711582184,
        "val_loss": 0.0016113445079619332,
        "train_loss": 0.001882560559002181
      },
      {
        "epoch": 1947,
        "reward": 0.45313817262649536,
        "val_loss": 0.0016330332644949003,
        "train_loss": 0.001882482277533899
      },
      {
        "epoch": 1948,
        "reward": 0.4540993869304657,
        "val_loss": 0.0016204162051768176,
        "train_loss": 0.0018545171828568878
      },
      {
        "epoch": 1949,
        "reward": 0.4559650123119354,
        "val_loss": 0.0015962161123752594,
        "train_loss": 0.0019984077975655403
      },
      {
        "epoch": 1950,
        "reward": 0.4466049373149872,
        "val_loss": 0.0017215697444044054,
        "train_loss": 0.0023830093291158285
      },
      {
        "epoch": 1951,
        "reward": 0.452944278717041,
        "val_loss": 0.00163559040187725,
        "train_loss": 0.002059468809210767
      },
      {
        "epoch": 1952,
        "reward": 0.41981741786003113,
        "val_loss": 0.0021414573836539474,
        "train_loss": 0.00193694710973292
      },
      {
        "epoch": 1953,
        "reward": 0.4553532600402832,
        "val_loss": 0.0016041093206565296,
        "train_loss": 0.0019332469175704038
      },
      {
        "epoch": 1954,
        "reward": 0.44924303889274597,
        "val_loss": 0.0016852269597750688,
        "train_loss": 0.0018639071422512643
      },
      {
        "epoch": 1955,
        "reward": 0.436405748128891,
        "val_loss": 0.0018700497457757592,
        "train_loss": 0.0019805917982012033
      },
      {
        "epoch": 1956,
        "reward": 0.45568719506263733,
        "val_loss": 0.0015997953513371094,
        "train_loss": 0.0020481346582528204
      },
      {
        "epoch": 1957,
        "reward": 0.4538061320781708,
        "val_loss": 0.0016242539859376848,
        "train_loss": 0.0018548851190784122
      },
      {
        "epoch": 1958,
        "reward": 0.43196901679039,
        "val_loss": 0.0019388309280787195,
        "train_loss": 0.001863935642177239
      },
      {
        "epoch": 1959,
        "reward": 0.44998088479042053,
        "val_loss": 0.0016752065857872367,
        "train_loss": 0.002145354770338879
      },
      {
        "epoch": 1960,
        "reward": 0.45568570494651794,
        "val_loss": 0.0015998146263882518,
        "train_loss": 0.0019503945519458144
      },
      {
        "epoch": 1961,
        "reward": 0.4406276345252991,
        "val_loss": 0.0018070059845090977,
        "train_loss": 0.0019818060861255685
      },
      {
        "epoch": 1962,
        "reward": 0.4428378641605377,
        "val_loss": 0.0017749035697696464,
        "train_loss": 0.002248422576275726
      },
      {
        "epoch": 1963,
        "reward": 0.4341038763523102,
        "val_loss": 0.001905404230845826,
        "train_loss": 0.001916213201763657
      },
      {
        "epoch": 1964,
        "reward": 0.44991013407707214,
        "val_loss": 0.0016761652659624815,
        "train_loss": 0.0019013798345650474
      },
      {
        "epoch": 1965,
        "reward": 0.4435645043849945,
        "val_loss": 0.001764481172098645,
        "train_loss": 0.0020554477501159105
      },
      {
        "epoch": 1966,
        "reward": 0.4567039906978607,
        "val_loss": 0.0015867347163813455,
        "train_loss": 0.002403469897287253
      },
      {
        "epoch": 1967,
        "reward": 0.45119690895080566,
        "val_loss": 0.0016588297023970102,
        "train_loss": 0.0020073322050918182
      },
      {
        "epoch": 1968,
        "reward": 0.45408985018730164,
        "val_loss": 0.0016205405201097684,
        "train_loss": 0.0018973289419451389
      },
      {
        "epoch": 1969,
        "reward": 0.45042529702186584,
        "val_loss": 0.0016692024156717317,
        "train_loss": 0.0019597640986411045
      },
      {
        "epoch": 1970,
        "reward": 0.4457206726074219,
        "val_loss": 0.0017339348726506745,
        "train_loss": 0.0019420685849371904
      },
      {
        "epoch": 1971,
        "reward": 0.4556691348552704,
        "val_loss": 0.0016000286226959101,
        "train_loss": 0.0019032558350143237
      },
      {
        "epoch": 1972,
        "reward": 0.45183902978897095,
        "val_loss": 0.0016502503006319915,
        "train_loss": 0.001943892955471081
      },
      {
        "epoch": 1973,
        "reward": 0.4519328773021698,
        "val_loss": 0.0016490007401444018,
        "train_loss": 0.0023532596130210618
      },
      {
        "epoch": 1974,
        "reward": 0.4535899758338928,
        "val_loss": 0.0016270899047542895,
        "train_loss": 0.001986379372493292
      },
      {
        "epoch": 1975,
        "reward": 0.4564970135688782,
        "val_loss": 0.0015893850026519171,
        "train_loss": 0.00205025554392845
      },
      {
        "epoch": 1976,
        "reward": 0.4566441476345062,
        "val_loss": 0.001587500230276159,
        "train_loss": 0.0018595357596495887
      },
      {
        "epoch": 1977,
        "reward": 0.44883060455322266,
        "val_loss": 0.0016908546926320664,
        "train_loss": 0.001973889606933181
      },
      {
        "epoch": 1978,
        "reward": 0.448030948638916,
        "val_loss": 0.0017018232361546584,
        "train_loss": 0.00189160209601351
      },
      {
        "epoch": 1979,
        "reward": 0.4185287654399872,
        "val_loss": 0.00216424824403865,
        "train_loss": 0.001979255751043988
      },
      {
        "epoch": 1980,
        "reward": 0.440155029296875,
        "val_loss": 0.001813949185556599,
        "train_loss": 0.0019210386674855656
      },
      {
        "epoch": 1981,
        "reward": 0.45125165581703186,
        "val_loss": 0.001658096759846168,
        "train_loss": 0.0018963953628463935
      },
      {
        "epoch": 1982,
        "reward": 0.4531938135623932,
        "val_loss": 0.0016322995070368052,
        "train_loss": 0.0019123604892788886
      },
      {
        "epoch": 1983,
        "reward": 0.44983384013175964,
        "val_loss": 0.0016771986515128187,
        "train_loss": 0.0018903076863632752
      },
      {
        "epoch": 1984,
        "reward": 0.4352177083492279,
        "val_loss": 0.001888208490397249,
        "train_loss": 0.0023146257780563948
      },
      {
        "epoch": 1985,
        "reward": 0.4192173480987549,
        "val_loss": 0.002152037590609065,
        "train_loss": 0.0027326574423708594
      },
      {
        "epoch": 1986,
        "reward": 0.4519517123699188,
        "val_loss": 0.0016487495408260397,
        "train_loss": 0.0019734318020010297
      },
      {
        "epoch": 1987,
        "reward": 0.43457546830177307,
        "val_loss": 0.0018981036929679768,
        "train_loss": 0.001927068752523225
      },
      {
        "epoch": 1988,
        "reward": 0.4215519428253174,
        "val_loss": 0.0021111909300088882,
        "train_loss": 0.00215462228963868
      },
      {
        "epoch": 1989,
        "reward": 0.45488429069519043,
        "val_loss": 0.0016101880631010448,
        "train_loss": 0.0019693095347555266
      },
      {
        "epoch": 1990,
        "reward": 0.4211655259132385,
        "val_loss": 0.002117894806100854,
        "train_loss": 0.0021407110437464258
      },
      {
        "epoch": 1991,
        "reward": 0.45082440972328186,
        "val_loss": 0.0016638290004006454,
        "train_loss": 0.0019794762304697474
      },
      {
        "epoch": 1992,
        "reward": 0.45251908898353577,
        "val_loss": 0.0016412134947521345,
        "train_loss": 0.00190422603414985
      },
      {
        "epoch": 1993,
        "reward": 0.4441869854927063,
        "val_loss": 0.0017556046368554235,
        "train_loss": 0.0019118912224747385
      },
      {
        "epoch": 1994,
        "reward": 0.4544818103313446,
        "val_loss": 0.001615423958615533,
        "train_loss": 0.0018989741276107873
      },
      {
        "epoch": 1995,
        "reward": 0.4309522211551666,
        "val_loss": 0.0019549707316660453,
        "train_loss": 0.0020671857413477623
      },
      {
        "epoch": 1996,
        "reward": 0.445526659488678,
        "val_loss": 0.0017366606209959304,
        "train_loss": 0.0024511964337971923
      },
      {
        "epoch": 1997,
        "reward": 0.42374739050865173,
        "val_loss": 0.0020735415496996473,
        "train_loss": 0.0024748122624049964
      },
      {
        "epoch": 1998,
        "reward": 0.4478355050086975,
        "val_loss": 0.0017045159890715564,
        "train_loss": 0.0023566038267185483
      },
      {
        "epoch": 1999,
        "reward": 0.43107128143310547,
        "val_loss": 0.0019530736608430743,
        "train_loss": 0.00206233165674628
      }
    ]
  }
}