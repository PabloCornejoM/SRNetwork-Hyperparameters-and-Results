{
  "experiment_info": {
    "experiment_name": "Nguyen-7",
    "dataset_name": "Nguyen-7",
    "timestamp": "2025-08-30T20:35:02.590677",
    "random_seed": 43
  },
  "model_config": {
    "input_size": 1,
    "output_size": 1,
    "num_layers": 3,
    "nonlinear_info": [
      [
        3,
        0
      ],
      [
        1,
        0
      ],
      [
        0,
        0
      ]
    ],
    "function_set": [
      "SafeIdentityFunction",
      "SafeExp",
      "SafeLog",
      "SafeSin",
      "SafePower",
      "SafeCos",
      "ExpSwitchActivation"
    ]
  },
  "training_config": {
    "num_epochs": 2000,
    "batch_size": 32,
    "learning_rate": 0.001,
    "reg_strength": 0.0,
    "scheduler": "none"
  },
  "final_equation": {
    "equation_string": "Matrix([[0.858225*log(0.987590670585632*x1**0.000783712 + 1.46921038627625*x1 + 2.57978248596191*x1**2.89823)]])",
    "equation_latex": "Matrix([[0.858225*log(0.987590670585632*x1**0.000783712 + 1.46921038627625*x1 + 2.57978248596191*x1**2.89823)]])"
  },
  "evaluation_metrics": {
    "mse": "2.3343595e-05",
    "rmse": "0.004831521",
    "mae": "0.0041676923"
  },
  "data_info": {
    "train_ratio": 0.8,
    "uncertainty_value": 0.0,
    "path_to_data": "/Users/pablocornejo/Documents/Tesis/SRNetwork/data/raw/nguyen.txt"
  },
  "lbfgs_optimization": {
    "enabled": true,
    "success": true,
    "message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
    "function_evaluations": 12,
    "gradient_evaluations": 12,
    "final_loss": 0.005956308690647358,
    "max_iterations": 1000,
    "tolerance": "1e-8",
    "criterion": "nrmse"
  },
  "lbfgs_topk_optimization": {
    "enabled": true,
    "num_models_optimized": 5,
    "optimization_summary": [
      {
        "rank": 1,
        "original_epoch": 358,
        "original_val_loss": 2.318949892859174e-05,
        "optimized_val_loss": "2.3343595e-05",
        "improvement_percent": "-0.6645063",
        "original_equation": "Matrix([[0.857968*log(0.987578928470612*x1**0.000789452 + 1.46918869018555*x1 + 2.57976293563843*x1**2.8982)]])",
        "optimized_equation": "Matrix([[0.858225*log(0.987590670585632*x1**0.000783712 + 1.46921038627625*x1 + 2.57978248596191*x1**2.89823)]])",
        "optimization_success": true,
        "function_evaluations": 12,
        "final_loss": 0.005956308690647358
      },
      {
        "rank": 2,
        "original_epoch": 359,
        "original_val_loss": 2.3110089387046173e-05,
        "optimized_val_loss": "2.352515e-05",
        "improvement_percent": "-1.7960148",
        "original_equation": "Matrix([[0.858316*log(0.987623035907745*x1**0.000601327 + 1.46988272666931*x1 + 2.57914781570435*x1**2.89709)]])",
        "optimized_equation": "Matrix([[0.858501*log(0.987569808959961*x1**0.000693889 + 1.46989500522614*x1 + 2.57915329933167*x1**2.89712)]])",
        "optimization_success": true,
        "function_evaluations": 9,
        "final_loss": 0.005908652600575327
      },
      {
        "rank": 3,
        "original_epoch": 356,
        "original_val_loss": 2.307571516472048e-05,
        "optimized_val_loss": "2.3593006e-05",
        "improvement_percent": "-2.2417057",
        "original_equation": "Matrix([[0.857963*log(0.988135635852814*x1**0.000861177 + 1.46833086013794*x1 + 2.58163022994995*x1**2.89819)]])",
        "optimized_equation": "Matrix([[0.857963*log(0.988135635852814*x1**0.000861177 + 1.46833086013794*x1 + 2.58163022994995*x1**2.89819)]])",
        "optimization_success": true,
        "function_evaluations": 10,
        "final_loss": 0.005991912792237957
      },
      {
        "rank": 4,
        "original_epoch": 354,
        "original_val_loss": 2.310109916184696e-05,
        "optimized_val_loss": "2.3624434e-05",
        "improvement_percent": "-2.265408",
        "original_equation": "Matrix([[0.857998*log(0.988538384437561*x1**0.00101618 + 1.46745920181274*x1 + 2.58348274230957*x1**2.89842)]])",
        "optimized_equation": "Matrix([[0.857998*log(0.988535284996033*x1**0.0010181 + 1.46746325492859*x1 + 2.58347988128662*x1**2.89842)]])",
        "optimization_success": true,
        "function_evaluations": 7,
        "final_loss": 0.005960774964905261
      },
      {
        "rank": 5,
        "original_epoch": 360,
        "original_val_loss": 2.3244547784478137e-05,
        "optimized_val_loss": "2.3714463e-05",
        "improvement_percent": "-2.021618",
        "original_equation": "Matrix([[0.858712*log(0.986929714679718*x1**0.000623767 + 1.4700608253479*x1 + 2.57838320732117*x1**2.89951)]])",
        "optimized_equation": "Matrix([[0.858712*log(0.986929714679718*x1**0.000623767 + 1.4700608253479*x1 + 2.57838320732117*x1**2.89951)]])",
        "optimization_success": true,
        "function_evaluations": 10,
        "final_loss": 0.00598261852315005
      }
    ],
    "best_model": {
      "original_val_loss": 2.318949892859174e-05,
      "optimized_val_loss": "2.3343595e-05",
      "improvement_percent": "-0.6645063",
      "equation": "Matrix([[0.858225*log(0.987590670585632*x1**0.000783712 + 1.46921038627625*x1 + 2.57978248596191*x1**2.89823)]])",
      "optimization_iterations": 2
    }
  },
  "reward_tracking": {
    "reward_type": "nrmse",
    "reward_interval": 1,
    "num_measurements": 2000,
    "initial_reward": 0.08441073447465897,
    "final_reward": 0.4629538655281067,
    "best_reward": 0.9435831904411316,
    "worst_reward": 0.08441073447465897,
    "average_reward": 0.42209396419674156,
    "reward_history": [
      {
        "epoch": 0,
        "reward": 0.08441073447465897,
        "val_loss": 0.7594592017786843,
        "train_loss": 0.9499746922117013
      },
      {
        "epoch": 1,
        "reward": 0.08662741631269455,
        "val_loss": 0.7176019975117275,
        "train_loss": 0.8011220601888803
      },
      {
        "epoch": 2,
        "reward": 0.08873122930526733,
        "val_loss": 0.6808295590536935,
        "train_loss": 0.7597509287297726
      },
      {
        "epoch": 3,
        "reward": 0.09085563570261002,
        "val_loss": 0.6463391355105809,
        "train_loss": 0.7341843201563909
      },
      {
        "epoch": 4,
        "reward": 0.09301546216011047,
        "val_loss": 0.6137448762144361,
        "train_loss": 0.6815103107633499
      },
      {
        "epoch": 5,
        "reward": 0.0949433222413063,
        "val_loss": 0.5865717317376818,
        "train_loss": 0.6481790714539014
      },
      {
        "epoch": 6,
        "reward": 0.09671329706907272,
        "val_loss": 0.5630893366677421,
        "train_loss": 0.6203123219311237
      },
      {
        "epoch": 7,
        "reward": 0.09852434694766998,
        "val_loss": 0.5404050584350314,
        "train_loss": 0.5943608321249485
      },
      {
        "epoch": 8,
        "reward": 0.10034520924091339,
        "val_loss": 0.5188680993659156,
        "train_loss": 0.6067122943126239
      },
      {
        "epoch": 9,
        "reward": 0.10218284279108047,
        "val_loss": 0.49833139564309803,
        "train_loss": 0.5462526426865504
      },
      {
        "epoch": 10,
        "reward": 0.10397540777921677,
        "val_loss": 0.4793769142457417,
        "train_loss": 0.5257480640250903
      },
      {
        "epoch": 11,
        "reward": 0.10577412694692612,
        "val_loss": 0.4613537149769919,
        "train_loss": 0.7225567480692496
      },
      {
        "epoch": 12,
        "reward": 0.10754100233316422,
        "val_loss": 0.44455630651542116,
        "train_loss": 0.4973772706893774
      },
      {
        "epoch": 13,
        "reward": 0.10939183086156845,
        "val_loss": 0.4278601918901716,
        "train_loss": 0.46691985858174473
      },
      {
        "epoch": 14,
        "reward": 0.11122269928455353,
        "val_loss": 0.4121900349855423,
        "train_loss": 0.44933685230521053
      },
      {
        "epoch": 15,
        "reward": 0.11306847631931305,
        "val_loss": 0.3971874713897705,
        "train_loss": 0.43415549569405043
      },
      {
        "epoch": 16,
        "reward": 0.11489162594079971,
        "val_loss": 0.3831021189689636,
        "train_loss": 0.41740419214161545
      },
      {
        "epoch": 17,
        "reward": 0.1168360710144043,
        "val_loss": 0.36883077238287243,
        "train_loss": 0.40978066565898746
      },
      {
        "epoch": 18,
        "reward": 0.1188494935631752,
        "val_loss": 0.35481663261141094,
        "train_loss": 0.38709676595261466
      },
      {
        "epoch": 19,
        "reward": 0.12088626623153687,
        "val_loss": 0.3413772444639887,
        "train_loss": 0.39759452125200856
      },
      {
        "epoch": 20,
        "reward": 0.12305575609207153,
        "val_loss": 0.32782232974256786,
        "train_loss": 0.35675502554155314
      },
      {
        "epoch": 21,
        "reward": 0.12527430057525635,
        "val_loss": 0.31471554402794155,
        "train_loss": 0.34278297438644445
      },
      {
        "epoch": 22,
        "reward": 0.1275804340839386,
        "val_loss": 0.3018430077603885,
        "train_loss": 0.3291957818258267
      },
      {
        "epoch": 23,
        "reward": 0.12996670603752136,
        "val_loss": 0.28927174849169596,
        "train_loss": 0.31511015717226726
      },
      {
        "epoch": 24,
        "reward": 0.13243134319782257,
        "val_loss": 0.27702857341085163,
        "train_loss": 0.3914042877463194
      },
      {
        "epoch": 25,
        "reward": 0.13513097167015076,
        "val_loss": 0.26441697776317596,
        "train_loss": 0.28829361799244696
      },
      {
        "epoch": 26,
        "reward": 0.1379421055316925,
        "val_loss": 0.2521027794906071,
        "train_loss": 0.27408179311225045
      },
      {
        "epoch": 27,
        "reward": 0.1410072296857834,
        "val_loss": 0.2395491504243442,
        "train_loss": 0.26094569659863526
      },
      {
        "epoch": 28,
        "reward": 0.14410239458084106,
        "val_loss": 0.2277191967836448,
        "train_loss": 0.24753359225220406
      },
      {
        "epoch": 29,
        "reward": 0.1476312130689621,
        "val_loss": 0.21517764191542352,
        "train_loss": 0.23528295741058314
      },
      {
        "epoch": 30,
        "reward": 0.1514197289943695,
        "val_loss": 0.2027306051126548,
        "train_loss": 0.2220261558317221
      },
      {
        "epoch": 31,
        "reward": 0.15550172328948975,
        "val_loss": 0.19038183082427299,
        "train_loss": 0.20993357352339304
      },
      {
        "epoch": 32,
        "reward": 0.1599218100309372,
        "val_loss": 0.178123983421496,
        "train_loss": 0.1943151138794537
      },
      {
        "epoch": 33,
        "reward": 0.16458748281002045,
        "val_loss": 0.16630552017263003,
        "train_loss": 0.19044914770011717
      },
      {
        "epoch": 34,
        "reward": 0.1698852926492691,
        "val_loss": 0.15412140877119132,
        "train_loss": 0.23470149002969265
      },
      {
        "epoch": 35,
        "reward": 0.17557093501091003,
        "val_loss": 0.142331083172134,
        "train_loss": 0.15568117503649914
      },
      {
        "epoch": 36,
        "reward": 0.18151487410068512,
        "val_loss": 0.1312488799116441,
        "train_loss": 0.143443493763558
      },
      {
        "epoch": 37,
        "reward": 0.18738985061645508,
        "val_loss": 0.12138658043529306,
        "train_loss": 0.13173980082725534
      },
      {
        "epoch": 38,
        "reward": 0.19421611726284027,
        "val_loss": 0.11111304004277502,
        "train_loss": 0.12134055302550013
      },
      {
        "epoch": 39,
        "reward": 0.20150421559810638,
        "val_loss": 0.10136206621038062,
        "train_loss": 0.11102461501454505
      },
      {
        "epoch": 40,
        "reward": 0.20836897194385529,
        "val_loss": 0.0931703947218401,
        "train_loss": 0.1014027543580876
      },
      {
        "epoch": 41,
        "reward": 0.21677179634571075,
        "val_loss": 0.08426932524889708,
        "train_loss": 0.09233677306642327
      },
      {
        "epoch": 42,
        "reward": 0.22505488991737366,
        "val_loss": 0.07653559112389173,
        "train_loss": 0.08361701676263832
      },
      {
        "epoch": 43,
        "reward": 0.23387129604816437,
        "val_loss": 0.06927046405949763,
        "train_loss": 0.07531100101018987
      },
      {
        "epoch": 44,
        "reward": 0.24330928921699524,
        "val_loss": 0.06243353117523449,
        "train_loss": 0.0683800781575533
      },
      {
        "epoch": 45,
        "reward": 0.2528410255908966,
        "val_loss": 0.056367571565455625,
        "train_loss": 0.06121274138677808
      },
      {
        "epoch": 46,
        "reward": 0.26263877749443054,
        "val_loss": 0.050879327613594275,
        "train_loss": 0.055189285919858284
      },
      {
        "epoch": 47,
        "reward": 0.27300548553466797,
        "val_loss": 0.045773910923994014,
        "train_loss": 0.04978342639962928
      },
      {
        "epoch": 48,
        "reward": 0.2830275297164917,
        "val_loss": 0.0414234220349629,
        "train_loss": 0.044655393629979626
      },
      {
        "epoch": 49,
        "reward": 0.2929854989051819,
        "val_loss": 0.03758918622042984,
        "train_loss": 0.04002857093627636
      },
      {
        "epoch": 50,
        "reward": 0.30406996607780457,
        "val_loss": 0.033812900323287716,
        "train_loss": 0.036168242482325204
      },
      {
        "epoch": 51,
        "reward": 0.3147129416465759,
        "val_loss": 0.03060654509213886,
        "train_loss": 0.0324206160439644
      },
      {
        "epoch": 52,
        "reward": 0.32569706439971924,
        "val_loss": 0.0276681964751333,
        "train_loss": 0.029289974548961394
      },
      {
        "epoch": 53,
        "reward": 0.33572956919670105,
        "val_loss": 0.02527021975921733,
        "train_loss": 0.02643544897168445
      },
      {
        "epoch": 54,
        "reward": 0.3470252454280853,
        "val_loss": 0.022854359138623943,
        "train_loss": 0.02412726104599782
      },
      {
        "epoch": 55,
        "reward": 0.3565426766872406,
        "val_loss": 0.0210239809738206,
        "train_loss": 0.021771419412778832
      },
      {
        "epoch": 56,
        "reward": 0.366301566362381,
        "val_loss": 0.019319067276748165,
        "train_loss": 0.0200451930734114
      },
      {
        "epoch": 57,
        "reward": 0.3746739625930786,
        "val_loss": 0.017980609188920686,
        "train_loss": 0.018200716509734496
      },
      {
        "epoch": 58,
        "reward": 0.38386863470077515,
        "val_loss": 0.01662953038300787,
        "train_loss": 0.016796741699531246
      },
      {
        "epoch": 59,
        "reward": 0.3919494152069092,
        "val_loss": 0.01553523394146136,
        "train_loss": 0.015593366025803754
      },
      {
        "epoch": 60,
        "reward": 0.39927297830581665,
        "val_loss": 0.014612109566639577,
        "train_loss": 0.014577395372236004
      },
      {
        "epoch": 61,
        "reward": 0.4068326950073242,
        "val_loss": 0.013722123079267996,
        "train_loss": 0.015327179356693076
      },
      {
        "epoch": 62,
        "reward": 0.4154684245586395,
        "val_loss": 0.012777279197637523,
        "train_loss": 0.012536811102388757
      },
      {
        "epoch": 63,
        "reward": 0.421540230512619,
        "val_loss": 0.01215532684831747,
        "train_loss": 0.012050717540730078
      },
      {
        "epoch": 64,
        "reward": 0.42650914192199707,
        "val_loss": 0.01167064396265362,
        "train_loss": 0.011387609939377468
      },
      {
        "epoch": 65,
        "reward": 0.4309091567993164,
        "val_loss": 0.011258749890008144,
        "train_loss": 0.010810896410615757
      },
      {
        "epoch": 66,
        "reward": 0.43476638197898865,
        "val_loss": 0.010910443030297756,
        "train_loss": 0.010385143062404286
      },
      {
        "epoch": 67,
        "reward": 0.4385632574558258,
        "val_loss": 0.01057877837281142,
        "train_loss": 0.010117051594604094
      },
      {
        "epoch": 68,
        "reward": 0.4420344829559326,
        "val_loss": 0.0102849183271506,
        "train_loss": 0.009862666009352185
      },
      {
        "epoch": 69,
        "reward": 0.44474950432777405,
        "val_loss": 0.01006109919399023,
        "train_loss": 0.009602984359774452
      },
      {
        "epoch": 70,
        "reward": 0.44756636023521423,
        "val_loss": 0.009834307478740811,
        "train_loss": 0.009295148920500651
      },
      {
        "epoch": 71,
        "reward": 0.4497818946838379,
        "val_loss": 0.009659712468939168,
        "train_loss": 0.009173759429429013
      },
      {
        "epoch": 72,
        "reward": 0.45200082659721375,
        "val_loss": 0.009488112592537488,
        "train_loss": 0.009091892208044346
      },
      {
        "epoch": 73,
        "reward": 0.453928142786026,
        "val_loss": 0.009341657560850893,
        "train_loss": 0.009518436183078358
      },
      {
        "epoch": 74,
        "reward": 0.4549880623817444,
        "val_loss": 0.009262120750333582,
        "train_loss": 0.00941045862586739
      },
      {
        "epoch": 75,
        "reward": 0.45616552233695984,
        "val_loss": 0.009174596485016602,
        "train_loss": 0.008572366316702055
      },
      {
        "epoch": 76,
        "reward": 0.45774778723716736,
        "val_loss": 0.009058340818488173,
        "train_loss": 0.009256509544614416
      },
      {
        "epoch": 77,
        "reward": 0.45876070857048035,
        "val_loss": 0.008984721930963653,
        "train_loss": 0.008548614730198797
      },
      {
        "epoch": 78,
        "reward": 0.45991450548171997,
        "val_loss": 0.008901626337319613,
        "train_loss": 0.008317550825617777
      },
      {
        "epoch": 79,
        "reward": 0.4608522057533264,
        "val_loss": 0.008834678347089462,
        "train_loss": 0.008261188290466985
      },
      {
        "epoch": 80,
        "reward": 0.46181854605674744,
        "val_loss": 0.008766238145264131,
        "train_loss": 0.008772180782845961
      },
      {
        "epoch": 81,
        "reward": 0.46253252029418945,
        "val_loss": 0.008716019535703319,
        "train_loss": 0.008250010513270704
      },
      {
        "epoch": 82,
        "reward": 0.463489830493927,
        "val_loss": 0.008649159954594714,
        "train_loss": 0.00819050242157223
      },
      {
        "epoch": 83,
        "reward": 0.4642680287361145,
        "val_loss": 0.008595203049480915,
        "train_loss": 0.008024793407037998
      },
      {
        "epoch": 84,
        "reward": 0.4649844765663147,
        "val_loss": 0.008545831511063235,
        "train_loss": 0.007970242939992343
      },
      {
        "epoch": 85,
        "reward": 0.4657432734966278,
        "val_loss": 0.00849386238093887,
        "train_loss": 0.007991026419823846
      },
      {
        "epoch": 86,
        "reward": 0.46638184785842896,
        "val_loss": 0.00845038119171347,
        "train_loss": 0.008065581187390937
      },
      {
        "epoch": 87,
        "reward": 0.46707797050476074,
        "val_loss": 0.008403244694428784,
        "train_loss": 0.007851696096902462
      },
      {
        "epoch": 88,
        "reward": 0.4676953852176666,
        "val_loss": 0.008361663802393846,
        "train_loss": 0.007922275063510124
      },
      {
        "epoch": 89,
        "reward": 0.46835634112358093,
        "val_loss": 0.008317390390272652,
        "train_loss": 0.007945924137647335
      },
      {
        "epoch": 90,
        "reward": 0.468910276889801,
        "val_loss": 0.008280465312834297,
        "train_loss": 0.008532803398198806
      },
      {
        "epoch": 91,
        "reward": 0.4692763388156891,
        "val_loss": 0.008256157394498587,
        "train_loss": 0.008475661618061937
      },
      {
        "epoch": 92,
        "reward": 0.46975040435791016,
        "val_loss": 0.008224789784955127,
        "train_loss": 0.00763921121639354
      },
      {
        "epoch": 93,
        "reward": 0.4705475866794586,
        "val_loss": 0.008172316875840937,
        "train_loss": 0.007614903069155004
      },
      {
        "epoch": 94,
        "reward": 0.47113513946533203,
        "val_loss": 0.008133863863934363,
        "train_loss": 0.0076511283673775885
      },
      {
        "epoch": 95,
        "reward": 0.4718400537967682,
        "val_loss": 0.008087973442992993,
        "train_loss": 0.007757802968486571
      },
      {
        "epoch": 96,
        "reward": 0.4726727604866028,
        "val_loss": 0.00803410807358367,
        "train_loss": 0.007599654079128344
      },
      {
        "epoch": 97,
        "reward": 0.4733700752258301,
        "val_loss": 0.007989286511604275,
        "train_loss": 0.007495129736176191
      },
      {
        "epoch": 98,
        "reward": 0.47400012612342834,
        "val_loss": 0.007949005446529813,
        "train_loss": 0.007524251284149404
      },
      {
        "epoch": 99,
        "reward": 0.47458550333976746,
        "val_loss": 0.007911771602396454,
        "train_loss": 0.007408434140066115
      },
      {
        "epoch": 100,
        "reward": 0.4752047657966614,
        "val_loss": 0.007872569940185972,
        "train_loss": 0.009093813150404738
      },
      {
        "epoch": 101,
        "reward": 0.4760045111179352,
        "val_loss": 0.007822246057912707,
        "train_loss": 0.007321386432382637
      },
      {
        "epoch": 102,
        "reward": 0.47665315866470337,
        "val_loss": 0.007781668798997998,
        "train_loss": 0.007407279112018072
      },
      {
        "epoch": 103,
        "reward": 0.4772888123989105,
        "val_loss": 0.007742112768547875,
        "train_loss": 0.007255674035360034
      },
      {
        "epoch": 104,
        "reward": 0.4780723750591278,
        "val_loss": 0.007693637761154345,
        "train_loss": 0.007177583618053736
      },
      {
        "epoch": 105,
        "reward": 0.4785919785499573,
        "val_loss": 0.007661661864923579,
        "train_loss": 0.007205756533389481
      },
      {
        "epoch": 106,
        "reward": 0.4792969226837158,
        "val_loss": 0.007618499054972615,
        "train_loss": 0.007082447610977956
      },
      {
        "epoch": 107,
        "reward": 0.479842871427536,
        "val_loss": 0.007585244885246668,
        "train_loss": 0.007203786992109739
      },
      {
        "epoch": 108,
        "reward": 0.48058366775512695,
        "val_loss": 0.0075403535073356965,
        "train_loss": 0.007132261552704642
      },
      {
        "epoch": 109,
        "reward": 0.4812285900115967,
        "val_loss": 0.007501492542879922,
        "train_loss": 0.007152460846835031
      },
      {
        "epoch": 110,
        "reward": 0.48197460174560547,
        "val_loss": 0.007456794447664704,
        "train_loss": 0.007070821987536664
      },
      {
        "epoch": 111,
        "reward": 0.48272982239723206,
        "val_loss": 0.007411822210997343,
        "train_loss": 0.006931468271292173
      },
      {
        "epoch": 112,
        "reward": 0.48331567645072937,
        "val_loss": 0.007377125855003085,
        "train_loss": 0.007611170670805642
      },
      {
        "epoch": 113,
        "reward": 0.48400506377220154,
        "val_loss": 0.007336510278816734,
        "train_loss": 0.006805860336149076
      },
      {
        "epoch": 114,
        "reward": 0.4848046898841858,
        "val_loss": 0.007289684078256998,
        "train_loss": 0.00679939822293818
      },
      {
        "epoch": 115,
        "reward": 0.4855210781097412,
        "val_loss": 0.007247987136776958,
        "train_loss": 0.007463880268355401
      },
      {
        "epoch": 116,
        "reward": 0.4860215187072754,
        "val_loss": 0.007219003579978432,
        "train_loss": 0.006696584782240769
      },
      {
        "epoch": 117,
        "reward": 0.48685070872306824,
        "val_loss": 0.007171241566538811,
        "train_loss": 0.006716316610646362
      },
      {
        "epoch": 118,
        "reward": 0.4878250062465668,
        "val_loss": 0.007115525459604604,
        "train_loss": 0.006648076156405016
      },
      {
        "epoch": 119,
        "reward": 0.48863789439201355,
        "val_loss": 0.007069379191047379,
        "train_loss": 0.0065908136804444855
      },
      {
        "epoch": 120,
        "reward": 0.48933741450309753,
        "val_loss": 0.007029909574027572,
        "train_loss": 0.006514702900578693
      },
      {
        "epoch": 121,
        "reward": 0.49025240540504456,
        "val_loss": 0.006978615652769804,
        "train_loss": 0.0071866469045814415
      },
      {
        "epoch": 122,
        "reward": 0.49093738198280334,
        "val_loss": 0.006940467515960336,
        "train_loss": 0.006505176048869124
      },
      {
        "epoch": 123,
        "reward": 0.4918924868106842,
        "val_loss": 0.006887620481263314,
        "train_loss": 0.007060835379748964
      },
      {
        "epoch": 124,
        "reward": 0.492603600025177,
        "val_loss": 0.006848540589479464,
        "train_loss": 0.006408721916019344
      },
      {
        "epoch": 125,
        "reward": 0.4935309886932373,
        "val_loss": 0.006797907242019262,
        "train_loss": 0.006634075302057541
      },
      {
        "epoch": 126,
        "reward": 0.49448099732398987,
        "val_loss": 0.006746433109843305,
        "train_loss": 0.006334490321863156
      },
      {
        "epoch": 127,
        "reward": 0.49553123116493225,
        "val_loss": 0.0066899823557053295,
        "train_loss": 0.00621095624676225
      },
      {
        "epoch": 128,
        "reward": 0.4962337017059326,
        "val_loss": 0.0066524890051888564,
        "train_loss": 0.006204314001549322
      },
      {
        "epoch": 129,
        "reward": 0.4974185526371002,
        "val_loss": 0.006589726045993822,
        "train_loss": 0.0065192492195190145
      },
      {
        "epoch": 130,
        "reward": 0.4982214570045471,
        "val_loss": 0.006547536268564207,
        "train_loss": 0.006254893235074213
      },
      {
        "epoch": 131,
        "reward": 0.4993308186531067,
        "val_loss": 0.006489680115399616,
        "train_loss": 0.006643106319153538
      },
      {
        "epoch": 132,
        "reward": 0.5006676316261292,
        "val_loss": 0.006420649987246309,
        "train_loss": 0.005984006037649054
      },
      {
        "epoch": 133,
        "reward": 0.5015196204185486,
        "val_loss": 0.006377033922555191,
        "train_loss": 0.005934604596964514
      },
      {
        "epoch": 134,
        "reward": 0.5025851726531982,
        "val_loss": 0.00632290099747479,
        "train_loss": 0.005987143314156968
      },
      {
        "epoch": 135,
        "reward": 0.5035850405693054,
        "val_loss": 0.006272526890305536,
        "train_loss": 0.006005245735510611
      },
      {
        "epoch": 136,
        "reward": 0.5045682787895203,
        "val_loss": 0.006223378303859915,
        "train_loss": 0.006494173242782171
      },
      {
        "epoch": 137,
        "reward": 0.5056725740432739,
        "val_loss": 0.006168636194031153,
        "train_loss": 0.005764770679748976
      },
      {
        "epoch": 138,
        "reward": 0.5067943334579468,
        "val_loss": 0.006113516931821193,
        "train_loss": 0.007325441272069628
      },
      {
        "epoch": 139,
        "reward": 0.507853627204895,
        "val_loss": 0.006061917303928307,
        "train_loss": 0.005624618532377868
      },
      {
        "epoch": 140,
        "reward": 0.5089818835258484,
        "val_loss": 0.006007433070668152,
        "train_loss": 0.006318044284573541
      },
      {
        "epoch": 141,
        "reward": 0.5102376937866211,
        "val_loss": 0.005947356844054801,
        "train_loss": 0.005632192648660678
      },
      {
        "epoch": 142,
        "reward": 0.5114489793777466,
        "val_loss": 0.005889978293063385,
        "train_loss": 0.00613404990424617
      },
      {
        "epoch": 143,
        "reward": 0.5123466849327087,
        "val_loss": 0.005847804680732744,
        "train_loss": 0.005956590596514826
      },
      {
        "epoch": 144,
        "reward": 0.5134004354476929,
        "val_loss": 0.005798684133748923,
        "train_loss": 0.005374902189942077
      },
      {
        "epoch": 145,
        "reward": 0.514734148979187,
        "val_loss": 0.005737092711829713,
        "train_loss": 0.005603743887219865
      },
      {
        "epoch": 146,
        "reward": 0.5156134963035583,
        "val_loss": 0.005696841848215887,
        "train_loss": 0.005283997629213935
      },
      {
        "epoch": 147,
        "reward": 0.5168759226799011,
        "val_loss": 0.005639532880325403,
        "train_loss": 0.005251648956730675
      },
      {
        "epoch": 148,
        "reward": 0.5184463262557983,
        "val_loss": 0.005569039411576731,
        "train_loss": 0.005485727281596225
      },
      {
        "epoch": 149,
        "reward": 0.5194124579429626,
        "val_loss": 0.005526101449504495,
        "train_loss": 0.005177932934692273
      },
      {
        "epoch": 150,
        "reward": 0.5208080410957336,
        "val_loss": 0.005464646865480712,
        "train_loss": 0.005060488864378735
      },
      {
        "epoch": 151,
        "reward": 0.5221769213676453,
        "val_loss": 0.005405020534193942,
        "train_loss": 0.0051161076049678605
      },
      {
        "epoch": 152,
        "reward": 0.5234438180923462,
        "val_loss": 0.005350404119651232,
        "train_loss": 0.004970685256501803
      },
      {
        "epoch": 153,
        "reward": 0.5248326063156128,
        "val_loss": 0.005291150783055595,
        "train_loss": 0.004912605318867673
      },
      {
        "epoch": 154,
        "reward": 0.5261549949645996,
        "val_loss": 0.005235324879842145,
        "train_loss": 0.004969198579111924
      },
      {
        "epoch": 155,
        "reward": 0.527624785900116,
        "val_loss": 0.0051739532167890245,
        "train_loss": 0.004850816702506004
      },
      {
        "epoch": 156,
        "reward": 0.528796374797821,
        "val_loss": 0.005125526937523058,
        "train_loss": 0.004758827879693574
      },
      {
        "epoch": 157,
        "reward": 0.5302388072013855,
        "val_loss": 0.005066518971164312,
        "train_loss": 0.004700450543448544
      },
      {
        "epoch": 158,
        "reward": 0.5316547751426697,
        "val_loss": 0.00500923501593726,
        "train_loss": 0.00495230363538632
      },
      {
        "epoch": 159,
        "reward": 0.5330412983894348,
        "val_loss": 0.004953744787988918,
        "train_loss": 0.004665686919067342
      },
      {
        "epoch": 160,
        "reward": 0.5345410108566284,
        "val_loss": 0.004894397919997573,
        "train_loss": 0.00467264476733712
      },
      {
        "epoch": 161,
        "reward": 0.5357625484466553,
        "val_loss": 0.004846566057364855,
        "train_loss": 0.004509267585000578
      },
      {
        "epoch": 162,
        "reward": 0.5377067923545837,
        "val_loss": 0.004771363222971559,
        "train_loss": 0.00455985193212445
      },
      {
        "epoch": 163,
        "reward": 0.5392049551010132,
        "val_loss": 0.004714180748643619,
        "train_loss": 0.004389911052735092
      },
      {
        "epoch": 164,
        "reward": 0.5405017733573914,
        "val_loss": 0.004665216763636896,
        "train_loss": 0.004388275010009797
      },
      {
        "epoch": 165,
        "reward": 0.5421282649040222,
        "val_loss": 0.004604493766756994,
        "train_loss": 0.004284589402721814
      },
      {
        "epoch": 166,
        "reward": 0.5437244176864624,
        "val_loss": 0.004545641397791249,
        "train_loss": 0.004270603719095771
      },
      {
        "epoch": 167,
        "reward": 0.545395016670227,
        "val_loss": 0.004484814708121121,
        "train_loss": 0.004182805452728644
      },
      {
        "epoch": 168,
        "reward": 0.5467989444732666,
        "val_loss": 0.00443429804207491,
        "train_loss": 0.004114395808056333
      },
      {
        "epoch": 169,
        "reward": 0.5484606623649597,
        "val_loss": 0.004375206472884331,
        "train_loss": 0.004071868727735888
      },
      {
        "epoch": 170,
        "reward": 0.5499997138977051,
        "val_loss": 0.0043211474216410094,
        "train_loss": 0.004019883753454241
      },
      {
        "epoch": 171,
        "reward": 0.551853597164154,
        "val_loss": 0.004256870747277779,
        "train_loss": 0.003959342433098265
      },
      {
        "epoch": 172,
        "reward": 0.5534283518791199,
        "val_loss": 0.004202985088340938,
        "train_loss": 0.004132414259052334
      },
      {
        "epoch": 173,
        "reward": 0.5551759600639343,
        "val_loss": 0.004143941798247397,
        "train_loss": 0.00388001049689662
      },
      {
        "epoch": 174,
        "reward": 0.5569541454315186,
        "val_loss": 0.00408466807233968,
        "train_loss": 0.0038591782660939945
      },
      {
        "epoch": 175,
        "reward": 0.5587084889411926,
        "val_loss": 0.004026976580332432,
        "train_loss": 0.003890969280081873
      },
      {
        "epoch": 176,
        "reward": 0.5606164336204529,
        "val_loss": 0.003965103832472648,
        "train_loss": 0.003703383800502007
      },
      {
        "epoch": 177,
        "reward": 0.5623325705528259,
        "val_loss": 0.003910214606938618,
        "train_loss": 0.0038233935573281576
      },
      {
        "epoch": 178,
        "reward": 0.5640200972557068,
        "val_loss": 0.003856935105951769,
        "train_loss": 0.003982273615502681
      },
      {
        "epoch": 179,
        "reward": 0.5656436085700989,
        "val_loss": 0.003806318056636623,
        "train_loss": 0.0037061474196469556
      },
      {
        "epoch": 180,
        "reward": 0.5676363706588745,
        "val_loss": 0.003745039093441197,
        "train_loss": 0.003505844873591111
      },
      {
        "epoch": 181,
        "reward": 0.5698023438453674,
        "val_loss": 0.0036794759133564575,
        "train_loss": 0.0034216612176141306
      },
      {
        "epoch": 182,
        "reward": 0.5717915892601013,
        "val_loss": 0.0036202077088611467,
        "train_loss": 0.003766141921425095
      },
      {
        "epoch": 183,
        "reward": 0.5737385749816895,
        "val_loss": 0.003563053656502494,
        "train_loss": 0.003304506690376194
      },
      {
        "epoch": 184,
        "reward": 0.5760883688926697,
        "val_loss": 0.003495191689580679,
        "train_loss": 0.0039063709734294275
      },
      {
        "epoch": 185,
        "reward": 0.5784187912940979,
        "val_loss": 0.0034290690340899994,
        "train_loss": 0.0034399720607325435
      },
      {
        "epoch": 186,
        "reward": 0.5808090567588806,
        "val_loss": 0.0033624477052528945,
        "train_loss": 0.003499054923080481
      },
      {
        "epoch": 187,
        "reward": 0.582558810710907,
        "val_loss": 0.003314434367764209,
        "train_loss": 0.003432251217488486
      },
      {
        "epoch": 188,
        "reward": 0.5845165252685547,
        "val_loss": 0.00326146135505821,
        "train_loss": 0.0031136837832701322
      },
      {
        "epoch": 189,
        "reward": 0.5870991945266724,
        "val_loss": 0.0031927653388785465,
        "train_loss": 0.003011794113822711
      },
      {
        "epoch": 190,
        "reward": 0.5891178846359253,
        "val_loss": 0.0031399926603106515,
        "train_loss": 0.002921053921454586
      },
      {
        "epoch": 191,
        "reward": 0.591484546661377,
        "val_loss": 0.0030791336071810554,
        "train_loss": 0.0028735468698029695
      },
      {
        "epoch": 192,
        "reward": 0.5935847163200378,
        "val_loss": 0.0030260291283151935,
        "train_loss": 0.0028851515917967144
      },
      {
        "epoch": 193,
        "reward": 0.5962369441986084,
        "val_loss": 0.002960149814108653,
        "train_loss": 0.0028198826386450003
      },
      {
        "epoch": 194,
        "reward": 0.598258912563324,
        "val_loss": 0.0029108021574627075,
        "train_loss": 0.0029231581720523536
      },
      {
        "epoch": 195,
        "reward": 0.6005377769470215,
        "val_loss": 0.002856072204719697,
        "train_loss": 0.002827511867508292
      },
      {
        "epoch": 196,
        "reward": 0.6024192571640015,
        "val_loss": 0.0028115869499742985,
        "train_loss": 0.0029178413320690966
      },
      {
        "epoch": 197,
        "reward": 0.6049095988273621,
        "val_loss": 0.0027536605152168442,
        "train_loss": 0.0025937838766437312
      },
      {
        "epoch": 198,
        "reward": 0.6073195338249207,
        "val_loss": 0.0026986245481696513,
        "train_loss": 0.002736290016820511
      },
      {
        "epoch": 199,
        "reward": 0.6097473502159119,
        "val_loss": 0.0026441767529052284,
        "train_loss": 0.002474842512478622
      },
      {
        "epoch": 200,
        "reward": 0.6125637292861938,
        "val_loss": 0.002582239203288087,
        "train_loss": 0.003291454596015123
      },
      {
        "epoch": 201,
        "reward": 0.6152631640434265,
        "val_loss": 0.0025240867398679256,
        "train_loss": 0.002449931070889131
      },
      {
        "epoch": 202,
        "reward": 0.618108868598938,
        "val_loss": 0.0024640398332849145,
        "train_loss": 0.0025970327193275667
      },
      {
        "epoch": 203,
        "reward": 0.620832085609436,
        "val_loss": 0.002407761531815465,
        "train_loss": 0.002279518870636821
      },
      {
        "epoch": 204,
        "reward": 0.6231738924980164,
        "val_loss": 0.002360270358622074,
        "train_loss": 0.002226142595575836
      },
      {
        "epoch": 205,
        "reward": 0.6256746649742126,
        "val_loss": 0.0023104666698990123,
        "train_loss": 0.002205407121576942
      },
      {
        "epoch": 206,
        "reward": 0.62856125831604,
        "val_loss": 0.0022541231010109186,
        "train_loss": 0.002150577087797081
      },
      {
        "epoch": 207,
        "reward": 0.6310378909111023,
        "val_loss": 0.0022067403021667686,
        "train_loss": 0.002098755754279689
      },
      {
        "epoch": 208,
        "reward": 0.6335014700889587,
        "val_loss": 0.0021604662262169378,
        "train_loss": 0.002044817096947764
      },
      {
        "epoch": 209,
        "reward": 0.6358997225761414,
        "val_loss": 0.002116231364198029,
        "train_loss": 0.0019847797940691146
      },
      {
        "epoch": 210,
        "reward": 0.6388576626777649,
        "val_loss": 0.0020627526100724936,
        "train_loss": 0.0019812482059933245
      },
      {
        "epoch": 211,
        "reward": 0.6411646008491516,
        "val_loss": 0.002021853978346501,
        "train_loss": 0.0019826961126035224
      },
      {
        "epoch": 212,
        "reward": 0.6442370414733887,
        "val_loss": 0.0019684688554012348,
        "train_loss": 0.0018677720318709572
      },
      {
        "epoch": 213,
        "reward": 0.6468881964683533,
        "val_loss": 0.0019233770435675979,
        "train_loss": 0.0018310585986070621
      },
      {
        "epoch": 214,
        "reward": 0.6497573852539062,
        "val_loss": 0.0018755731455582594,
        "train_loss": 0.0017939620861747803
      },
      {
        "epoch": 215,
        "reward": 0.6525093913078308,
        "val_loss": 0.0018306752733354057,
        "train_loss": 0.0017255197632878732
      },
      {
        "epoch": 216,
        "reward": 0.6555268168449402,
        "val_loss": 0.0017824961437976786,
        "train_loss": 0.002571613071128153
      },
      {
        "epoch": 217,
        "reward": 0.656290590763092,
        "val_loss": 0.001770471505421613,
        "train_loss": 0.001716890777550781
      },
      {
        "epoch": 218,
        "reward": 0.6611770987510681,
        "val_loss": 0.0016951510000840894,
        "train_loss": 0.001645210667307905
      },
      {
        "epoch": 219,
        "reward": 0.6647489070892334,
        "val_loss": 0.0016418116034141608,
        "train_loss": 0.0015694515621782136
      },
      {
        "epoch": 220,
        "reward": 0.6676222681999207,
        "val_loss": 0.0015999297611415386,
        "train_loss": 0.0015331239130598707
      },
      {
        "epoch": 221,
        "reward": 0.6703839898109436,
        "val_loss": 0.0015605144768155047,
        "train_loss": 0.001638357453675081
      },
      {
        "epoch": 222,
        "reward": 0.6733543276786804,
        "val_loss": 0.0015190241309548064,
        "train_loss": 0.0014368030701566918
      },
      {
        "epoch": 223,
        "reward": 0.6767475008964539,
        "val_loss": 0.0014727497764397413,
        "train_loss": 0.0014141394214955373
      },
      {
        "epoch": 224,
        "reward": 0.679577112197876,
        "val_loss": 0.0014350525868524397,
        "train_loss": 0.0013847671731267697
      },
      {
        "epoch": 225,
        "reward": 0.6826831698417664,
        "val_loss": 0.0013945897475683264,
        "train_loss": 0.0013242647419596883
      },
      {
        "epoch": 226,
        "reward": 0.6853926777839661,
        "val_loss": 0.001360057366712551,
        "train_loss": 0.001285921514723808
      },
      {
        "epoch": 227,
        "reward": 0.6886423826217651,
        "val_loss": 0.0013195627210994384,
        "train_loss": 0.001271337125217542
      },
      {
        "epoch": 228,
        "reward": 0.6913178563117981,
        "val_loss": 0.0012869626973822182,
        "train_loss": 0.0012335641143950992
      },
      {
        "epoch": 229,
        "reward": 0.6942540407180786,
        "val_loss": 0.0012519386655185372,
        "train_loss": 0.001328531474707863
      },
      {
        "epoch": 230,
        "reward": 0.6974405646324158,
        "val_loss": 0.0012148011134870882,
        "train_loss": 0.001149548917125615
      },
      {
        "epoch": 231,
        "reward": 0.7009827494621277,
        "val_loss": 0.0011745627021550068,
        "train_loss": 0.0011100708831970852
      },
      {
        "epoch": 232,
        "reward": 0.7044218182563782,
        "val_loss": 0.0011365209938958287,
        "train_loss": 0.0010805133774388547
      },
      {
        "epoch": 233,
        "reward": 0.7075153589248657,
        "val_loss": 0.0011031459518043058,
        "train_loss": 0.001043020951258838
      },
      {
        "epoch": 234,
        "reward": 0.7107149958610535,
        "val_loss": 0.0010694473832180457,
        "train_loss": 0.0010280343054686314
      },
      {
        "epoch": 235,
        "reward": 0.7139655947685242,
        "val_loss": 0.001036049665084907,
        "train_loss": 0.0009913311480956438
      },
      {
        "epoch": 236,
        "reward": 0.7171322703361511,
        "val_loss": 0.001004307302147416,
        "train_loss": 0.0009684609932054838
      },
      {
        "epoch": 237,
        "reward": 0.7204920649528503,
        "val_loss": 0.0009714672965596297,
        "train_loss": 0.000991514510063168
      },
      {
        "epoch": 238,
        "reward": 0.7239622473716736,
        "val_loss": 0.0009384341039029616,
        "train_loss": 0.0008930358926241192
      },
      {
        "epoch": 239,
        "reward": 0.7273539304733276,
        "val_loss": 0.0009069962543435395,
        "train_loss": 0.0009133020536794972
      },
      {
        "epoch": 240,
        "reward": 0.7306472063064575,
        "val_loss": 0.0008772547818287941,
        "train_loss": 0.0008430770814391928
      },
      {
        "epoch": 241,
        "reward": 0.7343038320541382,
        "val_loss": 0.0008451178312368159,
        "train_loss": 0.0008073701870811279
      },
      {
        "epoch": 242,
        "reward": 0.7372779250144958,
        "val_loss": 0.0008196515596604773,
        "train_loss": 0.0008774253062885971
      },
      {
        "epoch": 243,
        "reward": 0.7413310408592224,
        "val_loss": 0.0007858918439264276,
        "train_loss": 0.0008044178774490809
      },
      {
        "epoch": 244,
        "reward": 0.7452888488769531,
        "val_loss": 0.0007539547306285905,
        "train_loss": 0.000830208717021518
      },
      {
        "epoch": 245,
        "reward": 0.7485529780387878,
        "val_loss": 0.000728360447932833,
        "train_loss": 0.0007224861295141566
      },
      {
        "epoch": 246,
        "reward": 0.7526375651359558,
        "val_loss": 0.0006972595354974535,
        "train_loss": 0.0006685580228804611
      },
      {
        "epoch": 247,
        "reward": 0.756066620349884,
        "val_loss": 0.0006719253786806283,
        "train_loss": 0.0006454831631204938
      },
      {
        "epoch": 248,
        "reward": 0.759427011013031,
        "val_loss": 0.0006477691432727235,
        "train_loss": 0.0006197015186794138
      },
      {
        "epoch": 249,
        "reward": 0.7628313899040222,
        "val_loss": 0.0006239583578592699,
        "train_loss": 0.0006368921290581616
      },
      {
        "epoch": 250,
        "reward": 0.7662206292152405,
        "val_loss": 0.0006009013886796311,
        "train_loss": 0.000585665059938597
      },
      {
        "epoch": 251,
        "reward": 0.7702203392982483,
        "val_loss": 0.0005745023039967886,
        "train_loss": 0.0005560503886954393
      },
      {
        "epoch": 252,
        "reward": 0.7732570171356201,
        "val_loss": 0.0005550324463651382,
        "train_loss": 0.0005337627338191781
      },
      {
        "epoch": 253,
        "reward": 0.7771744132041931,
        "val_loss": 0.0005306298439141496,
        "train_loss": 0.0005241349337246412
      },
      {
        "epoch": 254,
        "reward": 0.780712366104126,
        "val_loss": 0.000509265496345636,
        "train_loss": 0.0004922776153342476
      },
      {
        "epoch": 255,
        "reward": 0.7841851115226746,
        "val_loss": 0.0004889045334753714,
        "train_loss": 0.00047131757645939407
      },
      {
        "epoch": 256,
        "reward": 0.7878448963165283,
        "val_loss": 0.000468084351658555,
        "train_loss": 0.0004531537116026112
      },
      {
        "epoch": 257,
        "reward": 0.7916709184646606,
        "val_loss": 0.0004470014651555435,
        "train_loss": 0.00043433721454605873
      },
      {
        "epoch": 258,
        "reward": 0.795066773891449,
        "val_loss": 0.00042886028989284696,
        "train_loss": 0.0004652731250434254
      },
      {
        "epoch": 259,
        "reward": 0.7987884879112244,
        "val_loss": 0.00040958161116577685,
        "train_loss": 0.00039870009333334077
      },
      {
        "epoch": 260,
        "reward": 0.8025863766670227,
        "val_loss": 0.0003905429642015536,
        "train_loss": 0.00038290320816696086
      },
      {
        "epoch": 261,
        "reward": 0.8060757517814636,
        "val_loss": 0.00037360335928886864,
        "train_loss": 0.0003627875171769819
      },
      {
        "epoch": 262,
        "reward": 0.8097741007804871,
        "val_loss": 0.0003562129183722261,
        "train_loss": 0.0003480039026629428
      },
      {
        "epoch": 263,
        "reward": 0.8131633996963501,
        "val_loss": 0.00034077398491457904,
        "train_loss": 0.0003379514265151766
      },
      {
        "epoch": 264,
        "reward": 0.8167849779129028,
        "val_loss": 0.00032479167774519216,
        "train_loss": 0.0003190418104238163
      },
      {
        "epoch": 265,
        "reward": 0.8203983306884766,
        "val_loss": 0.00030936395653822856,
        "train_loss": 0.0003023723757695944
      },
      {
        "epoch": 266,
        "reward": 0.8236077427864075,
        "val_loss": 0.00029608535987790674,
        "train_loss": 0.000329746033597845
      },
      {
        "epoch": 267,
        "reward": 0.8272979855537415,
        "val_loss": 0.0002812995995295101,
        "train_loss": 0.0002745928586591617
      },
      {
        "epoch": 268,
        "reward": 0.8312214016914368,
        "val_loss": 0.0002661335965967737,
        "train_loss": 0.0002615862839307353
      },
      {
        "epoch": 269,
        "reward": 0.8345737457275391,
        "val_loss": 0.000253616639903547,
        "train_loss": 0.00025045382538407395
      },
      {
        "epoch": 270,
        "reward": 0.8381896018981934,
        "val_loss": 0.0002405619686344705,
        "train_loss": 0.00024171064349222713
      },
      {
        "epoch": 271,
        "reward": 0.8417057394981384,
        "val_loss": 0.00022830132054098482,
        "train_loss": 0.0002602108887423618
      },
      {
        "epoch": 272,
        "reward": 0.8444180488586426,
        "val_loss": 0.00021912985175731592,
        "train_loss": 0.00021440219167673675
      },
      {
        "epoch": 273,
        "reward": 0.8484558463096619,
        "val_loss": 0.00020592949294950813,
        "train_loss": 0.00021487928559229028
      },
      {
        "epoch": 274,
        "reward": 0.8521167635917664,
        "val_loss": 0.00019441876117655608,
        "train_loss": 0.00019467789511159377
      },
      {
        "epoch": 275,
        "reward": 0.8555585145950317,
        "val_loss": 0.0001839850644630912,
        "train_loss": 0.00018435745117200824
      },
      {
        "epoch": 276,
        "reward": 0.8586120009422302,
        "val_loss": 0.0001750369618613539,
        "train_loss": 0.0001855294606055115
      },
      {
        "epoch": 277,
        "reward": 0.8620462417602539,
        "val_loss": 0.00016531200890312903,
        "train_loss": 0.00018999461211093987
      },
      {
        "epoch": 278,
        "reward": 0.8646937608718872,
        "val_loss": 0.00015805546718183905,
        "train_loss": 0.00015918291823114626
      },
      {
        "epoch": 279,
        "reward": 0.8684787154197693,
        "val_loss": 0.00014803760937606318,
        "train_loss": 0.00014729598192913656
      },
      {
        "epoch": 280,
        "reward": 0.8719149827957153,
        "val_loss": 0.00013929864144301973,
        "train_loss": 0.00014517567755179838
      },
      {
        "epoch": 281,
        "reward": 0.8745431900024414,
        "val_loss": 0.0001328386263464511,
        "train_loss": 0.00014201631865244752
      },
      {
        "epoch": 282,
        "reward": 0.8776444792747498,
        "val_loss": 0.00012546082923238697,
        "train_loss": 0.0001268484833277538
      },
      {
        "epoch": 283,
        "reward": 0.8809317946434021,
        "val_loss": 0.00011792487930506468,
        "train_loss": 0.0001195644266632511
      },
      {
        "epoch": 284,
        "reward": 0.8837874531745911,
        "val_loss": 0.00011161148229023508,
        "train_loss": 0.00011293014115555986
      },
      {
        "epoch": 285,
        "reward": 0.8865610361099243,
        "val_loss": 0.0001056832310756103,
        "train_loss": 0.00011632445812910401
      },
      {
        "epoch": 286,
        "reward": 0.8889108896255493,
        "val_loss": 0.0001008149229164701,
        "train_loss": 0.00010187066212753192
      },
      {
        "epoch": 287,
        "reward": 0.8918853998184204,
        "val_loss": 9.485261580266524e-05,
        "train_loss": 9.93828981126381e-05
      },
      {
        "epoch": 288,
        "reward": 0.8944675326347351,
        "val_loss": 8.985472153913829e-05,
        "train_loss": 9.154362662509532e-05
      },
      {
        "epoch": 289,
        "reward": 0.8971366882324219,
        "val_loss": 8.485985251484505e-05,
        "train_loss": 8.906694123512492e-05
      },
      {
        "epoch": 290,
        "reward": 0.8995426297187805,
        "val_loss": 8.050426419816046e-05,
        "train_loss": 8.283421063354651e-05
      },
      {
        "epoch": 291,
        "reward": 0.9019045233726501,
        "val_loss": 7.636171773940857e-05,
        "train_loss": 7.899231199049749e-05
      },
      {
        "epoch": 292,
        "reward": 0.9038749933242798,
        "val_loss": 7.300523871630762e-05,
        "train_loss": 7.562458505652522e-05
      },
      {
        "epoch": 293,
        "reward": 0.9061428904533386,
        "val_loss": 6.925308766117919e-05,
        "train_loss": 7.280696761077146e-05
      },
      {
        "epoch": 294,
        "reward": 0.9081816673278809,
        "val_loss": 6.597990406070104e-05,
        "train_loss": 6.815851545875026e-05
      },
      {
        "epoch": 295,
        "reward": 0.9106362462043762,
        "val_loss": 6.21629276013534e-05,
        "train_loss": 6.643447075195861e-05
      },
      {
        "epoch": 296,
        "reward": 0.9124364852905273,
        "val_loss": 5.944830939240221e-05,
        "train_loss": 6.300284195066734e-05
      },
      {
        "epoch": 297,
        "reward": 0.9141697883605957,
        "val_loss": 5.69016678387665e-05,
        "train_loss": 6.886109230645861e-05
      },
      {
        "epoch": 298,
        "reward": 0.9162468314170837,
        "val_loss": 5.393570817042408e-05,
        "train_loss": 5.6825438290476224e-05
      },
      {
        "epoch": 299,
        "reward": 0.9180159568786621,
        "val_loss": 5.148208869546319e-05,
        "train_loss": 5.3769262229672255e-05
      },
      {
        "epoch": 300,
        "reward": 0.9199978113174438,
        "val_loss": 4.8812175269371695e-05,
        "train_loss": 5.4025095988226196e-05
      },
      {
        "epoch": 301,
        "reward": 0.9211260676383972,
        "val_loss": 4.732893389050982e-05,
        "train_loss": 4.986887898457308e-05
      },
      {
        "epoch": 302,
        "reward": 0.9229939579963684,
        "val_loss": 4.493142997879269e-05,
        "train_loss": 4.8596484912895205e-05
      },
      {
        "epoch": 303,
        "reward": 0.9244711995124817,
        "val_loss": 4.3086068347162965e-05,
        "train_loss": 4.686604706176485e-05
      },
      {
        "epoch": 304,
        "reward": 0.925691545009613,
        "val_loss": 4.159514095850422e-05,
        "train_loss": 4.484917210972456e-05
      },
      {
        "epoch": 305,
        "reward": 0.9264848828315735,
        "val_loss": 4.0642057293942866e-05,
        "train_loss": 4.2349820367130284e-05
      },
      {
        "epoch": 306,
        "reward": 0.9279912114143372,
        "val_loss": 3.886710484428997e-05,
        "train_loss": 4.089852630456265e-05
      },
      {
        "epoch": 307,
        "reward": 0.9285721182823181,
        "val_loss": 3.819471021415666e-05,
        "train_loss": 4.6236062609330896e-05
      },
      {
        "epoch": 308,
        "reward": 0.9305042624473572,
        "val_loss": 3.6006355263193e-05,
        "train_loss": 3.905247033869203e-05
      },
      {
        "epoch": 309,
        "reward": 0.9312662482261658,
        "val_loss": 3.5163390618566025e-05,
        "train_loss": 3.724912879149018e-05
      },
      {
        "epoch": 310,
        "reward": 0.9323508143424988,
        "val_loss": 3.398323133296799e-05,
        "train_loss": 4.09257891078596e-05
      },
      {
        "epoch": 311,
        "reward": 0.9333247542381287,
        "val_loss": 3.294297493994236e-05,
        "train_loss": 3.519051410176662e-05
      },
      {
        "epoch": 312,
        "reward": 0.9341921806335449,
        "val_loss": 3.203177090784136e-05,
        "train_loss": 3.371788056938385e-05
      },
      {
        "epoch": 313,
        "reward": 0.9348194003105164,
        "val_loss": 3.1381963188843133e-05,
        "train_loss": 3.250118199651717e-05
      },
      {
        "epoch": 314,
        "reward": 0.9355401992797852,
        "val_loss": 3.064446380968937e-05,
        "train_loss": 3.628347041320432e-05
      },
      {
        "epoch": 315,
        "reward": 0.9360548257827759,
        "val_loss": 3.0123924131787915e-05,
        "train_loss": 3.272033630379995e-05
      },
      {
        "epoch": 316,
        "reward": 0.9369352459907532,
        "val_loss": 2.9245028209905805e-05,
        "train_loss": 3.157119079752682e-05
      },
      {
        "epoch": 317,
        "reward": 0.9374584555625916,
        "val_loss": 2.872979738250641e-05,
        "train_loss": 3.0905083664178026e-05
      },
      {
        "epoch": 318,
        "reward": 0.9370642900466919,
        "val_loss": 2.9117517572428498e-05,
        "train_loss": 3.0590568852718345e-05
      },
      {
        "epoch": 319,
        "reward": 0.9382944107055664,
        "val_loss": 2.791707239729086e-05,
        "train_loss": 3.0474778073907008e-05
      },
      {
        "epoch": 320,
        "reward": 0.9384055137634277,
        "val_loss": 2.7810015516089542e-05,
        "train_loss": 3.023807746033596e-05
      },
      {
        "epoch": 321,
        "reward": 0.9387205243110657,
        "val_loss": 2.7507806277883772e-05,
        "train_loss": 2.96581348755773e-05
      },
      {
        "epoch": 322,
        "reward": 0.9394347071647644,
        "val_loss": 2.6829540989378336e-05,
        "train_loss": 2.8295021867673033e-05
      },
      {
        "epoch": 323,
        "reward": 0.9390673637390137,
        "val_loss": 2.7177189622307196e-05,
        "train_loss": 2.8089969628826322e-05
      },
      {
        "epoch": 324,
        "reward": 0.9395624399185181,
        "val_loss": 2.6709249660988072e-05,
        "train_loss": 2.819654998977337e-05
      },
      {
        "epoch": 325,
        "reward": 0.9400647282600403,
        "val_loss": 2.623906038934365e-05,
        "train_loss": 2.6753418401662762e-05
      },
      {
        "epoch": 326,
        "reward": 0.9401745200157166,
        "val_loss": 2.613689581007098e-05,
        "train_loss": 2.7761427470697807e-05
      },
      {
        "epoch": 327,
        "reward": 0.9400650262832642,
        "val_loss": 2.623875323999008e-05,
        "train_loss": 2.8328439349514574e-05
      },
      {
        "epoch": 328,
        "reward": 0.9401007890701294,
        "val_loss": 2.6205457938236316e-05,
        "train_loss": 2.695976574894023e-05
      },
      {
        "epoch": 329,
        "reward": 0.9410433769226074,
        "val_loss": 2.533630660244463e-05,
        "train_loss": 2.780744125630008e-05
      },
      {
        "epoch": 330,
        "reward": 0.9400593638420105,
        "val_loss": 2.6244001803986195e-05,
        "train_loss": 2.8570716005141057e-05
      },
      {
        "epoch": 331,
        "reward": 0.9411675333976746,
        "val_loss": 2.522306931496132e-05,
        "train_loss": 2.7412361865012477e-05
      },
      {
        "epoch": 332,
        "reward": 0.9414898157119751,
        "val_loss": 2.4930482790555937e-05,
        "train_loss": 2.6086376972391288e-05
      },
      {
        "epoch": 333,
        "reward": 0.9414198994636536,
        "val_loss": 2.4993745423021858e-05,
        "train_loss": 2.592014065947104e-05
      },
      {
        "epoch": 334,
        "reward": 0.9406324625015259,
        "val_loss": 2.571323992534807e-05,
        "train_loss": 2.768087345500065e-05
      },
      {
        "epoch": 335,
        "reward": 0.9421125650405884,
        "val_loss": 2.43703366972373e-05,
        "train_loss": 2.764120206568175e-05
      },
      {
        "epoch": 336,
        "reward": 0.9420356154441833,
        "val_loss": 2.4439201817066142e-05,
        "train_loss": 2.5956311989060712e-05
      },
      {
        "epoch": 337,
        "reward": 0.942115306854248,
        "val_loss": 2.4367819215902792e-05,
        "train_loss": 2.6286137164368902e-05
      },
      {
        "epoch": 338,
        "reward": 0.9413914084434509,
        "val_loss": 2.5019602617248893e-05,
        "train_loss": 2.469378105948076e-05
      },
      {
        "epoch": 339,
        "reward": 0.9419633150100708,
        "val_loss": 2.4503912624952916e-05,
        "train_loss": 2.5321231497890458e-05
      },
      {
        "epoch": 340,
        "reward": 0.9416640400886536,
        "val_loss": 2.4773024051683024e-05,
        "train_loss": 2.492338919724856e-05
      },
      {
        "epoch": 341,
        "reward": 0.9423527121543884,
        "val_loss": 2.4156267370147232e-05,
        "train_loss": 2.4848484512264033e-05
      },
      {
        "epoch": 342,
        "reward": 0.9424919486045837,
        "val_loss": 2.4032607013525974e-05,
        "train_loss": 2.5115137689751395e-05
      },
      {
        "epoch": 343,
        "reward": 0.9427621960639954,
        "val_loss": 2.3793634682078846e-05,
        "train_loss": 2.5098971701271905e-05
      },
      {
        "epoch": 344,
        "reward": 0.9426621794700623,
        "val_loss": 2.3881871519344194e-05,
        "train_loss": 2.557377180122645e-05
      },
      {
        "epoch": 345,
        "reward": 0.9418474435806274,
        "val_loss": 2.460794946403309e-05,
        "train_loss": 2.5198168749249398e-05
      },
      {
        "epoch": 346,
        "reward": 0.9420491456985474,
        "val_loss": 2.442707825269151e-05,
        "train_loss": 2.4932155525903e-05
      },
      {
        "epoch": 347,
        "reward": 0.9427533149719238,
        "val_loss": 2.3801447761278333e-05,
        "train_loss": 2.561549612997064e-05
      },
      {
        "epoch": 348,
        "reward": 0.942629337310791,
        "val_loss": 2.3910934812322792e-05,
        "train_loss": 2.4924207606930464e-05
      },
      {
        "epoch": 349,
        "reward": 0.9431638121604919,
        "val_loss": 2.3440901973767074e-05,
        "train_loss": 2.596546724257328e-05
      },
      {
        "epoch": 350,
        "reward": 0.9432057738304138,
        "val_loss": 2.3404274543281645e-05,
        "train_loss": 2.3704224741567697e-05
      },
      {
        "epoch": 351,
        "reward": 0.9429295659065247,
        "val_loss": 2.3646201952942647e-05,
        "train_loss": 2.5659313625790393e-05
      },
      {
        "epoch": 352,
        "reward": 0.9430331587791443,
        "val_loss": 2.355532186421832e-05,
        "train_loss": 2.4457168854916326e-05
      },
      {
        "epoch": 353,
        "reward": 0.9430883526802063,
        "val_loss": 2.3506934927094596e-05,
        "train_loss": 2.5312244360975455e-05
      },
      {
        "epoch": 354,
        "reward": 0.9435539245605469,
        "val_loss": 2.310109916184696e-05,
        "train_loss": 2.4068845242744337e-05
      },
      {
        "epoch": 355,
        "reward": 0.9431838393211365,
        "val_loss": 2.3423350804867888e-05,
        "train_loss": 2.339219134866583e-05
      },
      {
        "epoch": 356,
        "reward": 0.9435831904411316,
        "val_loss": 2.307571516472048e-05,
        "train_loss": 2.3442196309658288e-05
      },
      {
        "epoch": 357,
        "reward": 0.9430083632469177,
        "val_loss": 2.3577070481094e-05,
        "train_loss": 2.3520281781832007e-05
      },
      {
        "epoch": 358,
        "reward": 0.9434521794319153,
        "val_loss": 2.318949892859174e-05,
        "train_loss": 2.4132867005951433e-05
      },
      {
        "epoch": 359,
        "reward": 0.943543553352356,
        "val_loss": 2.3110089387046173e-05,
        "train_loss": 2.434775090548031e-05
      },
      {
        "epoch": 360,
        "reward": 0.9433888792991638,
        "val_loss": 2.3244547784478137e-05,
        "train_loss": 2.4263815388481955e-05
      },
      {
        "epoch": 361,
        "reward": 0.9420650601387024,
        "val_loss": 2.4412852975988892e-05,
        "train_loss": 2.3544128173223446e-05
      },
      {
        "epoch": 362,
        "reward": 0.9433590173721313,
        "val_loss": 2.3270531788252162e-05,
        "train_loss": 2.455824208552188e-05
      },
      {
        "epoch": 363,
        "reward": 0.10776245594024658,
        "val_loss": 0.44251134778772083,
        "train_loss": 0.3544358331749978
      },
      {
        "epoch": 364,
        "reward": 0.112046979367733,
        "val_loss": 0.4053946627037866,
        "train_loss": 0.46117139564683807
      },
      {
        "epoch": 365,
        "reward": 0.11491753160953522,
        "val_loss": 0.3829070265804018,
        "train_loss": 0.42530946207877535
      },
      {
        "epoch": 366,
        "reward": 0.11736571043729782,
        "val_loss": 0.36507120515619007,
        "train_loss": 0.41554427490784573
      },
      {
        "epoch": 367,
        "reward": 0.12035079300403595,
        "val_loss": 0.34484151005744934,
        "train_loss": 0.3811015374958515
      },
      {
        "epoch": 368,
        "reward": 0.12127470970153809,
        "val_loss": 0.3388942213995116,
        "train_loss": 0.3684954757963379
      },
      {
        "epoch": 369,
        "reward": 0.12344861030578613,
        "val_loss": 0.3254473273243223,
        "train_loss": 0.3839022505741853
      },
      {
        "epoch": 370,
        "reward": 0.12542763352394104,
        "val_loss": 0.31383649898426874,
        "train_loss": 0.34323314326600385
      },
      {
        "epoch": 371,
        "reward": 0.12646161019802094,
        "val_loss": 0.30799594415085657,
        "train_loss": 0.3345053475529242
      },
      {
        "epoch": 372,
        "reward": 0.12819549441337585,
        "val_loss": 0.29853212726967676,
        "train_loss": 0.3261437721263904
      },
      {
        "epoch": 373,
        "reward": 0.12939518690109253,
        "val_loss": 0.2922161945274898,
        "train_loss": 0.3163802026090427
      },
      {
        "epoch": 374,
        "reward": 0.13054588437080383,
        "val_loss": 0.28632904482739313,
        "train_loss": 0.3134290070201342
      },
      {
        "epoch": 375,
        "reward": 0.13214492797851562,
        "val_loss": 0.2784145548939705,
        "train_loss": 0.30360999488486695
      },
      {
        "epoch": 376,
        "reward": 0.13309957087039948,
        "val_loss": 0.2738315686583519,
        "train_loss": 0.29737909434613985
      },
      {
        "epoch": 377,
        "reward": 0.1343878209590912,
        "val_loss": 0.2678091089640345,
        "train_loss": 0.28978290679291463
      },
      {
        "epoch": 378,
        "reward": 0.13551928102970123,
        "val_loss": 0.2626678576426847,
        "train_loss": 0.28631511301948476
      },
      {
        "epoch": 379,
        "reward": 0.13626611232757568,
        "val_loss": 0.25934778845735956,
        "train_loss": 0.2788589611561791
      },
      {
        "epoch": 380,
        "reward": 0.1374918818473816,
        "val_loss": 0.2540215887129307,
        "train_loss": 0.27482171134593397
      },
      {
        "epoch": 381,
        "reward": 0.13850322365760803,
        "val_loss": 0.24973878636956215,
        "train_loss": 0.272189096476023
      },
      {
        "epoch": 382,
        "reward": 0.13946235179901123,
        "val_loss": 0.24576736081923758,
        "train_loss": 0.27531560539053035
      },
      {
        "epoch": 383,
        "reward": 0.1408008188009262,
        "val_loss": 0.24036748866949761,
        "train_loss": 0.2582007323608895
      },
      {
        "epoch": 384,
        "reward": 0.1416298747062683,
        "val_loss": 0.23710343401346887,
        "train_loss": 0.2537261167940764
      },
      {
        "epoch": 385,
        "reward": 0.14249205589294434,
        "val_loss": 0.2337724683540208,
        "train_loss": 0.2502395022356023
      },
      {
        "epoch": 386,
        "reward": 0.14309541881084442,
        "val_loss": 0.23147918922560556,
        "train_loss": 0.2663352721585677
      },
      {
        "epoch": 387,
        "reward": 0.14408619701862335,
        "val_loss": 0.22777900472283363,
        "train_loss": 0.24317584826405017
      },
      {
        "epoch": 388,
        "reward": 0.14453409612178802,
        "val_loss": 0.22613257701907838,
        "train_loss": 0.24084278652078586
      },
      {
        "epoch": 389,
        "reward": 0.14541640877723694,
        "val_loss": 0.22293624494756972,
        "train_loss": 0.23982930011474168
      },
      {
        "epoch": 390,
        "reward": 0.14633594453334808,
        "val_loss": 0.219669798122985,
        "train_loss": 0.23529824485572484
      },
      {
        "epoch": 391,
        "reward": 0.1463710218667984,
        "val_loss": 0.21954649633594922,
        "train_loss": 0.23376209014419985
      },
      {
        "epoch": 392,
        "reward": 0.14732161164283752,
        "val_loss": 0.2162399542118822,
        "train_loss": 0.23090751427942172
      },
      {
        "epoch": 393,
        "reward": 0.14825288951396942,
        "val_loss": 0.2130656758589404,
        "train_loss": 0.22715754765354526
      },
      {
        "epoch": 394,
        "reward": 0.14890922605991364,
        "val_loss": 0.2108662107161113,
        "train_loss": 0.23261073503929836
      },
      {
        "epoch": 395,
        "reward": 0.1498427838087082,
        "val_loss": 0.20779026140059745,
        "train_loss": 0.22132766083597324
      },
      {
        "epoch": 396,
        "reward": 0.1503109484910965,
        "val_loss": 0.2062705441245011,
        "train_loss": 0.21855788312565821
      },
      {
        "epoch": 397,
        "reward": 0.151067852973938,
        "val_loss": 0.20384508211697852,
        "train_loss": 0.21758348903117272
      },
      {
        "epoch": 398,
        "reward": 0.15148460865020752,
        "val_loss": 0.20252602068441256,
        "train_loss": 0.21492494873774165
      },
      {
        "epoch": 399,
        "reward": 0.15232610702514648,
        "val_loss": 0.1998974989567484,
        "train_loss": 0.2139250974242504
      },
      {
        "epoch": 400,
        "reward": 0.1526511162519455,
        "val_loss": 0.1988945472985506,
        "train_loss": 0.21137125267145726
      },
      {
        "epoch": 401,
        "reward": 0.15337932109832764,
        "val_loss": 0.19667197577655315,
        "train_loss": 0.20805267422558524
      },
      {
        "epoch": 402,
        "reward": 0.15373583137989044,
        "val_loss": 0.19559603370726109,
        "train_loss": 0.20676622459779118
      },
      {
        "epoch": 403,
        "reward": 0.15460991859436035,
        "val_loss": 0.19299138550247466,
        "train_loss": 0.20518415983623037
      },
      {
        "epoch": 404,
        "reward": 0.15528272092342377,
        "val_loss": 0.19101826048323087,
        "train_loss": 0.20184858145120627
      },
      {
        "epoch": 405,
        "reward": 0.15537217259407043,
        "val_loss": 0.19075797524835383,
        "train_loss": 0.2021857864724902
      },
      {
        "epoch": 406,
        "reward": 0.15613697469234467,
        "val_loss": 0.18855184369853564,
        "train_loss": 0.20968565774651673
      },
      {
        "epoch": 407,
        "reward": 0.1569616198539734,
        "val_loss": 0.18621136487594672,
        "train_loss": 0.1972460373519705
      },
      {
        "epoch": 408,
        "reward": 0.1574183702468872,
        "val_loss": 0.18493175506591797,
        "train_loss": 0.19535371918419303
      },
      {
        "epoch": 409,
        "reward": 0.15811462700366974,
        "val_loss": 0.18300382074500834,
        "train_loss": 0.19853577920450613
      },
      {
        "epoch": 410,
        "reward": 0.15886610746383667,
        "val_loss": 0.18095316338751996,
        "train_loss": 0.19128270780381101
      },
      {
        "epoch": 411,
        "reward": 0.15951739251613617,
        "val_loss": 0.1792007458529302,
        "train_loss": 0.18923916219948575
      },
      {
        "epoch": 412,
        "reward": 0.15968307852745056,
        "val_loss": 0.17875855203185761,
        "train_loss": 0.18758787711759886
      },
      {
        "epoch": 413,
        "reward": 0.16000643372535706,
        "val_loss": 0.17789979119385993,
        "train_loss": 0.18751900943999106
      },
      {
        "epoch": 414,
        "reward": 0.16089697182178497,
        "val_loss": 0.17556312520589148,
        "train_loss": 0.18557678521252596
      },
      {
        "epoch": 415,
        "reward": 0.16134965419769287,
        "val_loss": 0.17439105760838305,
        "train_loss": 0.1833283810500199
      },
      {
        "epoch": 416,
        "reward": 0.16142818331718445,
        "val_loss": 0.17418878552104747,
        "train_loss": 0.18317758438822168
      },
      {
        "epoch": 417,
        "reward": 0.16214518249034882,
        "val_loss": 0.17235654965043068,
        "train_loss": 0.18178266136181684
      },
      {
        "epoch": 418,
        "reward": 0.16277217864990234,
        "val_loss": 0.17077541191663062,
        "train_loss": 0.18078306238525188
      },
      {
        "epoch": 419,
        "reward": 0.16272512078285217,
        "val_loss": 0.17089342139661312,
        "train_loss": 0.17982441191158544
      },
      {
        "epoch": 420,
        "reward": 0.16352927684783936,
        "val_loss": 0.16889190008597715,
        "train_loss": 0.1867794989106747
      },
      {
        "epoch": 421,
        "reward": 0.16437938809394836,
        "val_loss": 0.16680996465895856,
        "train_loss": 0.1753461574598287
      },
      {
        "epoch": 422,
        "reward": 0.16487358510494232,
        "val_loss": 0.16561537289193698,
        "train_loss": 0.17398454753968579
      },
      {
        "epoch": 423,
        "reward": 0.16547270119190216,
        "val_loss": 0.16418246632175787,
        "train_loss": 0.17419585721710554
      },
      {
        "epoch": 424,
        "reward": 0.1656680554151535,
        "val_loss": 0.1637187823653221,
        "train_loss": 0.17377928483228272
      },
      {
        "epoch": 425,
        "reward": 0.16604650020599365,
        "val_loss": 0.16282556152769498,
        "train_loss": 0.17195536826665586
      },
      {
        "epoch": 426,
        "reward": 0.1671077460050583,
        "val_loss": 0.16035515974674905,
        "train_loss": 0.16903201622279504
      },
      {
        "epoch": 427,
        "reward": 0.16771508753299713,
        "val_loss": 0.15896378484155452,
        "train_loss": 0.16661779626547985
      },
      {
        "epoch": 428,
        "reward": 0.16818682849407196,
        "val_loss": 0.15789417124220304,
        "train_loss": 0.16566606921752772
      },
      {
        "epoch": 429,
        "reward": 0.16847923398017883,
        "val_loss": 0.1572359874844551,
        "train_loss": 0.16515893048535174
      },
      {
        "epoch": 430,
        "reward": 0.16911490261554718,
        "val_loss": 0.1558176348251956,
        "train_loss": 0.1705118310279571
      },
      {
        "epoch": 431,
        "reward": 0.1697952002286911,
        "val_loss": 0.15431850509984152,
        "train_loss": 0.1619429977861448
      },
      {
        "epoch": 432,
        "reward": 0.17036674916744232,
        "val_loss": 0.15307387390307017,
        "train_loss": 0.16083947465253565
      },
      {
        "epoch": 433,
        "reward": 0.1709883064031601,
        "val_loss": 0.1517353957252843,
        "train_loss": 0.15932312016733563
      },
      {
        "epoch": 434,
        "reward": 0.17164070904254913,
        "val_loss": 0.15034718359155314,
        "train_loss": 0.15967521243370497
      },
      {
        "epoch": 435,
        "reward": 0.17177163064479828,
        "val_loss": 0.15007063427141734,
        "train_loss": 0.1565823356817978
      },
      {
        "epoch": 436,
        "reward": 0.17245610058307648,
        "val_loss": 0.14863579533994198,
        "train_loss": 0.1562332552902472
      },
      {
        "epoch": 437,
        "reward": 0.17321822047233582,
        "val_loss": 0.14705951006284781,
        "train_loss": 0.1547448683100251
      },
      {
        "epoch": 438,
        "reward": 0.17405053973197937,
        "val_loss": 0.14536328933068685,
        "train_loss": 0.15195425237750618
      },
      {
        "epoch": 439,
        "reward": 0.1742965131998062,
        "val_loss": 0.14486694442374365,
        "train_loss": 0.15142272205020374
      },
      {
        "epoch": 440,
        "reward": 0.17507068812847137,
        "val_loss": 0.143319415726832,
        "train_loss": 0.15046056675223204
      },
      {
        "epoch": 441,
        "reward": 0.17572779953479767,
        "val_loss": 0.1420230498271329,
        "train_loss": 0.3663934488565876
      },
      {
        "epoch": 442,
        "reward": 0.17639242112636566,
        "val_loss": 0.14072759050343717,
        "train_loss": 0.14725842130988334
      },
      {
        "epoch": 443,
        "reward": 0.17692124843597412,
        "val_loss": 0.1397079530039004,
        "train_loss": 0.1546193058244311
      },
      {
        "epoch": 444,
        "reward": 0.17758627235889435,
        "val_loss": 0.13843961166484015,
        "train_loss": 0.14497852970201236
      },
      {
        "epoch": 445,
        "reward": 0.1781407743692398,
        "val_loss": 0.13739363928990705,
        "train_loss": 0.1436437279290448
      },
      {
        "epoch": 446,
        "reward": 0.17869889736175537,
        "val_loss": 0.13635137757020338,
        "train_loss": 0.14865903155161783
      },
      {
        "epoch": 447,
        "reward": 0.17941956222057343,
        "val_loss": 0.13502094681773866,
        "train_loss": 0.14667947490054828
      },
      {
        "epoch": 448,
        "reward": 0.18003541231155396,
        "val_loss": 0.13389759457537107,
        "train_loss": 0.14535507473808068
      },
      {
        "epoch": 449,
        "reward": 0.18059146404266357,
        "val_loss": 0.13289387470909528,
        "train_loss": 0.13920456887437746
      },
      {
        "epoch": 450,
        "reward": 0.1813882440328598,
        "val_loss": 0.13147284223565034,
        "train_loss": 0.13815690157935023
      },
      {
        "epoch": 451,
        "reward": 0.18182750046253204,
        "val_loss": 0.13069801511509077,
        "train_loss": 0.1432217973499344
      },
      {
        "epoch": 452,
        "reward": 0.18233270943164825,
        "val_loss": 0.1298143080036555,
        "train_loss": 0.1353727397318625
      },
      {
        "epoch": 453,
        "reward": 0.18301230669021606,
        "val_loss": 0.1286378846104656,
        "train_loss": 0.13477300247177482
      },
      {
        "epoch": 454,
        "reward": 0.183641716837883,
        "val_loss": 0.1275608403874295,
        "train_loss": 0.1741089686178244
      },
      {
        "epoch": 455,
        "reward": 0.18430697917938232,
        "val_loss": 0.12643529142120055,
        "train_loss": 0.1320903494488448
      },
      {
        "epoch": 456,
        "reward": 0.18471769988536835,
        "val_loss": 0.12574693520686456,
        "train_loss": 0.188880166468712
      },
      {
        "epoch": 457,
        "reward": 0.18564455211162567,
        "val_loss": 0.12421155920518297,
        "train_loss": 0.13012611548093936
      },
      {
        "epoch": 458,
        "reward": 0.18618635833263397,
        "val_loss": 0.12332541402429342,
        "train_loss": 0.12846321202681127
      },
      {
        "epoch": 459,
        "reward": 0.18681928515434265,
        "val_loss": 0.12230076787195035,
        "train_loss": 0.12803791302184647
      },
      {
        "epoch": 460,
        "reward": 0.1875733584165573,
        "val_loss": 0.12109449066753898,
        "train_loss": 0.3300645576001933
      },
      {
        "epoch": 461,
        "reward": 0.18840095400810242,
        "val_loss": 0.11978853906371764,
        "train_loss": 0.12498618713736785
      },
      {
        "epoch": 462,
        "reward": 0.18891756236553192,
        "val_loss": 0.11898267934364933,
        "train_loss": 0.1241683683787974
      },
      {
        "epoch": 463,
        "reward": 0.18947647511959076,
        "val_loss": 0.11811882496944495,
        "train_loss": 0.1238733775770435
      },
      {
        "epoch": 464,
        "reward": 0.18990403413772583,
        "val_loss": 0.11746351780103785,
        "train_loss": 0.12340336228505923
      },
      {
        "epoch": 465,
        "reward": 0.190778911113739,
        "val_loss": 0.11613738017954997,
        "train_loss": 0.12178132875571744
      },
      {
        "epoch": 466,
        "reward": 0.19174359738826752,
        "val_loss": 0.11469778631414686,
        "train_loss": 0.12023841861922008
      },
      {
        "epoch": 467,
        "reward": 0.19248686730861664,
        "val_loss": 0.11360446363687515,
        "train_loss": 0.11917195569437283
      },
      {
        "epoch": 468,
        "reward": 0.19289113581180573,
        "val_loss": 0.11301552264818124,
        "train_loss": 0.11827616629978785
      },
      {
        "epoch": 469,
        "reward": 0.19318316876888275,
        "val_loss": 0.1125925670244864,
        "train_loss": 0.11796399001748516
      },
      {
        "epoch": 470,
        "reward": 0.19437669217586517,
        "val_loss": 0.1108853207635028,
        "train_loss": 0.11615906920857154
      },
      {
        "epoch": 471,
        "reward": 0.19496726989746094,
        "val_loss": 0.11005305591970682,
        "train_loss": 0.11479678857498445
      },
      {
        "epoch": 472,
        "reward": 0.19574348628520966,
        "val_loss": 0.10897150715546948,
        "train_loss": 0.11364839403764702
      },
      {
        "epoch": 473,
        "reward": 0.1964350789785385,
        "val_loss": 0.10801952398781266,
        "train_loss": 0.11299926200165199
      },
      {
        "epoch": 474,
        "reward": 0.19736480712890625,
        "val_loss": 0.10675676167011261,
        "train_loss": 0.11154970947581415
      },
      {
        "epoch": 475,
        "reward": 0.19798998534679413,
        "val_loss": 0.10591841475772006,
        "train_loss": 0.14871856290847063
      },
      {
        "epoch": 476,
        "reward": 0.1988295316696167,
        "val_loss": 0.10480608431888479,
        "train_loss": 0.10964986803726508
      },
      {
        "epoch": 477,
        "reward": 0.19890685379505157,
        "val_loss": 0.10470441968313285,
        "train_loss": 0.10931806798236302
      },
      {
        "epoch": 478,
        "reward": 0.19948197901248932,
        "val_loss": 0.1039521134059344,
        "train_loss": 0.1092003439911283
      },
      {
        "epoch": 479,
        "reward": 0.20056450366973877,
        "val_loss": 0.102555061158325,
        "train_loss": 0.10786801988545519
      },
      {
        "epoch": 480,
        "reward": 0.2014724314212799,
        "val_loss": 0.10140211095235177,
        "train_loss": 0.10601575144280034
      },
      {
        "epoch": 481,
        "reward": 0.20230849087238312,
        "val_loss": 0.10035526419856719,
        "train_loss": 0.10532531357155396
      },
      {
        "epoch": 482,
        "reward": 0.20268486440181732,
        "val_loss": 0.09988856967538595,
        "train_loss": 0.10406597031033016
      },
      {
        "epoch": 483,
        "reward": 0.2036135196685791,
        "val_loss": 0.09874906510646854,
        "train_loss": 0.10332002820303807
      },
      {
        "epoch": 484,
        "reward": 0.20412008464336395,
        "val_loss": 0.0981345625062074,
        "train_loss": 0.10247954520253608
      },
      {
        "epoch": 485,
        "reward": 0.2051197588443756,
        "val_loss": 0.09693640337458678,
        "train_loss": 0.10111986306023588
      },
      {
        "epoch": 486,
        "reward": 0.20589523017406464,
        "val_loss": 0.09601995521890265,
        "train_loss": 0.10001856232814205
      },
      {
        "epoch": 487,
        "reward": 0.20657216012477875,
        "val_loss": 0.09522911999374628,
        "train_loss": 0.09916520548554567
      },
      {
        "epoch": 488,
        "reward": 0.20731258392333984,
        "val_loss": 0.0943737133805241,
        "train_loss": 0.09834009065077855
      },
      {
        "epoch": 489,
        "reward": 0.20801568031311035,
        "val_loss": 0.09357062221637794,
        "train_loss": 0.09729646773149188
      },
      {
        "epoch": 490,
        "reward": 0.2087591141462326,
        "val_loss": 0.09273101588977235,
        "train_loss": 0.09750342809666808
      },
      {
        "epoch": 491,
        "reward": 0.20943613350391388,
        "val_loss": 0.09197487588971853,
        "train_loss": 0.12805344982860753
      },
      {
        "epoch": 492,
        "reward": 0.21008925139904022,
        "val_loss": 0.0912529191534434,
        "train_loss": 0.09482321461949211
      },
      {
        "epoch": 493,
        "reward": 0.2106812447309494,
        "val_loss": 0.09060486831835338,
        "train_loss": 0.09402733935838534
      },
      {
        "epoch": 494,
        "reward": 0.2114008218050003,
        "val_loss": 0.08982510824820825,
        "train_loss": 0.09351395571586461
      },
      {
        "epoch": 495,
        "reward": 0.21215040981769562,
        "val_loss": 0.08902198734826275,
        "train_loss": 0.0924798902661468
      },
      {
        "epoch": 496,
        "reward": 0.21290898323059082,
        "val_loss": 0.0882186410682542,
        "train_loss": 0.09167763625905187
      },
      {
        "epoch": 497,
        "reward": 0.21355603635311127,
        "val_loss": 0.08754077500530652,
        "train_loss": 0.09087959790933663
      },
      {
        "epoch": 498,
        "reward": 0.21427641808986664,
        "val_loss": 0.08679392541359578,
        "train_loss": 0.0902207793506722
      },
      {
        "epoch": 499,
        "reward": 0.21494343876838684,
        "val_loss": 0.08610968218584146,
        "train_loss": 0.08940278397606632
      },
      {
        "epoch": 500,
        "reward": 0.21566776931285858,
        "val_loss": 0.08537445589900017,
        "train_loss": 0.09210941843831769
      },
      {
        "epoch": 501,
        "reward": 0.21648259460926056,
        "val_loss": 0.08455704624897667,
        "train_loss": 0.08832760051322672
      },
      {
        "epoch": 502,
        "reward": 0.21716442704200745,
        "val_loss": 0.08388071327603289,
        "train_loss": 0.08748990270004679
      },
      {
        "epoch": 503,
        "reward": 0.21820349991321564,
        "val_loss": 0.08286333077454142,
        "train_loss": 0.08615874085360421
      },
      {
        "epoch": 504,
        "reward": 0.21868419647216797,
        "val_loss": 0.08239802778033274,
        "train_loss": 0.1007772320881486
      },
      {
        "epoch": 505,
        "reward": 0.21955373883247375,
        "val_loss": 0.08156480500474572,
        "train_loss": 0.08453696246328125
      },
      {
        "epoch": 506,
        "reward": 0.22018824517726898,
        "val_loss": 0.08096360634746295,
        "train_loss": 0.08421155821102169
      },
      {
        "epoch": 507,
        "reward": 0.22082968056201935,
        "val_loss": 0.08036156577457275,
        "train_loss": 0.0832367722026762
      },
      {
        "epoch": 508,
        "reward": 0.2216031402349472,
        "val_loss": 0.0796432294882834,
        "train_loss": 0.08270295245501284
      },
      {
        "epoch": 509,
        "reward": 0.22233079373836517,
        "val_loss": 0.07897490016849977,
        "train_loss": 0.08402423793449998
      },
      {
        "epoch": 510,
        "reward": 0.2232598066329956,
        "val_loss": 0.07813198072835803,
        "train_loss": 0.08101786641502538
      },
      {
        "epoch": 511,
        "reward": 0.22378309071063995,
        "val_loss": 0.07766227637018476,
        "train_loss": 0.08028661951762982
      },
      {
        "epoch": 512,
        "reward": 0.22458863258361816,
        "val_loss": 0.07694620645738073,
        "train_loss": 0.07977544838146199
      },
      {
        "epoch": 513,
        "reward": 0.2252420037984848,
        "val_loss": 0.07637159193732909,
        "train_loss": 0.07909856966356389
      },
      {
        "epoch": 514,
        "reward": 0.22609840333461761,
        "val_loss": 0.07562666412975107,
        "train_loss": 0.08318187368030731
      },
      {
        "epoch": 515,
        "reward": 0.22684012353420258,
        "val_loss": 0.07498897086562854,
        "train_loss": 0.07755776083705804
      },
      {
        "epoch": 516,
        "reward": 0.2273586541414261,
        "val_loss": 0.07454719913325139,
        "train_loss": 0.18039504739527518
      },
      {
        "epoch": 517,
        "reward": 0.22835016250610352,
        "val_loss": 0.07371169880830816,
        "train_loss": 0.07650418884944744
      },
      {
        "epoch": 518,
        "reward": 0.22890327870845795,
        "val_loss": 0.07325075693162424,
        "train_loss": 0.0759106707745769
      },
      {
        "epoch": 519,
        "reward": 0.2297833263874054,
        "val_loss": 0.07252492369817835,
        "train_loss": 0.07493785510408858
      },
      {
        "epoch": 520,
        "reward": 0.230413556098938,
        "val_loss": 0.07201073099193829,
        "train_loss": 0.10022575569410737
      },
      {
        "epoch": 521,
        "reward": 0.23131044209003448,
        "val_loss": 0.07128693529271654,
        "train_loss": 0.07365528270439917
      },
      {
        "epoch": 522,
        "reward": 0.23191110789775848,
        "val_loss": 0.07080734195187688,
        "train_loss": 0.07318911731440145
      },
      {
        "epoch": 523,
        "reward": 0.23260369896888733,
        "val_loss": 0.07025943809588041,
        "train_loss": 0.07481662176835996
      },
      {
        "epoch": 524,
        "reward": 0.233208566904068,
        "val_loss": 0.06978531783845808,
        "train_loss": 0.08697301853233232
      },
      {
        "epoch": 525,
        "reward": 0.23403659462928772,
        "val_loss": 0.06914279337174126,
        "train_loss": 0.07136009358174096
      },
      {
        "epoch": 526,
        "reward": 0.23462538421154022,
        "val_loss": 0.06869048861387585,
        "train_loss": 0.07076950898996213
      },
      {
        "epoch": 527,
        "reward": 0.23557038605213165,
        "val_loss": 0.06797230975436312,
        "train_loss": 0.07019299376182832
      },
      {
        "epoch": 528,
        "reward": 0.23620568215847015,
        "val_loss": 0.06749485399840134,
        "train_loss": 0.06961288918794778
      },
      {
        "epoch": 529,
        "reward": 0.2367636263370514,
        "val_loss": 0.06707900629511901,
        "train_loss": 0.0690667379903621
      },
      {
        "epoch": 530,
        "reward": 0.2374202460050583,
        "val_loss": 0.06659376005908209,
        "train_loss": 0.0694880759737526
      },
      {
        "epoch": 531,
        "reward": 0.23814964294433594,
        "val_loss": 0.06605990337474006,
        "train_loss": 0.06810281530264407
      },
      {
        "epoch": 532,
        "reward": 0.23902633786201477,
        "val_loss": 0.06542538565450481,
        "train_loss": 0.06741737382477507
      },
      {
        "epoch": 533,
        "reward": 0.23942001163959503,
        "val_loss": 0.06514293697130467,
        "train_loss": 0.06690400995005173
      },
      {
        "epoch": 534,
        "reward": 0.24031983315944672,
        "val_loss": 0.0645031382529331,
        "train_loss": 0.06897293579263183
      },
      {
        "epoch": 535,
        "reward": 0.24106156826019287,
        "val_loss": 0.06398166988843254,
        "train_loss": 0.06581086483101199
      },
      {
        "epoch": 536,
        "reward": 0.2416325807571411,
        "val_loss": 0.06358384021690913,
        "train_loss": 0.06535610709313634
      },
      {
        "epoch": 537,
        "reward": 0.24234914779663086,
        "val_loss": 0.06308900937438011,
        "train_loss": 0.06497967507143934
      },
      {
        "epoch": 538,
        "reward": 0.2430804967880249,
        "val_loss": 0.06258894526399672,
        "train_loss": 0.0643752888225628
      },
      {
        "epoch": 539,
        "reward": 0.24369804561138153,
        "val_loss": 0.062170565727033784,
        "train_loss": 0.0639447220875389
      },
      {
        "epoch": 540,
        "reward": 0.24439971148967743,
        "val_loss": 0.06169944303110242,
        "train_loss": 0.06349031962543869
      },
      {
        "epoch": 541,
        "reward": 0.24504981935024261,
        "val_loss": 0.06126696243882179,
        "train_loss": 0.06310089978908834
      },
      {
        "epoch": 542,
        "reward": 0.24560825526714325,
        "val_loss": 0.060898455957482965,
        "train_loss": 0.06247096702673634
      },
      {
        "epoch": 543,
        "reward": 0.24654383957386017,
        "val_loss": 0.060287336918658445,
        "train_loss": 0.062017453843369506
      },
      {
        "epoch": 544,
        "reward": 0.24696385860443115,
        "val_loss": 0.060015472383903604,
        "train_loss": 0.06663568700269724
      },
      {
        "epoch": 545,
        "reward": 0.2478523999452591,
        "val_loss": 0.059445417985054,
        "train_loss": 0.09168771719291377
      },
      {
        "epoch": 546,
        "reward": 0.24861888587474823,
        "val_loss": 0.058959089286093204,
        "train_loss": 0.06046051169351603
      },
      {
        "epoch": 547,
        "reward": 0.2492576688528061,
        "val_loss": 0.05855759499328477,
        "train_loss": 0.06008117291345955
      },
      {
        "epoch": 548,
        "reward": 0.24983787536621094,
        "val_loss": 0.058195862553215454,
        "train_loss": 0.05969833854760509
      },
      {
        "epoch": 549,
        "reward": 0.25064897537231445,
        "val_loss": 0.057694862164290886,
        "train_loss": 0.059210698152757965
      },
      {
        "epoch": 550,
        "reward": 0.2511286735534668,
        "val_loss": 0.057401109187464626,
        "train_loss": 0.05874337623894322
      },
      {
        "epoch": 551,
        "reward": 0.251895934343338,
        "val_loss": 0.056935103660050244,
        "train_loss": 0.05840593113904246
      },
      {
        "epoch": 552,
        "reward": 0.2525310516357422,
        "val_loss": 0.056552945220443816,
        "train_loss": 0.05802260671939271
      },
      {
        "epoch": 553,
        "reward": 0.2531970739364624,
        "val_loss": 0.05615561206026801,
        "train_loss": 0.05890422551713597
      },
      {
        "epoch": 554,
        "reward": 0.25377222895622253,
        "val_loss": 0.0558152854542381,
        "train_loss": 0.05709251363385612
      },
      {
        "epoch": 555,
        "reward": 0.25440359115600586,
        "val_loss": 0.05544463879362281,
        "train_loss": 0.05677106637365516
      },
      {
        "epoch": 556,
        "reward": 0.2551690936088562,
        "val_loss": 0.05499936720090253,
        "train_loss": 0.05626504969102196
      },
      {
        "epoch": 557,
        "reward": 0.2558518052101135,
        "val_loss": 0.054606005998461375,
        "train_loss": 0.05583518438120686
      },
      {
        "epoch": 558,
        "reward": 0.2565603256225586,
        "val_loss": 0.05420145470582481,
        "train_loss": 0.055447461432777345
      },
      {
        "epoch": 559,
        "reward": 0.2572352886199951,
        "val_loss": 0.05381952533831021,
        "train_loss": 0.055003796598891944
      },
      {
        "epoch": 560,
        "reward": 0.25776350498199463,
        "val_loss": 0.05352295938480113,
        "train_loss": 0.054681059785672496
      },
      {
        "epoch": 561,
        "reward": 0.25839704275131226,
        "val_loss": 0.053169965594341714,
        "train_loss": 0.05692370996201554
      },
      {
        "epoch": 562,
        "reward": 0.25922951102256775,
        "val_loss": 0.05271047980724169,
        "train_loss": 0.054168604175524354
      },
      {
        "epoch": 563,
        "reward": 0.259863018989563,
        "val_loss": 0.05236411557000663,
        "train_loss": 0.1381164365224182
      },
      {
        "epoch": 564,
        "reward": 0.2606150805950165,
        "val_loss": 0.051956573218506365,
        "train_loss": 0.05296615934191952
      },
      {
        "epoch": 565,
        "reward": 0.2611774206161499,
        "val_loss": 0.05165441621959742,
        "train_loss": 0.052673968897859316
      },
      {
        "epoch": 566,
        "reward": 0.2616618275642395,
        "val_loss": 0.051395885862543116,
        "train_loss": 0.05237875617156253
      },
      {
        "epoch": 567,
        "reward": 0.2624405324459076,
        "val_loss": 0.05098362775918629,
        "train_loss": 0.0520043287061316
      },
      {
        "epoch": 568,
        "reward": 0.2629130780696869,
        "val_loss": 0.050735442649706135,
        "train_loss": 0.05231122059810262
      },
      {
        "epoch": 569,
        "reward": 0.26381808519363403,
        "val_loss": 0.050264299930339415,
        "train_loss": 0.0512363721186725
      },
      {
        "epoch": 570,
        "reward": 0.2642981708049774,
        "val_loss": 0.05001655558589846,
        "train_loss": 0.0510183025079851
      },
      {
        "epoch": 571,
        "reward": 0.2651803195476532,
        "val_loss": 0.04956525833612042,
        "train_loss": 0.050467828017784856
      },
      {
        "epoch": 572,
        "reward": 0.26572278141975403,
        "val_loss": 0.04929025441275111,
        "train_loss": 0.05024890817451076
      },
      {
        "epoch": 573,
        "reward": 0.2664000689983368,
        "val_loss": 0.048949508129486015,
        "train_loss": 0.05676757427863777
      },
      {
        "epoch": 574,
        "reward": 0.26715460419654846,
        "val_loss": 0.04857333563268185,
        "train_loss": 0.0544831274713103
      },
      {
        "epoch": 575,
        "reward": 0.2678839862346649,
        "val_loss": 0.0482130619264873,
        "train_loss": 0.04900139260168474
      },
      {
        "epoch": 576,
        "reward": 0.2684797942638397,
        "val_loss": 0.04792121876796175,
        "train_loss": 0.04871198178387623
      },
      {
        "epoch": 577,
        "reward": 0.26910343766212463,
        "val_loss": 0.047618076720807166,
        "train_loss": 0.04837707018758955
      },
      {
        "epoch": 578,
        "reward": 0.2697381377220154,
        "val_loss": 0.047311975313017944,
        "train_loss": 0.0480814332493957
      },
      {
        "epoch": 579,
        "reward": 0.27031320333480835,
        "val_loss": 0.04703670401691592,
        "train_loss": 0.04781507285840165
      },
      {
        "epoch": 580,
        "reward": 0.27101218700408936,
        "val_loss": 0.04670477703413261,
        "train_loss": 0.04738524879660243
      },
      {
        "epoch": 581,
        "reward": 0.271526038646698,
        "val_loss": 0.04646261104582144,
        "train_loss": 0.04715581378751757
      },
      {
        "epoch": 582,
        "reward": 0.2723066806793213,
        "val_loss": 0.04609763926626848,
        "train_loss": 0.046825342144494735
      },
      {
        "epoch": 583,
        "reward": 0.27276286482810974,
        "val_loss": 0.045885980262288024,
        "train_loss": 0.04652945372240188
      },
      {
        "epoch": 584,
        "reward": 0.27326154708862305,
        "val_loss": 0.045655988422887664,
        "train_loss": 0.04633223619412792
      },
      {
        "epoch": 585,
        "reward": 0.2739088833332062,
        "val_loss": 0.04535952647815326,
        "train_loss": 0.0459646096871718
      },
      {
        "epoch": 586,
        "reward": 0.2746007442474365,
        "val_loss": 0.045045277902058194,
        "train_loss": 0.04564888401704191
      },
      {
        "epoch": 587,
        "reward": 0.2751202881336212,
        "val_loss": 0.04481104978393497,
        "train_loss": 0.04531380541448016
      },
      {
        "epoch": 588,
        "reward": 0.2757848799228668,
        "val_loss": 0.04451360175984779,
        "train_loss": 0.04511654763840712
      },
      {
        "epoch": 589,
        "reward": 0.27642956376075745,
        "val_loss": 0.04422736637726692,
        "train_loss": 0.0447789314270127
      },
      {
        "epoch": 590,
        "reward": 0.27701497077941895,
        "val_loss": 0.04396941012237221,
        "train_loss": 0.04449074879476729
      },
      {
        "epoch": 591,
        "reward": 0.2775171995162964,
        "val_loss": 0.04374955712202271,
        "train_loss": 0.13897376213795865
      },
      {
        "epoch": 592,
        "reward": 0.27806955575942993,
        "val_loss": 0.04350932482131092,
        "train_loss": 0.04394004352014655
      },
      {
        "epoch": 593,
        "reward": 0.2788788080215454,
        "val_loss": 0.043160251524698524,
        "train_loss": 0.04360944748175545
      },
      {
        "epoch": 594,
        "reward": 0.27930471301078796,
        "val_loss": 0.042977914143453484,
        "train_loss": 0.04332598797694887
      },
      {
        "epoch": 595,
        "reward": 0.2800148129463196,
        "val_loss": 0.04267598981303828,
        "train_loss": 0.043223861092813495
      },
      {
        "epoch": 596,
        "reward": 0.2802809178829193,
        "val_loss": 0.04256352029707549,
        "train_loss": 0.04283979683882185
      },
      {
        "epoch": 597,
        "reward": 0.2811166048049927,
        "val_loss": 0.04221262727099072,
        "train_loss": 0.04532789593996803
      },
      {
        "epoch": 598,
        "reward": 0.2816959321498871,
        "val_loss": 0.0419714436450574,
        "train_loss": 0.04227658384143769
      },
      {
        "epoch": 599,
        "reward": 0.2822418212890625,
        "val_loss": 0.041745730684072314,
        "train_loss": 0.04211994159805517
      },
      {
        "epoch": 600,
        "reward": 0.28265079855918884,
        "val_loss": 0.0415775857441726,
        "train_loss": 0.041804558843768276
      },
      {
        "epoch": 601,
        "reward": 0.28323686122894287,
        "val_loss": 0.04133807114807756,
        "train_loss": 0.0416711634341202
      },
      {
        "epoch": 602,
        "reward": 0.28379637002944946,
        "val_loss": 0.04111098241992295,
        "train_loss": 0.04193224725895561
      },
      {
        "epoch": 603,
        "reward": 0.28454434871673584,
        "val_loss": 0.0408097516878375,
        "train_loss": 0.04117543310880697
      },
      {
        "epoch": 604,
        "reward": 0.28497084975242615,
        "val_loss": 0.04063920468407949,
        "train_loss": 0.04078215783262679
      },
      {
        "epoch": 605,
        "reward": 0.28546836972236633,
        "val_loss": 0.04044132685937386,
        "train_loss": 0.04065625677825525
      },
      {
        "epoch": 606,
        "reward": 0.2861776053905487,
        "val_loss": 0.04016127272292839,
        "train_loss": 0.040428053445514076
      },
      {
        "epoch": 607,
        "reward": 0.2865495979785919,
        "val_loss": 0.04001533260452561,
        "train_loss": 0.04022687840132186
      },
      {
        "epoch": 608,
        "reward": 0.2872121036052704,
        "val_loss": 0.03975698681564869,
        "train_loss": 0.039988755026850134
      },
      {
        "epoch": 609,
        "reward": 0.2876565158367157,
        "val_loss": 0.03958483993691126,
        "train_loss": 0.03969474459322205
      },
      {
        "epoch": 610,
        "reward": 0.28827401995658875,
        "val_loss": 0.039347132065034075,
        "train_loss": 0.040410694263230726
      },
      {
        "epoch": 611,
        "reward": 0.28894633054733276,
        "val_loss": 0.03909028580112915,
        "train_loss": 0.03925571766180488
      },
      {
        "epoch": 612,
        "reward": 0.2894766330718994,
        "val_loss": 0.03888912204170732,
        "train_loss": 0.03899105972120127
      },
      {
        "epoch": 613,
        "reward": 0.2899814248085022,
        "val_loss": 0.03869880232793678,
        "train_loss": 0.03880039484773498
      },
      {
        "epoch": 614,
        "reward": 0.29054486751556396,
        "val_loss": 0.03848769230535254,
        "train_loss": 0.03855567638227232
      },
      {
        "epoch": 615,
        "reward": 0.29110488295555115,
        "val_loss": 0.03827924663034667,
        "train_loss": 0.038386957379631124
      },
      {
        "epoch": 616,
        "reward": 0.2916765511035919,
        "val_loss": 0.0380678768560756,
        "train_loss": 0.03816645548123723
      },
      {
        "epoch": 617,
        "reward": 0.29212722182273865,
        "val_loss": 0.03790224153116079,
        "train_loss": 0.037929976865528334
      },
      {
        "epoch": 618,
        "reward": 0.2926676869392395,
        "val_loss": 0.03770473157887214,
        "train_loss": 0.03771162908994414
      },
      {
        "epoch": 619,
        "reward": 0.293179988861084,
        "val_loss": 0.037518668541451916,
        "train_loss": 0.037544865122002266
      },
      {
        "epoch": 620,
        "reward": 0.29381194710731506,
        "val_loss": 0.037290676401296095,
        "train_loss": 0.03726689250722232
      },
      {
        "epoch": 621,
        "reward": 0.2941407859325409,
        "val_loss": 0.03717270693284393,
        "train_loss": 0.03708779368882959
      },
      {
        "epoch": 622,
        "reward": 0.2949102520942688,
        "val_loss": 0.03689840393573312,
        "train_loss": 0.036914447357328475
      },
      {
        "epoch": 623,
        "reward": 0.29536449909210205,
        "val_loss": 0.036737611259533356,
        "train_loss": 0.036979636687857025
      },
      {
        "epoch": 624,
        "reward": 0.29586490988731384,
        "val_loss": 0.03656146064167842,
        "train_loss": 0.04291422220054441
      },
      {
        "epoch": 625,
        "reward": 0.29653486609458923,
        "val_loss": 0.03632720859189119,
        "train_loss": 0.036241933123584695
      },
      {
        "epoch": 626,
        "reward": 0.29709336161613464,
        "val_loss": 0.036133321471944715,
        "train_loss": 0.03605863121069538
      },
      {
        "epoch": 627,
        "reward": 0.29753461480140686,
        "val_loss": 0.0359810015111829,
        "train_loss": 0.03590636246260077
      },
      {
        "epoch": 628,
        "reward": 0.2981531023979187,
        "val_loss": 0.035768815578194335,
        "train_loss": 0.0356477444067003
      },
      {
        "epoch": 629,
        "reward": 0.2986162006855011,
        "val_loss": 0.0356109231361188,
        "train_loss": 0.035584166390785515
      },
      {
        "epoch": 630,
        "reward": 0.298820436000824,
        "val_loss": 0.035541554006548334,
        "train_loss": 0.04009867460878853
      },
      {
        "epoch": 631,
        "reward": 0.29982906579971313,
        "val_loss": 0.03520133641515193,
        "train_loss": 0.03510042029665783
      },
      {
        "epoch": 632,
        "reward": 0.3003010153770447,
        "val_loss": 0.03504349531223332,
        "train_loss": 0.034931605227309495
      },
      {
        "epoch": 633,
        "reward": 0.30076834559440613,
        "val_loss": 0.03488802137768029,
        "train_loss": 0.03501072298296584
      },
      {
        "epoch": 634,
        "reward": 0.3012655973434448,
        "val_loss": 0.034723504554546834,
        "train_loss": 0.034534095640992746
      },
      {
        "epoch": 635,
        "reward": 0.30172690749168396,
        "val_loss": 0.03457171560564477,
        "train_loss": 0.03444025489107634
      },
      {
        "epoch": 636,
        "reward": 0.3023373782634735,
        "val_loss": 0.034372069053850804,
        "train_loss": 0.03970462431271489
      },
      {
        "epoch": 637,
        "reward": 0.3029003441333771,
        "val_loss": 0.034189184208766425,
        "train_loss": 0.03396754407395537
      },
      {
        "epoch": 638,
        "reward": 0.3034478425979614,
        "val_loss": 0.034012423029967716,
        "train_loss": 0.03381991729391022
      },
      {
        "epoch": 639,
        "reward": 0.3039305806159973,
        "val_loss": 0.033857489441288635,
        "train_loss": 0.03385669544849616
      },
      {
        "epoch": 640,
        "reward": 0.3044194281101227,
        "val_loss": 0.033701449869632985,
        "train_loss": 0.03342033512196325
      },
      {
        "epoch": 641,
        "reward": 0.304934024810791,
        "val_loss": 0.03353811224639815,
        "train_loss": 0.033242865999279905
      },
      {
        "epoch": 642,
        "reward": 0.30539172887802124,
        "val_loss": 0.033393646735930815,
        "train_loss": 0.033086631954085115
      },
      {
        "epoch": 643,
        "reward": 0.30593809485435486,
        "val_loss": 0.03322214622416401,
        "train_loss": 0.03294685220820471
      },
      {
        "epoch": 644,
        "reward": 0.3063870072364807,
        "val_loss": 0.03308203083413121,
        "train_loss": 0.03283442858642397
      },
      {
        "epoch": 645,
        "reward": 0.3069166839122772,
        "val_loss": 0.032917612531621544,
        "train_loss": 0.032640586837942465
      },
      {
        "epoch": 646,
        "reward": 0.3073510229587555,
        "val_loss": 0.03278351405918199,
        "train_loss": 0.03250724137223397
      },
      {
        "epoch": 647,
        "reward": 0.3079400956630707,
        "val_loss": 0.03260268500058113,
        "train_loss": 0.032293840165948495
      },
      {
        "epoch": 648,
        "reward": 0.30809396505355835,
        "val_loss": 0.03255564390565269,
        "train_loss": 0.032079342180692874
      },
      {
        "epoch": 649,
        "reward": 0.30885550379753113,
        "val_loss": 0.03232402780226299,
        "train_loss": 0.031982828718005646
      },
      {
        "epoch": 650,
        "reward": 0.30933740735054016,
        "val_loss": 0.03217846921013136,
        "train_loss": 0.03185293958141791
      },
      {
        "epoch": 651,
        "reward": 0.309781551361084,
        "val_loss": 0.03204500922168206,
        "train_loss": 0.03257391554787038
      },
      {
        "epoch": 652,
        "reward": 0.3103681802749634,
        "val_loss": 0.03186975112683805,
        "train_loss": 0.031533262990706135
      },
      {
        "epoch": 653,
        "reward": 0.310606986284256,
        "val_loss": 0.031798722995777746,
        "train_loss": 0.03126846347717779
      },
      {
        "epoch": 654,
        "reward": 0.31137341260910034,
        "val_loss": 0.031572061125189066,
        "train_loss": 0.031285420887378186
      },
      {
        "epoch": 655,
        "reward": 0.3118036091327667,
        "val_loss": 0.03144568269739726,
        "train_loss": 0.03229779225792019
      },
      {
        "epoch": 656,
        "reward": 0.3123064637184143,
        "val_loss": 0.03129871056548187,
        "train_loss": 0.030940385622670874
      },
      {
        "epoch": 657,
        "reward": 0.3126338720321655,
        "val_loss": 0.031203447300608138,
        "train_loss": 0.030776405895057205
      },
      {
        "epoch": 658,
        "reward": 0.31319156289100647,
        "val_loss": 0.031041987373360565,
        "train_loss": 0.0306383964098831
      },
      {
        "epoch": 659,
        "reward": 0.31353759765625,
        "val_loss": 0.030942306213546544,
        "train_loss": 0.03047213129376849
      },
      {
        "epoch": 660,
        "reward": 0.3140833079814911,
        "val_loss": 0.030785871461765573,
        "train_loss": 0.030474529118062213
      },
      {
        "epoch": 661,
        "reward": 0.31458374857902527,
        "val_loss": 0.030643237047895257,
        "train_loss": 0.030201914667626485
      },
      {
        "epoch": 662,
        "reward": 0.31501033902168274,
        "val_loss": 0.030522271408699453,
        "train_loss": 0.03009750518664917
      },
      {
        "epoch": 663,
        "reward": 0.31527164578437805,
        "val_loss": 0.030448455904011747,
        "train_loss": 0.05586391660080363
      },
      {
        "epoch": 664,
        "reward": 0.31562143564224243,
        "val_loss": 0.030349974528819854,
        "train_loss": 0.03201849000582185
      },
      {
        "epoch": 665,
        "reward": 0.3164752721786499,
        "val_loss": 0.03011115422538881,
        "train_loss": 0.02965834265768745
      },
      {
        "epoch": 666,
        "reward": 0.316670298576355,
        "val_loss": 0.0300569163851573,
        "train_loss": 0.02952275984884741
      },
      {
        "epoch": 667,
        "reward": 0.3173914849758148,
        "val_loss": 0.02985735362329121,
        "train_loss": 0.029412241139652906
      },
      {
        "epoch": 668,
        "reward": 0.317884236574173,
        "val_loss": 0.029721907631028444,
        "train_loss": 0.029210533727914132
      },
      {
        "epoch": 669,
        "reward": 0.31839990615844727,
        "val_loss": 0.02958092717121222,
        "train_loss": 0.029013914627145053
      },
      {
        "epoch": 670,
        "reward": 0.3188450038433075,
        "val_loss": 0.029459885961841792,
        "train_loss": 0.02892101425263368
      },
      {
        "epoch": 671,
        "reward": 0.31927669048309326,
        "val_loss": 0.029343052035463706,
        "train_loss": 0.028826790996110782
      },
      {
        "epoch": 672,
        "reward": 0.31971287727355957,
        "val_loss": 0.029225551182337637,
        "train_loss": 0.02875889715505764
      },
      {
        "epoch": 673,
        "reward": 0.3201580047607422,
        "val_loss": 0.029106208389358863,
        "train_loss": 0.028673235398645584
      },
      {
        "epoch": 674,
        "reward": 0.3206956386566162,
        "val_loss": 0.028962845489981452,
        "train_loss": 0.028491965974143777
      },
      {
        "epoch": 675,
        "reward": 0.3210282623767853,
        "val_loss": 0.028874553723393807,
        "train_loss": 0.02826748337807098
      },
      {
        "epoch": 676,
        "reward": 0.32152068614959717,
        "val_loss": 0.028744437823271646,
        "train_loss": 0.028159617809041474
      },
      {
        "epoch": 677,
        "reward": 0.3219812512397766,
        "val_loss": 0.02862336819193193,
        "train_loss": 0.028001961027397416
      },
      {
        "epoch": 678,
        "reward": 0.3224042057991028,
        "val_loss": 0.028512711545252905,
        "train_loss": 0.02790357534387602
      },
      {
        "epoch": 679,
        "reward": 0.32281607389450073,
        "val_loss": 0.028405431217314408,
        "train_loss": 0.02778345224550531
      },
      {
        "epoch": 680,
        "reward": 0.322699636220932,
        "val_loss": 0.028435712688535984,
        "train_loss": 0.027662445970166188
      },
      {
        "epoch": 681,
        "reward": 0.32368576526641846,
        "val_loss": 0.0281804701413161,
        "train_loss": 0.027723186891167782
      },
      {
        "epoch": 682,
        "reward": 0.32363077998161316,
        "val_loss": 0.02819463357861553,
        "train_loss": 0.027480201777787164
      },
      {
        "epoch": 683,
        "reward": 0.3244290053844452,
        "val_loss": 0.027989880539410348,
        "train_loss": 0.027455071882846262
      },
      {
        "epoch": 684,
        "reward": 0.3249717056751251,
        "val_loss": 0.02785167803189584,
        "train_loss": 0.04951823079206336
      },
      {
        "epoch": 685,
        "reward": 0.325452983379364,
        "val_loss": 0.027729779274003313,
        "train_loss": 0.02708080019096297
      },
      {
        "epoch": 686,
        "reward": 0.32583296298980713,
        "val_loss": 0.027633981513125554,
        "train_loss": 0.027038295815985363
      },
      {
        "epoch": 687,
        "reward": 0.32628846168518066,
        "val_loss": 0.027519650807205056,
        "train_loss": 0.026873458181328785
      },
      {
        "epoch": 688,
        "reward": 0.3266713321208954,
        "val_loss": 0.0274239845374333,
        "train_loss": 0.026858631767726574
      },
      {
        "epoch": 689,
        "reward": 0.3271591067314148,
        "val_loss": 0.02730267431720027,
        "train_loss": 0.026619285766838193
      },
      {
        "epoch": 690,
        "reward": 0.32740578055381775,
        "val_loss": 0.027241564605252018,
        "train_loss": 0.026589287037495524
      },
      {
        "epoch": 691,
        "reward": 0.32786038517951965,
        "val_loss": 0.02712935719838632,
        "train_loss": 0.026505445264494762
      },
      {
        "epoch": 692,
        "reward": 0.32829275727272034,
        "val_loss": 0.02702314529701003,
        "train_loss": 0.026369313445264615
      },
      {
        "epoch": 693,
        "reward": 0.3287893831729889,
        "val_loss": 0.026901748280839195,
        "train_loss": 0.026183039573739873
      },
      {
        "epoch": 694,
        "reward": 0.3291245698928833,
        "val_loss": 0.02682017142485295,
        "train_loss": 0.026164744550792072
      },
      {
        "epoch": 695,
        "reward": 0.3295898139476776,
        "val_loss": 0.02670742864055293,
        "train_loss": 0.02598098911235306
      },
      {
        "epoch": 696,
        "reward": 0.32999613881111145,
        "val_loss": 0.02660941839816847,
        "train_loss": 0.025907439667767342
      },
      {
        "epoch": 697,
        "reward": 0.3304840922355652,
        "val_loss": 0.026492271439305375,
        "train_loss": 0.025763933880415816
      },
      {
        "epoch": 698,
        "reward": 0.3307497203350067,
        "val_loss": 0.026428751248334135,
        "train_loss": 0.025645796271909112
      },
      {
        "epoch": 699,
        "reward": 0.33129069209098816,
        "val_loss": 0.02629993754505579,
        "train_loss": 0.025528205642611004
      },
      {
        "epoch": 700,
        "reward": 0.3317359387874603,
        "val_loss": 0.026194471599800245,
        "train_loss": 0.0255495517138535
      },
      {
        "epoch": 701,
        "reward": 0.33214351534843445,
        "val_loss": 0.026098358212038875,
        "train_loss": 0.02545201282751245
      },
      {
        "epoch": 702,
        "reward": 0.33251720666885376,
        "val_loss": 0.026010604492122575,
        "train_loss": 0.02527116851174819
      },
      {
        "epoch": 703,
        "reward": 0.33293119072914124,
        "val_loss": 0.025913778176930333,
        "train_loss": 0.02512282522953823
      },
      {
        "epoch": 704,
        "reward": 0.3333062529563904,
        "val_loss": 0.025826427337181355,
        "train_loss": 0.025068490265626818
      },
      {
        "epoch": 705,
        "reward": 0.3336341977119446,
        "val_loss": 0.02575032416331981,
        "train_loss": 0.026804995969331894
      },
      {
        "epoch": 706,
        "reward": 0.33417436480522156,
        "val_loss": 0.025625549705832133,
        "train_loss": 0.024935041751282718
      },
      {
        "epoch": 707,
        "reward": 0.33456531167030334,
        "val_loss": 0.025535683979147246,
        "train_loss": 0.024801894211962532
      },
      {
        "epoch": 708,
        "reward": 0.33493146300315857,
        "val_loss": 0.025451844657904336,
        "train_loss": 0.02467054009768897
      },
      {
        "epoch": 709,
        "reward": 0.3353615701198578,
        "val_loss": 0.02535378931289805,
        "train_loss": 0.024517515508565478
      },
      {
        "epoch": 710,
        "reward": 0.3357076644897461,
        "val_loss": 0.025275191192382147,
        "train_loss": 0.02446843090337307
      },
      {
        "epoch": 711,
        "reward": 0.33608943223953247,
        "val_loss": 0.02518882093551968,
        "train_loss": 0.024359175160917894
      },
      {
        "epoch": 712,
        "reward": 0.33647772669792175,
        "val_loss": 0.025101339128533646,
        "train_loss": 0.0243300566664682
      },
      {
        "epoch": 713,
        "reward": 0.3367876410484314,
        "val_loss": 0.025031760917045176,
        "train_loss": 0.024195984382039078
      },
      {
        "epoch": 714,
        "reward": 0.3372226059436798,
        "val_loss": 0.024934485371756767,
        "train_loss": 0.0242058162111789
      },
      {
        "epoch": 715,
        "reward": 0.33762219548225403,
        "val_loss": 0.02484552005106317,
        "train_loss": 0.024004611515010765
      },
      {
        "epoch": 716,
        "reward": 0.33798637986183167,
        "val_loss": 0.02476475211525602,
        "train_loss": 0.02394755198082958
      },
      {
        "epoch": 717,
        "reward": 0.33837783336639404,
        "val_loss": 0.024678269916746234,
        "train_loss": 0.023813744125688503
      },
      {
        "epoch": 718,
        "reward": 0.3385320007801056,
        "val_loss": 0.024644307509463812,
        "train_loss": 0.023739303747928577
      },
      {
        "epoch": 719,
        "reward": 0.33910247683525085,
        "val_loss": 0.024519114788355573,
        "train_loss": 0.02364440687905209
      },
      {
        "epoch": 720,
        "reward": 0.3392361104488373,
        "val_loss": 0.02448989063434835,
        "train_loss": 0.023593810342180613
      },
      {
        "epoch": 721,
        "reward": 0.33981093764305115,
        "val_loss": 0.024364659196830223,
        "train_loss": 0.0234656230198355
      },
      {
        "epoch": 722,
        "reward": 0.34027764201164246,
        "val_loss": 0.024263533730325953,
        "train_loss": 0.023495096458086315
      },
      {
        "epoch": 723,
        "reward": 0.3406524658203125,
        "val_loss": 0.024182656181177924,
        "train_loss": 0.023288986086597036
      },
      {
        "epoch": 724,
        "reward": 0.34103599190711975,
        "val_loss": 0.024100243130565753,
        "train_loss": 0.02319284833972163
      },
      {
        "epoch": 725,
        "reward": 0.34129053354263306,
        "val_loss": 0.02404572458804718,
        "train_loss": 0.023174322290847506
      },
      {
        "epoch": 726,
        "reward": 0.3417554795742035,
        "val_loss": 0.023946502013131976,
        "train_loss": 0.023222779913339764
      },
      {
        "epoch": 727,
        "reward": 0.3420982360839844,
        "val_loss": 0.023873651616408358,
        "train_loss": 0.02307837482434339
      },
      {
        "epoch": 728,
        "reward": 0.3424755930900574,
        "val_loss": 0.023793752720978643,
        "train_loss": 0.02289619343355298
      },
      {
        "epoch": 729,
        "reward": 0.3427596986293793,
        "val_loss": 0.023733801075390408,
        "train_loss": 0.022905770684771527
      },
      {
        "epoch": 730,
        "reward": 0.3431527018547058,
        "val_loss": 0.023651157888317748,
        "train_loss": 0.022720432662796296
      },
      {
        "epoch": 731,
        "reward": 0.3434722125530243,
        "val_loss": 0.02358421540286924,
        "train_loss": 0.022762260247523394
      },
      {
        "epoch": 732,
        "reward": 0.34383317828178406,
        "val_loss": 0.023508850801070885,
        "train_loss": 0.022593956145171363
      },
      {
        "epoch": 733,
        "reward": 0.34429702162742615,
        "val_loss": 0.02341241900077356,
        "train_loss": 0.022492796475349817
      },
      {
        "epoch": 734,
        "reward": 0.34462153911590576,
        "val_loss": 0.023345214248235737,
        "train_loss": 0.0224292716011405
      },
      {
        "epoch": 735,
        "reward": 0.3449477553367615,
        "val_loss": 0.023277898601788496,
        "train_loss": 0.022397315949022483
      },
      {
        "epoch": 736,
        "reward": 0.3452647924423218,
        "val_loss": 0.02321267661838127,
        "train_loss": 0.022405616419676404
      },
      {
        "epoch": 737,
        "reward": 0.3456151783466339,
        "val_loss": 0.023140849844951714,
        "train_loss": 0.02219969013710327
      },
      {
        "epoch": 738,
        "reward": 0.3457576334476471,
        "val_loss": 0.023111723446553305,
        "train_loss": 0.02211098120068737
      },
      {
        "epoch": 739,
        "reward": 0.34636762738227844,
        "val_loss": 0.022987456543238034,
        "train_loss": 0.022082428031003822
      },
      {
        "epoch": 740,
        "reward": 0.3466133773326874,
        "val_loss": 0.022937626112252474,
        "train_loss": 0.021993692245674677
      },
      {
        "epoch": 741,
        "reward": 0.3470393419265747,
        "val_loss": 0.02285152005164751,
        "train_loss": 0.021903606149582908
      },
      {
        "epoch": 742,
        "reward": 0.34727349877357483,
        "val_loss": 0.022804351789610728,
        "train_loss": 0.021911081123667266
      },
      {
        "epoch": 743,
        "reward": 0.34768763184547424,
        "val_loss": 0.022721201547288468,
        "train_loss": 0.021743859756567802
      },
      {
        "epoch": 744,
        "reward": 0.348003625869751,
        "val_loss": 0.02265798839341317,
        "train_loss": 0.021650466974917366
      },
      {
        "epoch": 745,
        "reward": 0.34842750430107117,
        "val_loss": 0.022573507889839157,
        "train_loss": 0.0216745145421905
      },
      {
        "epoch": 746,
        "reward": 0.3487037122249603,
        "val_loss": 0.022518660008375133,
        "train_loss": 0.0712629044518018
      },
      {
        "epoch": 747,
        "reward": 0.34896743297576904,
        "val_loss": 0.02246642774636192,
        "train_loss": 0.02144654156290926
      },
      {
        "epoch": 748,
        "reward": 0.3493778109550476,
        "val_loss": 0.02238543308340013,
        "train_loss": 0.021653567870649006
      },
      {
        "epoch": 749,
        "reward": 0.34961172938346863,
        "val_loss": 0.022339418131325926,
        "train_loss": 0.021334031890345474
      },
      {
        "epoch": 750,
        "reward": 0.34998759627342224,
        "val_loss": 0.022265697130933404,
        "train_loss": 0.02125935400209318
      },
      {
        "epoch": 751,
        "reward": 0.3502695858478546,
        "val_loss": 0.022210579199184264,
        "train_loss": 0.021356576744717762
      },
      {
        "epoch": 752,
        "reward": 0.35066452622413635,
        "val_loss": 0.02213364852858441,
        "train_loss": 0.02114878295980396
      },
      {
        "epoch": 753,
        "reward": 0.35105738043785095,
        "val_loss": 0.02205742759230946,
        "train_loss": 0.021065187042740244
      },
      {
        "epoch": 754,
        "reward": 0.35137611627578735,
        "val_loss": 0.02199581059228097,
        "train_loss": 0.021070431071655966
      },
      {
        "epoch": 755,
        "reward": 0.3516820967197418,
        "val_loss": 0.021936832760859813,
        "train_loss": 0.020934208503884014
      },
      {
        "epoch": 756,
        "reward": 0.35200080275535583,
        "val_loss": 0.021875607781112194,
        "train_loss": 0.020988495541342463
      },
      {
        "epoch": 757,
        "reward": 0.35232892632484436,
        "val_loss": 0.02181277287724827,
        "train_loss": 0.021011237180433594
      },
      {
        "epoch": 758,
        "reward": 0.35265877842903137,
        "val_loss": 0.021749812377882854,
        "train_loss": 0.020716541250854228
      },
      {
        "epoch": 759,
        "reward": 0.3529362678527832,
        "val_loss": 0.021697010711899826,
        "train_loss": 0.020716974632635426
      },
      {
        "epoch": 760,
        "reward": 0.3531275987625122,
        "val_loss": 0.021660689331058944,
        "train_loss": 0.020621945754660722
      },
      {
        "epoch": 761,
        "reward": 0.3535724878311157,
        "val_loss": 0.021576508414000273,
        "train_loss": 0.02074756367185798
      },
      {
        "epoch": 762,
        "reward": 0.35391637682914734,
        "val_loss": 0.021511689061298966,
        "train_loss": 0.020552448825373385
      },
      {
        "epoch": 763,
        "reward": 0.35413429141044617,
        "val_loss": 0.021470740836645876,
        "train_loss": 0.020543591974553868
      },
      {
        "epoch": 764,
        "reward": 0.35444095730781555,
        "val_loss": 0.0214132501943303,
        "train_loss": 0.020375042285125416
      },
      {
        "epoch": 765,
        "reward": 0.3547162413597107,
        "val_loss": 0.02136179804801941,
        "train_loss": 0.0203053516334666
      },
      {
        "epoch": 766,
        "reward": 0.35516709089279175,
        "val_loss": 0.02127783190059875,
        "train_loss": 0.020987101718604278
      },
      {
        "epoch": 767,
        "reward": 0.355474054813385,
        "val_loss": 0.021220882323437502,
        "train_loss": 0.020315252060894497
      },
      {
        "epoch": 768,
        "reward": 0.3555317521095276,
        "val_loss": 0.02121019646126245,
        "train_loss": 0.020434053278922174
      },
      {
        "epoch": 769,
        "reward": 0.3556608259677887,
        "val_loss": 0.021186320443770716,
        "train_loss": 0.020098813455730963
      },
      {
        "epoch": 770,
        "reward": 0.3562070429325104,
        "val_loss": 0.02108559800711061,
        "train_loss": 0.020240074104199614
      },
      {
        "epoch": 771,
        "reward": 0.3565995991230011,
        "val_loss": 0.021013550027938827,
        "train_loss": 0.019924631773007535
      },
      {
        "epoch": 772,
        "reward": 0.3569323718547821,
        "val_loss": 0.02095268843030291,
        "train_loss": 0.0200012259122629
      },
      {
        "epoch": 773,
        "reward": 0.35732758045196533,
        "val_loss": 0.02088068305913891,
        "train_loss": 0.019993797755047966
      },
      {
        "epoch": 774,
        "reward": 0.3575596511363983,
        "val_loss": 0.02083852338338537,
        "train_loss": 0.019900891992550056
      },
      {
        "epoch": 775,
        "reward": 0.35783979296684265,
        "val_loss": 0.020787772656019245,
        "train_loss": 0.019774329324718565
      },
      {
        "epoch": 776,
        "reward": 0.3580479919910431,
        "val_loss": 0.020750139972993305,
        "train_loss": 0.019801454408130106
      },
      {
        "epoch": 777,
        "reward": 0.3583996593952179,
        "val_loss": 0.02068676313917552,
        "train_loss": 0.019727023381095093
      },
      {
        "epoch": 778,
        "reward": 0.3585870563983917,
        "val_loss": 0.020653068919533064,
        "train_loss": 0.01992387161590159
      },
      {
        "epoch": 779,
        "reward": 0.35856685042381287,
        "val_loss": 0.020656702108681202,
        "train_loss": 0.0197922806837596
      },
      {
        "epoch": 780,
        "reward": 0.3589692711830139,
        "val_loss": 0.02058456409057336,
        "train_loss": 0.019432283167798933
      },
      {
        "epoch": 781,
        "reward": 0.3596141040325165,
        "val_loss": 0.020469558125893985,
        "train_loss": 0.019461748924536202
      },
      {
        "epoch": 782,
        "reward": 0.3598795235157013,
        "val_loss": 0.020422439124169096,
        "train_loss": 0.01940764583503971
      },
      {
        "epoch": 783,
        "reward": 0.360126256942749,
        "val_loss": 0.020378741635275737,
        "train_loss": 0.019298072045785375
      },
      {
        "epoch": 784,
        "reward": 0.3602907359600067,
        "val_loss": 0.020349677219720825,
        "train_loss": 0.01922485660971828
      },
      {
        "epoch": 785,
        "reward": 0.36030837893486023,
        "val_loss": 0.02034655732235738,
        "train_loss": 0.019293863868090108
      },
      {
        "epoch": 786,
        "reward": 0.36096516251564026,
        "val_loss": 0.020230982253061875,
        "train_loss": 0.019127000387855402
      },
      {
        "epoch": 787,
        "reward": 0.36112910509109497,
        "val_loss": 0.020202246428068196,
        "train_loss": 0.019130856067372057
      },
      {
        "epoch": 788,
        "reward": 0.36119532585144043,
        "val_loss": 0.020190650763522302,
        "train_loss": 0.019099760949757183
      },
      {
        "epoch": 789,
        "reward": 0.361767441034317,
        "val_loss": 0.0200908101895558,
        "train_loss": 0.019025307295613365
      },
      {
        "epoch": 790,
        "reward": 0.3620521128177643,
        "val_loss": 0.020041336438485553,
        "train_loss": 0.01908068056218326
      },
      {
        "epoch": 791,
        "reward": 0.362317830324173,
        "val_loss": 0.019995281639109765,
        "train_loss": 0.018893630250554103
      },
      {
        "epoch": 792,
        "reward": 0.3625902235507965,
        "val_loss": 0.01994819939136505,
        "train_loss": 0.018861723732418165
      },
      {
        "epoch": 793,
        "reward": 0.36289772391319275,
        "val_loss": 0.019895198056474328,
        "train_loss": 0.0190263001803452
      },
      {
        "epoch": 794,
        "reward": 0.36304181814193726,
        "val_loss": 0.01987041819042393,
        "train_loss": 0.018738029911988772
      },
      {
        "epoch": 795,
        "reward": 0.36342254281044006,
        "val_loss": 0.019805110791432008,
        "train_loss": 0.020287703400334485
      },
      {
        "epoch": 796,
        "reward": 0.36362916231155396,
        "val_loss": 0.01976977165655366,
        "train_loss": 0.0201427788572171
      },
      {
        "epoch": 797,
        "reward": 0.3640422523021698,
        "val_loss": 0.01969932788051665,
        "train_loss": 0.018576904313354483
      },
      {
        "epoch": 798,
        "reward": 0.36421847343444824,
        "val_loss": 0.019669357587450316,
        "train_loss": 0.01877599539091954
      },
      {
        "epoch": 799,
        "reward": 0.36435264348983765,
        "val_loss": 0.01964658934489957,
        "train_loss": 0.018835197838668067
      },
      {
        "epoch": 800,
        "reward": 0.364790678024292,
        "val_loss": 0.01957242503496153,
        "train_loss": 0.018517722089130145
      },
      {
        "epoch": 801,
        "reward": 0.3649192452430725,
        "val_loss": 0.01955072478657322,
        "train_loss": 0.01844667978450441
      },
      {
        "epoch": 802,
        "reward": 0.3651840090751648,
        "val_loss": 0.019506107716421996,
        "train_loss": 0.018439843726810068
      },
      {
        "epoch": 803,
        "reward": 0.3654769957065582,
        "val_loss": 0.019456878204696944,
        "train_loss": 0.018338488043250088
      },
      {
        "epoch": 804,
        "reward": 0.36576294898986816,
        "val_loss": 0.019408958232296363,
        "train_loss": 0.018310849424988892
      },
      {
        "epoch": 805,
        "reward": 0.36602532863616943,
        "val_loss": 0.019365104347733513,
        "train_loss": 0.01827665387491624
      },
      {
        "epoch": 806,
        "reward": 0.36622461676597595,
        "val_loss": 0.019331878117684807,
        "train_loss": 0.01832030252374422
      },
      {
        "epoch": 807,
        "reward": 0.36653563380241394,
        "val_loss": 0.01928014650807849,
        "train_loss": 0.018199946189549968
      },
      {
        "epoch": 808,
        "reward": 0.3665705919265747,
        "val_loss": 0.01927434273862413,
        "train_loss": 0.01812508757799291
      },
      {
        "epoch": 809,
        "reward": 0.3670024573802948,
        "val_loss": 0.019202798438657607,
        "train_loss": 0.018159207771532238
      },
      {
        "epoch": 810,
        "reward": 0.367153137922287,
        "val_loss": 0.019177909175466214,
        "train_loss": 0.018052975667300276
      },
      {
        "epoch": 811,
        "reward": 0.3675028085708618,
        "val_loss": 0.01912028239374714,
        "train_loss": 0.0180354782496579
      },
      {
        "epoch": 812,
        "reward": 0.3677419126033783,
        "val_loss": 0.01908100113671805,
        "train_loss": 0.01796388843257983
      },
      {
        "epoch": 813,
        "reward": 0.36792752146720886,
        "val_loss": 0.01905056125750499,
        "train_loss": 0.01795500581815409
      },
      {
        "epoch": 814,
        "reward": 0.368148535490036,
        "val_loss": 0.019014380872249603,
        "train_loss": 0.017897859500058424
      },
      {
        "epoch": 815,
        "reward": 0.36811473965644836,
        "val_loss": 0.019019908105422343,
        "train_loss": 0.017926515303910352
      },
      {
        "epoch": 816,
        "reward": 0.36853641271591187,
        "val_loss": 0.01895109354518354,
        "train_loss": 0.017835449627769916
      },
      {
        "epoch": 817,
        "reward": 0.3688566982746124,
        "val_loss": 0.01889900809952191,
        "train_loss": 0.0177543629453724
      },
      {
        "epoch": 818,
        "reward": 0.3688487708568573,
        "val_loss": 0.018900295852550437,
        "train_loss": 0.017716891981763183
      },
      {
        "epoch": 819,
        "reward": 0.36931437253952026,
        "val_loss": 0.018824865143480047,
        "train_loss": 0.01766658863701965
      },
      {
        "epoch": 820,
        "reward": 0.36961206793785095,
        "val_loss": 0.018776815916810716,
        "train_loss": 0.01762660876220952
      },
      {
        "epoch": 821,
        "reward": 0.36981284618377686,
        "val_loss": 0.01874448561907879,
        "train_loss": 0.01757720551820687
      },
      {
        "epoch": 822,
        "reward": 0.36994221806526184,
        "val_loss": 0.01872368828792657,
        "train_loss": 0.017593176471284375
      },
      {
        "epoch": 823,
        "reward": 0.3702619969844818,
        "val_loss": 0.018672390275501778,
        "train_loss": 0.0175977739944266
      },
      {
        "epoch": 824,
        "reward": 0.3702394664287567,
        "val_loss": 0.01867599948309362,
        "train_loss": 0.01750638970406726
      },
      {
        "epoch": 825,
        "reward": 0.37072524428367615,
        "val_loss": 0.018598367060933794,
        "train_loss": 0.017483820488380913
      },
      {
        "epoch": 826,
        "reward": 0.37082037329673767,
        "val_loss": 0.018583204297881042,
        "train_loss": 0.0175132274430675
      },
      {
        "epoch": 827,
        "reward": 0.37119653820991516,
        "val_loss": 0.018523390937064375,
        "train_loss": 0.017362810065466104
      },
      {
        "epoch": 828,
        "reward": 0.37139952182769775,
        "val_loss": 0.018491197676796998,
        "train_loss": 0.017433448139434822
      },
      {
        "epoch": 829,
        "reward": 0.37159091234207153,
        "val_loss": 0.01846091472543776,
        "train_loss": 0.017512829490722373
      },
      {
        "epoch": 830,
        "reward": 0.37182167172431946,
        "val_loss": 0.018424468048449074,
        "train_loss": 0.017271288010166384
      },
      {
        "epoch": 831,
        "reward": 0.3720260262489319,
        "val_loss": 0.018392256926745176,
        "train_loss": 0.017271828627249654
      },
      {
        "epoch": 832,
        "reward": 0.37227970361709595,
        "val_loss": 0.018352368314351355,
        "train_loss": 0.0171714546394329
      },
      {
        "epoch": 833,
        "reward": 0.3725097179412842,
        "val_loss": 0.018316273810341954,
        "train_loss": 0.01713753856333474
      },
      {
        "epoch": 834,
        "reward": 0.37272560596466064,
        "val_loss": 0.018282481402690922,
        "train_loss": 0.01709974930571871
      },
      {
        "epoch": 835,
        "reward": 0.3729603886604309,
        "val_loss": 0.018245805587087358,
        "train_loss": 0.017387844438557155
      },
      {
        "epoch": 836,
        "reward": 0.37316063046455383,
        "val_loss": 0.018214585026726127,
        "train_loss": 0.017041752440631032
      },
      {
        "epoch": 837,
        "reward": 0.37290236353874207,
        "val_loss": 0.018254863464140465,
        "train_loss": 0.017085735471202776
      },
      {
        "epoch": 838,
        "reward": 0.3734339773654938,
        "val_loss": 0.01817207151491727,
        "train_loss": 0.017031797360127363
      },
      {
        "epoch": 839,
        "reward": 0.3735719621181488,
        "val_loss": 0.018150654987299016,
        "train_loss": 0.017052552156830922
      },
      {
        "epoch": 840,
        "reward": 0.3739036023616791,
        "val_loss": 0.0180992969710912,
        "train_loss": 0.017156581703322724
      },
      {
        "epoch": 841,
        "reward": 0.3741784989833832,
        "val_loss": 0.018056843995249698,
        "train_loss": 0.016971140831279066
      },
      {
        "epoch": 842,
        "reward": 0.3743252754211426,
        "val_loss": 0.018034219642036727,
        "train_loss": 0.017292236461519048
      },
      {
        "epoch": 843,
        "reward": 0.37459737062454224,
        "val_loss": 0.017992373456114104,
        "train_loss": 0.01725783637868097
      },
      {
        "epoch": 844,
        "reward": 0.37454280257225037,
        "val_loss": 0.018000754195132425,
        "train_loss": 0.019254486680997964
      },
      {
        "epoch": 845,
        "reward": 0.37502679228782654,
        "val_loss": 0.01792655243272228,
        "train_loss": 0.016762472123865828
      },
      {
        "epoch": 846,
        "reward": 0.3749285042285919,
        "val_loss": 0.01794158826981272,
        "train_loss": 0.0167850049955842
      },
      {
        "epoch": 847,
        "reward": 0.37539783120155334,
        "val_loss": 0.017869892829496945,
        "train_loss": 0.017144893278152898
      },
      {
        "epoch": 848,
        "reward": 0.37556779384613037,
        "val_loss": 0.01784400861444218,
        "train_loss": 0.016765911884319324
      },
      {
        "epoch": 849,
        "reward": 0.37578433752059937,
        "val_loss": 0.01781109088499631,
        "train_loss": 0.016643043220168553
      },
      {
        "epoch": 850,
        "reward": 0.37585726380348206,
        "val_loss": 0.017800014266478165,
        "train_loss": 0.016630761024246637
      },
      {
        "epoch": 851,
        "reward": 0.3761652112007141,
        "val_loss": 0.017753353974382793,
        "train_loss": 0.016622815744575255
      },
      {
        "epoch": 852,
        "reward": 0.3762436509132385,
        "val_loss": 0.017741489124351313,
        "train_loss": 0.016606095112645283
      },
      {
        "epoch": 853,
        "reward": 0.37625086307525635,
        "val_loss": 0.01774039668297129,
        "train_loss": 0.016675844869146552
      },
      {
        "epoch": 854,
        "reward": 0.3765462338924408,
        "val_loss": 0.017695811776710407,
        "train_loss": 0.016941214893729642
      },
      {
        "epoch": 855,
        "reward": 0.3767980635166168,
        "val_loss": 0.01765788722384189,
        "train_loss": 0.016440071526840957
      },
      {
        "epoch": 856,
        "reward": 0.3769458830356598,
        "val_loss": 0.01763567002490163,
        "train_loss": 0.016474159783683717
      },
      {
        "epoch": 857,
        "reward": 0.3770214915275574,
        "val_loss": 0.01762431949776198,
        "train_loss": 0.016595430681123756
      },
      {
        "epoch": 858,
        "reward": 0.37743517756462097,
        "val_loss": 0.01756235641161246,
        "train_loss": 0.01639075357860957
      },
      {
        "epoch": 859,
        "reward": 0.37767380475997925,
        "val_loss": 0.01752673096156546,
        "train_loss": 0.01633277496680071
      },
      {
        "epoch": 860,
        "reward": 0.3777925372123718,
        "val_loss": 0.01750903160843466,
        "train_loss": 0.01639123295003978
      },
      {
        "epoch": 861,
        "reward": 0.37803125381469727,
        "val_loss": 0.017473506475133554,
        "train_loss": 0.016344338059962656
      },
      {
        "epoch": 862,
        "reward": 0.3781251907348633,
        "val_loss": 0.017459554797304527,
        "train_loss": 0.016259229836578015
      },
      {
        "epoch": 863,
        "reward": 0.37820208072662354,
        "val_loss": 0.017448141306106533,
        "train_loss": 0.016643550515604708
      },
      {
        "epoch": 864,
        "reward": 0.37847432494163513,
        "val_loss": 0.017407790924023305,
        "train_loss": 0.016246691219398948
      },
      {
        "epoch": 865,
        "reward": 0.3787287175655365,
        "val_loss": 0.017370190704241395,
        "train_loss": 0.01618311621580058
      },
      {
        "epoch": 866,
        "reward": 0.37876859307289124,
        "val_loss": 0.01736430241726339,
        "train_loss": 0.016216293984773353
      },
      {
        "epoch": 867,
        "reward": 0.37902021408081055,
        "val_loss": 0.017327210599822656,
        "train_loss": 0.016106737966205962
      },
      {
        "epoch": 868,
        "reward": 0.3790395259857178,
        "val_loss": 0.01732436564218785,
        "train_loss": 0.016398934969821803
      },
      {
        "epoch": 869,
        "reward": 0.37932488322257996,
        "val_loss": 0.017282419305826937,
        "train_loss": 0.016074960395389307
      },
      {
        "epoch": 870,
        "reward": 0.3797111511230469,
        "val_loss": 0.01722581504977175,
        "train_loss": 0.016154693923174188
      },
      {
        "epoch": 871,
        "reward": 0.3798571228981018,
        "val_loss": 0.017204474358420287,
        "train_loss": 0.016012608886879977
      },
      {
        "epoch": 872,
        "reward": 0.3799414038658142,
        "val_loss": 0.017192169159118618,
        "train_loss": 0.01605640367891353
      },
      {
        "epoch": 873,
        "reward": 0.3801668584346771,
        "val_loss": 0.017159297496878674,
        "train_loss": 0.01740337413055106
      },
      {
        "epoch": 874,
        "reward": 0.3804387152194977,
        "val_loss": 0.017119754405160035,
        "train_loss": 0.015944822962270476
      },
      {
        "epoch": 875,
        "reward": 0.3805515468120575,
        "val_loss": 0.01710337839488472,
        "train_loss": 0.0162230609343029
      },
      {
        "epoch": 876,
        "reward": 0.38074278831481934,
        "val_loss": 0.01707564723411841,
        "train_loss": 0.015975591260939837
      },
      {
        "epoch": 877,
        "reward": 0.38071346282958984,
        "val_loss": 0.017079895229211876,
        "train_loss": 0.015882682450375378
      },
      {
        "epoch": 878,
        "reward": 0.3811485171318054,
        "val_loss": 0.017016996629536152,
        "train_loss": 0.015966787544759706
      },
      {
        "epoch": 879,
        "reward": 0.38116058707237244,
        "val_loss": 0.01701525449087577,
        "train_loss": 0.015859176449549314
      },
      {
        "epoch": 880,
        "reward": 0.3814008831977844,
        "val_loss": 0.016980625023799285,
        "train_loss": 0.015755236138759825
      },
      {
        "epoch": 881,
        "reward": 0.38163551688194275,
        "val_loss": 0.016946887264826467,
        "train_loss": 0.016173362212542158
      },
      {
        "epoch": 882,
        "reward": 0.3817630410194397,
        "val_loss": 0.01692858338356018,
        "train_loss": 0.015716916068483373
      },
      {
        "epoch": 883,
        "reward": 0.381967157125473,
        "val_loss": 0.01689933449961245,
        "train_loss": 0.01577467124801702
      },
      {
        "epoch": 884,
        "reward": 0.38212499022483826,
        "val_loss": 0.01687674906237849,
        "train_loss": 0.01572786427165668
      },
      {
        "epoch": 885,
        "reward": 0.38228297233581543,
        "val_loss": 0.01685418581057872,
        "train_loss": 0.01565972164770266
      },
      {
        "epoch": 886,
        "reward": 0.38230836391448975,
        "val_loss": 0.01685055671259761,
        "train_loss": 0.015623391622144621
      },
      {
        "epoch": 887,
        "reward": 0.3826668858528137,
        "val_loss": 0.016799482882821133,
        "train_loss": 0.015711849206127226
      },
      {
        "epoch": 888,
        "reward": 0.3827713131904602,
        "val_loss": 0.016784633975476027,
        "train_loss": 0.015603358839563533
      },
      {
        "epoch": 889,
        "reward": 0.3829290568828583,
        "val_loss": 0.016762234636449387,
        "train_loss": 0.015552872201414384
      },
      {
        "epoch": 890,
        "reward": 0.3830077350139618,
        "val_loss": 0.016751078589420234,
        "train_loss": 0.015611551925898172
      },
      {
        "epoch": 891,
        "reward": 0.38334110379219055,
        "val_loss": 0.016703893397269503,
        "train_loss": 0.015527886422485327
      },
      {
        "epoch": 892,
        "reward": 0.3833652436733246,
        "val_loss": 0.016700481696586524,
        "train_loss": 0.015693496482876632
      },
      {
        "epoch": 893,
        "reward": 0.38367876410484314,
        "val_loss": 0.016656243641461645,
        "train_loss": 0.015640114353468213
      },
      {
        "epoch": 894,
        "reward": 0.38384318351745605,
        "val_loss": 0.016633102637050406,
        "train_loss": 0.015472774313261302
      },
      {
        "epoch": 895,
        "reward": 0.38400378823280334,
        "val_loss": 0.016610528907871673,
        "train_loss": 0.015485358764775671
      },
      {
        "epoch": 896,
        "reward": 0.3841775059700012,
        "val_loss": 0.016586156262617027,
        "train_loss": 0.015407432573668372
      },
      {
        "epoch": 897,
        "reward": 0.38433319330215454,
        "val_loss": 0.01656434029739882,
        "train_loss": 0.015349585861958285
      },
      {
        "epoch": 898,
        "reward": 0.3844374120235443,
        "val_loss": 0.016549750829913785,
        "train_loss": 0.015417616912880195
      },
      {
        "epoch": 899,
        "reward": 0.38466188311576843,
        "val_loss": 0.016518393897318413,
        "train_loss": 0.015342449226234468
      },
      {
        "epoch": 900,
        "reward": 0.38463279604911804,
        "val_loss": 0.016522455993773683,
        "train_loss": 0.015433493643425979
      },
      {
        "epoch": 901,
        "reward": 0.3849608600139618,
        "val_loss": 0.016476718675611273,
        "train_loss": 0.01541524048214062
      },
      {
        "epoch": 902,
        "reward": 0.3850986957550049,
        "val_loss": 0.016457548398258432,
        "train_loss": 0.01529173929996502
      },
      {
        "epoch": 903,
        "reward": 0.3851606547832489,
        "val_loss": 0.016448943044192026,
        "train_loss": 0.01572959933680697
      },
      {
        "epoch": 904,
        "reward": 0.3852945566177368,
        "val_loss": 0.016430349155728306,
        "train_loss": 0.015335778356529772
      },
      {
        "epoch": 905,
        "reward": 0.3856409788131714,
        "val_loss": 0.01638236522142376,
        "train_loss": 0.015399816759432165
      },
      {
        "epoch": 906,
        "reward": 0.3854809105396271,
        "val_loss": 0.016404521485258425,
        "train_loss": 0.015288779207576927
      },
      {
        "epoch": 907,
        "reward": 0.3856661021709442,
        "val_loss": 0.016378886764869094,
        "train_loss": 0.015355850865419667
      },
      {
        "epoch": 908,
        "reward": 0.38589709997177124,
        "val_loss": 0.016346987004258802,
        "train_loss": 0.015142276088366859
      },
      {
        "epoch": 909,
        "reward": 0.3861849009990692,
        "val_loss": 0.016307336444567357,
        "train_loss": 0.015640095977757413
      },
      {
        "epoch": 910,
        "reward": 0.3860059082508087,
        "val_loss": 0.016331985193703855,
        "train_loss": 0.015235007185345659
      },
      {
        "epoch": 911,
        "reward": 0.3864811062812805,
        "val_loss": 0.01626663681651865,
        "train_loss": 0.015093193377721876
      },
      {
        "epoch": 912,
        "reward": 0.3867162764072418,
        "val_loss": 0.016234408299039518,
        "train_loss": 0.015017915494459326
      },
      {
        "epoch": 913,
        "reward": 0.38685932755470276,
        "val_loss": 0.01621483881691737,
        "train_loss": 0.015333561764027063
      },
      {
        "epoch": 914,
        "reward": 0.38684049248695374,
        "val_loss": 0.016217409267223308,
        "train_loss": 0.015144431887445254
      },
      {
        "epoch": 915,
        "reward": 0.3867166340351105,
        "val_loss": 0.01623435351731522,
        "train_loss": 0.014976873784549892
      },
      {
        "epoch": 916,
        "reward": 0.3868694305419922,
        "val_loss": 0.0162134531087109,
        "train_loss": 0.03667743902545995
      },
      {
        "epoch": 917,
        "reward": 0.3872521221637726,
        "val_loss": 0.01616123421782894,
        "train_loss": 0.015041230362839997
      },
      {
        "epoch": 918,
        "reward": 0.38684606552124023,
        "val_loss": 0.016216644950743233,
        "train_loss": 0.014952417160832109
      },
      {
        "epoch": 919,
        "reward": 0.3876214027404785,
        "val_loss": 0.01611101194950087,
        "train_loss": 0.015450653172313021
      },
      {
        "epoch": 920,
        "reward": 0.3876042068004608,
        "val_loss": 0.01611334614322654,
        "train_loss": 0.015008085067025743
      },
      {
        "epoch": 921,
        "reward": 0.38804692029953003,
        "val_loss": 0.016053371530558382,
        "train_loss": 0.014931243557769518
      },
      {
        "epoch": 922,
        "reward": 0.38764461874961853,
        "val_loss": 0.016107866474028145,
        "train_loss": 0.015202653567449978
      },
      {
        "epoch": 923,
        "reward": 0.3883132338523865,
        "val_loss": 0.01601741323247552,
        "train_loss": 0.014822469971057637
      },
      {
        "epoch": 924,
        "reward": 0.38842663168907166,
        "val_loss": 0.016002122412568758,
        "train_loss": 0.014806096905466313
      },
      {
        "epoch": 925,
        "reward": 0.388455331325531,
        "val_loss": 0.015998260783297674,
        "train_loss": 0.01476812520391272
      },
      {
        "epoch": 926,
        "reward": 0.3887134790420532,
        "val_loss": 0.01596352880421494,
        "train_loss": 0.014822826201382738
      },
      {
        "epoch": 927,
        "reward": 0.3888462483882904,
        "val_loss": 0.015945705152781948,
        "train_loss": 0.01475451755126974
      },
      {
        "epoch": 928,
        "reward": 0.38892924785614014,
        "val_loss": 0.015934562177530358,
        "train_loss": 0.0147385419650863
      },
      {
        "epoch": 929,
        "reward": 0.38918375968933105,
        "val_loss": 0.01590047384213124,
        "train_loss": 0.014857020094775809
      },
      {
        "epoch": 930,
        "reward": 0.38932666182518005,
        "val_loss": 0.01588137640750834,
        "train_loss": 0.014842387664919863
      },
      {
        "epoch": 931,
        "reward": 0.3893323838710785,
        "val_loss": 0.015880606336785213,
        "train_loss": 0.01465522364966231
      },
      {
        "epoch": 932,
        "reward": 0.3894760012626648,
        "val_loss": 0.015861435493986522,
        "train_loss": 0.014641079217172913
      },
      {
        "epoch": 933,
        "reward": 0.38946595788002014,
        "val_loss": 0.01586277230775782,
        "train_loss": 0.0146294197475072
      },
      {
        "epoch": 934,
        "reward": 0.3896983563899994,
        "val_loss": 0.015831800077908804,
        "train_loss": 0.015614821163650889
      },
      {
        "epoch": 935,
        "reward": 0.3899548351764679,
        "val_loss": 0.01579769843790148,
        "train_loss": 0.014582062103167677
      },
      {
        "epoch": 936,
        "reward": 0.39017853140830994,
        "val_loss": 0.015768016954617842,
        "train_loss": 0.014586663256453063
      },
      {
        "epoch": 937,
        "reward": 0.39028772711753845,
        "val_loss": 0.015753556741401553,
        "train_loss": 0.014673574782836322
      },
      {
        "epoch": 938,
        "reward": 0.39040812849998474,
        "val_loss": 0.015737617621198297,
        "train_loss": 0.014891199454163702
      },
      {
        "epoch": 939,
        "reward": 0.3905114233493805,
        "val_loss": 0.015723963833547065,
        "train_loss": 0.014558138175813768
      },
      {
        "epoch": 940,
        "reward": 0.39074307680130005,
        "val_loss": 0.015693395232249583,
        "train_loss": 0.014868000732698979
      },
      {
        "epoch": 941,
        "reward": 0.3908686339855194,
        "val_loss": 0.01567685031997306,
        "train_loss": 0.014649274114232797
      },
      {
        "epoch": 942,
        "reward": 0.3900776505470276,
        "val_loss": 0.01578139593558652,
        "train_loss": 0.014826492245237414
      },
      {
        "epoch": 943,
        "reward": 0.39105066657066345,
        "val_loss": 0.015652892911540612,
        "train_loss": 0.014570122620520683
      },
      {
        "epoch": 944,
        "reward": 0.3907778859138489,
        "val_loss": 0.015688805408509716,
        "train_loss": 0.014497145508917479
      },
      {
        "epoch": 945,
        "reward": 0.3913065791130066,
        "val_loss": 0.015619295383138316,
        "train_loss": 0.014408661690350318
      },
      {
        "epoch": 946,
        "reward": 0.39127084612846375,
        "val_loss": 0.015623981432457055,
        "train_loss": 0.01465543658615878
      },
      {
        "epoch": 947,
        "reward": 0.3916430175304413,
        "val_loss": 0.015575233880164368,
        "train_loss": 0.014421867876080796
      },
      {
        "epoch": 948,
        "reward": 0.39126449823379517,
        "val_loss": 0.015624815598130226,
        "train_loss": 0.0143873125310235
      },
      {
        "epoch": 949,
        "reward": 0.3916657865047455,
        "val_loss": 0.015572254213371448,
        "train_loss": 0.01486100791953504
      },
      {
        "epoch": 950,
        "reward": 0.39201295375823975,
        "val_loss": 0.015526949960206236,
        "train_loss": 0.01435134112342404
      },
      {
        "epoch": 951,
        "reward": 0.3921245038509369,
        "val_loss": 0.015512425851609026,
        "train_loss": 0.014367325813509524
      },
      {
        "epoch": 952,
        "reward": 0.39229369163513184,
        "val_loss": 0.015490421592923147,
        "train_loss": 0.014348176303498734
      },
      {
        "epoch": 953,
        "reward": 0.39229506254196167,
        "val_loss": 0.01549024211375841,
        "train_loss": 0.014271774821771452
      },
      {
        "epoch": 954,
        "reward": 0.39254334568977356,
        "val_loss": 0.01545801808658455,
        "train_loss": 0.014275117655275747
      },
      {
        "epoch": 955,
        "reward": 0.3926810324192047,
        "val_loss": 0.01544017783765282,
        "train_loss": 0.014240926328616647
      },
      {
        "epoch": 956,
        "reward": 0.39235571026802063,
        "val_loss": 0.015482364954160792,
        "train_loss": 0.018054581623381145
      },
      {
        "epoch": 957,
        "reward": 0.3928883969783783,
        "val_loss": 0.015413352088736636,
        "train_loss": 0.014347411781692734
      },
      {
        "epoch": 958,
        "reward": 0.39303335547447205,
        "val_loss": 0.015394632371940784,
        "train_loss": 0.014223164070594626
      },
      {
        "epoch": 959,
        "reward": 0.39315542578697205,
        "val_loss": 0.015378884206126844,
        "train_loss": 0.014325689067705892
      },
      {
        "epoch": 960,
        "reward": 0.39310768246650696,
        "val_loss": 0.01538504018182201,
        "train_loss": 0.014394790878913436
      },
      {
        "epoch": 961,
        "reward": 0.3933901786804199,
        "val_loss": 0.015348649716803007,
        "train_loss": 0.014182487565379303
      },
      {
        "epoch": 962,
        "reward": 0.39354148507118225,
        "val_loss": 0.01532920845784247,
        "train_loss": 0.014358763520319302
      },
      {
        "epoch": 963,
        "reward": 0.39348432421684265,
        "val_loss": 0.015336544385978155,
        "train_loss": 0.014247409936685402
      },
      {
        "epoch": 964,
        "reward": 0.3928620517253876,
        "val_loss": 0.015416762292651194,
        "train_loss": 0.014686624071775721
      },
      {
        "epoch": 965,
        "reward": 0.393582284450531,
        "val_loss": 0.015323966575254287,
        "train_loss": 0.014225479940740535
      },
      {
        "epoch": 966,
        "reward": 0.3940754532814026,
        "val_loss": 0.015260780196903008,
        "train_loss": 0.01426161692227022
      },
      {
        "epoch": 967,
        "reward": 0.39397451281547546,
        "val_loss": 0.015273688161479575,
        "train_loss": 0.014057588044894286
      },
      {
        "epoch": 968,
        "reward": 0.3942292034626007,
        "val_loss": 0.015241141564079694,
        "train_loss": 0.014187612597687313
      },
      {
        "epoch": 969,
        "reward": 0.3942681550979614,
        "val_loss": 0.015236169565469027,
        "train_loss": 0.014072224639956122
      },
      {
        "epoch": 970,
        "reward": 0.3946082592010498,
        "val_loss": 0.015192845536928092,
        "train_loss": 0.014001543739980731
      },
      {
        "epoch": 971,
        "reward": 0.3945929706096649,
        "val_loss": 0.015194789007572191,
        "train_loss": 0.04618621042643029
      },
      {
        "epoch": 972,
        "reward": 0.3947015702724457,
        "val_loss": 0.015180979689050998,
        "train_loss": 0.014015017726566069
      },
      {
        "epoch": 973,
        "reward": 0.39498278498649597,
        "val_loss": 0.01514528738334775,
        "train_loss": 0.014172075799881266
      },
      {
        "epoch": 974,
        "reward": 0.39471614360809326,
        "val_loss": 0.015179127155404006,
        "train_loss": 0.01404893366046823
      },
      {
        "epoch": 975,
        "reward": 0.395027756690979,
        "val_loss": 0.015139591580789005,
        "train_loss": 0.014126596291764425
      },
      {
        "epoch": 976,
        "reward": 0.3952006995677948,
        "val_loss": 0.015117694357676166,
        "train_loss": 0.013921673412998924
      },
      {
        "epoch": 977,
        "reward": 0.3954967260360718,
        "val_loss": 0.015080299195168274,
        "train_loss": 0.01428795251278923
      },
      {
        "epoch": 978,
        "reward": 0.39559420943260193,
        "val_loss": 0.015068003442138433,
        "train_loss": 0.013904134053378724
      },
      {
        "epoch": 979,
        "reward": 0.3947293758392334,
        "val_loss": 0.0151774446213884,
        "train_loss": 0.013984061867141953
      },
      {
        "epoch": 980,
        "reward": 0.3958504796028137,
        "val_loss": 0.015035747749997037,
        "train_loss": 0.014434683772448737
      },
      {
        "epoch": 981,
        "reward": 0.3959999978542328,
        "val_loss": 0.015016960612099086,
        "train_loss": 0.01381114490735714
      },
      {
        "epoch": 982,
        "reward": 0.39604875445365906,
        "val_loss": 0.015010831478450979,
        "train_loss": 0.013807083876319947
      },
      {
        "epoch": 983,
        "reward": 0.3960391879081726,
        "val_loss": 0.015012039869491543,
        "train_loss": 0.013819262909237295
      },
      {
        "epoch": 984,
        "reward": 0.3963371217250824,
        "val_loss": 0.014974689643297876,
        "train_loss": 0.013951688951167922
      },
      {
        "epoch": 985,
        "reward": 0.39616870880126953,
        "val_loss": 0.014995789521240763,
        "train_loss": 0.013807525119493501
      },
      {
        "epoch": 986,
        "reward": 0.39650294184684753,
        "val_loss": 0.014953953446820378,
        "train_loss": 0.013771974852156395
      },
      {
        "epoch": 987,
        "reward": 0.3966296911239624,
        "val_loss": 0.014938116273177522,
        "train_loss": 0.014262619468634231
      },
      {
        "epoch": 988,
        "reward": 0.3967306315898895,
        "val_loss": 0.014925523561292462,
        "train_loss": 0.013746071305761758
      },
      {
        "epoch": 989,
        "reward": 0.3967350423336029,
        "val_loss": 0.014924973216173905,
        "train_loss": 0.013747548568062484
      },
      {
        "epoch": 990,
        "reward": 0.39702877402305603,
        "val_loss": 0.014888388204521366,
        "train_loss": 0.013812412364551654
      },
      {
        "epoch": 991,
        "reward": 0.39707621932029724,
        "val_loss": 0.014882486247058426,
        "train_loss": 0.013693031848211272
      },
      {
        "epoch": 992,
        "reward": 0.39726999402046204,
        "val_loss": 0.014858416747301817,
        "train_loss": 0.013666830119396204
      },
      {
        "epoch": 993,
        "reward": 0.39734435081481934,
        "val_loss": 0.014849190733262472,
        "train_loss": 0.013734311492253955
      },
      {
        "epoch": 994,
        "reward": 0.39737722277641296,
        "val_loss": 0.0148451169620135,
        "train_loss": 0.013690672246201966
      },
      {
        "epoch": 995,
        "reward": 0.39723828434944153,
        "val_loss": 0.014862351984317814,
        "train_loss": 0.043815286785292513
      },
      {
        "epoch": 996,
        "reward": 0.3977542817592621,
        "val_loss": 0.014798447123861738,
        "train_loss": 0.013645401204345174
      },
      {
        "epoch": 997,
        "reward": 0.39773961901664734,
        "val_loss": 0.014800257814515914,
        "train_loss": 0.013845712949450199
      },
      {
        "epoch": 998,
        "reward": 0.3979482650756836,
        "val_loss": 0.014774502255022526,
        "train_loss": 0.013702902862300666
      },
      {
        "epoch": 999,
        "reward": 0.3980015218257904,
        "val_loss": 0.014767936264563884,
        "train_loss": 0.013602562230796767
      },
      {
        "epoch": 1000,
        "reward": 0.3981325328350067,
        "val_loss": 0.014751795080623456,
        "train_loss": 0.013555753318472013
      },
      {
        "epoch": 1001,
        "reward": 0.3982805907726288,
        "val_loss": 0.014733574220112391,
        "train_loss": 0.013530594064062686
      },
      {
        "epoch": 1002,
        "reward": 0.3983646035194397,
        "val_loss": 0.014723253070509859,
        "train_loss": 0.013553966875546254
      },
      {
        "epoch": 1003,
        "reward": 0.3978826403617859,
        "val_loss": 0.014782596911702837,
        "train_loss": 0.013523683801395237
      },
      {
        "epoch": 1004,
        "reward": 0.39842158555984497,
        "val_loss": 0.01471625258480864,
        "train_loss": 0.013615574481753776
      },
      {
        "epoch": 1005,
        "reward": 0.3985806107521057,
        "val_loss": 0.014696738350072078,
        "train_loss": 0.013506229655132092
      },
      {
        "epoch": 1006,
        "reward": 0.3988599181175232,
        "val_loss": 0.014662535561780845,
        "train_loss": 0.013551262968506377
      },
      {
        "epoch": 1007,
        "reward": 0.39893922209739685,
        "val_loss": 0.01465283616978143,
        "train_loss": 0.013588688201987399
      },
      {
        "epoch": 1008,
        "reward": 0.3991028666496277,
        "val_loss": 0.014632852681513344,
        "train_loss": 0.013496766685141036
      },
      {
        "epoch": 1009,
        "reward": 0.3991888761520386,
        "val_loss": 0.01462236060095685,
        "train_loss": 0.013453601559516616
      },
      {
        "epoch": 1010,
        "reward": 0.3991561233997345,
        "val_loss": 0.014626354877171772,
        "train_loss": 0.013532089544101976
      },
      {
        "epoch": 1011,
        "reward": 0.39944836497306824,
        "val_loss": 0.01459076055990798,
        "train_loss": 0.013477322582800228
      },
      {
        "epoch": 1012,
        "reward": 0.399543821811676,
        "val_loss": 0.014579149994200893,
        "train_loss": 0.013557941312543474
      },
      {
        "epoch": 1013,
        "reward": 0.3996504545211792,
        "val_loss": 0.014566200020323907,
        "train_loss": 0.013892694188353535
      },
      {
        "epoch": 1014,
        "reward": 0.3997197151184082,
        "val_loss": 0.01455779031052121,
        "train_loss": 0.013384330169803714
      },
      {
        "epoch": 1015,
        "reward": 0.399786114692688,
        "val_loss": 0.01454973450329687,
        "train_loss": 0.013357770063241613
      },
      {
        "epoch": 1016,
        "reward": 0.3999715745449066,
        "val_loss": 0.014527260259326016,
        "train_loss": 0.013478964168685846
      },
      {
        "epoch": 1017,
        "reward": 0.4000234603881836,
        "val_loss": 0.01452098454215697,
        "train_loss": 0.013336626670969473
      },
      {
        "epoch": 1018,
        "reward": 0.40016910433769226,
        "val_loss": 0.014503368309565954,
        "train_loss": 0.013319779969326472
      },
      {
        "epoch": 1019,
        "reward": 0.400317519903183,
        "val_loss": 0.01448544573837093,
        "train_loss": 0.013545744398680445
      },
      {
        "epoch": 1020,
        "reward": 0.4003903567790985,
        "val_loss": 0.01447666170341628,
        "train_loss": 0.013423246591208646
      },
      {
        "epoch": 1021,
        "reward": 0.4005189538002014,
        "val_loss": 0.014461161468976311,
        "train_loss": 0.013416873559785577
      },
      {
        "epoch": 1022,
        "reward": 0.4004348814487457,
        "val_loss": 0.014471296087971755,
        "train_loss": 0.013306905759516386
      },
      {
        "epoch": 1023,
        "reward": 0.40050074458122253,
        "val_loss": 0.014463357028684445,
        "train_loss": 0.013264540184956366
      },
      {
        "epoch": 1024,
        "reward": 0.4003443419933319,
        "val_loss": 0.014482214780790465,
        "train_loss": 0.013403189440186206
      },
      {
        "epoch": 1025,
        "reward": 0.4009260833263397,
        "val_loss": 0.014412215977374996,
        "train_loss": 0.013280935251924138
      },
      {
        "epoch": 1026,
        "reward": 0.4007515013217926,
        "val_loss": 0.014433181445513452,
        "train_loss": 0.013217210822202875
      },
      {
        "epoch": 1027,
        "reward": 0.40120211243629456,
        "val_loss": 0.014379132738603013,
        "train_loss": 0.013226185685198288
      },
      {
        "epoch": 1028,
        "reward": 0.40122947096824646,
        "val_loss": 0.014375852487449135,
        "train_loss": 0.013336280710063875
      },
      {
        "epoch": 1029,
        "reward": 0.4013315737247467,
        "val_loss": 0.014363642016957914,
        "train_loss": 0.022086189450839393
      },
      {
        "epoch": 1030,
        "reward": 0.4015657603740692,
        "val_loss": 0.014335669011675886,
        "train_loss": 0.013206777854065876
      },
      {
        "epoch": 1031,
        "reward": 0.40164700150489807,
        "val_loss": 0.014325979731178709,
        "train_loss": 0.013595238784686305
      },
      {
        "epoch": 1032,
        "reward": 0.40171509981155396,
        "val_loss": 0.014317867213061877,
        "train_loss": 0.013179036367756244
      },
      {
        "epoch": 1033,
        "reward": 0.40136653184890747,
        "val_loss": 0.014359465933271818,
        "train_loss": 0.013109515833863182
      },
      {
        "epoch": 1034,
        "reward": 0.4018888473510742,
        "val_loss": 0.0142971730258848,
        "train_loss": 0.013136073479052776
      },
      {
        "epoch": 1035,
        "reward": 0.4020814895629883,
        "val_loss": 0.014274285208167774,
        "train_loss": 0.013291718071111692
      },
      {
        "epoch": 1036,
        "reward": 0.40192776918411255,
        "val_loss": 0.01429255270133061,
        "train_loss": 0.013259267219557213
      },
      {
        "epoch": 1037,
        "reward": 0.4014348089694977,
        "val_loss": 0.01435130521921175,
        "train_loss": 0.013624193424430605
      },
      {
        "epoch": 1038,
        "reward": 0.402132511138916,
        "val_loss": 0.014268222896914397,
        "train_loss": 0.013204257138288366
      },
      {
        "epoch": 1039,
        "reward": 0.4025302827358246,
        "val_loss": 0.014221097941377334,
        "train_loss": 0.013056731411499921
      },
      {
        "epoch": 1040,
        "reward": 0.40205833315849304,
        "val_loss": 0.014277032243886165,
        "train_loss": 0.01312176462334509
      },
      {
        "epoch": 1041,
        "reward": 0.4027423560619354,
        "val_loss": 0.014196047160242285,
        "train_loss": 0.013655079313768791
      },
      {
        "epoch": 1042,
        "reward": 0.4027358591556549,
        "val_loss": 0.01419680698641709,
        "train_loss": 0.0130226323102785
      },
      {
        "epoch": 1043,
        "reward": 0.4029325544834137,
        "val_loss": 0.014173613960987754,
        "train_loss": 0.013171016990851898
      },
      {
        "epoch": 1044,
        "reward": 0.40304747223854065,
        "val_loss": 0.014160076821488994,
        "train_loss": 0.013001861096619485
      },
      {
        "epoch": 1045,
        "reward": 0.4031486511230469,
        "val_loss": 0.014148174352677805,
        "train_loss": 0.0130213200687789
      },
      {
        "epoch": 1046,
        "reward": 0.403129905462265,
        "val_loss": 0.01415037949170385,
        "train_loss": 0.013010534287716907
      },
      {
        "epoch": 1047,
        "reward": 0.4033287465572357,
        "val_loss": 0.014127008716708847,
        "train_loss": 0.012968442676030744
      },
      {
        "epoch": 1048,
        "reward": 0.4034445881843567,
        "val_loss": 0.014113419655976551,
        "train_loss": 0.01300301651756924
      },
      {
        "epoch": 1049,
        "reward": 0.4034983217716217,
        "val_loss": 0.014107115799561143,
        "train_loss": 0.01332227154993094
      },
      {
        "epoch": 1050,
        "reward": 0.40358757972717285,
        "val_loss": 0.014096662867814302,
        "train_loss": 0.013071209366898984
      },
      {
        "epoch": 1051,
        "reward": 0.40339741110801697,
        "val_loss": 0.014118950148778302,
        "train_loss": 0.012989682512572752
      },
      {
        "epoch": 1052,
        "reward": 0.4034844934940338,
        "val_loss": 0.014108741522899695,
        "train_loss": 0.013539126357780052
      },
      {
        "epoch": 1053,
        "reward": 0.4034159779548645,
        "val_loss": 0.014116778204749738,
        "train_loss": 0.013297555359223714
      },
      {
        "epoch": 1054,
        "reward": 0.4040197432041168,
        "val_loss": 0.014046142775831478,
        "train_loss": 0.013270742595733073
      },
      {
        "epoch": 1055,
        "reward": 0.40410658717155457,
        "val_loss": 0.01403601244757218,
        "train_loss": 0.013008640989517936
      },
      {
        "epoch": 1056,
        "reward": 0.403917521238327,
        "val_loss": 0.014058074248688561,
        "train_loss": 0.012887922464869916
      },
      {
        "epoch": 1057,
        "reward": 0.4042888581752777,
        "val_loss": 0.014014781386192356,
        "train_loss": 0.013326179464526761
      },
      {
        "epoch": 1058,
        "reward": 0.4039829671382904,
        "val_loss": 0.014050433844594019,
        "train_loss": 0.012956423631224494
      },
      {
        "epoch": 1059,
        "reward": 0.40452805161476135,
        "val_loss": 0.013986974089805568,
        "train_loss": 0.01300446073918675
      },
      {
        "epoch": 1060,
        "reward": 0.4045920968055725,
        "val_loss": 0.013979539973661304,
        "train_loss": 0.01280642266045526
      },
      {
        "epoch": 1061,
        "reward": 0.404717355966568,
        "val_loss": 0.013965007882299168,
        "train_loss": 0.012807217890020603
      },
      {
        "epoch": 1062,
        "reward": 0.4047708213329315,
        "val_loss": 0.01395881169342569,
        "train_loss": 0.012778994934146444
      },
      {
        "epoch": 1063,
        "reward": 0.4049336016178131,
        "val_loss": 0.013939966281343783,
        "train_loss": 0.012780529769280782
      },
      {
        "epoch": 1064,
        "reward": 0.4048266112804413,
        "val_loss": 0.01395235160764839,
        "train_loss": 0.012795033815424316
      },
      {
        "epoch": 1065,
        "reward": 0.40449777245521545,
        "val_loss": 0.013990492293877261,
        "train_loss": 0.012744085946626281
      },
      {
        "epoch": 1066,
        "reward": 0.404874324798584,
        "val_loss": 0.01394682573819799,
        "train_loss": 0.012795694931320703
      },
      {
        "epoch": 1067,
        "reward": 0.4051785171031952,
        "val_loss": 0.0139116583325501,
        "train_loss": 0.0132403904482579
      },
      {
        "epoch": 1068,
        "reward": 0.40537571907043457,
        "val_loss": 0.013888911144541842,
        "train_loss": 0.012885882017704157
      },
      {
        "epoch": 1069,
        "reward": 0.4053597152233124,
        "val_loss": 0.013890760285513741,
        "train_loss": 0.012838035347298361
      },
      {
        "epoch": 1070,
        "reward": 0.40556564927101135,
        "val_loss": 0.013867043956582035,
        "train_loss": 0.012974991113878787
      },
      {
        "epoch": 1071,
        "reward": 0.4056806266307831,
        "val_loss": 0.013853824364819698,
        "train_loss": 0.012858124933420466
      },
      {
        "epoch": 1072,
        "reward": 0.4057759940624237,
        "val_loss": 0.013842871745250054,
        "train_loss": 0.013348523079632567
      },
      {
        "epoch": 1073,
        "reward": 0.40587303042411804,
        "val_loss": 0.013831729634797998,
        "train_loss": 0.012796276347496761
      },
      {
        "epoch": 1074,
        "reward": 0.40579530596733093,
        "val_loss": 0.013840656328414167,
        "train_loss": 0.012698168279782224
      },
      {
        "epoch": 1075,
        "reward": 0.40606170892715454,
        "val_loss": 0.013810111608888422,
        "train_loss": 0.01591181474773643
      },
      {
        "epoch": 1076,
        "reward": 0.4061647057533264,
        "val_loss": 0.013798313947128398,
        "train_loss": 0.01319707716958454
      },
      {
        "epoch": 1077,
        "reward": 0.4062662720680237,
        "val_loss": 0.01378669885785452,
        "train_loss": 0.012722983902606826
      },
      {
        "epoch": 1078,
        "reward": 0.4063645899295807,
        "val_loss": 0.013775469702003258,
        "train_loss": 0.012614466434640165
      },
      {
        "epoch": 1079,
        "reward": 0.4064788818359375,
        "val_loss": 0.013762423336239797,
        "train_loss": 0.012611121907516813
      },
      {
        "epoch": 1080,
        "reward": 0.4065763056278229,
        "val_loss": 0.013751313289893525,
        "train_loss": 0.012600270661096147
      },
      {
        "epoch": 1081,
        "reward": 0.40664705634117126,
        "val_loss": 0.013743247470951505,
        "train_loss": 0.012591990416135209
      },
      {
        "epoch": 1082,
        "reward": 0.40673384070396423,
        "val_loss": 0.013733363111636468,
        "train_loss": 0.012604863474245156
      },
      {
        "epoch": 1083,
        "reward": 0.4068639874458313,
        "val_loss": 0.013718558674944299,
        "train_loss": 0.013175014101971801
      },
      {
        "epoch": 1084,
        "reward": 0.4069335460662842,
        "val_loss": 0.013710658764466643,
        "train_loss": 0.012664828601723107
      },
      {
        "epoch": 1085,
        "reward": 0.4070410430431366,
        "val_loss": 0.013698447096560682,
        "train_loss": 0.012550745316100521
      },
      {
        "epoch": 1086,
        "reward": 0.4071459472179413,
        "val_loss": 0.013686542831627386,
        "train_loss": 0.012646352702106994
      },
      {
        "epoch": 1087,
        "reward": 0.40724602341651917,
        "val_loss": 0.013675202149897814,
        "train_loss": 0.012533844283797616
      },
      {
        "epoch": 1088,
        "reward": 0.40684986114501953,
        "val_loss": 0.01372016716881522,
        "train_loss": 0.012653345349602975
      },
      {
        "epoch": 1089,
        "reward": 0.4070874750614166,
        "val_loss": 0.013693180766754917,
        "train_loss": 0.012570703643947266
      },
      {
        "epoch": 1090,
        "reward": 0.4073961675167084,
        "val_loss": 0.013658201321959496,
        "train_loss": 0.013202728694663025
      },
      {
        "epoch": 1091,
        "reward": 0.40760669112205505,
        "val_loss": 0.0136344015398728,
        "train_loss": 0.012608068636976756
      },
      {
        "epoch": 1092,
        "reward": 0.40671873092651367,
        "val_loss": 0.01373508373009307,
        "train_loss": 0.013087084454197723
      },
      {
        "epoch": 1093,
        "reward": 0.4077532887458801,
        "val_loss": 0.013617859887225288,
        "train_loss": 0.012496315041481956
      },
      {
        "epoch": 1094,
        "reward": 0.4078505039215088,
        "val_loss": 0.013606901446889554,
        "train_loss": 0.012631702756222624
      },
      {
        "epoch": 1095,
        "reward": 0.40775641798973083,
        "val_loss": 0.013617501993264471,
        "train_loss": 0.012945189686993567
      },
      {
        "epoch": 1096,
        "reward": 0.4080885946750641,
        "val_loss": 0.01358009928039142,
        "train_loss": 0.012506662267976655
      },
      {
        "epoch": 1097,
        "reward": 0.4065362513065338,
        "val_loss": 0.013755879298384701,
        "train_loss": 0.012875323228609677
      },
      {
        "epoch": 1098,
        "reward": 0.4082394242286682,
        "val_loss": 0.013563147280365229,
        "train_loss": 0.012453279892901912
      },
      {
        "epoch": 1099,
        "reward": 0.40836524963378906,
        "val_loss": 0.013549030791702015,
        "train_loss": 0.012398940484182766
      },
      {
        "epoch": 1100,
        "reward": 0.408440500497818,
        "val_loss": 0.01354059696729694,
        "train_loss": 0.012393720562193686
      },
      {
        "epoch": 1101,
        "reward": 0.4085312485694885,
        "val_loss": 0.013530425128660031,
        "train_loss": 0.01239668821486143
      },
      {
        "epoch": 1102,
        "reward": 0.40830016136169434,
        "val_loss": 0.013556333624624781,
        "train_loss": 0.01239142500428268
      },
      {
        "epoch": 1103,
        "reward": 0.40860214829444885,
        "val_loss": 0.013522487732448749,
        "train_loss": 0.012515967756581422
      },
      {
        "epoch": 1104,
        "reward": 0.4081510007381439,
        "val_loss": 0.013573083095252514,
        "train_loss": 0.012566455039912118
      },
      {
        "epoch": 1105,
        "reward": 0.408870667219162,
        "val_loss": 0.013492471904360823,
        "train_loss": 0.013011812411535244
      },
      {
        "epoch": 1106,
        "reward": 0.4090006351470947,
        "val_loss": 0.013477971544489264,
        "train_loss": 0.012331890002175126
      },
      {
        "epoch": 1107,
        "reward": 0.4090728461742401,
        "val_loss": 0.013469920759754521,
        "train_loss": 0.012431971075084921
      },
      {
        "epoch": 1108,
        "reward": 0.40904465317726135,
        "val_loss": 0.013473060680553317,
        "train_loss": 0.012922136256327996
      },
      {
        "epoch": 1109,
        "reward": 0.4092628061771393,
        "val_loss": 0.013448770956269332,
        "train_loss": 0.012314397016710315
      },
      {
        "epoch": 1110,
        "reward": 0.4093489646911621,
        "val_loss": 0.013439185385193144,
        "train_loss": 0.012459635900226064
      },
      {
        "epoch": 1111,
        "reward": 0.4091360569000244,
        "val_loss": 0.013462875770138842,
        "train_loss": 0.012304543748541619
      },
      {
        "epoch": 1112,
        "reward": 0.4095260202884674,
        "val_loss": 0.013419521140999027,
        "train_loss": 0.01228828357628887
      },
      {
        "epoch": 1113,
        "reward": 0.40964674949645996,
        "val_loss": 0.013406124797516636,
        "train_loss": 0.012270647599227512
      },
      {
        "epoch": 1114,
        "reward": 0.40973058342933655,
        "val_loss": 0.01339683635160327,
        "train_loss": 0.012400852838674417
      },
      {
        "epoch": 1115,
        "reward": 0.4094812870025635,
        "val_loss": 0.013424483793122428,
        "train_loss": 0.012776007625059439
      },
      {
        "epoch": 1116,
        "reward": 0.4097382128238678,
        "val_loss": 0.013395989646336861,
        "train_loss": 0.012278462919102121
      },
      {
        "epoch": 1117,
        "reward": 0.4095950126647949,
        "val_loss": 0.013411866002050894,
        "train_loss": 0.012875709333457053
      },
      {
        "epoch": 1118,
        "reward": 0.4092005789279938,
        "val_loss": 0.013455692046721066,
        "train_loss": 0.012350877102177877
      },
      {
        "epoch": 1119,
        "reward": 0.4099198877811432,
        "val_loss": 0.013375881327582257,
        "train_loss": 0.012241386691235116
      },
      {
        "epoch": 1120,
        "reward": 0.40969759225845337,
        "val_loss": 0.013400491692924075,
        "train_loss": 0.01231489924248308
      },
      {
        "epoch": 1121,
        "reward": 0.40999099612236023,
        "val_loss": 0.013368018570223026,
        "train_loss": 0.012221721456066566
      },
      {
        "epoch": 1122,
        "reward": 0.4104066491127014,
        "val_loss": 0.013322168894644295,
        "train_loss": 0.01220925410318439
      },
      {
        "epoch": 1123,
        "reward": 0.41005825996398926,
        "val_loss": 0.013360587131631161,
        "train_loss": 0.012265472099758111
      },
      {
        "epoch": 1124,
        "reward": 0.4106315076351166,
        "val_loss": 0.013297429773956537,
        "train_loss": 0.012216118727407705
      },
      {
        "epoch": 1125,
        "reward": 0.4106789231300354,
        "val_loss": 0.013292219855689577,
        "train_loss": 0.012750645302451001
      },
      {
        "epoch": 1126,
        "reward": 0.41055426001548767,
        "val_loss": 0.013305920575346266,
        "train_loss": 0.012339187562107466
      },
      {
        "epoch": 1127,
        "reward": 0.4108341634273529,
        "val_loss": 0.013275182672909327,
        "train_loss": 0.01228632574650244
      },
      {
        "epoch": 1128,
        "reward": 0.4108640253543854,
        "val_loss": 0.013271902588063053,
        "train_loss": 0.01225647624904433
      },
      {
        "epoch": 1129,
        "reward": 0.40978381037712097,
        "val_loss": 0.013390941279275077,
        "train_loss": 0.012254479806870222
      },
      {
        "epoch": 1130,
        "reward": 0.4105263650417328,
        "val_loss": 0.013308987986030323,
        "train_loss": 0.012640013493812429
      },
      {
        "epoch": 1131,
        "reward": 0.4107770621776581,
        "val_loss": 0.013281447945960931,
        "train_loss": 0.012153316783951595
      },
      {
        "epoch": 1132,
        "reward": 0.4109707474708557,
        "val_loss": 0.013260209666831153,
        "train_loss": 0.01208432621150188
      },
      {
        "epoch": 1133,
        "reward": 0.4113929271697998,
        "val_loss": 0.01321404640163694,
        "train_loss": 0.012098130324515156
      },
      {
        "epoch": 1134,
        "reward": 0.4114554524421692,
        "val_loss": 0.013207227157961045,
        "train_loss": 0.012102047521553826
      },
      {
        "epoch": 1135,
        "reward": 0.41154375672340393,
        "val_loss": 0.013197597714939288,
        "train_loss": 0.027684977184085604
      },
      {
        "epoch": 1136,
        "reward": 0.4114595353603363,
        "val_loss": 0.013206774352251418,
        "train_loss": 0.012166981737559231
      },
      {
        "epoch": 1137,
        "reward": 0.4116644561290741,
        "val_loss": 0.013184447174093552,
        "train_loss": 0.01225298485503747
      },
      {
        "epoch": 1138,
        "reward": 0.4118516147136688,
        "val_loss": 0.01316408473732216,
        "train_loss": 0.012098972381164249
      },
      {
        "epoch": 1139,
        "reward": 0.41193172335624695,
        "val_loss": 0.013155384920537472,
        "train_loss": 0.012185974762989925
      },
      {
        "epoch": 1140,
        "reward": 0.4120224118232727,
        "val_loss": 0.013145537614556295,
        "train_loss": 0.012029752035652144
      },
      {
        "epoch": 1141,
        "reward": 0.41208139061927795,
        "val_loss": 0.013139135470347745,
        "train_loss": 0.012124338339512737
      },
      {
        "epoch": 1142,
        "reward": 0.4120098054409027,
        "val_loss": 0.013146907822894198,
        "train_loss": 0.012066345273209524
      },
      {
        "epoch": 1143,
        "reward": 0.41219663619995117,
        "val_loss": 0.013126639017303075,
        "train_loss": 0.012021988451194305
      },
      {
        "epoch": 1144,
        "reward": 0.4123161733150482,
        "val_loss": 0.013113694531576974,
        "train_loss": 0.012128023475480195
      },
      {
        "epoch": 1145,
        "reward": 0.4116845726966858,
        "val_loss": 0.013182255239891154,
        "train_loss": 0.012544040201016916
      },
      {
        "epoch": 1146,
        "reward": 0.41243425011634827,
        "val_loss": 0.013100926498217242,
        "train_loss": 0.012008819631144153
      },
      {
        "epoch": 1147,
        "reward": 0.41253000497817993,
        "val_loss": 0.013090571238925415,
        "train_loss": 0.011987982548397178
      },
      {
        "epoch": 1148,
        "reward": 0.41262373328208923,
        "val_loss": 0.013080449957799698,
        "train_loss": 0.012104996686013272
      },
      {
        "epoch": 1149,
        "reward": 0.4126887917518616,
        "val_loss": 0.013073437414797289,
        "train_loss": 0.011980097365617089
      },
      {
        "epoch": 1150,
        "reward": 0.41276198625564575,
        "val_loss": 0.013065544322931342,
        "train_loss": 0.012411243743442286
      },
      {
        "epoch": 1151,
        "reward": 0.41293883323669434,
        "val_loss": 0.013046489463054709,
        "train_loss": 0.011936730321254939
      },
      {
        "epoch": 1152,
        "reward": 0.4130130708217621,
        "val_loss": 0.0130385045361306,
        "train_loss": 0.011926520142878871
      },
      {
        "epoch": 1153,
        "reward": 0.41290196776390076,
        "val_loss": 0.013050460389682226,
        "train_loss": 0.012005007145209955
      },
      {
        "epoch": 1154,
        "reward": 0.4131295382976532,
        "val_loss": 0.013025987327897124,
        "train_loss": 0.012037475826218724
      },
      {
        "epoch": 1155,
        "reward": 0.41326403617858887,
        "val_loss": 0.013011538090982608,
        "train_loss": 0.012024869139377888
      },
      {
        "epoch": 1156,
        "reward": 0.41315698623657227,
        "val_loss": 0.01302303170918354,
        "train_loss": 0.011957807994734209
      },
      {
        "epoch": 1157,
        "reward": 0.4133962094783783,
        "val_loss": 0.012997359669368182,
        "train_loss": 0.012032168192000916
      },
      {
        "epoch": 1158,
        "reward": 0.4135066568851471,
        "val_loss": 0.012985523956428682,
        "train_loss": 0.011868013609273476
      },
      {
        "epoch": 1159,
        "reward": 0.41363364458084106,
        "val_loss": 0.012971935627449836,
        "train_loss": 0.011982183822860511
      },
      {
        "epoch": 1160,
        "reward": 0.41371092200279236,
        "val_loss": 0.012963669574154275,
        "train_loss": 0.011961975116999103
      },
      {
        "epoch": 1161,
        "reward": 0.41381460428237915,
        "val_loss": 0.012952596980280109,
        "train_loss": 0.012280920404009521
      },
      {
        "epoch": 1162,
        "reward": 0.41385388374328613,
        "val_loss": 0.012948400972943221,
        "train_loss": 0.012473314705018241
      },
      {
        "epoch": 1163,
        "reward": 0.4139612317085266,
        "val_loss": 0.012936951293210899,
        "train_loss": 0.011945121138034245
      },
      {
        "epoch": 1164,
        "reward": 0.4140654504299164,
        "val_loss": 0.012925833596714906,
        "train_loss": 0.011893410338626172
      },
      {
        "epoch": 1165,
        "reward": 0.41416317224502563,
        "val_loss": 0.012915428012742527,
        "train_loss": 0.012048661592416465
      },
      {
        "epoch": 1166,
        "reward": 0.41423651576042175,
        "val_loss": 0.012907625974289008,
        "train_loss": 0.011935788421676708
      },
      {
        "epoch": 1167,
        "reward": 0.4141065180301666,
        "val_loss": 0.012921464695994343,
        "train_loss": 0.011802912619364529
      },
      {
        "epoch": 1168,
        "reward": 0.41432610154151917,
        "val_loss": 0.01289809082767793,
        "train_loss": 0.011785178460950892
      },
      {
        "epoch": 1169,
        "reward": 0.4142496585845947,
        "val_loss": 0.012906228125627552,
        "train_loss": 0.012423268935750596
      },
      {
        "epoch": 1170,
        "reward": 0.41456323862075806,
        "val_loss": 0.012872913586241859,
        "train_loss": 0.011789129628316285
      },
      {
        "epoch": 1171,
        "reward": 0.41464653611183167,
        "val_loss": 0.012864082286666547,
        "train_loss": 0.011849870117237935
      },
      {
        "epoch": 1172,
        "reward": 0.41462770104408264,
        "val_loss": 0.012866075616329908,
        "train_loss": 0.011763348454573693
      },
      {
        "epoch": 1173,
        "reward": 0.41480752825737,
        "val_loss": 0.012847024581528135,
        "train_loss": 0.011818335816944735
      },
      {
        "epoch": 1174,
        "reward": 0.4147430956363678,
        "val_loss": 0.012853852888968374,
        "train_loss": 0.011756262664745849
      },
      {
        "epoch": 1175,
        "reward": 0.4148974120616913,
        "val_loss": 0.01283752020182354,
        "train_loss": 0.011731507677513246
      },
      {
        "epoch": 1176,
        "reward": 0.4150013029575348,
        "val_loss": 0.012826531726334776,
        "train_loss": 0.011723802667872336
      },
      {
        "epoch": 1177,
        "reward": 0.41495439410209656,
        "val_loss": 0.012831491551228933,
        "train_loss": 0.012319424744838705
      },
      {
        "epoch": 1178,
        "reward": 0.41516509652137756,
        "val_loss": 0.012809236068278551,
        "train_loss": 0.011873037975209836
      },
      {
        "epoch": 1179,
        "reward": 0.4151836037635803,
        "val_loss": 0.01280728604511491,
        "train_loss": 0.012217095282931741
      },
      {
        "epoch": 1180,
        "reward": 0.41538047790527344,
        "val_loss": 0.012786535912060313,
        "train_loss": 0.031789017017357625
      },
      {
        "epoch": 1181,
        "reward": 0.4152226448059082,
        "val_loss": 0.012803170796749848,
        "train_loss": 0.011700203892989801
      },
      {
        "epoch": 1182,
        "reward": 0.41487082839012146,
        "val_loss": 0.012840331199445896,
        "train_loss": 0.011800412124452682
      },
      {
        "epoch": 1183,
        "reward": 0.41537943482398987,
        "val_loss": 0.012786646805969732,
        "train_loss": 0.011697482174405685
      },
      {
        "epoch": 1184,
        "reward": 0.414715439081192,
        "val_loss": 0.012856778123282961,
        "train_loss": 0.011654660283528965
      },
      {
        "epoch": 1185,
        "reward": 0.41579708456993103,
        "val_loss": 0.012742741233003991,
        "train_loss": 0.011682652344741374
      },
      {
        "epoch": 1186,
        "reward": 0.4157828986644745,
        "val_loss": 0.012744235756274844,
        "train_loss": 0.011653230308393877
      },
      {
        "epoch": 1187,
        "reward": 0.4159714877605438,
        "val_loss": 0.0127244588220492,
        "train_loss": 0.011639759219108852
      },
      {
        "epoch": 1188,
        "reward": 0.41603681445121765,
        "val_loss": 0.012717624361227666,
        "train_loss": 0.01161690403020106
      },
      {
        "epoch": 1189,
        "reward": 0.41600996255874634,
        "val_loss": 0.012720431068113871,
        "train_loss": 0.01164157147734211
      },
      {
        "epoch": 1190,
        "reward": 0.41612568497657776,
        "val_loss": 0.012708317322124327,
        "train_loss": 0.011642137457294246
      },
      {
        "epoch": 1191,
        "reward": 0.41629481315612793,
        "val_loss": 0.012690638823966895,
        "train_loss": 0.012157169887079643
      },
      {
        "epoch": 1192,
        "reward": 0.41623741388320923,
        "val_loss": 0.01269663790506976,
        "train_loss": 0.011746986840779964
      },
      {
        "epoch": 1193,
        "reward": 0.41627237200737,
        "val_loss": 0.012692989016483937,
        "train_loss": 0.011581024077223936
      },
      {
        "epoch": 1194,
        "reward": 0.41655516624450684,
        "val_loss": 0.012663477050539638,
        "train_loss": 0.011560481684262833
      },
      {
        "epoch": 1195,
        "reward": 0.41661062836647034,
        "val_loss": 0.012657699873670936,
        "train_loss": 0.01156470382389111
      },
      {
        "epoch": 1196,
        "reward": 0.41664940118789673,
        "val_loss": 0.012653665101554776,
        "train_loss": 0.011562872626689988
      },
      {
        "epoch": 1197,
        "reward": 0.4167807102203369,
        "val_loss": 0.012639998840833349,
        "train_loss": 0.011803648246523853
      },
      {
        "epoch": 1198,
        "reward": 0.41669049859046936,
        "val_loss": 0.012649379504312361,
        "train_loss": 0.011823281430854248
      },
      {
        "epoch": 1199,
        "reward": 0.41696974635124207,
        "val_loss": 0.012620356632396579,
        "train_loss": 0.01166584707187632
      },
      {
        "epoch": 1200,
        "reward": 0.4169011116027832,
        "val_loss": 0.012627482314461045,
        "train_loss": 0.011606954047098182
      },
      {
        "epoch": 1201,
        "reward": 0.41712328791618347,
        "val_loss": 0.01260442118759134,
        "train_loss": 0.011503769719638512
      },
      {
        "epoch": 1202,
        "reward": 0.4172225892543793,
        "val_loss": 0.012594126630574465,
        "train_loss": 0.011631456741060201
      },
      {
        "epoch": 1203,
        "reward": 0.41730067133903503,
        "val_loss": 0.012586045611117567,
        "train_loss": 0.011544835950749425
      },
      {
        "epoch": 1204,
        "reward": 0.41739463806152344,
        "val_loss": 0.012576317181810737,
        "train_loss": 0.011531147429755388
      },
      {
        "epoch": 1205,
        "reward": 0.4172641336917877,
        "val_loss": 0.012589827579047,
        "train_loss": 0.01147292054002509
      },
      {
        "epoch": 1206,
        "reward": 0.4172329604625702,
        "val_loss": 0.012593057006597519,
        "train_loss": 0.012085683196066664
      },
      {
        "epoch": 1207,
        "reward": 0.41758331656455994,
        "val_loss": 0.012556822870724968,
        "train_loss": 0.011513066057187434
      },
      {
        "epoch": 1208,
        "reward": 0.4172302186489105,
        "val_loss": 0.012593337501000081,
        "train_loss": 0.011491027309183175
      },
      {
        "epoch": 1209,
        "reward": 0.4175891578197479,
        "val_loss": 0.012556218375851,
        "train_loss": 0.011600023628069231
      },
      {
        "epoch": 1210,
        "reward": 0.41772913932800293,
        "val_loss": 0.01254177512601018,
        "train_loss": 0.01147188719523211
      },
      {
        "epoch": 1211,
        "reward": 0.4179137647151947,
        "val_loss": 0.012522748904302716,
        "train_loss": 0.011606702169116873
      },
      {
        "epoch": 1212,
        "reward": 0.417969286441803,
        "val_loss": 0.012517037635136927,
        "train_loss": 0.011453189553531747
      },
      {
        "epoch": 1213,
        "reward": 0.4181031286716461,
        "val_loss": 0.012503268563055567,
        "train_loss": 0.011451872092528412
      },
      {
        "epoch": 1214,
        "reward": 0.4181794226169586,
        "val_loss": 0.01249543106782117,
        "train_loss": 0.011404300907490604
      },
      {
        "epoch": 1215,
        "reward": 0.4179050028324127,
        "val_loss": 0.012523654981383256,
        "train_loss": 0.017138839618732724
      },
      {
        "epoch": 1216,
        "reward": 0.41826969385147095,
        "val_loss": 0.01248616078269801,
        "train_loss": 0.011395026562800363
      },
      {
        "epoch": 1217,
        "reward": 0.4184153079986572,
        "val_loss": 0.012471227141629373,
        "train_loss": 0.011449501218381695
      },
      {
        "epoch": 1218,
        "reward": 0.41847607493400574,
        "val_loss": 0.012465000867710583,
        "train_loss": 0.011386906450542692
      },
      {
        "epoch": 1219,
        "reward": 0.41856643557548523,
        "val_loss": 0.012455746997147799,
        "train_loss": 0.011365682870781222
      },
      {
        "epoch": 1220,
        "reward": 0.41844436526298523,
        "val_loss": 0.01246825056815786,
        "train_loss": 0.011872925025482591
      },
      {
        "epoch": 1221,
        "reward": 0.4187459647655487,
        "val_loss": 0.01243738440929779,
        "train_loss": 0.011355247408993399
      },
      {
        "epoch": 1222,
        "reward": 0.4186968505382538,
        "val_loss": 0.012442408462188073,
        "train_loss": 0.011490382218303589
      },
      {
        "epoch": 1223,
        "reward": 0.4188794791698456,
        "val_loss": 0.012423750977697117,
        "train_loss": 0.011388319378826194
      },
      {
        "epoch": 1224,
        "reward": 0.41886886954307556,
        "val_loss": 0.01242483121209911,
        "train_loss": 0.011411096855926398
      },
      {
        "epoch": 1225,
        "reward": 0.41908231377601624,
        "val_loss": 0.012403066935283797,
        "train_loss": 0.011456254838356892
      },
      {
        "epoch": 1226,
        "reward": 0.4189518094062805,
        "val_loss": 0.012416367585371648,
        "train_loss": 0.011497438589755733
      },
      {
        "epoch": 1227,
        "reward": 0.4188881516456604,
        "val_loss": 0.012422863826421755,
        "train_loss": 0.011457853807279697
      },
      {
        "epoch": 1228,
        "reward": 0.41929206252098083,
        "val_loss": 0.012381710411448563,
        "train_loss": 0.011373381318452839
      },
      {
        "epoch": 1229,
        "reward": 0.4193970263004303,
        "val_loss": 0.012371042643540673,
        "train_loss": 0.011301193694914847
      },
      {
        "epoch": 1230,
        "reward": 0.41948366165161133,
        "val_loss": 0.012362241046503186,
        "train_loss": 0.011282398343857162
      },
      {
        "epoch": 1231,
        "reward": 0.41942450404167175,
        "val_loss": 0.012368253731567944,
        "train_loss": 0.011313044130264852
      },
      {
        "epoch": 1232,
        "reward": 0.41953134536743164,
        "val_loss": 0.01235740169483636,
        "train_loss": 0.011395236692176415
      },
      {
        "epoch": 1233,
        "reward": 0.4197200834751129,
        "val_loss": 0.012338265111403806,
        "train_loss": 0.011383592133195354
      },
      {
        "epoch": 1234,
        "reward": 0.41962218284606934,
        "val_loss": 0.012348189068559026,
        "train_loss": 0.011368260432321291
      },
      {
        "epoch": 1235,
        "reward": 0.4194033741950989,
        "val_loss": 0.012370401028809803,
        "train_loss": 0.011894923522889327
      },
      {
        "epoch": 1236,
        "reward": 0.4199146330356598,
        "val_loss": 0.012318570449549173,
        "train_loss": 0.011910289696131188
      },
      {
        "epoch": 1237,
        "reward": 0.4200124442577362,
        "val_loss": 0.012308682448097638,
        "train_loss": 0.01124414940400479
      },
      {
        "epoch": 1238,
        "reward": 0.4199768602848053,
        "val_loss": 0.012312274692314011,
        "train_loss": 0.011286177484390255
      },
      {
        "epoch": 1239,
        "reward": 0.41992488503456116,
        "val_loss": 0.012317532357493681,
        "train_loss": 0.0114785919431597
      },
      {
        "epoch": 1240,
        "reward": 0.42010602355003357,
        "val_loss": 0.012299223470368556,
        "train_loss": 0.011305481150674705
      },
      {
        "epoch": 1241,
        "reward": 0.4203089773654938,
        "val_loss": 0.012278753881608801,
        "train_loss": 0.01122294603443991
      },
      {
        "epoch": 1242,
        "reward": 0.4198834002017975,
        "val_loss": 0.012321726651862264,
        "train_loss": 0.011204660894761149
      },
      {
        "epoch": 1243,
        "reward": 0.4203660488128662,
        "val_loss": 0.012273005276386226,
        "train_loss": 0.011376609304884018
      },
      {
        "epoch": 1244,
        "reward": 0.4204191267490387,
        "val_loss": 0.012267654046549328,
        "train_loss": 0.011296779611327041
      },
      {
        "epoch": 1245,
        "reward": 0.4202118515968323,
        "val_loss": 0.012288548019049423,
        "train_loss": 0.011389370318143986
      },
      {
        "epoch": 1246,
        "reward": 0.4204578101634979,
        "val_loss": 0.012263764128355044,
        "train_loss": 0.011189864305868888
      },
      {
        "epoch": 1247,
        "reward": 0.42077913880348206,
        "val_loss": 0.012231463865776147,
        "train_loss": 0.011167494766001394
      },
      {
        "epoch": 1248,
        "reward": 0.4207257926464081,
        "val_loss": 0.012236820899748377,
        "train_loss": 0.011334962874221114
      },
      {
        "epoch": 1249,
        "reward": 0.42093682289123535,
        "val_loss": 0.012215647014922329,
        "train_loss": 0.011798439587717159
      },
      {
        "epoch": 1250,
        "reward": 0.4209945797920227,
        "val_loss": 0.012209863834349173,
        "train_loss": 0.011154843790651424
      },
      {
        "epoch": 1251,
        "reward": 0.42103472352027893,
        "val_loss": 0.012205840371149992,
        "train_loss": 0.011238271424260277
      },
      {
        "epoch": 1252,
        "reward": 0.42114147543907166,
        "val_loss": 0.012195151731637972,
        "train_loss": 0.011150999061870746
      },
      {
        "epoch": 1253,
        "reward": 0.4212200343608856,
        "val_loss": 0.012187298952734895,
        "train_loss": 0.011117512994622722
      },
      {
        "epoch": 1254,
        "reward": 0.4213176667690277,
        "val_loss": 0.012177536629938654,
        "train_loss": 0.011142821454156477
      },
      {
        "epoch": 1255,
        "reward": 0.42137765884399414,
        "val_loss": 0.012171548658183642,
        "train_loss": 0.011185947138493737
      },
      {
        "epoch": 1256,
        "reward": 0.4214168190956116,
        "val_loss": 0.012167641427367926,
        "train_loss": 0.011245475683468752
      },
      {
        "epoch": 1257,
        "reward": 0.4212043881416321,
        "val_loss": 0.012188864605767387,
        "train_loss": 0.011680998024530709
      },
      {
        "epoch": 1258,
        "reward": 0.4216248095035553,
        "val_loss": 0.012146901239507965,
        "train_loss": 0.011192703744969688
      },
      {
        "epoch": 1259,
        "reward": 0.4214494824409485,
        "val_loss": 0.01216438366100192,
        "train_loss": 0.011075482369199982
      },
      {
        "epoch": 1260,
        "reward": 0.42174288630485535,
        "val_loss": 0.012135145237802394,
        "train_loss": 0.011065499319766577
      },
      {
        "epoch": 1261,
        "reward": 0.4217550456523895,
        "val_loss": 0.012133934135947908,
        "train_loss": 0.011066299005156347
      },
      {
        "epoch": 1262,
        "reward": 0.42187872529029846,
        "val_loss": 0.01212162893664624,
        "train_loss": 0.011046796239008052
      },
      {
        "epoch": 1263,
        "reward": 0.4213181138038635,
        "val_loss": 0.012177492192547237,
        "train_loss": 0.011536691140813323
      },
      {
        "epoch": 1264,
        "reward": 0.4220801889896393,
        "val_loss": 0.012101624926019992,
        "train_loss": 0.011068255885150462
      },
      {
        "epoch": 1265,
        "reward": 0.4220237731933594,
        "val_loss": 0.012107219996063836,
        "train_loss": 0.011033616906318527
      },
      {
        "epoch": 1266,
        "reward": 0.42221948504447937,
        "val_loss": 0.012087809786732708,
        "train_loss": 0.011036703388806647
      },
      {
        "epoch": 1267,
        "reward": 0.42210420966148376,
        "val_loss": 0.012099237646907568,
        "train_loss": 0.011116692939629922
      },
      {
        "epoch": 1268,
        "reward": 0.4220893383026123,
        "val_loss": 0.01210071349383465,
        "train_loss": 0.011012751919924294
      },
      {
        "epoch": 1269,
        "reward": 0.4224446415901184,
        "val_loss": 0.012065517233817704,
        "train_loss": 0.011041276004666893
      },
      {
        "epoch": 1270,
        "reward": 0.42252498865127563,
        "val_loss": 0.012057579355314374,
        "train_loss": 0.01230797803369709
      },
      {
        "epoch": 1271,
        "reward": 0.4224226474761963,
        "val_loss": 0.012067700237301844,
        "train_loss": 0.01103688387844998
      },
      {
        "epoch": 1272,
        "reward": 0.42255082726478577,
        "val_loss": 0.012055023074416178,
        "train_loss": 0.011580514999178167
      },
      {
        "epoch": 1273,
        "reward": 0.42268887162208557,
        "val_loss": 0.012041393068752118,
        "train_loss": 0.010977313663785866
      },
      {
        "epoch": 1274,
        "reward": 0.4228181838989258,
        "val_loss": 0.012028634714494859,
        "train_loss": 0.01096641215875794
      },
      {
        "epoch": 1275,
        "reward": 0.42257261276245117,
        "val_loss": 0.012052874380190457,
        "train_loss": 0.010968767746537477
      },
      {
        "epoch": 1276,
        "reward": 0.4229446351528168,
        "val_loss": 0.01201617599664522,
        "train_loss": 0.010947435793241311
      },
      {
        "epoch": 1277,
        "reward": 0.42304739356040955,
        "val_loss": 0.012006062282515424,
        "train_loss": 0.011344571911300031
      },
      {
        "epoch": 1278,
        "reward": 0.42303267121315,
        "val_loss": 0.012007508792781405,
        "train_loss": 0.011504714977211105
      },
      {
        "epoch": 1279,
        "reward": 0.4229661524295807,
        "val_loss": 0.012014060530678503,
        "train_loss": 0.010973655524699448
      },
      {
        "epoch": 1280,
        "reward": 0.4228857159614563,
        "val_loss": 0.012021986218834562,
        "train_loss": 0.01109317323873536
      },
      {
        "epoch": 1281,
        "reward": 0.42331233620643616,
        "val_loss": 0.011980029887386731,
        "train_loss": 0.011100123717019765
      },
      {
        "epoch": 1282,
        "reward": 0.42299124598503113,
        "val_loss": 0.012011589249596,
        "train_loss": 0.011090221698395908
      },
      {
        "epoch": 1283,
        "reward": 0.4235009253025055,
        "val_loss": 0.01196153275668621,
        "train_loss": 0.011077265635741731
      },
      {
        "epoch": 1284,
        "reward": 0.4234902858734131,
        "val_loss": 0.01196257387554007,
        "train_loss": 0.010973221201521274
      },
      {
        "epoch": 1285,
        "reward": 0.42363715171813965,
        "val_loss": 0.011948191577435605,
        "train_loss": 0.012082340822626766
      },
      {
        "epoch": 1286,
        "reward": 0.42368385195732117,
        "val_loss": 0.01194362954369613,
        "train_loss": 0.011523565649090765
      },
      {
        "epoch": 1287,
        "reward": 0.4237586557865143,
        "val_loss": 0.011936306703968771,
        "train_loss": 0.011217530333222104
      },
      {
        "epoch": 1288,
        "reward": 0.4238624572753906,
        "val_loss": 0.011926165116684777,
        "train_loss": 0.010892082525130648
      },
      {
        "epoch": 1289,
        "reward": 0.4239600598812103,
        "val_loss": 0.011916638651330556,
        "train_loss": 0.010885484516620636
      },
      {
        "epoch": 1290,
        "reward": 0.42380377650260925,
        "val_loss": 0.011931901897436805,
        "train_loss": 0.01120884077122005
      },
      {
        "epoch": 1291,
        "reward": 0.4240318834781647,
        "val_loss": 0.011909631114186985,
        "train_loss": 0.010948552678410824
      },
      {
        "epoch": 1292,
        "reward": 0.4241105616092682,
        "val_loss": 0.01190195872914046,
        "train_loss": 0.010942547868650693
      },
      {
        "epoch": 1293,
        "reward": 0.4237041175365448,
        "val_loss": 0.01194164584324296,
        "train_loss": 0.010935841822244514
      },
      {
        "epoch": 1294,
        "reward": 0.4225623607635498,
        "val_loss": 0.01205388190490859,
        "train_loss": 0.010889147300846301
      },
      {
        "epoch": 1295,
        "reward": 0.4243878424167633,
        "val_loss": 0.011874970281496644,
        "train_loss": 0.010854882605669375
      },
      {
        "epoch": 1296,
        "reward": 0.4240668714046478,
        "val_loss": 0.01190621841565839,
        "train_loss": 0.010901065888062406
      },
      {
        "epoch": 1297,
        "reward": 0.4245459735393524,
        "val_loss": 0.011859605687537364,
        "train_loss": 0.011335852475335391
      },
      {
        "epoch": 1298,
        "reward": 0.4245952069759369,
        "val_loss": 0.011854824144393206,
        "train_loss": 0.010806902724932744
      },
      {
        "epoch": 1299,
        "reward": 0.4246133267879486,
        "val_loss": 0.011853066655541105,
        "train_loss": 0.011296765440000365
      },
      {
        "epoch": 1300,
        "reward": 0.4247048795223236,
        "val_loss": 0.01184419060258993,
        "train_loss": 0.010828762646549596
      },
      {
        "epoch": 1301,
        "reward": 0.4246230125427246,
        "val_loss": 0.011852127449986125,
        "train_loss": 0.010791659323261298
      },
      {
        "epoch": 1302,
        "reward": 0.4247070848941803,
        "val_loss": 0.011843977229935783,
        "train_loss": 0.010853588785931397
      },
      {
        "epoch": 1303,
        "reward": 0.42437320947647095,
        "val_loss": 0.011876394473282354,
        "train_loss": 0.010879113446347989
      },
      {
        "epoch": 1304,
        "reward": 0.4248751103878021,
        "val_loss": 0.011827693187764712,
        "train_loss": 0.010816551917322123
      },
      {
        "epoch": 1305,
        "reward": 0.42510342597961426,
        "val_loss": 0.011805618048778601,
        "train_loss": 0.010899950230780702
      },
      {
        "epoch": 1306,
        "reward": 0.4251912236213684,
        "val_loss": 0.011797136161476374,
        "train_loss": 0.011108483993806519
      },
      {
        "epoch": 1307,
        "reward": 0.4252093732357025,
        "val_loss": 0.011795383745006152,
        "train_loss": 0.010743075477395135
      },
      {
        "epoch": 1308,
        "reward": 0.4246985912322998,
        "val_loss": 0.011844799720815249,
        "train_loss": 0.01074319950133101
      },
      {
        "epoch": 1309,
        "reward": 0.4254005551338196,
        "val_loss": 0.011776948846610529,
        "train_loss": 0.010812639079701442
      },
      {
        "epoch": 1310,
        "reward": 0.42548877000808716,
        "val_loss": 0.011768448133287686,
        "train_loss": 0.010729053260652458
      },
      {
        "epoch": 1311,
        "reward": 0.42551031708717346,
        "val_loss": 0.011766375824143844,
        "train_loss": 0.010819496072004907
      },
      {
        "epoch": 1312,
        "reward": 0.4255926311016083,
        "val_loss": 0.01175845620621528,
        "train_loss": 0.02218612482269796
      },
      {
        "epoch": 1313,
        "reward": 0.42548757791519165,
        "val_loss": 0.01176856311836413,
        "train_loss": 0.010736472092013663
      },
      {
        "epoch": 1314,
        "reward": 0.4252118170261383,
        "val_loss": 0.011795152161669518,
        "train_loss": 0.010775233833835674
      },
      {
        "epoch": 1315,
        "reward": 0.42568016052246094,
        "val_loss": 0.011750036584479468,
        "train_loss": 0.010683790091766591
      },
      {
        "epoch": 1316,
        "reward": 0.42579007148742676,
        "val_loss": 0.011739480275926846,
        "train_loss": 0.010681942792110441
      },
      {
        "epoch": 1317,
        "reward": 0.4252011477947235,
        "val_loss": 0.011796181123437626,
        "train_loss": 0.011229051885983119
      },
      {
        "epoch": 1318,
        "reward": 0.4260554015636444,
        "val_loss": 0.011714025167748332,
        "train_loss": 0.01075543372784383
      },
      {
        "epoch": 1319,
        "reward": 0.4260818064212799,
        "val_loss": 0.01171149720903486,
        "train_loss": 0.010713376805562383
      },
      {
        "epoch": 1320,
        "reward": 0.4255102276802063,
        "val_loss": 0.011766388480152403,
        "train_loss": 0.01407218266887447
      },
      {
        "epoch": 1321,
        "reward": 0.4262707233428955,
        "val_loss": 0.01169341626310987,
        "train_loss": 0.010813083589220276
      },
      {
        "epoch": 1322,
        "reward": 0.4261748790740967,
        "val_loss": 0.011702583936442221,
        "train_loss": 0.010765469203201624
      },
      {
        "epoch": 1323,
        "reward": 0.42636486887931824,
        "val_loss": 0.011684420219223415,
        "train_loss": 0.010646571393006244
      },
      {
        "epoch": 1324,
        "reward": 0.4265187382698059,
        "val_loss": 0.011669724813795515,
        "train_loss": 0.010690868093381422
      },
      {
        "epoch": 1325,
        "reward": 0.42648711800575256,
        "val_loss": 0.01167274294753692,
        "train_loss": 0.01064697439253975
      },
      {
        "epoch": 1326,
        "reward": 0.4266664981842041,
        "val_loss": 0.011655635133917843,
        "train_loss": 0.010735754017682316
      },
      {
        "epoch": 1327,
        "reward": 0.426703542470932,
        "val_loss": 0.011652103226099695,
        "train_loss": 0.010690686131755892
      },
      {
        "epoch": 1328,
        "reward": 0.42673206329345703,
        "val_loss": 0.011649390017347676,
        "train_loss": 0.010633112372418579
      },
      {
        "epoch": 1329,
        "reward": 0.4263157844543457,
        "val_loss": 0.011689107848464378,
        "train_loss": 0.010648012411995577
      },
      {
        "epoch": 1330,
        "reward": 0.4267992675304413,
        "val_loss": 0.011642990201445562,
        "train_loss": 0.01065676223907548
      },
      {
        "epoch": 1331,
        "reward": 0.42698922753334045,
        "val_loss": 0.011624926518249725,
        "train_loss": 0.011009367872387744
      },
      {
        "epoch": 1332,
        "reward": 0.42665448784828186,
        "val_loss": 0.011656781891360879,
        "train_loss": 0.010722460941626476
      },
      {
        "epoch": 1333,
        "reward": 0.4267863929271698,
        "val_loss": 0.01164421796732183,
        "train_loss": 0.01068657988574929
      },
      {
        "epoch": 1334,
        "reward": 0.42717328667640686,
        "val_loss": 0.011607448404122676,
        "train_loss": 0.010929184003124157
      },
      {
        "epoch": 1335,
        "reward": 0.42686986923217773,
        "val_loss": 0.011636270326562226,
        "train_loss": 0.010573017516855123
      },
      {
        "epoch": 1336,
        "reward": 0.4272990822792053,
        "val_loss": 0.011595522768662445,
        "train_loss": 0.010563371860301301
      },
      {
        "epoch": 1337,
        "reward": 0.42742687463760376,
        "val_loss": 0.01158341983266707,
        "train_loss": 0.010582666986570425
      },
      {
        "epoch": 1338,
        "reward": 0.4275072515010834,
        "val_loss": 0.01157580891491047,
        "train_loss": 0.010576573522904744
      },
      {
        "epoch": 1339,
        "reward": 0.42758065462112427,
        "val_loss": 0.01156887543454234,
        "train_loss": 0.01053979965693613
      },
      {
        "epoch": 1340,
        "reward": 0.4273911118507385,
        "val_loss": 0.011586806886563343,
        "train_loss": 0.010536222914005031
      },
      {
        "epoch": 1341,
        "reward": 0.4276784062385559,
        "val_loss": 0.011559633671173028,
        "train_loss": 0.010609314812777134
      },
      {
        "epoch": 1342,
        "reward": 0.42701634764671326,
        "val_loss": 0.011622350812623543,
        "train_loss": 0.01062879275279836
      },
      {
        "epoch": 1343,
        "reward": 0.4277551770210266,
        "val_loss": 0.011552385437036199,
        "train_loss": 0.01070708896105106
      },
      {
        "epoch": 1344,
        "reward": 0.42786478996276855,
        "val_loss": 0.011542042850383691,
        "train_loss": 0.01730480849241408
      },
      {
        "epoch": 1345,
        "reward": 0.42788609862327576,
        "val_loss": 0.011540033338990594,
        "train_loss": 0.010503893674887457
      },
      {
        "epoch": 1346,
        "reward": 0.428067684173584,
        "val_loss": 0.01152292831933924,
        "train_loss": 0.010577743684944626
      },
      {
        "epoch": 1347,
        "reward": 0.42811593413352966,
        "val_loss": 0.01151838171894529,
        "train_loss": 0.011036795438625492
      },
      {
        "epoch": 1348,
        "reward": 0.42745447158813477,
        "val_loss": 0.01158080534410796,
        "train_loss": 0.010620329699192483
      },
      {
        "epoch": 1349,
        "reward": 0.42814579606056213,
        "val_loss": 0.011515580067810203,
        "train_loss": 0.01107609119767753
      },
      {
        "epoch": 1350,
        "reward": 0.4282270073890686,
        "val_loss": 0.01150794021253075,
        "train_loss": 0.010487345350646557
      },
      {
        "epoch": 1351,
        "reward": 0.42841941118240356,
        "val_loss": 0.011489871723045195,
        "train_loss": 0.011015811576866187
      },
      {
        "epoch": 1352,
        "reward": 0.428382009267807,
        "val_loss": 0.011493376456201077,
        "train_loss": 0.010470239152429993
      },
      {
        "epoch": 1353,
        "reward": 0.4284730851650238,
        "val_loss": 0.011484831222333014,
        "train_loss": 0.01046488873907947
      },
      {
        "epoch": 1354,
        "reward": 0.42809629440307617,
        "val_loss": 0.01152023154177836,
        "train_loss": 0.024885387670320388
      },
      {
        "epoch": 1355,
        "reward": 0.428623765707016,
        "val_loss": 0.011470706734274114,
        "train_loss": 0.011063773238744874
      },
      {
        "epoch": 1356,
        "reward": 0.42875009775161743,
        "val_loss": 0.011458882762651359,
        "train_loss": 0.010988914524205029
      },
      {
        "epoch": 1357,
        "reward": 0.4287433624267578,
        "val_loss": 0.011459514714910515,
        "train_loss": 0.010427842594673655
      },
      {
        "epoch": 1358,
        "reward": 0.42889103293418884,
        "val_loss": 0.011445700689884169,
        "train_loss": 0.010427364297076845
      },
      {
        "epoch": 1359,
        "reward": 0.42891231179237366,
        "val_loss": 0.01144371323087918,
        "train_loss": 0.01042526791682646
      },
      {
        "epoch": 1360,
        "reward": 0.42883357405662537,
        "val_loss": 0.011451072907740516,
        "train_loss": 0.010426240749438875
      },
      {
        "epoch": 1361,
        "reward": 0.42904558777809143,
        "val_loss": 0.011431267501653306,
        "train_loss": 0.010427796172175126
      },
      {
        "epoch": 1362,
        "reward": 0.42913317680358887,
        "val_loss": 0.011423096809137081,
        "train_loss": 0.01046822126954794
      },
      {
        "epoch": 1363,
        "reward": 0.4292307496070862,
        "val_loss": 0.01141399856922882,
        "train_loss": 0.010386921252575121
      },
      {
        "epoch": 1364,
        "reward": 0.4292692244052887,
        "val_loss": 0.011410418814713401,
        "train_loss": 0.010583474435127126
      },
      {
        "epoch": 1365,
        "reward": 0.42913708090782166,
        "val_loss": 0.011422728570843381,
        "train_loss": 0.01039505729456253
      },
      {
        "epoch": 1366,
        "reward": 0.4294615387916565,
        "val_loss": 0.01139251927712134,
        "train_loss": 0.010392456549687687
      },
      {
        "epoch": 1367,
        "reward": 0.4295189082622528,
        "val_loss": 0.011387188586273364,
        "train_loss": 0.010366353376521868
      },
      {
        "epoch": 1368,
        "reward": 0.4295789301395416,
        "val_loss": 0.011381609465128608,
        "train_loss": 0.010365378862423733
      },
      {
        "epoch": 1369,
        "reward": 0.42963019013404846,
        "val_loss": 0.011376845783420972,
        "train_loss": 0.010362328825487146
      },
      {
        "epoch": 1370,
        "reward": 0.4293536841869354,
        "val_loss": 0.011402552515002233,
        "train_loss": 0.010345729650418014
      },
      {
        "epoch": 1371,
        "reward": 0.4298079013824463,
        "val_loss": 0.011360356617452843,
        "train_loss": 0.010771853392585538
      },
      {
        "epoch": 1372,
        "reward": 0.4298584461212158,
        "val_loss": 0.01135567216468709,
        "train_loss": 0.010474288316730123
      },
      {
        "epoch": 1373,
        "reward": 0.4296594560146332,
        "val_loss": 0.011374127685225435,
        "train_loss": 0.010479884078869453
      },
      {
        "epoch": 1374,
        "reward": 0.4296722114086151,
        "val_loss": 0.011372949628691589,
        "train_loss": 0.01034729472527173
      },
      {
        "epoch": 1375,
        "reward": 0.43007969856262207,
        "val_loss": 0.011335187791181462,
        "train_loss": 0.010330105538462074
      },
      {
        "epoch": 1376,
        "reward": 0.43015056848526,
        "val_loss": 0.011328637982452554,
        "train_loss": 0.010329181536919717
      },
      {
        "epoch": 1377,
        "reward": 0.4302080571651459,
        "val_loss": 0.011323324704010571,
        "train_loss": 0.01031092412421668
      },
      {
        "epoch": 1378,
        "reward": 0.43026986718177795,
        "val_loss": 0.01131761448258268,
        "train_loss": 0.010712908276428398
      },
      {
        "epoch": 1379,
        "reward": 0.42998167872428894,
        "val_loss": 0.011344260536134243,
        "train_loss": 0.010309423846103108
      },
      {
        "epoch": 1380,
        "reward": 0.4299444258213043,
        "val_loss": 0.011347707627075059,
        "train_loss": 0.010950238220035456
      },
      {
        "epoch": 1381,
        "reward": 0.4303154945373535,
        "val_loss": 0.011313402576238982,
        "train_loss": 0.010331642523501964
      },
      {
        "epoch": 1382,
        "reward": 0.4303429126739502,
        "val_loss": 0.011310872339111353,
        "train_loss": 0.010285917581086323
      },
      {
        "epoch": 1383,
        "reward": 0.43062958121299744,
        "val_loss": 0.011284451732145888,
        "train_loss": 0.010283129457373153
      },
      {
        "epoch": 1384,
        "reward": 0.4306628406047821,
        "val_loss": 0.011281392071396112,
        "train_loss": 0.01028395954870995
      },
      {
        "epoch": 1385,
        "reward": 0.4307539463043213,
        "val_loss": 0.011273008322210185,
        "train_loss": 0.010331362991844518
      },
      {
        "epoch": 1386,
        "reward": 0.4308064877986908,
        "val_loss": 0.011268178333661385,
        "train_loss": 0.010283089238398064
      },
      {
        "epoch": 1387,
        "reward": 0.43068939447402954,
        "val_loss": 0.01127894886303693,
        "train_loss": 0.010880712527208604
      },
      {
        "epoch": 1388,
        "reward": 0.4309524595737457,
        "val_loss": 0.011254775737013136,
        "train_loss": 0.010385635774582624
      },
      {
        "epoch": 1389,
        "reward": 0.4310074746608734,
        "val_loss": 0.011249722763230758,
        "train_loss": 0.0102388632140691
      },
      {
        "epoch": 1390,
        "reward": 0.4310707747936249,
        "val_loss": 0.011243920606960143,
        "train_loss": 0.010248559215912022
      },
      {
        "epoch": 1391,
        "reward": 0.4311628043651581,
        "val_loss": 0.01123548679918583,
        "train_loss": 0.010245077375657274
      },
      {
        "epoch": 1392,
        "reward": 0.4312315881252289,
        "val_loss": 0.011229185720107384,
        "train_loss": 0.010236009430417862
      },
      {
        "epoch": 1393,
        "reward": 0.4312719404697418,
        "val_loss": 0.011225490431700434,
        "train_loss": 0.010298171434372377
      },
      {
        "epoch": 1394,
        "reward": 0.43124252557754517,
        "val_loss": 0.011228182585909963,
        "train_loss": 0.010228625514532023
      },
      {
        "epoch": 1395,
        "reward": 0.4312421977519989,
        "val_loss": 0.01122821363553937,
        "train_loss": 0.010211465965207585
      },
      {
        "epoch": 1396,
        "reward": 0.43150249123573303,
        "val_loss": 0.011204410344362259,
        "train_loss": 0.010191598859399584
      },
      {
        "epoch": 1397,
        "reward": 0.4315301477909088,
        "val_loss": 0.011201882668371712,
        "train_loss": 0.010402686858119873
      },
      {
        "epoch": 1398,
        "reward": 0.43163415789604187,
        "val_loss": 0.011192388134077191,
        "train_loss": 0.010204362578056484
      },
      {
        "epoch": 1399,
        "reward": 0.4317033290863037,
        "val_loss": 0.011186076494465982,
        "train_loss": 0.010177755389472272
      },
      {
        "epoch": 1400,
        "reward": 0.43146201968193054,
        "val_loss": 0.011208109990028399,
        "train_loss": 0.010569081144729773
      },
      {
        "epoch": 1401,
        "reward": 0.43178701400756836,
        "val_loss": 0.01117845144056316,
        "train_loss": 0.010193707325155489
      },
      {
        "epoch": 1402,
        "reward": 0.4319040775299072,
        "val_loss": 0.011167787481099367,
        "train_loss": 0.010290311165870382
      },
      {
        "epoch": 1403,
        "reward": 0.4318695664405823,
        "val_loss": 0.011170934652909636,
        "train_loss": 0.010254713724582242
      },
      {
        "epoch": 1404,
        "reward": 0.43175873160362244,
        "val_loss": 0.01118102646432817,
        "train_loss": 0.010176146230570829
      },
      {
        "epoch": 1405,
        "reward": 0.4320988357067108,
        "val_loss": 0.011150076436544103,
        "train_loss": 0.010151149392885809
      },
      {
        "epoch": 1406,
        "reward": 0.43217983841896057,
        "val_loss": 0.01114271760785154,
        "train_loss": 0.010197106668224128
      },
      {
        "epoch": 1407,
        "reward": 0.43218570947647095,
        "val_loss": 0.01114218299543219,
        "train_loss": 0.024245881251632594
      },
      {
        "epoch": 1408,
        "reward": 0.43219658732414246,
        "val_loss": 0.011141195394364851,
        "train_loss": 0.010145781550538512
      },
      {
        "epoch": 1409,
        "reward": 0.43237215280532837,
        "val_loss": 0.011125263874419034,
        "train_loss": 0.010132111910094794
      },
      {
        "epoch": 1410,
        "reward": 0.43243011832237244,
        "val_loss": 0.0111200123459899,
        "train_loss": 0.010146193140336926
      },
      {
        "epoch": 1411,
        "reward": 0.43251973390579224,
        "val_loss": 0.011111891445969897,
        "train_loss": 0.010111065615896782
      },
      {
        "epoch": 1412,
        "reward": 0.43253979086875916,
        "val_loss": 0.01111007688034858,
        "train_loss": 0.01012144153803372
      },
      {
        "epoch": 1413,
        "reward": 0.4324509799480438,
        "val_loss": 0.011118122393132321,
        "train_loss": 0.010110024260099566
      },
      {
        "epoch": 1414,
        "reward": 0.4323671758174896,
        "val_loss": 0.011125710693054966,
        "train_loss": 0.01021288912026928
      },
      {
        "epoch": 1415,
        "reward": 0.43150779604911804,
        "val_loss": 0.011203925125300884,
        "train_loss": 0.010107212118992511
      },
      {
        "epoch": 1416,
        "reward": 0.43283629417419434,
        "val_loss": 0.011083271537375237,
        "train_loss": 0.010659731015598832
      },
      {
        "epoch": 1417,
        "reward": 0.43291589617729187,
        "val_loss": 0.011076085019989737,
        "train_loss": 0.010318665890596233
      },
      {
        "epoch": 1418,
        "reward": 0.43263742327690125,
        "val_loss": 0.011101246877972568,
        "train_loss": 0.010101482542477943
      },
      {
        "epoch": 1419,
        "reward": 0.4329555630683899,
        "val_loss": 0.011072508292272687,
        "train_loss": 0.010150175541639328
      },
      {
        "epoch": 1420,
        "reward": 0.43304452300071716,
        "val_loss": 0.011064484366215765,
        "train_loss": 0.010316373641566874
      },
      {
        "epoch": 1421,
        "reward": 0.4331096112728119,
        "val_loss": 0.01105862157419324,
        "train_loss": 0.010048607766573415
      },
      {
        "epoch": 1422,
        "reward": 0.432558536529541,
        "val_loss": 0.011108378214495522,
        "train_loss": 0.010061389114036081
      },
      {
        "epoch": 1423,
        "reward": 0.43313008546829224,
        "val_loss": 0.011056774861312338,
        "train_loss": 0.010381403513467656
      },
      {
        "epoch": 1424,
        "reward": 0.43333789706230164,
        "val_loss": 0.011038076664720262,
        "train_loss": 0.010063345179682633
      },
      {
        "epoch": 1425,
        "reward": 0.4334309697151184,
        "val_loss": 0.011029713537677057,
        "train_loss": 0.010070059417697709
      },
      {
        "epoch": 1426,
        "reward": 0.43345823884010315,
        "val_loss": 0.011027265207043715,
        "train_loss": 0.010157588524564814
      },
      {
        "epoch": 1427,
        "reward": 0.43343600630760193,
        "val_loss": 0.011029260266306145,
        "train_loss": 0.010058050717746552
      },
      {
        "epoch": 1428,
        "reward": 0.4330612123012543,
        "val_loss": 0.011062982458887356,
        "train_loss": 0.010352537412053118
      },
      {
        "epoch": 1429,
        "reward": 0.4336347281932831,
        "val_loss": 0.011011428282862263,
        "train_loss": 0.010206215110464165
      },
      {
        "epoch": 1430,
        "reward": 0.43313875794410706,
        "val_loss": 0.011055996791193528,
        "train_loss": 0.010121592745865481
      },
      {
        "epoch": 1431,
        "reward": 0.43373557925224304,
        "val_loss": 0.011002390628813632,
        "train_loss": 0.010080603515514387
      },
      {
        "epoch": 1432,
        "reward": 0.433502197265625,
        "val_loss": 0.011023315667573894,
        "train_loss": 0.010147102418928765
      },
      {
        "epoch": 1433,
        "reward": 0.43375301361083984,
        "val_loss": 0.011000823063243712,
        "train_loss": 0.01000960616710682
      },
      {
        "epoch": 1434,
        "reward": 0.43378955125808716,
        "val_loss": 0.010997553023376636,
        "train_loss": 0.010029162784751232
      },
      {
        "epoch": 1435,
        "reward": 0.43407437205314636,
        "val_loss": 0.01097208128443786,
        "train_loss": 0.010008366570288602
      },
      {
        "epoch": 1436,
        "reward": 0.43412381410598755,
        "val_loss": 0.01096766269100564,
        "train_loss": 0.01009821602089617
      },
      {
        "epoch": 1437,
        "reward": 0.43257030844688416,
        "val_loss": 0.011107316972421748,
        "train_loss": 0.010056624851691036
      },
      {
        "epoch": 1438,
        "reward": 0.43375125527381897,
        "val_loss": 0.011000981820481164,
        "train_loss": 0.010078704338341665
      },
      {
        "epoch": 1439,
        "reward": 0.4342873692512512,
        "val_loss": 0.010953069531491824,
        "train_loss": 0.010086499047107421
      },
      {
        "epoch": 1440,
        "reward": 0.4343867301940918,
        "val_loss": 0.010944212953160917,
        "train_loss": 0.009978070928459952
      },
      {
        "epoch": 1441,
        "reward": 0.43431493639945984,
        "val_loss": 0.010950610124772149,
        "train_loss": 0.00999970119804717
      },
      {
        "epoch": 1442,
        "reward": 0.4344886243343353,
        "val_loss": 0.010935137780117137,
        "train_loss": 0.00998215183454494
      },
      {
        "epoch": 1443,
        "reward": 0.4345872402191162,
        "val_loss": 0.010926363008495952,
        "train_loss": 0.010077426263775963
      },
      {
        "epoch": 1444,
        "reward": 0.4344806671142578,
        "val_loss": 0.010935846383550338,
        "train_loss": 0.013094347140465219
      },
      {
        "epoch": 1445,
        "reward": 0.43424493074417114,
        "val_loss": 0.010956849686668388,
        "train_loss": 0.010459882986301986
      },
      {
        "epoch": 1446,
        "reward": 0.4348110854625702,
        "val_loss": 0.010906477674974926,
        "train_loss": 0.010540546759819755
      },
      {
        "epoch": 1447,
        "reward": 0.4348178505897522,
        "val_loss": 0.010905875225684472,
        "train_loss": 0.009943328885128722
      },
      {
        "epoch": 1448,
        "reward": 0.434513658285141,
        "val_loss": 0.010932911353717958,
        "train_loss": 0.009903884407461962
      },
      {
        "epoch": 1449,
        "reward": 0.43492498993873596,
        "val_loss": 0.0108963722595945,
        "train_loss": 0.009916317210529367
      },
      {
        "epoch": 1450,
        "reward": 0.434780091047287,
        "val_loss": 0.01090922549233905,
        "train_loss": 0.009994891230375148
      },
      {
        "epoch": 1451,
        "reward": 0.43479838967323303,
        "val_loss": 0.010907601681537926,
        "train_loss": 0.010010440063734468
      },
      {
        "epoch": 1452,
        "reward": 0.43442168831825256,
        "val_loss": 0.01094109589965748,
        "train_loss": 0.010074465705726583
      },
      {
        "epoch": 1453,
        "reward": 0.4351433217525482,
        "val_loss": 0.010877031034656934,
        "train_loss": 0.009890498393500681
      },
      {
        "epoch": 1454,
        "reward": 0.4351721704006195,
        "val_loss": 0.01087447754772646,
        "train_loss": 0.01044285604551148
      },
      {
        "epoch": 1455,
        "reward": 0.43537479639053345,
        "val_loss": 0.010856560315005481,
        "train_loss": 0.00987002104711092
      },
      {
        "epoch": 1456,
        "reward": 0.43539246916770935,
        "val_loss": 0.010855000432846802,
        "train_loss": 0.010263284708623989
      },
      {
        "epoch": 1457,
        "reward": 0.43489381670951843,
        "val_loss": 0.010899134030166482,
        "train_loss": 0.009889896635566121
      },
      {
        "epoch": 1458,
        "reward": 0.4354930818080902,
        "val_loss": 0.010846122450727438,
        "train_loss": 0.009967267262534453
      },
      {
        "epoch": 1459,
        "reward": 0.43531617522239685,
        "val_loss": 0.010861740015181047,
        "train_loss": 0.010447094404998306
      },
      {
        "epoch": 1460,
        "reward": 0.43565604090690613,
        "val_loss": 0.010831751694370593,
        "train_loss": 0.0098447400432633
      },
      {
        "epoch": 1461,
        "reward": 0.4357428252696991,
        "val_loss": 0.010824108330000724,
        "train_loss": 0.009838388435757505
      },
      {
        "epoch": 1462,
        "reward": 0.4355224668979645,
        "val_loss": 0.01084353048021772,
        "train_loss": 0.009925511929815492
      },
      {
        "epoch": 1463,
        "reward": 0.435801237821579,
        "val_loss": 0.010818967196558203,
        "train_loss": 0.010134874413219782
      },
      {
        "epoch": 1464,
        "reward": 0.4358308017253876,
        "val_loss": 0.010816366145653384,
        "train_loss": 0.009828387172514287
      },
      {
        "epoch": 1465,
        "reward": 0.4358976483345032,
        "val_loss": 0.010810489017915512,
        "train_loss": 0.009942420113545198
      },
      {
        "epoch": 1466,
        "reward": 0.4360504746437073,
        "val_loss": 0.010797057117867683,
        "train_loss": 0.009922728336487826
      },
      {
        "epoch": 1467,
        "reward": 0.43579426407814026,
        "val_loss": 0.010819579142012767,
        "train_loss": 0.009955674006890219
      },
      {
        "epoch": 1468,
        "reward": 0.4358430802822113,
        "val_loss": 0.010815279940808458,
        "train_loss": 0.009856682912448797
      },
      {
        "epoch": 1469,
        "reward": 0.43582087755203247,
        "val_loss": 0.010817240092105098,
        "train_loss": 0.009924622843615137
      },
      {
        "epoch": 1470,
        "reward": 0.4359304904937744,
        "val_loss": 0.010807597943182503,
        "train_loss": 0.009808030603240835
      },
      {
        "epoch": 1471,
        "reward": 0.43633756041526794,
        "val_loss": 0.010771878113571023,
        "train_loss": 0.009849280557738474
      },
      {
        "epoch": 1472,
        "reward": 0.43641915917396545,
        "val_loss": 0.010764733655378222,
        "train_loss": 0.009819749722597547
      },
      {
        "epoch": 1473,
        "reward": 0.43646860122680664,
        "val_loss": 0.010760402822467898,
        "train_loss": 0.009782094003290135
      },
      {
        "epoch": 1474,
        "reward": 0.43618351221084595,
        "val_loss": 0.010785379480304462,
        "train_loss": 0.009774391945309336
      },
      {
        "epoch": 1475,
        "reward": 0.43658778071403503,
        "val_loss": 0.010749986628070474,
        "train_loss": 0.009834293038763393
      },
      {
        "epoch": 1476,
        "reward": 0.43667158484458923,
        "val_loss": 0.010742658050730824,
        "train_loss": 0.009871155636994025
      },
      {
        "epoch": 1477,
        "reward": 0.4354950487613678,
        "val_loss": 0.01084594476768481,
        "train_loss": 0.010130422548032723
      },
      {
        "epoch": 1478,
        "reward": 0.43675753474235535,
        "val_loss": 0.010735161652389382,
        "train_loss": 0.00990729990343635
      },
      {
        "epoch": 1479,
        "reward": 0.4366450011730194,
        "val_loss": 0.010744986041182918,
        "train_loss": 0.012308207125617908
      },
      {
        "epoch": 1480,
        "reward": 0.4369080662727356,
        "val_loss": 0.01072202917254929,
        "train_loss": 0.009844396223063366
      },
      {
        "epoch": 1481,
        "reward": 0.4369905889034271,
        "val_loss": 0.010714835204583193,
        "train_loss": 0.010347189883200021
      },
      {
        "epoch": 1482,
        "reward": 0.43698883056640625,
        "val_loss": 0.010714987359408821,
        "train_loss": 0.00999329043014978
      },
      {
        "epoch": 1483,
        "reward": 0.43694496154785156,
        "val_loss": 0.010718813199283821,
        "train_loss": 0.01564233004151342
      },
      {
        "epoch": 1484,
        "reward": 0.437178373336792,
        "val_loss": 0.010698493104428053,
        "train_loss": 0.009830084821889894
      },
      {
        "epoch": 1485,
        "reward": 0.43658947944641113,
        "val_loss": 0.010749833824645196,
        "train_loss": 0.01020662051338989
      },
      {
        "epoch": 1486,
        "reward": 0.4372710883617401,
        "val_loss": 0.010690436149681253,
        "train_loss": 0.009769152708311314
      },
      {
        "epoch": 1487,
        "reward": 0.43680354952812195,
        "val_loss": 0.01073113875463605,
        "train_loss": 0.009734726626377848
      },
      {
        "epoch": 1488,
        "reward": 0.43737027049064636,
        "val_loss": 0.010681823012419045,
        "train_loss": 0.009726793166079845
      },
      {
        "epoch": 1489,
        "reward": 0.43744808435440063,
        "val_loss": 0.010675068296092962,
        "train_loss": 0.009818661443065278
      },
      {
        "epoch": 1490,
        "reward": 0.4372827708721161,
        "val_loss": 0.01068942155689001,
        "train_loss": 0.009697363327494312
      },
      {
        "epoch": 1491,
        "reward": 0.43731018900871277,
        "val_loss": 0.010687041977819587,
        "train_loss": 0.009716462810187156
      },
      {
        "epoch": 1492,
        "reward": 0.4373534619808197,
        "val_loss": 0.010683280432463757,
        "train_loss": 0.009734161919018684
      },
      {
        "epoch": 1493,
        "reward": 0.43751177191734314,
        "val_loss": 0.010669542642842447,
        "train_loss": 0.009836993771246992
      },
      {
        "epoch": 1494,
        "reward": 0.4377243220806122,
        "val_loss": 0.010651127435266972,
        "train_loss": 0.009800085197919263
      },
      {
        "epoch": 1495,
        "reward": 0.4372761845588684,
        "val_loss": 0.010689990910967546,
        "train_loss": 0.00972353450085323
      },
      {
        "epoch": 1496,
        "reward": 0.4378949701786041,
        "val_loss": 0.010636373522824474,
        "train_loss": 0.009684896230912553
      },
      {
        "epoch": 1497,
        "reward": 0.43792763352394104,
        "val_loss": 0.010633545079534608,
        "train_loss": 0.010076156374102889
      },
      {
        "epoch": 1498,
        "reward": 0.438028484582901,
        "val_loss": 0.010624837812169321,
        "train_loss": 0.009657149826615261
      },
      {
        "epoch": 1499,
        "reward": 0.43798813223838806,
        "val_loss": 0.010628323187120259,
        "train_loss": 0.009649639787767228
      },
      {
        "epoch": 1500,
        "reward": 0.43801170587539673,
        "val_loss": 0.010626288530017649,
        "train_loss": 0.00965692911519839
      },
      {
        "epoch": 1501,
        "reward": 0.4382146894931793,
        "val_loss": 0.010608774476817675,
        "train_loss": 0.009688236146198155
      },
      {
        "epoch": 1502,
        "reward": 0.438025563955307,
        "val_loss": 0.010625090533202248,
        "train_loss": 0.00967605860876994
      },
      {
        "epoch": 1503,
        "reward": 0.4382338523864746,
        "val_loss": 0.010607122576662473,
        "train_loss": 0.009746897580603568
      },
      {
        "epoch": 1504,
        "reward": 0.4382304251194,
        "val_loss": 0.010607419518886932,
        "train_loss": 0.009636510860078627
      },
      {
        "epoch": 1505,
        "reward": 0.43843671679496765,
        "val_loss": 0.01058966024512691,
        "train_loss": 0.009622364707988358
      },
      {
        "epoch": 1506,
        "reward": 0.43821755051612854,
        "val_loss": 0.010608530586718448,
        "train_loss": 0.009730042164357236
      },
      {
        "epoch": 1507,
        "reward": 0.4383679926395416,
        "val_loss": 0.010595571499184839,
        "train_loss": 0.00993950714249737
      },
      {
        "epoch": 1508,
        "reward": 0.43810078501701355,
        "val_loss": 0.010618599613995425,
        "train_loss": 0.009640261481623523
      },
      {
        "epoch": 1509,
        "reward": 0.4379206597805023,
        "val_loss": 0.01063415004006986,
        "train_loss": 0.009625753162813803
      },
      {
        "epoch": 1510,
        "reward": 0.438718318939209,
        "val_loss": 0.01056546697925244,
        "train_loss": 0.009663729274717089
      },
      {
        "epoch": 1511,
        "reward": 0.4388113021850586,
        "val_loss": 0.010557485744357109,
        "train_loss": 0.00959194440992388
      },
      {
        "epoch": 1512,
        "reward": 0.43887314200401306,
        "val_loss": 0.010552189096675388,
        "train_loss": 0.009615139093232127
      },
      {
        "epoch": 1513,
        "reward": 0.4388948976993561,
        "val_loss": 0.010550324638773288,
        "train_loss": 0.010173646464514045
      },
      {
        "epoch": 1514,
        "reward": 0.4384845793247223,
        "val_loss": 0.010585542269317167,
        "train_loss": 0.009650475058991175
      },
      {
        "epoch": 1515,
        "reward": 0.43900129199028015,
        "val_loss": 0.01054121074931962,
        "train_loss": 0.009594499277367365
      },
      {
        "epoch": 1516,
        "reward": 0.43893739581108093,
        "val_loss": 0.010546684631013445,
        "train_loss": 0.009567148247076428
      },
      {
        "epoch": 1517,
        "reward": 0.4389663338661194,
        "val_loss": 0.010544204585520285,
        "train_loss": 0.009591441254507607
      },
      {
        "epoch": 1518,
        "reward": 0.43918728828430176,
        "val_loss": 0.010525303327345423,
        "train_loss": 0.009682474877291288
      },
      {
        "epoch": 1519,
        "reward": 0.4392440915107727,
        "val_loss": 0.01052044827624091,
        "train_loss": 0.00964024684463556
      },
      {
        "epoch": 1520,
        "reward": 0.43811771273612976,
        "val_loss": 0.010617140846859132,
        "train_loss": 0.009559855415248491
      },
      {
        "epoch": 1521,
        "reward": 0.43916064500808716,
        "val_loss": 0.010527580161578953,
        "train_loss": 0.009687467361800373
      },
      {
        "epoch": 1522,
        "reward": 0.43944740295410156,
        "val_loss": 0.010503096273168921,
        "train_loss": 0.009614319491307609
      },
      {
        "epoch": 1523,
        "reward": 0.43944692611694336,
        "val_loss": 0.010503137467562087,
        "train_loss": 0.009588293373011626
      },
      {
        "epoch": 1524,
        "reward": 0.4395310878753662,
        "val_loss": 0.010495960429709936,
        "train_loss": 0.009559852537362391
      },
      {
        "epoch": 1525,
        "reward": 0.43960753083229065,
        "val_loss": 0.010489450900682382,
        "train_loss": 0.009535711233463818
      },
      {
        "epoch": 1526,
        "reward": 0.43967047333717346,
        "val_loss": 0.0104840943490022,
        "train_loss": 0.009621258923568977
      },
      {
        "epoch": 1527,
        "reward": 0.4395063817501068,
        "val_loss": 0.010498066931696875,
        "train_loss": 0.009524377960605516
      },
      {
        "epoch": 1528,
        "reward": 0.4395642876625061,
        "val_loss": 0.010493134797018553,
        "train_loss": 0.009668218065948727
      },
      {
        "epoch": 1529,
        "reward": 0.43981266021728516,
        "val_loss": 0.010471999279356428,
        "train_loss": 0.009527813102557467
      },
      {
        "epoch": 1530,
        "reward": 0.43978163599967957,
        "val_loss": 0.010474634689411946,
        "train_loss": 0.009582444837388512
      },
      {
        "epoch": 1531,
        "reward": 0.43996524810791016,
        "val_loss": 0.010459035984240472,
        "train_loss": 0.009496432033511856
      },
      {
        "epoch": 1532,
        "reward": 0.44001245498657227,
        "val_loss": 0.010455028519832663,
        "train_loss": 0.009781800447784077
      },
      {
        "epoch": 1533,
        "reward": 0.440112441778183,
        "val_loss": 0.010446549459759678,
        "train_loss": 0.009510676465022417
      },
      {
        "epoch": 1534,
        "reward": 0.4398406445980072,
        "val_loss": 0.010469616889687521,
        "train_loss": 0.009601104673213111
      },
      {
        "epoch": 1535,
        "reward": 0.44013524055480957,
        "val_loss": 0.010444612541635121,
        "train_loss": 0.009626034911399564
      },
      {
        "epoch": 1536,
        "reward": 0.43970170617103577,
        "val_loss": 0.01048143402606781,
        "train_loss": 0.010014223799002
      },
      {
        "epoch": 1537,
        "reward": 0.4402141273021698,
        "val_loss": 0.010437929437362723,
        "train_loss": 0.009554409377205256
      },
      {
        "epoch": 1538,
        "reward": 0.4403298497200012,
        "val_loss": 0.010428131657785602,
        "train_loss": 0.009583289233537821
      },
      {
        "epoch": 1539,
        "reward": 0.4403909146785736,
        "val_loss": 0.010422964214480348,
        "train_loss": 0.009462507629275653
      },
      {
        "epoch": 1540,
        "reward": 0.4405093193054199,
        "val_loss": 0.010412952929202999,
        "train_loss": 0.009473003496658259
      },
      {
        "epoch": 1541,
        "reward": 0.44050055742263794,
        "val_loss": 0.010413694577956838,
        "train_loss": 0.009461522412983378
      },
      {
        "epoch": 1542,
        "reward": 0.4406176507472992,
        "val_loss": 0.010403799475170672,
        "train_loss": 0.010044775473383756
      },
      {
        "epoch": 1543,
        "reward": 0.4406537711620331,
        "val_loss": 0.010400754416228406,
        "train_loss": 0.009456282903276868
      },
      {
        "epoch": 1544,
        "reward": 0.44072404503822327,
        "val_loss": 0.01039482413658074,
        "train_loss": 0.009437465900891066
      },
      {
        "epoch": 1545,
        "reward": 0.44063305854797363,
        "val_loss": 0.010402504604176752,
        "train_loss": 0.01000260131415696
      },
      {
        "epoch": 1546,
        "reward": 0.4405209720134735,
        "val_loss": 0.010411970267471458,
        "train_loss": 0.009446446530861206
      },
      {
        "epoch": 1547,
        "reward": 0.44090911746025085,
        "val_loss": 0.010379228042438626,
        "train_loss": 0.009525673817664098
      },
      {
        "epoch": 1548,
        "reward": 0.4408707320690155,
        "val_loss": 0.010382462392694183,
        "train_loss": 0.009510377220487079
      },
      {
        "epoch": 1549,
        "reward": 0.44101181626319885,
        "val_loss": 0.010370583273470402,
        "train_loss": 0.009436332824547068
      },
      {
        "epoch": 1550,
        "reward": 0.4410155713558197,
        "val_loss": 0.010370268752532346,
        "train_loss": 0.009430306625570385
      },
      {
        "epoch": 1551,
        "reward": 0.44108113646507263,
        "val_loss": 0.010364753061107226,
        "train_loss": 0.00983607271560826
      },
      {
        "epoch": 1552,
        "reward": 0.44111666083335876,
        "val_loss": 0.010361765627749264,
        "train_loss": 0.009403211415841585
      },
      {
        "epoch": 1553,
        "reward": 0.4412055015563965,
        "val_loss": 0.010354302091790097,
        "train_loss": 0.009411739013068235
      },
      {
        "epoch": 1554,
        "reward": 0.4412751793861389,
        "val_loss": 0.010348450259438582,
        "train_loss": 0.009436341913197584
      },
      {
        "epoch": 1555,
        "reward": 0.4412519037723541,
        "val_loss": 0.010350404606599892,
        "train_loss": 0.009497319222786106
      },
      {
        "epoch": 1556,
        "reward": 0.44132348895072937,
        "val_loss": 0.010344399638207895,
        "train_loss": 0.009458561141330462
      },
      {
        "epoch": 1557,
        "reward": 0.4414333999156952,
        "val_loss": 0.010335181457256632,
        "train_loss": 0.009386571217104435
      },
      {
        "epoch": 1558,
        "reward": 0.44155532121658325,
        "val_loss": 0.010324962536937423,
        "train_loss": 0.009375272406259683
      },
      {
        "epoch": 1559,
        "reward": 0.4416060447692871,
        "val_loss": 0.010320714508582438,
        "train_loss": 0.00937287059780199
      },
      {
        "epoch": 1560,
        "reward": 0.4413471817970276,
        "val_loss": 0.010342410133619393,
        "train_loss": 0.009372093814433286
      },
      {
        "epoch": 1561,
        "reward": 0.4416811168193817,
        "val_loss": 0.010314436463106955,
        "train_loss": 0.009486688592005521
      },
      {
        "epoch": 1562,
        "reward": 0.4416196346282959,
        "val_loss": 0.010319580523563283,
        "train_loss": 0.00952237778647731
      },
      {
        "epoch": 1563,
        "reward": 0.4417191445827484,
        "val_loss": 0.010311253302331482,
        "train_loss": 0.009437940607313067
      },
      {
        "epoch": 1564,
        "reward": 0.44189777970314026,
        "val_loss": 0.01029632902438087,
        "train_loss": 0.009360366411923539
      },
      {
        "epoch": 1565,
        "reward": 0.4419213831424713,
        "val_loss": 0.010294356466537076,
        "train_loss": 0.00941518615358151
      },
      {
        "epoch": 1566,
        "reward": 0.4419611394405365,
        "val_loss": 0.010291036484496934,
        "train_loss": 0.00934510658806595
      },
      {
        "epoch": 1567,
        "reward": 0.4409719407558441,
        "val_loss": 0.010373940275582885,
        "train_loss": 0.00943360262317583
      },
      {
        "epoch": 1568,
        "reward": 0.44208773970603943,
        "val_loss": 0.01028047689968454,
        "train_loss": 0.009983743451392421
      },
      {
        "epoch": 1569,
        "reward": 0.4420691430568695,
        "val_loss": 0.010282026903171624,
        "train_loss": 0.009335044637667194
      },
      {
        "epoch": 1570,
        "reward": 0.44202861189842224,
        "val_loss": 0.010285405408857124,
        "train_loss": 0.009355980667178389
      },
      {
        "epoch": 1571,
        "reward": 0.44229480624198914,
        "val_loss": 0.010263235008876239,
        "train_loss": 0.009324238337425274
      },
      {
        "epoch": 1572,
        "reward": 0.44177690148353577,
        "val_loss": 0.010306422898013676,
        "train_loss": 0.009855118208528997
      },
      {
        "epoch": 1573,
        "reward": 0.44238948822021484,
        "val_loss": 0.010255358132001544,
        "train_loss": 0.009333216600752463
      },
      {
        "epoch": 1574,
        "reward": 0.4423874318599701,
        "val_loss": 0.010255526584972228,
        "train_loss": 0.009325456501616057
      },
      {
        "epoch": 1575,
        "reward": 0.4424773156642914,
        "val_loss": 0.010248054134925562,
        "train_loss": 0.009296176412214243
      },
      {
        "epoch": 1576,
        "reward": 0.44254007935523987,
        "val_loss": 0.010242841855090643,
        "train_loss": 0.009302034018918885
      },
      {
        "epoch": 1577,
        "reward": 0.4426472783088684,
        "val_loss": 0.010233946460565286,
        "train_loss": 0.009306704951226354
      },
      {
        "epoch": 1578,
        "reward": 0.44236788153648376,
        "val_loss": 0.010257151127526802,
        "train_loss": 0.009392581553234218
      },
      {
        "epoch": 1579,
        "reward": 0.4426787495613098,
        "val_loss": 0.010231334150635771,
        "train_loss": 0.009409526779423825
      },
      {
        "epoch": 1580,
        "reward": 0.44279175996780396,
        "val_loss": 0.010221963997797243,
        "train_loss": 0.009289660024408546
      },
      {
        "epoch": 1581,
        "reward": 0.44283151626586914,
        "val_loss": 0.010218670541819717,
        "train_loss": 0.009277594704774227
      },
      {
        "epoch": 1582,
        "reward": 0.44253990054130554,
        "val_loss": 0.010242857853882015,
        "train_loss": 0.009368676065395657
      },
      {
        "epoch": 1583,
        "reward": 0.4429679811000824,
        "val_loss": 0.010207375877403788,
        "train_loss": 0.009364860114426566
      },
      {
        "epoch": 1584,
        "reward": 0.4428690969944,
        "val_loss": 0.010215559541913015,
        "train_loss": 0.009382175223436207
      },
      {
        "epoch": 1585,
        "reward": 0.44229623675346375,
        "val_loss": 0.010263111359173698,
        "train_loss": 0.009293570489927124
      },
      {
        "epoch": 1586,
        "reward": 0.44303128123283386,
        "val_loss": 0.010202140879950352,
        "train_loss": 0.009574771437865611
      },
      {
        "epoch": 1587,
        "reward": 0.4431191384792328,
        "val_loss": 0.010194874185669636,
        "train_loss": 0.009256764424767775
      },
      {
        "epoch": 1588,
        "reward": 0.44309359788894653,
        "val_loss": 0.01019698817149869,
        "train_loss": 0.00925691732670832
      },
      {
        "epoch": 1589,
        "reward": 0.44296136498451233,
        "val_loss": 0.010207922863108771,
        "train_loss": 0.00981238747212606
      },
      {
        "epoch": 1590,
        "reward": 0.4433692395687103,
        "val_loss": 0.0101742325018027,
        "train_loss": 0.009243041569893999
      },
      {
        "epoch": 1591,
        "reward": 0.44343453645706177,
        "val_loss": 0.010168854030780494,
        "train_loss": 0.009237326459417371
      },
      {
        "epoch": 1592,
        "reward": 0.44346627593040466,
        "val_loss": 0.010166235833561845,
        "train_loss": 0.009226542599367785
      },
      {
        "epoch": 1593,
        "reward": 0.44299522042274475,
        "val_loss": 0.010205125619125153,
        "train_loss": 0.009551100755253663
      },
      {
        "epoch": 1594,
        "reward": 0.44360724091529846,
        "val_loss": 0.010154634148680739,
        "train_loss": 0.009234161194259426
      },
      {
        "epoch": 1595,
        "reward": 0.4436326026916504,
        "val_loss": 0.010152541882624584,
        "train_loss": 0.009264762992433343
      },
      {
        "epoch": 1596,
        "reward": 0.4437192380428314,
        "val_loss": 0.010145417713959302,
        "train_loss": 0.009236782234298656
      },
      {
        "epoch": 1597,
        "reward": 0.4437590539455414,
        "val_loss": 0.010142149636521935,
        "train_loss": 0.009608502360956313
      },
      {
        "epoch": 1598,
        "reward": 0.4438384175300598,
        "val_loss": 0.010135629430546291,
        "train_loss": 0.009490900417753996
      },
      {
        "epoch": 1599,
        "reward": 0.44388848543167114,
        "val_loss": 0.010131515595795853,
        "train_loss": 0.009209152262673551
      },
      {
        "epoch": 1600,
        "reward": 0.44393712282180786,
        "val_loss": 0.010127522550257189,
        "train_loss": 0.009689685149798887
      },
      {
        "epoch": 1601,
        "reward": 0.4438619613647461,
        "val_loss": 0.010133696886311685,
        "train_loss": 0.009191535990864325
      },
      {
        "epoch": 1602,
        "reward": 0.4438752233982086,
        "val_loss": 0.010132602948163236,
        "train_loss": 0.00919612457227441
      },
      {
        "epoch": 1603,
        "reward": 0.4440738260746002,
        "val_loss": 0.010116315546578594,
        "train_loss": 0.009213693742192565
      },
      {
        "epoch": 1604,
        "reward": 0.44417649507522583,
        "val_loss": 0.01010790650200631,
        "train_loss": 0.00928400494516469
      },
      {
        "epoch": 1605,
        "reward": 0.4442256987094879,
        "val_loss": 0.01010387613704162,
        "train_loss": 0.009296045961001745
      },
      {
        "epoch": 1606,
        "reward": 0.44422265887260437,
        "val_loss": 0.010104128325890218,
        "train_loss": 0.009226911880362492
      },
      {
        "epoch": 1607,
        "reward": 0.4443318843841553,
        "val_loss": 0.01009519160392561,
        "train_loss": 0.009173250080773588
      },
      {
        "epoch": 1608,
        "reward": 0.44438597559928894,
        "val_loss": 0.010090767555604023,
        "train_loss": 0.009200190046193222
      },
      {
        "epoch": 1609,
        "reward": 0.4444456100463867,
        "val_loss": 0.010085889986450118,
        "train_loss": 0.009165737813768478
      },
      {
        "epoch": 1610,
        "reward": 0.44413891434669495,
        "val_loss": 0.010110980631517512,
        "train_loss": 0.009488323107899096
      },
      {
        "epoch": 1611,
        "reward": 0.4445211589336395,
        "val_loss": 0.010079723999037274,
        "train_loss": 0.00915483168886602
      },
      {
        "epoch": 1612,
        "reward": 0.4445250630378723,
        "val_loss": 0.010079404339194298,
        "train_loss": 0.00914114875978647
      },
      {
        "epoch": 1613,
        "reward": 0.4446476399898529,
        "val_loss": 0.010069400072097778,
        "train_loss": 0.009138243887089349
      },
      {
        "epoch": 1614,
        "reward": 0.44472429156303406,
        "val_loss": 0.010063156319249953,
        "train_loss": 0.009269972949718626
      },
      {
        "epoch": 1615,
        "reward": 0.44464918971061707,
        "val_loss": 0.010069277686333018,
        "train_loss": 0.009264162992342161
      },
      {
        "epoch": 1616,
        "reward": 0.4448440968990326,
        "val_loss": 0.010053392915454294,
        "train_loss": 0.009125028528125348
      },
      {
        "epoch": 1617,
        "reward": 0.444705069065094,
        "val_loss": 0.010064721473359637,
        "train_loss": 0.009120013923026048
      },
      {
        "epoch": 1618,
        "reward": 0.44494253396987915,
        "val_loss": 0.010045380614298795,
        "train_loss": 0.009674610570073128
      },
      {
        "epoch": 1619,
        "reward": 0.4450039863586426,
        "val_loss": 0.01004038260517908,
        "train_loss": 0.009117715665874689
      },
      {
        "epoch": 1620,
        "reward": 0.44505372643470764,
        "val_loss": 0.010036344739741512,
        "train_loss": 0.009106739084717656
      },
      {
        "epoch": 1621,
        "reward": 0.44501563906669617,
        "val_loss": 0.010039437312765844,
        "train_loss": 0.009413376566953957
      },
      {
        "epoch": 1622,
        "reward": 0.4450783431529999,
        "val_loss": 0.010034342196636967,
        "train_loss": 0.009130533439859461
      },
      {
        "epoch": 1623,
        "reward": 0.4450102746486664,
        "val_loss": 0.010039872855746321,
        "train_loss": 0.009101152684217175
      },
      {
        "epoch": 1624,
        "reward": 0.4452815651893616,
        "val_loss": 0.010017841688490339,
        "train_loss": 0.009414853675899884
      },
      {
        "epoch": 1625,
        "reward": 0.445278137922287,
        "val_loss": 0.010018118590648686,
        "train_loss": 0.009151041462945823
      },
      {
        "epoch": 1626,
        "reward": 0.44534197449684143,
        "val_loss": 0.010012942981640143,
        "train_loss": 0.009163090851731025
      },
      {
        "epoch": 1627,
        "reward": 0.4454076886177063,
        "val_loss": 0.010007615899667144,
        "train_loss": 0.009117549060787357
      },
      {
        "epoch": 1628,
        "reward": 0.4453352093696594,
        "val_loss": 0.010013492611636008,
        "train_loss": 0.00918553654068651
      },
      {
        "epoch": 1629,
        "reward": 0.4455171525478363,
        "val_loss": 0.009998752469463008,
        "train_loss": 0.009092224766321193
      },
      {
        "epoch": 1630,
        "reward": 0.4455912709236145,
        "val_loss": 0.009992754851867045,
        "train_loss": 0.00911038513116252
      },
      {
        "epoch": 1631,
        "reward": 0.44563722610473633,
        "val_loss": 0.009989038359240763,
        "train_loss": 0.00907286671246346
      },
      {
        "epoch": 1632,
        "reward": 0.4454527795314789,
        "val_loss": 0.010003962246368505,
        "train_loss": 0.009090865230134044
      },
      {
        "epoch": 1633,
        "reward": 0.4457528293132782,
        "val_loss": 0.009979693651465433,
        "train_loss": 0.0304889711461818
      },
      {
        "epoch": 1634,
        "reward": 0.4457221031188965,
        "val_loss": 0.009982175027419413,
        "train_loss": 0.009056961293726299
      },
      {
        "epoch": 1635,
        "reward": 0.4458182752132416,
        "val_loss": 0.00997440645005554,
        "train_loss": 0.009052553052741202
      },
      {
        "epoch": 1636,
        "reward": 0.4458034634590149,
        "val_loss": 0.009975602983364038,
        "train_loss": 0.009037314194057008
      },
      {
        "epoch": 1637,
        "reward": 0.4459945857524872,
        "val_loss": 0.009960186202079058,
        "train_loss": 0.009044501699183737
      },
      {
        "epoch": 1638,
        "reward": 0.44552889466285706,
        "val_loss": 0.009997804790535676,
        "train_loss": 0.009040630914359308
      },
      {
        "epoch": 1639,
        "reward": 0.4460589587688446,
        "val_loss": 0.00995499680617026,
        "train_loss": 0.009030294918585032
      },
      {
        "epoch": 1640,
        "reward": 0.44615545868873596,
        "val_loss": 0.009947220329195261,
        "train_loss": 0.009149945779846838
      },
      {
        "epoch": 1641,
        "reward": 0.4449106752872467,
        "val_loss": 0.010047976060637407,
        "train_loss": 0.009115138995604446
      },
      {
        "epoch": 1642,
        "reward": 0.4462352395057678,
        "val_loss": 0.00994080030691943,
        "train_loss": 0.009077446384568387
      },
      {
        "epoch": 1643,
        "reward": 0.4460087716579437,
        "val_loss": 0.009959039677466665,
        "train_loss": 0.009011815864141681
      },
      {
        "epoch": 1644,
        "reward": 0.4463634490966797,
        "val_loss": 0.00993049006709563,
        "train_loss": 0.009053483840454226
      },
      {
        "epoch": 1645,
        "reward": 0.44643616676330566,
        "val_loss": 0.009924645934786116,
        "train_loss": 0.009103382874924976
      },
      {
        "epoch": 1646,
        "reward": 0.4464440941810608,
        "val_loss": 0.009924010423544263,
        "train_loss": 0.009013733465018539
      },
      {
        "epoch": 1647,
        "reward": 0.44607359170913696,
        "val_loss": 0.009953815307069038,
        "train_loss": 0.008999081280185587
      },
      {
        "epoch": 1648,
        "reward": 0.44610896706581116,
        "val_loss": 0.009950967006651419,
        "train_loss": 0.009096559159493504
      },
      {
        "epoch": 1649,
        "reward": 0.4461735188961029,
        "val_loss": 0.009945766750856169,
        "train_loss": 0.009049678234777484
      },
      {
        "epoch": 1650,
        "reward": 0.44668933749198914,
        "val_loss": 0.00990433438814112,
        "train_loss": 0.009096199310778711
      },
      {
        "epoch": 1651,
        "reward": 0.446732759475708,
        "val_loss": 0.009900854601125633,
        "train_loss": 0.00899168696500615
      },
      {
        "epoch": 1652,
        "reward": 0.4467916190624237,
        "val_loss": 0.009896141510190708,
        "train_loss": 0.008977710420577541
      },
      {
        "epoch": 1653,
        "reward": 0.44648095965385437,
        "val_loss": 0.009921053041970091,
        "train_loss": 0.008976382048506192
      },
      {
        "epoch": 1654,
        "reward": 0.446876585483551,
        "val_loss": 0.009889343420841865,
        "train_loss": 0.009007791737810923
      },
      {
        "epoch": 1655,
        "reward": 0.4469617009162903,
        "val_loss": 0.009882531527962004,
        "train_loss": 0.009499195658673461
      },
      {
        "epoch": 1656,
        "reward": 0.4470396041870117,
        "val_loss": 0.009876303657490228,
        "train_loss": 0.009323726300723277
      },
      {
        "epoch": 1657,
        "reward": 0.4470512866973877,
        "val_loss": 0.009875368559733033,
        "train_loss": 0.0212848486396699
      },
      {
        "epoch": 1658,
        "reward": 0.4469233453273773,
        "val_loss": 0.009885598606030856,
        "train_loss": 0.009069038268465262
      },
      {
        "epoch": 1659,
        "reward": 0.44689223170280457,
        "val_loss": 0.00988809040947152,
        "train_loss": 0.009081924056562666
      },
      {
        "epoch": 1660,
        "reward": 0.4472225308418274,
        "val_loss": 0.009861696844122239,
        "train_loss": 0.008999455332881413
      },
      {
        "epoch": 1661,
        "reward": 0.4471859037876129,
        "val_loss": 0.009864621903813844,
        "train_loss": 0.008946012326307394
      },
      {
        "epoch": 1662,
        "reward": 0.44734105467796326,
        "val_loss": 0.009852248460187443,
        "train_loss": 0.009527224429453222
      },
      {
        "epoch": 1663,
        "reward": 0.4474126398563385,
        "val_loss": 0.00984654194741909,
        "train_loss": 0.008940561545806794
      },
      {
        "epoch": 1664,
        "reward": 0.4473075866699219,
        "val_loss": 0.009854914271272719,
        "train_loss": 0.009030167125344563
      },
      {
        "epoch": 1665,
        "reward": 0.4475044310092926,
        "val_loss": 0.009839235987913395,
        "train_loss": 0.008990456999387018
      },
      {
        "epoch": 1666,
        "reward": 0.4475512206554413,
        "val_loss": 0.009835510680984174,
        "train_loss": 0.009058422570188459
      },
      {
        "epoch": 1667,
        "reward": 0.44739842414855957,
        "val_loss": 0.009847676381468773,
        "train_loss": 0.009016891726507591
      },
      {
        "epoch": 1668,
        "reward": 0.4473521411418915,
        "val_loss": 0.009851368443508233,
        "train_loss": 0.00931871202863896
      },
      {
        "epoch": 1669,
        "reward": 0.4471353590488434,
        "val_loss": 0.009868657000229828,
        "train_loss": 0.009078870446851047
      },
      {
        "epoch": 1670,
        "reward": 0.44776421785354614,
        "val_loss": 0.009818580317577081,
        "train_loss": 0.00891468401180016
      },
      {
        "epoch": 1671,
        "reward": 0.4472883641719818,
        "val_loss": 0.009856445415477668,
        "train_loss": 0.009481177933943959
      },
      {
        "epoch": 1672,
        "reward": 0.44781121611595154,
        "val_loss": 0.009814849788589137,
        "train_loss": 0.008892109766127131
      },
      {
        "epoch": 1673,
        "reward": 0.4477505385875702,
        "val_loss": 0.009819669183343649,
        "train_loss": 0.008895264122796877
      },
      {
        "epoch": 1674,
        "reward": 0.4479341506958008,
        "val_loss": 0.00980509618031127,
        "train_loss": 0.010747451868015699
      },
      {
        "epoch": 1675,
        "reward": 0.4480133056640625,
        "val_loss": 0.009798819265727485,
        "train_loss": 0.00889003602959257
      },
      {
        "epoch": 1676,
        "reward": 0.44794464111328125,
        "val_loss": 0.009804264974913426,
        "train_loss": 0.008875730098592473
      },
      {
        "epoch": 1677,
        "reward": 0.4481526017189026,
        "val_loss": 0.009787787733200406,
        "train_loss": 0.009104655030219315
      },
      {
        "epoch": 1678,
        "reward": 0.448228657245636,
        "val_loss": 0.009781773518105703,
        "train_loss": 0.008938363296552919
      },
      {
        "epoch": 1679,
        "reward": 0.44828057289123535,
        "val_loss": 0.009777665088352348,
        "train_loss": 0.013220415414812474
      },
      {
        "epoch": 1680,
        "reward": 0.44748398661613464,
        "val_loss": 0.009840865153819323,
        "train_loss": 0.008889943685901996
      },
      {
        "epoch": 1681,
        "reward": 0.4481676518917084,
        "val_loss": 0.009786600463225372,
        "train_loss": 0.009117423001533518
      },
      {
        "epoch": 1682,
        "reward": 0.44838887453079224,
        "val_loss": 0.009769106699552919,
        "train_loss": 0.00890509687955133
      },
      {
        "epoch": 1683,
        "reward": 0.44848471879959106,
        "val_loss": 0.009761540036249374,
        "train_loss": 0.008879895018673358
      },
      {
        "epoch": 1684,
        "reward": 0.4485186040401459,
        "val_loss": 0.00975886286635484,
        "train_loss": 0.008851837326102004
      },
      {
        "epoch": 1685,
        "reward": 0.4485560953617096,
        "val_loss": 0.009755906066857278,
        "train_loss": 0.008843233228057775
      },
      {
        "epoch": 1686,
        "reward": 0.44859129190444946,
        "val_loss": 0.00975313047612352,
        "train_loss": 0.009361151314806193
      },
      {
        "epoch": 1687,
        "reward": 0.44843634963035583,
        "val_loss": 0.009765355864406697,
        "train_loss": 0.008853198386412067
      },
      {
        "epoch": 1688,
        "reward": 0.44870540499687195,
        "val_loss": 0.009744136993374144,
        "train_loss": 0.009293745195743842
      },
      {
        "epoch": 1689,
        "reward": 0.44879069924354553,
        "val_loss": 0.009737420294966017,
        "train_loss": 0.008878803997784136
      },
      {
        "epoch": 1690,
        "reward": 0.4488472640514374,
        "val_loss": 0.00973297020287386,
        "train_loss": 0.009114436115711354
      },
      {
        "epoch": 1691,
        "reward": 0.44876980781555176,
        "val_loss": 0.009739061435019332,
        "train_loss": 0.008832844657752923
      },
      {
        "epoch": 1692,
        "reward": 0.44895821809768677,
        "val_loss": 0.009724242928703981,
        "train_loss": 0.008828495931223958
      },
      {
        "epoch": 1693,
        "reward": 0.4477841854095459,
        "val_loss": 0.00981699479078608,
        "train_loss": 0.009342348870212356
      },
      {
        "epoch": 1694,
        "reward": 0.44834837317466736,
        "val_loss": 0.009772304179412978,
        "train_loss": 0.00891833426766635
      },
      {
        "epoch": 1695,
        "reward": 0.44908174872398376,
        "val_loss": 0.00971453234420291,
        "train_loss": 0.008814779156147359
      },
      {
        "epoch": 1696,
        "reward": 0.44915032386779785,
        "val_loss": 0.009709150097998125,
        "train_loss": 0.008873693421124838
      },
      {
        "epoch": 1697,
        "reward": 0.44921016693115234,
        "val_loss": 0.009704453122269894,
        "train_loss": 0.008806668708880002
      },
      {
        "epoch": 1698,
        "reward": 0.4491715431213379,
        "val_loss": 0.00970748148392886,
        "train_loss": 0.008880676021083044
      },
      {
        "epoch": 1699,
        "reward": 0.4493074119091034,
        "val_loss": 0.009696828600551401,
        "train_loss": 0.008813493225506345
      },
      {
        "epoch": 1700,
        "reward": 0.4493752419948578,
        "val_loss": 0.009691511746495962,
        "train_loss": 0.008792249643682646
      },
      {
        "epoch": 1701,
        "reward": 0.4492168128490448,
        "val_loss": 0.009703936446125485,
        "train_loss": 0.008794049839847363
      },
      {
        "epoch": 1702,
        "reward": 0.4493415355682373,
        "val_loss": 0.009694154648708977,
        "train_loss": 0.008797284480001858
      },
      {
        "epoch": 1703,
        "reward": 0.44943419098854065,
        "val_loss": 0.009686898706214768,
        "train_loss": 0.008790233230683953
      },
      {
        "epoch": 1704,
        "reward": 0.44932422041893005,
        "val_loss": 0.009695510945415922,
        "train_loss": 0.009089940478308843
      },
      {
        "epoch": 1705,
        "reward": 0.4488028585910797,
        "val_loss": 0.009736462546113347,
        "train_loss": 0.0088990649763638
      },
      {
        "epoch": 1706,
        "reward": 0.44967132806777954,
        "val_loss": 0.009668350252988083,
        "train_loss": 0.008929363819054114
      },
      {
        "epoch": 1707,
        "reward": 0.44967323541641235,
        "val_loss": 0.009668199952492225,
        "train_loss": 0.00910198599852335
      },
      {
        "epoch": 1708,
        "reward": 0.4497002065181732,
        "val_loss": 0.009666090132668614,
        "train_loss": 0.008762710078232115
      },
      {
        "epoch": 1709,
        "reward": 0.4497568607330322,
        "val_loss": 0.009661667148715683,
        "train_loss": 0.008749105431818931
      },
      {
        "epoch": 1710,
        "reward": 0.4498186707496643,
        "val_loss": 0.009656843945517071,
        "train_loss": 0.008763289122585914
      },
      {
        "epoch": 1711,
        "reward": 0.44975996017456055,
        "val_loss": 0.00966142670118383,
        "train_loss": 0.008953793860900287
      },
      {
        "epoch": 1712,
        "reward": 0.4476657509803772,
        "val_loss": 0.009826404907341515,
        "train_loss": 0.008751739954627387
      },
      {
        "epoch": 1713,
        "reward": 0.4496590793132782,
        "val_loss": 0.00966930657991075,
        "train_loss": 0.00883385854271742
      },
      {
        "epoch": 1714,
        "reward": 0.45007893443107605,
        "val_loss": 0.009636554958498371,
        "train_loss": 0.008794922763627255
      },
      {
        "epoch": 1715,
        "reward": 0.45012959837913513,
        "val_loss": 0.009632609418726392,
        "train_loss": 0.009093182998745201
      },
      {
        "epoch": 1716,
        "reward": 0.45017752051353455,
        "val_loss": 0.009628879771168743,
        "train_loss": 0.008723715340553238
      },
      {
        "epoch": 1717,
        "reward": 0.4501381516456604,
        "val_loss": 0.009631943523085542,
        "train_loss": 0.008841220343198914
      },
      {
        "epoch": 1718,
        "reward": 0.4502556324005127,
        "val_loss": 0.00962280428835324,
        "train_loss": 0.008995506505016237
      },
      {
        "epoch": 1719,
        "reward": 0.4503374993801117,
        "val_loss": 0.009616440827293056,
        "train_loss": 0.008760668917182976
      },
      {
        "epoch": 1720,
        "reward": 0.45030853152275085,
        "val_loss": 0.009618693862908654,
        "train_loss": 0.009238380911903312
      },
      {
        "epoch": 1721,
        "reward": 0.45044705271720886,
        "val_loss": 0.009607933960588915,
        "train_loss": 0.008715722215408906
      },
      {
        "epoch": 1722,
        "reward": 0.4504466652870178,
        "val_loss": 0.009607967604616923,
        "train_loss": 0.008710940247729363
      },
      {
        "epoch": 1723,
        "reward": 0.4504053294658661,
        "val_loss": 0.00961117512945618,
        "train_loss": 0.008701105211282712
      },
      {
        "epoch": 1724,
        "reward": 0.45057550072669983,
        "val_loss": 0.009597973332607321,
        "train_loss": 0.008706088040176278
      },
      {
        "epoch": 1725,
        "reward": 0.45041823387145996,
        "val_loss": 0.009610173026365893,
        "train_loss": 0.00880978771377928
      },
      {
        "epoch": 1726,
        "reward": 0.45067259669303894,
        "val_loss": 0.009590442367230676,
        "train_loss": 0.008724867108797368
      },
      {
        "epoch": 1727,
        "reward": 0.450542688369751,
        "val_loss": 0.009600510812431042,
        "train_loss": 0.008843017334584147
      },
      {
        "epoch": 1728,
        "reward": 0.45070895552635193,
        "val_loss": 0.009587623312004976,
        "train_loss": 0.030454758966628175
      },
      {
        "epoch": 1729,
        "reward": 0.4504995346069336,
        "val_loss": 0.009603858160387193,
        "train_loss": 0.008703114816223835
      },
      {
        "epoch": 1730,
        "reward": 0.4507692754268646,
        "val_loss": 0.009582952513093395,
        "train_loss": 0.008683269815789502
      },
      {
        "epoch": 1731,
        "reward": 0.45087751746177673,
        "val_loss": 0.009574578376486897,
        "train_loss": 0.008693082421114714
      },
      {
        "epoch": 1732,
        "reward": 0.4509882926940918,
        "val_loss": 0.009566014699105705,
        "train_loss": 0.008673628032039023
      },
      {
        "epoch": 1733,
        "reward": 0.45071473717689514,
        "val_loss": 0.00958717635200758,
        "train_loss": 0.008773751655378593
      },
      {
        "epoch": 1734,
        "reward": 0.4507875144481659,
        "val_loss": 0.009581544669345021,
        "train_loss": 0.008805487457161339
      },
      {
        "epoch": 1735,
        "reward": 0.45103365182876587,
        "val_loss": 0.009562510281934269,
        "train_loss": 0.00903389466783175
      },
      {
        "epoch": 1736,
        "reward": 0.4508705139160156,
        "val_loss": 0.009575121936255268,
        "train_loss": 0.008684982141578356
      },
      {
        "epoch": 1737,
        "reward": 0.45111092925071716,
        "val_loss": 0.009556543963429118,
        "train_loss": 0.00866503856374178
      },
      {
        "epoch": 1738,
        "reward": 0.45125818252563477,
        "val_loss": 0.009545185137540102,
        "train_loss": 0.008685871694559375
      },
      {
        "epoch": 1739,
        "reward": 0.4513247013092041,
        "val_loss": 0.009540058190136083,
        "train_loss": 0.0089425877488863
      },
      {
        "epoch": 1740,
        "reward": 0.4513905942440033,
        "val_loss": 0.00953498249041981,
        "train_loss": 0.008641976433024796
      },
      {
        "epoch": 1741,
        "reward": 0.4513114392757416,
        "val_loss": 0.009541080366554005,
        "train_loss": 0.008753697083403286
      },
      {
        "epoch": 1742,
        "reward": 0.45139575004577637,
        "val_loss": 0.009534587135671504,
        "train_loss": 0.008913164179270657
      },
      {
        "epoch": 1743,
        "reward": 0.4514077305793762,
        "val_loss": 0.009533665350837899,
        "train_loss": 0.009449371696413996
      },
      {
        "epoch": 1744,
        "reward": 0.4515763819217682,
        "val_loss": 0.009520687395706773,
        "train_loss": 0.009157919392097168
      },
      {
        "epoch": 1745,
        "reward": 0.45151185989379883,
        "val_loss": 0.00952565113714497,
        "train_loss": 0.008659028309361579
      },
      {
        "epoch": 1746,
        "reward": 0.4517011344432831,
        "val_loss": 0.009511103379606669,
        "train_loss": 0.009056227304077206
      },
      {
        "epoch": 1747,
        "reward": 0.45143815875053406,
        "val_loss": 0.00953132304130122,
        "train_loss": 0.00862554705292076
      },
      {
        "epoch": 1748,
        "reward": 0.4516933560371399,
        "val_loss": 0.009511700199384774,
        "train_loss": 0.0086416843920373
      },
      {
        "epoch": 1749,
        "reward": 0.45166054368019104,
        "val_loss": 0.009514217963442206,
        "train_loss": 0.008646381715572296
      },
      {
        "epoch": 1750,
        "reward": 0.4517035484313965,
        "val_loss": 0.009510913813885833,
        "train_loss": 0.008605487138136315
      },
      {
        "epoch": 1751,
        "reward": 0.45141950249671936,
        "val_loss": 0.00953275618043595,
        "train_loss": 0.00862750997587752
      },
      {
        "epoch": 1752,
        "reward": 0.45189300179481506,
        "val_loss": 0.009496377481679832,
        "train_loss": 0.008723146273181416
      },
      {
        "epoch": 1753,
        "reward": 0.452009916305542,
        "val_loss": 0.00948741365989138,
        "train_loss": 0.008605283920132933
      },
      {
        "epoch": 1754,
        "reward": 0.45194026827812195,
        "val_loss": 0.009492751027989601,
        "train_loss": 0.008675571293749202
      },
      {
        "epoch": 1755,
        "reward": 0.452101469039917,
        "val_loss": 0.009480405815078743,
        "train_loss": 0.00894221895857929
      },
      {
        "epoch": 1756,
        "reward": 0.4513213336467743,
        "val_loss": 0.009540319026980017,
        "train_loss": 0.008582266863063874
      },
      {
        "epoch": 1757,
        "reward": 0.45137354731559753,
        "val_loss": 0.009536294499412179,
        "train_loss": 0.008659348290306158
      },
      {
        "epoch": 1758,
        "reward": 0.45222386717796326,
        "val_loss": 0.009471041549529349,
        "train_loss": 0.008586909931462007
      },
      {
        "epoch": 1759,
        "reward": 0.4523216187953949,
        "val_loss": 0.00946356771912958,
        "train_loss": 0.008648091313751558
      },
      {
        "epoch": 1760,
        "reward": 0.45226049423217773,
        "val_loss": 0.009468239964917302,
        "train_loss": 0.008677422539151918
      },
      {
        "epoch": 1761,
        "reward": 0.45230230689048767,
        "val_loss": 0.009465044331071632,
        "train_loss": 0.008629918711868903
      },
      {
        "epoch": 1762,
        "reward": 0.45243778824806213,
        "val_loss": 0.009454696946444787,
        "train_loss": 0.008562072553803982
      },
      {
        "epoch": 1763,
        "reward": 0.452421635389328,
        "val_loss": 0.009455933094224227,
        "train_loss": 0.008577635311457225
      },
      {
        "epoch": 1764,
        "reward": 0.45254063606262207,
        "val_loss": 0.009446848790893065,
        "train_loss": 0.008563568644079238
      },
      {
        "epoch": 1765,
        "reward": 0.45217427611351013,
        "val_loss": 0.009474832581223122,
        "train_loss": 0.008577646006485268
      },
      {
        "epoch": 1766,
        "reward": 0.451993852853775,
        "val_loss": 0.009488646306895785,
        "train_loss": 0.008897829639653746
      },
      {
        "epoch": 1767,
        "reward": 0.45267271995544434,
        "val_loss": 0.00943678555943604,
        "train_loss": 0.00856360188216653
      },
      {
        "epoch": 1768,
        "reward": 0.45271697640419006,
        "val_loss": 0.00943341024685651,
        "train_loss": 0.008626431880447153
      },
      {
        "epoch": 1769,
        "reward": 0.45236244797706604,
        "val_loss": 0.009460450100180293,
        "train_loss": 0.008541769167305365
      },
      {
        "epoch": 1770,
        "reward": 0.4528793394565582,
        "val_loss": 0.009421058456479971,
        "train_loss": 0.008543477514159839
      },
      {
        "epoch": 1771,
        "reward": 0.452593058347702,
        "val_loss": 0.009442853508517146,
        "train_loss": 0.008586860190217312
      },
      {
        "epoch": 1772,
        "reward": 0.45289555191993713,
        "val_loss": 0.009419827189828669,
        "train_loss": 0.008536418667063117
      },
      {
        "epoch": 1773,
        "reward": 0.4525878429412842,
        "val_loss": 0.009443252347409725,
        "train_loss": 0.008556260113646904
      },
      {
        "epoch": 1774,
        "reward": 0.4529591202735901,
        "val_loss": 0.009414991264098458,
        "train_loss": 0.008528419597636318
      },
      {
        "epoch": 1775,
        "reward": 0.4527932107448578,
        "val_loss": 0.009427610136169409,
        "train_loss": 0.009023213978462782
      },
      {
        "epoch": 1776,
        "reward": 0.4529399871826172,
        "val_loss": 0.00941644560745252,
        "train_loss": 0.008529274165994138
      },
      {
        "epoch": 1777,
        "reward": 0.4529061019420624,
        "val_loss": 0.00941902504668438,
        "train_loss": 0.008520762592245145
      },
      {
        "epoch": 1778,
        "reward": 0.4532017707824707,
        "val_loss": 0.009396574909000524,
        "train_loss": 0.008576987879888084
      },
      {
        "epoch": 1779,
        "reward": 0.45309099555015564,
        "val_loss": 0.009404978581837245,
        "train_loss": 0.008513233718986157
      },
      {
        "epoch": 1780,
        "reward": 0.45332810282707214,
        "val_loss": 0.009386997811296689,
        "train_loss": 0.008856370776461868
      },
      {
        "epoch": 1781,
        "reward": 0.4532735347747803,
        "val_loss": 0.009391130862890609,
        "train_loss": 0.0085179658036885
      },
      {
        "epoch": 1782,
        "reward": 0.4534222185611725,
        "val_loss": 0.009379869576410524,
        "train_loss": 0.008917407795357017
      },
      {
        "epoch": 1783,
        "reward": 0.45351526141166687,
        "val_loss": 0.009372829193515437,
        "train_loss": 0.008975311500342706
      },
      {
        "epoch": 1784,
        "reward": 0.4535408020019531,
        "val_loss": 0.009370896449711705,
        "train_loss": 0.008491688647191827
      },
      {
        "epoch": 1785,
        "reward": 0.45357105135917664,
        "val_loss": 0.00936860979501424,
        "train_loss": 0.008484908173928628
      },
      {
        "epoch": 1786,
        "reward": 0.45354515314102173,
        "val_loss": 0.009370567085820116,
        "train_loss": 0.008479554448119696
      },
      {
        "epoch": 1787,
        "reward": 0.45339059829711914,
        "val_loss": 0.009382261944535588,
        "train_loss": 0.008574178267735988
      },
      {
        "epoch": 1788,
        "reward": 0.45363640785217285,
        "val_loss": 0.009363670226386083,
        "train_loss": 0.008519153748728478
      },
      {
        "epoch": 1789,
        "reward": 0.45373234152793884,
        "val_loss": 0.009356425967000957,
        "train_loss": 0.00847641330046127
      },
      {
        "epoch": 1790,
        "reward": 0.45382052659988403,
        "val_loss": 0.009349770278536848,
        "train_loss": 0.008774118954673983
      },
      {
        "epoch": 1791,
        "reward": 0.45362257957458496,
        "val_loss": 0.009364716558983284,
        "train_loss": 0.008533644194428164
      },
      {
        "epoch": 1792,
        "reward": 0.45301347970962524,
        "val_loss": 0.009410864690185658,
        "train_loss": 0.008526884879057225
      },
      {
        "epoch": 1793,
        "reward": 0.45398351550102234,
        "val_loss": 0.009337483273286904,
        "train_loss": 0.008472763458120024
      },
      {
        "epoch": 1794,
        "reward": 0.4539249539375305,
        "val_loss": 0.009341895929537714,
        "train_loss": 0.008653058894336797
      },
      {
        "epoch": 1795,
        "reward": 0.4540533721446991,
        "val_loss": 0.009332222032493778,
        "train_loss": 0.008461414318214967
      },
      {
        "epoch": 1796,
        "reward": 0.45368853211402893,
        "val_loss": 0.009359733184932597,
        "train_loss": 0.008444211313994506
      },
      {
        "epoch": 1797,
        "reward": 0.4541381895542145,
        "val_loss": 0.009325837716460228,
        "train_loss": 0.008457363397960412
      },
      {
        "epoch": 1798,
        "reward": 0.45413270592689514,
        "val_loss": 0.009326249568922711,
        "train_loss": 0.008450042319544502
      },
      {
        "epoch": 1799,
        "reward": 0.4541572630405426,
        "val_loss": 0.009324402066080697,
        "train_loss": 0.008739249019597013
      },
      {
        "epoch": 1800,
        "reward": 0.45396557450294495,
        "val_loss": 0.009338833541343254,
        "train_loss": 0.008461015228441773
      },
      {
        "epoch": 1801,
        "reward": 0.45347142219543457,
        "val_loss": 0.009376147179864347,
        "train_loss": 0.00890442606760189
      },
      {
        "epoch": 1802,
        "reward": 0.4544135630130768,
        "val_loss": 0.009305143022044961,
        "train_loss": 0.00845788370273882
      },
      {
        "epoch": 1803,
        "reward": 0.45445942878723145,
        "val_loss": 0.009301701086639826,
        "train_loss": 0.008668342161959467
      },
      {
        "epoch": 1804,
        "reward": 0.45448556542396545,
        "val_loss": 0.009299737284891307,
        "train_loss": 0.008545631068185545
      },
      {
        "epoch": 1805,
        "reward": 0.4544472396373749,
        "val_loss": 0.009302613998962832,
        "train_loss": 0.008435150236786844
      },
      {
        "epoch": 1806,
        "reward": 0.454622358083725,
        "val_loss": 0.009289482550229877,
        "train_loss": 0.008420044058171837
      },
      {
        "epoch": 1807,
        "reward": 0.4543265998363495,
        "val_loss": 0.009311674245899277,
        "train_loss": 0.008416281361300766
      },
      {
        "epoch": 1808,
        "reward": 0.4546681344509125,
        "val_loss": 0.009286052929902715,
        "train_loss": 0.008413465613367284
      },
      {
        "epoch": 1809,
        "reward": 0.45459315180778503,
        "val_loss": 0.009291671657203031,
        "train_loss": 0.008403446135651813
      },
      {
        "epoch": 1810,
        "reward": 0.4546699523925781,
        "val_loss": 0.009285917580460332,
        "train_loss": 0.008408417585787201
      },
      {
        "epoch": 1811,
        "reward": 0.45480218529701233,
        "val_loss": 0.009276016008308423,
        "train_loss": 0.00841550344845333
      },
      {
        "epoch": 1812,
        "reward": 0.454738587141037,
        "val_loss": 0.009280780380192612,
        "train_loss": 0.008394828271845584
      },
      {
        "epoch": 1813,
        "reward": 0.4549083709716797,
        "val_loss": 0.009268073032477073,
        "train_loss": 0.00840403516457837
      },
      {
        "epoch": 1814,
        "reward": 0.4549529254436493,
        "val_loss": 0.009264749474823475,
        "train_loss": 0.00838473611881614
      },
      {
        "epoch": 1815,
        "reward": 0.45490318536758423,
        "val_loss": 0.009268462666243846,
        "train_loss": 0.008697621587019127
      },
      {
        "epoch": 1816,
        "reward": 0.4550633430480957,
        "val_loss": 0.009256500077234315,
        "train_loss": 0.008433175376222398
      },
      {
        "epoch": 1817,
        "reward": 0.4546106457710266,
        "val_loss": 0.009290361161609846,
        "train_loss": 0.008446887842952631
      },
      {
        "epoch": 1818,
        "reward": 0.4549599587917328,
        "val_loss": 0.00926421650884939,
        "train_loss": 0.00851139423992628
      },
      {
        "epoch": 1819,
        "reward": 0.45449313521385193,
        "val_loss": 0.009299168837190206,
        "train_loss": 0.008444585819513751
      },
      {
        "epoch": 1820,
        "reward": 0.4550345838069916,
        "val_loss": 0.009258644114847161,
        "train_loss": 0.008433055873655785
      },
      {
        "epoch": 1821,
        "reward": 0.4552615284919739,
        "val_loss": 0.009241716661823116,
        "train_loss": 0.008465519936110538
      },
      {
        "epoch": 1822,
        "reward": 0.4552951753139496,
        "val_loss": 0.00923920890948336,
        "train_loss": 0.00838496302961945
      },
      {
        "epoch": 1823,
        "reward": 0.45532098412513733,
        "val_loss": 0.00923728895473427,
        "train_loss": 0.008720316059994869
      },
      {
        "epoch": 1824,
        "reward": 0.45537933707237244,
        "val_loss": 0.009232938988134265,
        "train_loss": 0.00836718719466052
      },
      {
        "epoch": 1825,
        "reward": 0.45549020171165466,
        "val_loss": 0.009224688368184226,
        "train_loss": 0.008352050173506051
      },
      {
        "epoch": 1826,
        "reward": 0.45554476976394653,
        "val_loss": 0.009220631851349026,
        "train_loss": 0.00835646222001812
      },
      {
        "epoch": 1827,
        "reward": 0.4555858075618744,
        "val_loss": 0.00921757859344195,
        "train_loss": 0.00838795652648864
      },
      {
        "epoch": 1828,
        "reward": 0.45560184121131897,
        "val_loss": 0.009216388063837908,
        "train_loss": 0.008424607598079512
      },
      {
        "epoch": 1829,
        "reward": 0.4556679427623749,
        "val_loss": 0.009211478763193424,
        "train_loss": 0.008349143435155453
      },
      {
        "epoch": 1830,
        "reward": 0.4556914269924164,
        "val_loss": 0.009209730279898005,
        "train_loss": 0.008434173145080702
      },
      {
        "epoch": 1831,
        "reward": 0.4555773437023163,
        "val_loss": 0.00921821060390877,
        "train_loss": 0.008361830591341528
      },
      {
        "epoch": 1832,
        "reward": 0.4557744562625885,
        "val_loss": 0.009203571077835346,
        "train_loss": 0.008336708326728863
      },
      {
        "epoch": 1833,
        "reward": 0.4558216631412506,
        "val_loss": 0.009200066436148648,
        "train_loss": 0.00882649577061574
      },
      {
        "epoch": 1834,
        "reward": 0.4559240937232971,
        "val_loss": 0.00919247345466699,
        "train_loss": 0.008342755101414067
      },
      {
        "epoch": 1835,
        "reward": 0.45590338110923767,
        "val_loss": 0.009194008482154459,
        "train_loss": 0.008403806100921849
      },
      {
        "epoch": 1836,
        "reward": 0.4560023844242096,
        "val_loss": 0.00918667095746579,
        "train_loss": 0.008862909328085013
      },
      {
        "epoch": 1837,
        "reward": 0.4558788239955902,
        "val_loss": 0.009195829600295318,
        "train_loss": 0.008315429184361935
      },
      {
        "epoch": 1838,
        "reward": 0.45612087845802307,
        "val_loss": 0.009177900601311453,
        "train_loss": 0.008314225944139672
      },
      {
        "epoch": 1839,
        "reward": 0.45575934648513794,
        "val_loss": 0.009204692473368985,
        "train_loss": 0.00832903057632323
      },
      {
        "epoch": 1840,
        "reward": 0.4544273316860199,
        "val_loss": 0.009304107274926667,
        "train_loss": 0.008345748459060606
      },
      {
        "epoch": 1841,
        "reward": 0.45622044801712036,
        "val_loss": 0.009170539186535669,
        "train_loss": 0.008912581157906411
      },
      {
        "epoch": 1842,
        "reward": 0.4562808573246002,
        "val_loss": 0.009166072247483368,
        "train_loss": 0.00831848261385368
      },
      {
        "epoch": 1843,
        "reward": 0.45632821321487427,
        "val_loss": 0.009162570682487317,
        "train_loss": 0.008340869672023334
      },
      {
        "epoch": 1844,
        "reward": 0.45639878511428833,
        "val_loss": 0.009157361179989363,
        "train_loss": 0.00829734560696894
      },
      {
        "epoch": 1845,
        "reward": 0.45644474029541016,
        "val_loss": 0.009153969269911093,
        "train_loss": 0.008285744982668593
      },
      {
        "epoch": 1846,
        "reward": 0.4564850926399231,
        "val_loss": 0.009150991540601743,
        "train_loss": 0.008318117235411102
      },
      {
        "epoch": 1847,
        "reward": 0.4565289616584778,
        "val_loss": 0.009147757747476655,
        "train_loss": 0.008294345751752329
      },
      {
        "epoch": 1848,
        "reward": 0.456428587436676,
        "val_loss": 0.00915516443118187,
        "train_loss": 0.008349122658658486
      },
      {
        "epoch": 1849,
        "reward": 0.4565970003604889,
        "val_loss": 0.009142741103590066,
        "train_loss": 0.008732017868449194
      },
      {
        "epoch": 1850,
        "reward": 0.45667076110839844,
        "val_loss": 0.009137306462175079,
        "train_loss": 0.008278410599342142
      },
      {
        "epoch": 1851,
        "reward": 0.45670127868652344,
        "val_loss": 0.009135057010488319,
        "train_loss": 0.008328667985132108
      },
      {
        "epoch": 1852,
        "reward": 0.4566539227962494,
        "val_loss": 0.009138543724215456,
        "train_loss": 0.008307979325763881
      },
      {
        "epoch": 1853,
        "reward": 0.4567260444164276,
        "val_loss": 0.00913323778825413,
        "train_loss": 0.00844782301171038
      },
      {
        "epoch": 1854,
        "reward": 0.45676061511039734,
        "val_loss": 0.009130692608388407,
        "train_loss": 0.008260571448527817
      },
      {
        "epoch": 1855,
        "reward": 0.45687952637672424,
        "val_loss": 0.009121946192213468,
        "train_loss": 0.008294853614643216
      },
      {
        "epoch": 1856,
        "reward": 0.4568781554698944,
        "val_loss": 0.0091220464091748,
        "train_loss": 0.00826984647686074
      },
      {
        "epoch": 1857,
        "reward": 0.4569462835788727,
        "val_loss": 0.009117040242667176,
        "train_loss": 0.008334664130905787
      },
      {
        "epoch": 1858,
        "reward": 0.45665937662124634,
        "val_loss": 0.009138142157878195,
        "train_loss": 0.008406924822618468
      },
      {
        "epoch": 1859,
        "reward": 0.45694732666015625,
        "val_loss": 0.00911695955021839,
        "train_loss": 0.008313132906690814
      },
      {
        "epoch": 1860,
        "reward": 0.45707520842552185,
        "val_loss": 0.009107569631721293,
        "train_loss": 0.008257432244765649
      },
      {
        "epoch": 1861,
        "reward": 0.4569977819919586,
        "val_loss": 0.009113250807526388,
        "train_loss": 0.008234945229000564
      },
      {
        "epoch": 1862,
        "reward": 0.4571046531200409,
        "val_loss": 0.009105410784416432,
        "train_loss": 0.008236674335596316
      },
      {
        "epoch": 1863,
        "reward": 0.45718786120414734,
        "val_loss": 0.009099303744733334,
        "train_loss": 0.00824258864447704
      },
      {
        "epoch": 1864,
        "reward": 0.4560016691684723,
        "val_loss": 0.009186726612305003,
        "train_loss": 0.00825354586926061
      },
      {
        "epoch": 1865,
        "reward": 0.45722857117652893,
        "val_loss": 0.009096317924559116,
        "train_loss": 0.008375907585454674
      },
      {
        "epoch": 1866,
        "reward": 0.4573417603969574,
        "val_loss": 0.009088023698755674,
        "train_loss": 0.0082321359231383
      },
      {
        "epoch": 1867,
        "reward": 0.45739397406578064,
        "val_loss": 0.009084199289126056,
        "train_loss": 0.008757317076043155
      },
      {
        "epoch": 1868,
        "reward": 0.4574061930179596,
        "val_loss": 0.00908330739808402,
        "train_loss": 0.008260195181579687
      },
      {
        "epoch": 1869,
        "reward": 0.45709165930747986,
        "val_loss": 0.009106360550504178,
        "train_loss": 0.00830533905312992
      },
      {
        "epoch": 1870,
        "reward": 0.457409143447876,
        "val_loss": 0.009083090607808637,
        "train_loss": 0.008316277642734349
      },
      {
        "epoch": 1871,
        "reward": 0.457531213760376,
        "val_loss": 0.009074161702301353,
        "train_loss": 0.00822794846674067
      },
      {
        "epoch": 1872,
        "reward": 0.45762211084365845,
        "val_loss": 0.009067519276868552,
        "train_loss": 0.008255704946350306
      },
      {
        "epoch": 1873,
        "reward": 0.45766764879226685,
        "val_loss": 0.009064192567685885,
        "train_loss": 0.008206491124068495
      },
      {
        "epoch": 1874,
        "reward": 0.45743343234062195,
        "val_loss": 0.009081315432142998,
        "train_loss": 0.008240675750690011
      },
      {
        "epoch": 1875,
        "reward": 0.45770126581192017,
        "val_loss": 0.009061738033778965,
        "train_loss": 0.008251330551082412
      },
      {
        "epoch": 1876,
        "reward": 0.4577043950557709,
        "val_loss": 0.0090615069659959,
        "train_loss": 0.008281776833777817
      },
      {
        "epoch": 1877,
        "reward": 0.4578230381011963,
        "val_loss": 0.009052847744897008,
        "train_loss": 0.008311163038552668
      },
      {
        "epoch": 1878,
        "reward": 0.4578905701637268,
        "val_loss": 0.009047925621936364,
        "train_loss": 0.008189685778094057
      },
      {
        "epoch": 1879,
        "reward": 0.45789265632629395,
        "val_loss": 0.00904777246926512,
        "train_loss": 0.009237803568024762
      },
      {
        "epoch": 1880,
        "reward": 0.4579578936100006,
        "val_loss": 0.009043017136199134,
        "train_loss": 0.008173773642493661
      },
      {
        "epoch": 1881,
        "reward": 0.4573550224304199,
        "val_loss": 0.009087053551671229,
        "train_loss": 0.008265686566189218
      },
      {
        "epoch": 1882,
        "reward": 0.45791441202163696,
        "val_loss": 0.00904618636039751,
        "train_loss": 0.00818314604727605
      },
      {
        "epoch": 1883,
        "reward": 0.45814061164855957,
        "val_loss": 0.009029716685680407,
        "train_loss": 0.008601469789237644
      },
      {
        "epoch": 1884,
        "reward": 0.45789799094200134,
        "val_loss": 0.009047383816713201,
        "train_loss": 0.00816650354248885
      },
      {
        "epoch": 1885,
        "reward": 0.4576053321361542,
        "val_loss": 0.009068742161616683,
        "train_loss": 0.008515218487725807
      },
      {
        "epoch": 1886,
        "reward": 0.45763158798217773,
        "val_loss": 0.009066823537328414,
        "train_loss": 0.008158668983154573
      },
      {
        "epoch": 1887,
        "reward": 0.4575757086277008,
        "val_loss": 0.009070909906378282,
        "train_loss": 0.008233992176918456
      },
      {
        "epoch": 1888,
        "reward": 0.458370178937912,
        "val_loss": 0.009013033754724478,
        "train_loss": 0.00818897115760382
      },
      {
        "epoch": 1889,
        "reward": 0.4582482874393463,
        "val_loss": 0.009021885244042746,
        "train_loss": 0.008155483188637356
      },
      {
        "epoch": 1890,
        "reward": 0.45815959572792053,
        "val_loss": 0.009028331925427275,
        "train_loss": 0.008650647041996798
      },
      {
        "epoch": 1891,
        "reward": 0.4583989679813385,
        "val_loss": 0.009010940998060895,
        "train_loss": 0.008159381449961355
      },
      {
        "epoch": 1892,
        "reward": 0.45818549394607544,
        "val_loss": 0.009026450836764914,
        "train_loss": 0.00932073931191833
      },
      {
        "epoch": 1893,
        "reward": 0.45816418528556824,
        "val_loss": 0.009027999709360301,
        "train_loss": 0.008135776689764148
      },
      {
        "epoch": 1894,
        "reward": 0.4586394727230072,
        "val_loss": 0.00899349691046934,
        "train_loss": 0.00814058113484442
      },
      {
        "epoch": 1895,
        "reward": 0.4577893316745758,
        "val_loss": 0.009055306411547852,
        "train_loss": 0.008151733404352294
      },
      {
        "epoch": 1896,
        "reward": 0.4579407274723053,
        "val_loss": 0.009044267885786082,
        "train_loss": 0.008488394539409246
      },
      {
        "epoch": 1897,
        "reward": 0.4587509334087372,
        "val_loss": 0.008985432122634458,
        "train_loss": 0.009787035573166437
      },
      {
        "epoch": 1898,
        "reward": 0.4585692584514618,
        "val_loss": 0.008998587278516166,
        "train_loss": 0.008663508884358006
      },
      {
        "epoch": 1899,
        "reward": 0.4588993191719055,
        "val_loss": 0.008974698056200785,
        "train_loss": 0.008167985159723492
      },
      {
        "epoch": 1900,
        "reward": 0.4589540958404541,
        "val_loss": 0.008970737307598549,
        "train_loss": 0.008406077166840147
      },
      {
        "epoch": 1901,
        "reward": 0.4586338996887207,
        "val_loss": 0.008993902942165732,
        "train_loss": 0.008137145813424677
      },
      {
        "epoch": 1902,
        "reward": 0.45901361107826233,
        "val_loss": 0.008966437624102193,
        "train_loss": 0.008181949369967557
      },
      {
        "epoch": 1903,
        "reward": 0.4590821862220764,
        "val_loss": 0.008961489715147763,
        "train_loss": 0.008356407495179715
      },
      {
        "epoch": 1904,
        "reward": 0.45909520983695984,
        "val_loss": 0.008960548804939858,
        "train_loss": 0.008137486221340414
      },
      {
        "epoch": 1905,
        "reward": 0.4585127830505371,
        "val_loss": 0.0090026829524764,
        "train_loss": 0.00812169256208178
      },
      {
        "epoch": 1906,
        "reward": 0.4587899148464203,
        "val_loss": 0.00898260497654389,
        "train_loss": 0.008139365362764623
      },
      {
        "epoch": 1907,
        "reward": 0.4592094123363495,
        "val_loss": 0.00895230790566919,
        "train_loss": 0.008328122180850746
      },
      {
        "epoch": 1908,
        "reward": 0.4593055844306946,
        "val_loss": 0.008945380221121013,
        "train_loss": 0.008097063837619945
      },
      {
        "epoch": 1909,
        "reward": 0.4593411386013031,
        "val_loss": 0.0089428178367338,
        "train_loss": 0.008233322564942332
      },
      {
        "epoch": 1910,
        "reward": 0.4593147337436676,
        "val_loss": 0.00894472240802965,
        "train_loss": 0.008085718884943232
      },
      {
        "epoch": 1911,
        "reward": 0.4594271779060364,
        "val_loss": 0.008936624400251145,
        "train_loss": 0.008199963333586661
      },
      {
        "epoch": 1912,
        "reward": 0.45939189195632935,
        "val_loss": 0.008939166636472302,
        "train_loss": 0.008119515774104422
      },
      {
        "epoch": 1913,
        "reward": 0.4594956040382385,
        "val_loss": 0.008931701063245003,
        "train_loss": 0.008234601046961661
      },
      {
        "epoch": 1914,
        "reward": 0.45930036902427673,
        "val_loss": 0.008945755743687707,
        "train_loss": 0.008080850963639162
      },
      {
        "epoch": 1915,
        "reward": 0.4584445655345917,
        "val_loss": 0.009007631268884455,
        "train_loss": 0.008100902583324708
      },
      {
        "epoch": 1916,
        "reward": 0.4595582187175751,
        "val_loss": 0.00892719891687323,
        "train_loss": 0.008097333789359814
      },
      {
        "epoch": 1917,
        "reward": 0.4596521854400635,
        "val_loss": 0.008920445955092353,
        "train_loss": 0.008091500399901773
      },
      {
        "epoch": 1918,
        "reward": 0.45953208208084106,
        "val_loss": 0.008929077427767749,
        "train_loss": 0.008074673061435953
      },
      {
        "epoch": 1919,
        "reward": 0.4596913456916809,
        "val_loss": 0.008917635256823684,
        "train_loss": 0.008065868686641737
      },
      {
        "epoch": 1920,
        "reward": 0.4597393572330475,
        "val_loss": 0.00891418577936877,
        "train_loss": 0.008065766967215145
      },
      {
        "epoch": 1921,
        "reward": 0.45981279015541077,
        "val_loss": 0.008908919058740139,
        "train_loss": 0.008562234924353946
      },
      {
        "epoch": 1922,
        "reward": 0.4597497582435608,
        "val_loss": 0.008913441278439547,
        "train_loss": 0.00805887177333576
      },
      {
        "epoch": 1923,
        "reward": 0.4597863256931305,
        "val_loss": 0.008910816495439835,
        "train_loss": 0.008047291649964232
      },
      {
        "epoch": 1924,
        "reward": 0.4598943889141083,
        "val_loss": 0.008903066053920026,
        "train_loss": 0.008050257744046645
      },
      {
        "epoch": 1925,
        "reward": 0.4600260257720947,
        "val_loss": 0.008893635847406196,
        "train_loss": 0.008046784761902997
      },
      {
        "epoch": 1926,
        "reward": 0.4600003659725189,
        "val_loss": 0.008895473089069128,
        "train_loss": 0.008045855485341655
      },
      {
        "epoch": 1927,
        "reward": 0.4599912166595459,
        "val_loss": 0.008896128440807973,
        "train_loss": 0.008054696360956699
      },
      {
        "epoch": 1928,
        "reward": 0.4600585103034973,
        "val_loss": 0.008891306942262287,
        "train_loss": 0.008126778725104837
      },
      {
        "epoch": 1929,
        "reward": 0.4601535499095917,
        "val_loss": 0.008884508877859585,
        "train_loss": 0.008038911403883294
      },
      {
        "epoch": 1930,
        "reward": 0.46020251512527466,
        "val_loss": 0.008881005982402712,
        "train_loss": 0.008035272390840804
      },
      {
        "epoch": 1931,
        "reward": 0.45966386795043945,
        "val_loss": 0.008919604671453791,
        "train_loss": 0.008424651061292164
      },
      {
        "epoch": 1932,
        "reward": 0.46026942133903503,
        "val_loss": 0.008876224697035338,
        "train_loss": 0.008037126907418304
      },
      {
        "epoch": 1933,
        "reward": 0.46028557419776917,
        "val_loss": 0.008875067994397665,
        "train_loss": 0.011934946801585074
      },
      {
        "epoch": 1934,
        "reward": 0.46041569113731384,
        "val_loss": 0.008865776538316692,
        "train_loss": 0.008023614338386463
      },
      {
        "epoch": 1935,
        "reward": 0.46041855216026306,
        "val_loss": 0.00886557244562677,
        "train_loss": 0.008049012638646392
      },
      {
        "epoch": 1936,
        "reward": 0.46040841937065125,
        "val_loss": 0.008866297871073974,
        "train_loss": 0.008055499513060428
      },
      {
        "epoch": 1937,
        "reward": 0.460527241230011,
        "val_loss": 0.008857820582176958,
        "train_loss": 0.008034685197904205
      },
      {
        "epoch": 1938,
        "reward": 0.460574209690094,
        "val_loss": 0.008854472901605601,
        "train_loss": 0.008024219400725157
      },
      {
        "epoch": 1939,
        "reward": 0.46060076355934143,
        "val_loss": 0.008852578466758132,
        "train_loss": 0.008505492654736511
      },
      {
        "epoch": 1940,
        "reward": 0.46067723631858826,
        "val_loss": 0.008847131634995873,
        "train_loss": 0.008143435953220783
      },
      {
        "epoch": 1941,
        "reward": 0.46066758036613464,
        "val_loss": 0.008847818618440735,
        "train_loss": 0.00800302624786407
      },
      {
        "epoch": 1942,
        "reward": 0.4605748653411865,
        "val_loss": 0.008854425711823362,
        "train_loss": 0.00825855125619385
      },
      {
        "epoch": 1943,
        "reward": 0.4607691466808319,
        "val_loss": 0.008840589493047446,
        "train_loss": 0.008309565793472128
      },
      {
        "epoch": 1944,
        "reward": 0.46083760261535645,
        "val_loss": 0.008835717353836767,
        "train_loss": 0.007992422664616382
      },
      {
        "epoch": 1945,
        "reward": 0.46090418100357056,
        "val_loss": 0.008830982617967362,
        "train_loss": 0.008343484964615736
      },
      {
        "epoch": 1946,
        "reward": 0.46075639128685,
        "val_loss": 0.00884149206935295,
        "train_loss": 0.007997100856860366
      },
      {
        "epoch": 1947,
        "reward": 0.46097469329833984,
        "val_loss": 0.008825971653485405,
        "train_loss": 0.008074289725090448
      },
      {
        "epoch": 1948,
        "reward": 0.4610315263271332,
        "val_loss": 0.008821937912476383,
        "train_loss": 0.007982645958411293
      },
      {
        "epoch": 1949,
        "reward": 0.4608844816684723,
        "val_loss": 0.008832384083819176,
        "train_loss": 0.00801174861128227
      },
      {
        "epoch": 1950,
        "reward": 0.4611169993877411,
        "val_loss": 0.008815868533149893,
        "train_loss": 0.00805485131030974
      },
      {
        "epoch": 1951,
        "reward": 0.461071640253067,
        "val_loss": 0.00881908692619098,
        "train_loss": 0.00808590826524708
      },
      {
        "epoch": 1952,
        "reward": 0.46116915345191956,
        "val_loss": 0.008812169020529836,
        "train_loss": 0.007968539570881079
      },
      {
        "epoch": 1953,
        "reward": 0.46118345856666565,
        "val_loss": 0.008811154693830758,
        "train_loss": 0.008187439064316165
      },
      {
        "epoch": 1954,
        "reward": 0.4612293243408203,
        "val_loss": 0.00880790369618418,
        "train_loss": 0.007959742637327648
      },
      {
        "epoch": 1955,
        "reward": 0.461276113986969,
        "val_loss": 0.008804586574634803,
        "train_loss": 0.007960902461248382
      },
      {
        "epoch": 1956,
        "reward": 0.4606442153453827,
        "val_loss": 0.008849481977189757,
        "train_loss": 0.008006458206532093
      },
      {
        "epoch": 1957,
        "reward": 0.4613223075866699,
        "val_loss": 0.00880131178668567,
        "train_loss": 0.00796545639940842
      },
      {
        "epoch": 1958,
        "reward": 0.4611752927303314,
        "val_loss": 0.008811732670957488,
        "train_loss": 0.007955565865114086
      },
      {
        "epoch": 1959,
        "reward": 0.46142879128456116,
        "val_loss": 0.008793773877966617,
        "train_loss": 0.007956362952917026
      },
      {
        "epoch": 1960,
        "reward": 0.4609528183937073,
        "val_loss": 0.00882752803486905,
        "train_loss": 0.008043546977345474
      },
      {
        "epoch": 1961,
        "reward": 0.46105700731277466,
        "val_loss": 0.008820127321606768,
        "train_loss": 0.007983339813878186
      },
      {
        "epoch": 1962,
        "reward": 0.4613014757633209,
        "val_loss": 0.008802789221850358,
        "train_loss": 0.00793669427954368
      },
      {
        "epoch": 1963,
        "reward": 0.46133407950401306,
        "val_loss": 0.008800480032472737,
        "train_loss": 0.007947926405554777
      },
      {
        "epoch": 1964,
        "reward": 0.4614119529724121,
        "val_loss": 0.00879496632842347,
        "train_loss": 0.00796542903677059
      },
      {
        "epoch": 1965,
        "reward": 0.46165594458580017,
        "val_loss": 0.00877771559836609,
        "train_loss": 0.008046052749985112
      },
      {
        "epoch": 1966,
        "reward": 0.46162328124046326,
        "val_loss": 0.008780020172707736,
        "train_loss": 0.008499595569446683
      },
      {
        "epoch": 1967,
        "reward": 0.46179652214050293,
        "val_loss": 0.008767790551896073,
        "train_loss": 0.01031614281461001
      },
      {
        "epoch": 1968,
        "reward": 0.4618709683418274,
        "val_loss": 0.008762538250136589,
        "train_loss": 0.008047634046166562
      },
      {
        "epoch": 1969,
        "reward": 0.4617989659309387,
        "val_loss": 0.00876761638625924,
        "train_loss": 0.007983213863693751
      },
      {
        "epoch": 1970,
        "reward": 0.4618997275829315,
        "val_loss": 0.008760509962615157,
        "train_loss": 0.007974081211544286
      },
      {
        "epoch": 1971,
        "reward": 0.4619685113430023,
        "val_loss": 0.00875566340982914,
        "train_loss": 0.028131715559328977
      },
      {
        "epoch": 1972,
        "reward": 0.46196219325065613,
        "val_loss": 0.00875611207447946,
        "train_loss": 0.00798378979267839
      },
      {
        "epoch": 1973,
        "reward": 0.4619967043399811,
        "val_loss": 0.008753680091883455,
        "train_loss": 0.008003457332961261
      },
      {
        "epoch": 1974,
        "reward": 0.46205630898475647,
        "val_loss": 0.008749479020480067,
        "train_loss": 0.007990398018871648
      },
      {
        "epoch": 1975,
        "reward": 0.4620590806007385,
        "val_loss": 0.008749285829253495,
        "train_loss": 0.007951952616657274
      },
      {
        "epoch": 1976,
        "reward": 0.4621577858924866,
        "val_loss": 0.008742342885982777,
        "train_loss": 0.007917547629543921
      },
      {
        "epoch": 1977,
        "reward": 0.4622116982936859,
        "val_loss": 0.008738547430506774,
        "train_loss": 0.007938207993552519
      },
      {
        "epoch": 1978,
        "reward": 0.4622330665588379,
        "val_loss": 0.008737046238301056,
        "train_loss": 0.00790373440699673
      },
      {
        "epoch": 1979,
        "reward": 0.4620459973812103,
        "val_loss": 0.008750204529081072,
        "train_loss": 0.00799761082117374
      },
      {
        "epoch": 1980,
        "reward": 0.4623192250728607,
        "val_loss": 0.008730991610458918,
        "train_loss": 0.007892680635520195
      },
      {
        "epoch": 1981,
        "reward": 0.4623356759548187,
        "val_loss": 0.008729834625098323,
        "train_loss": 0.007894792825167175
      },
      {
        "epoch": 1982,
        "reward": 0.4618135094642639,
        "val_loss": 0.008766590817166226,
        "train_loss": 0.00790511367421669
      },
      {
        "epoch": 1983,
        "reward": 0.462445467710495,
        "val_loss": 0.008722128146993262,
        "train_loss": 0.007909837066948127
      },
      {
        "epoch": 1984,
        "reward": 0.4623779356479645,
        "val_loss": 0.008726869277389986,
        "train_loss": 0.007939623995648267
      },
      {
        "epoch": 1985,
        "reward": 0.46223655343055725,
        "val_loss": 0.008736799654018666,
        "train_loss": 0.007962860220756669
      },
      {
        "epoch": 1986,
        "reward": 0.46252885460853577,
        "val_loss": 0.008716276422741689,
        "train_loss": 0.007887817814802335
      },
      {
        "epoch": 1987,
        "reward": 0.4625241458415985,
        "val_loss": 0.008716608206408896,
        "train_loss": 0.007871175481870414
      },
      {
        "epoch": 1988,
        "reward": 0.46213433146476746,
        "val_loss": 0.008743990512032594,
        "train_loss": 0.007865394960425385
      },
      {
        "epoch": 1989,
        "reward": 0.4626343250274658,
        "val_loss": 0.008708883326367609,
        "train_loss": 0.007874608099707704
      },
      {
        "epoch": 1990,
        "reward": 0.462587833404541,
        "val_loss": 0.00871214219036379,
        "train_loss": 0.00791449462905383
      },
      {
        "epoch": 1991,
        "reward": 0.4627852141857147,
        "val_loss": 0.008698318669173335,
        "train_loss": 0.007885406600437888
      },
      {
        "epoch": 1992,
        "reward": 0.4627978801727295,
        "val_loss": 0.008697434261973416,
        "train_loss": 0.007869247685168656
      },
      {
        "epoch": 1993,
        "reward": 0.4627608358860016,
        "val_loss": 0.008700026872767401,
        "train_loss": 0.007862439645438056
      },
      {
        "epoch": 1994,
        "reward": 0.4628921151161194,
        "val_loss": 0.008690845637050058,
        "train_loss": 0.007947201921174733
      },
      {
        "epoch": 1995,
        "reward": 0.46281805634498596,
        "val_loss": 0.008696023399742054,
        "train_loss": 0.007859153477721311
      },
      {
        "epoch": 1996,
        "reward": 0.46279168128967285,
        "val_loss": 0.008697866844678563,
        "train_loss": 0.00788188182363788
      },
      {
        "epoch": 1997,
        "reward": 0.462991327047348,
        "val_loss": 0.008683907525015197,
        "train_loss": 0.007860211469960632
      },
      {
        "epoch": 1998,
        "reward": 0.4625045359134674,
        "val_loss": 0.008717981840683413,
        "train_loss": 0.008010782301425934
      },
      {
        "epoch": 1999,
        "reward": 0.4629538655281067,
        "val_loss": 0.008686530353900577,
        "train_loss": 0.007878029950706359
      }
    ]
  }
}